[
["index.html", "Визуализация и анализ географических данных на языке R Введение Программное обеспечение Установка и подключение пакетов Выполнение программного кода Установка рабочей директории Диагностические функции Получение справки Комментарии Стандарт оформления кода на R Зарезервированные слова Названия переменных Названия специальных символов Ссылка на пособие", " Визуализация и анализ географических данных на языке R Тимофей Самсонов 2020-02-10 Введение Добро пожаловать в курс “Визуализация и анализ географических данных на языке R”! В данном курсе мы освоим азы программирования на языке R, а затем научимся использовать его для решения географических задач. Никаких предварительных знаний и навыков программирования не требуется. Программное обеспечение Для успешного прохождения курса на вашем компьютере должно быть установлено следующее программное обеспечение: Язык R Среда разработки RStudio Выбирайте инсталлятор, соответствующий вашей операционной системе. Обратите внимание на то, что RStudio не будет работать, пока вы не установите базовые библиотеки языка R. Поэтому обе вышеуказанные компоненты ПО обязательны для установки. Установка и подключение пакетов Существует множество дополнительных пакетов R практически на все случаи жизни (вы тоже можете написать свой). Как и дистрибутив R, они доступны через CRAN (Comprehensive R Archive Network). Одним из таких пакетов является, например, пакет readxl, позволяющий читать и записывать файлы в форматах Microsoft Excel. Существует два способа установки пакетов в RStudio. Во-первых, вы можете сделать это в графическом интерфесе, нажав кнопку Install на панели Packages (по умолчанию эта панель расположена в нижней правой четверти окна программы). В появившемся окне введите название пакета и нажмите Install: Установка пакета Во-вторых, вы можете вызвать из консоли команду install.packages(), передав ей в качестве параметра название пакета, заключенное в кавычки: install.packages(&quot;readxl&quot;) Никогда не включайте команду install.packages() в тело скрипта. Это приведет к тому, что каждый раз при запуске программы среда RStudio будет пытаться заново установить пакет, который уже установлен. Запускайте эту функцию только из консоли. Подключение пакета осуществляется с помощью функции library(), при этом название пакета можно в кавычки не заключать: library(readxl) Выполнение программного кода Существует несколько способов выполнения исходного кода: Выполнить одну строку: поставить курсор в любую строку и нажать над редактором кода кнопку Run или сочетание клавиш Ctrl+Enter (Cmd+Enter для OS X). Выполнить несколько строк: выделить необходимые строки и нажать над редактором кода кнопку Run или сочетание клавиш Ctrl+Enter (Cmd+Enter для OS X). Выполнить весь код можно сразу тремя способами: Выделить весь текст и нажать над редактором кода кнопку Run или сочетание клавиш Ctrl+Enter (Cmd+Enter для OS X) Нажать клавиатурное сочетание Ctrl+Alt+Enter (Cmd+Alt+Enter для OS X) Нажать в правом верхнем углу редактора кода кнопку Source Команды Source и Ctrl+Alt+Enter могут не сработать, если у вас не установлена рабочая директория, или если в пути к рабочей директории содержатся кириллические символы (не актуально для Windows 10+ и OS X, которые являются системами, основанными на кодировке Unicode). Существует также ряд дополнительных опций выполнения кода, которые вы можете найти в меню Code &gt; Run Region Выполняя код построчно, делайте это последовательно, начиная с первой строки программы. Одна из самых распространенных ошибок новичков заключается в попытке выполнить некую строку, не выполнив предыдущий код. Нет никаких гарантий, что что-то получится, если открыть файл, поставить курсор в произвольную строку посередине программы и попытаться выполнить ее. Возможно, вам и повезет — если эта строка никак не зависит от предыдущего кода. Однако в реальных программах такие строки составляют лишь небольшую долю от общего объема. Как правило, в них происходит инициализация новых переменных стартовыми значениями. Установка рабочей директории Вы можете открывать и сохранять любые поддерживаемые файлы в R, указывая полный системный путь к файлу. Например, так может выглядеть открытие и сохранение таблицы в формате CSV на компьютере Mac: d = read.csv(&quot;/Volumes/Data/GitHub/r-geo-course/data/oxr_vod.csv&quot;) write.csv(d, &quot;/Volumes/Data/GitHub/r-geo-course/data/oxr_vod_copy.csv&quot;) Однако, если вам требуется открыть или сохранить несколько файлов (и не только данных, но и графиков, карт и т.п.), программа будет выглядеть громоздко. К тому же, прописывать каждый раз полный путь достаточно утомительно и неприятно (даже путем копирования и вставки), а главное — может привести к ошибкам. Чтобы облегчить работу с файлами, в R существует понятие домашней директории. Домашняя директория задается для текущей сессии R с помощью функции setwd(). После установки домашней директории R будет полагать, что все открываемые и сохраняемые файлы должны находиться в ней: setwd(&quot;/Volumes/Data/GitHub/r-geo-course/data&quot;) read.csv(&quot;oxr_vod.csv&quot;) write.csv(d, &quot;oxr_vod_copy.csv&quot;) Как видно, мы добавили дополнительную строчку кода, но сэкономили на длине двух других строк. При увеличении количества обращений к файлам польза домашней директории будет возрастать. При этом вы можете открывать и сохранять файлы в поддиректориях, наддиректориях и соседних директориях, используя синтаксис, стандартный для большинства операционных систем: # сохранить файл в поддиректорию data write.csv(d, &quot;data/oxr_vod_copy.csv&quot;) # сохранить файл в наддиректорию по отношению к текущей директории write.csv(d, &quot;../oxr_vod_copy.csv&quot;) # сохранить файл в директорию data, соседнюю по отношению к текущей директории write.csv(d, &quot;../data/oxr_vod_copy.csv&quot;) Если вы перенесли код и данные с другого компьютера (возможно, вы получили их от своего коллеги или скачали с репозитория данного пособия), необходимо заменить путь, указанный в функции setwd() на путь к каталогу, в который вы положили данные. Рабочая директория и местоположение скрипта могут не совпадать. Вы можете хранить их в разных местах. Однако рекомендуется держать их вместе, что облегчит передачу вашей программы вместе с данными другим пользователям. К сожалению, не существует надежного программного способа сказать среде выполнения R, что в качестве домашей директории следует использовать директорию в которой лежит сам скрипт (что, вообще говоря, было бы крайне удобно). Возможно, в будущем разработчики языка добавят такую полезную функцию. Однако, если для работы с R вы пользуетесь средой RStudio, задача может быть решена путем использования проектов. Подробнее читайте здесь. Диагностические функции В R существует ряд диагностических функций, которые позволяют узнавать информацию об объектах, переменных, а также текущих параметрах среды, оказывающих влияние на результаты выполнения программы. Эти функции полезны, когда необходимо понять, какого типа, размера и содержания данные хранятся в той или иной переменной. Нижеприведенный список функций не являются исчерпывающим, но охватывает наиболее употребильные функции: Функция Назначение class() Класс (тип данных или структура данных) объекта str() Компактное представление внутренней структуры объекта. names() Названия элементов объекта colnames() Названия колонок фрейма данных или матрицы rownames() Названия строк фрейма данных или матрицы mode() Режим хранения объекта. length() Размер (длина) объекта. dim() Измерение объекта. sessionInfo() Информация о текущей сессии R и подключенных пакетах. options() Получение и установка параметров среды. getwd() Текущая рабочая директория Получение справки Любая функция R содержит документированное описание ее параметров и правил использования. Справку можно получить несколькими способами: Найти интересующую вас функцию вручную на вкладке Packages, выбрав нужный пакет Воспользоваться строкой поиска на вкладке Help Ввести знак вопроса и название функции в консоли (будет искать только среди подключенных в настоящий момент пакетов): library(readxl) ?read_xlsx # равносильно вызову функции help(read_xlsx) Справка по функции Ввести двойной знак вопроса и название функции в консоли (будет искать по всем установленным пакетам, независимо от того, подключены ли они в настоящий момент): ??spsample Поиск по функциям Во многих пакетах есть также подробная документация с примерами использования функций в виде руководств и так называемых виньеток (vignettes), которые представляют из себя расширенные руководства (статьи) по использованию пакета. С документацией пакета можно ознакомиться, щелкнув на его названии на вкладке Packages и перейдя по ссылке User guides, package vignettes and other documentation: Документация пакета Комментарии Комментарии — это фрагменты текста программы, начинающиеся с символа #. Комментарии не воспринимаются как исполняемый код и служат для документирования программы. При выполнении программы содержимое комментария в зависимости от настроек среды может выводиться или не выводиться в консоль, однако их содержание никак не влияет на результаты выполнения программы. Всегда пишите комментарии, чтобы по прошествии времени можно было открыть файл и быстро восстановить в памяти логику программы и смысл отдельных операций. Комментарии особенно необходимы, если вашей программой будет пользоваться кто-то другой — без них будет трудно разобраться в программном коде. Действие комментария продолжается от символа # до конца строки. Соответственно, вы можете поставить данный символ в самом начале строки и тогда комментарий будет занимать всю строку. Комментарий также можно расположить справа от исполняемого кода, и тогда он будет занимать только часть строки. Прервать комментарий и написать справа от него исполняемый код нельзя Полнострочные комментарии часто используются для выделения разделов в программе и написания объемных пояснений. Часто в них вводят имитации разделительных линий с помощью символов дефиса (-) или подчеркивания (_), а заголовки набирают прописными буквами. Короткие комментарии справа от фрагментов кода обычно служат пояснением конкретных простых операций. Подобная логика употребления комментариев не является обязательной. Вы можете оформлять их на свое усмотрение. Главное, чтобы они выполняли свою основную функцию — пояснять смысл выполняемых действий. Например: # ОПЕРАЦИИ С ЧИСЛАМИ # --------------------------- # В данном разделе рассматриваются арифметические операции, такие как сложение, вычитание, деление, деление с остатком, взятие остатка и возведение в степень: a = 3 + 2 # Сложение b = 4 ^ 8 # Возведение в степень c = b %% a # Взятие остатка # Деление d = c / a # Умножение e = d * b Однако, усердствовать с комментированием каждой мелочи в программе, разумеется, не стоит. Со временем у вас выработается взвешенный подход к документированию программ и понимание того, какие ее фрагменты требуют пояснения, а какие самоочевидны. Для быстрой вставки комментария, обозначающего новый раздел программы, воспользуйтесь командой меню Code &gt; Insert Section или клавиатурным сочетанием Ctrl+Shift+R (Cmd+Shift+R для OS X) Стандарт оформления кода на R Очень важно сразу же приучить себя грамотно, структурированно и красиво оформлять код на языке R. Это существенно облегчит чтение и понимание ваших программ не только вами, но и другими пользователями и разработчиками. Помимо вышеуказанных рекомендаций по написанию комментариев существует также определенное количество хорошо зарекомендовавших себя и широко используемых практик оформления кода. Эти практики есть в каждом языке программирования и их можно найти в литературе (и в Интернете) в виде негласных сводов правил (style guides) Если вы не хотите быть белой вороной в мире R, вам будет полезно внимательно ознакомиться со стандартом оформления кода на R от компании Google, которая широко использует этот язык в своей работе. Стандарт оформления кода иногда также называют стилем программирования. Мы не будем использовать этот термин, поскольку под стилем программирования традиционно понимают фундаментальный подход (парадигму) к построению программ: процедурный, функциональный, логический, объектно-ориентированный стиль и некоторые другие. К числу негласных правил оформления кода на R можно отнести следующие: Последовательно используйте знак присвоения &lt;- или = на протяжении всей программы. Если вы начали использовать = – применяйте его на протяжении всей программы, не используя &lt;-. Традиционный подход предполагает использование &lt;-, однако все больше программистов использует знак = в своих программах, что делает R более похожим на другие языки программирования. Помните, что использование = официально не рекомендуется, поскольку существует много старого кода на R, который может ошибочно выполняться в сочетании с кодом, использующим =. Но вы, скорее всего, с такими проблемами не столкнетесь. Так что выбор за вами! После запятой всегда ставьте пробел, перед запятой – нет: # Правильно: a = c(1, 2, 3, 4) m = matrix(a, 2, 2) # Неправильно: a = c(1,2,3,4) a = c(1 ,2 ,3 ,4) a = c(1 , 2 , 3 , 4) m = matrix(a,2,2) m = matrix(a ,2 ,2) m = matrix(a , 2 , 2) Отделяйте любые бинарные операторы (такие как =, +, -, &lt;-, *) пробелами с двух сторон: a = sin(b + pi * 0.5) # правильно a=sin(b+pi*0.5) # неправильно Между названием функции и открывающей скобкой пробела быть не должно. То же самое касается обращения к элементам вектора, матрицы и т.п.: # Правильно: sin(b) a[2] # Неправильно: sin (b) a [2] В то же время, при вызове команд управления выполнением программы (условные операторы и циклы) перед и после скобок пробел должен стоять: # Правильно: if (a &gt; 0) { print(a) } i = 0 while (i &lt; a) { print(i) i = i + 1 } # Неправильно: if(a &gt; 0){ print(a) } i = 0 while(i &lt; a){ print(i) i = i + 1 } Зарезервированные слова В R существует небольшое количество зарезервированных слов, которые нельзя использовать в качестве имен переменных, функций и проч. Список этих слов можно получить, набрав в консоли ?Reserved. К ним относятся: Слово Назначение if Условный оператор ЕСЛИ else Условный оператор ИНАЧЕ repeat Цикл без внешнего условия while Цикл “пока верно условие, повторять” function Функция for Цикл “пройти по элементам последовательности” in Оператор вхождения в множество next Переход на новую итерацию цикла break Принудительный выход из цикла или условного оператора TRUE Логическое значение ИСТИНА FALSE Логическое значение ЛОЖЬ NULL Пустое значение Inf Бесконечность NaN Нечисловое значние NA Отсутствующее значение NA_integer_ Отсутствующее целое число NA_real_ Отсутствующее число с плавающей точкой NA_complex_ Отсутствующее комплексное число NA_character_ Отсутствующая строка Названия переменных В качестве названий переменных нельзя использовать заразервированные слова, а также не рекомендуется использовать названия общеупотребительных (диагностических) функций и констант. Также не следует давать переменным названия, совпадающие с широко распространенными функциями – например, котороткими функциями из пакета base, такими как t(), с() и т.д., так как это может привести к путанице в программе и даже ошибкам выполнения кода. Каждый раз, создавая переменную, спрашивайте себя, не совпадает ли ее название с названием одной из используемых вами функций. Названия специальных символов В R, как и во многих других языках программирования испльзуются различные специальные символы. Их смысл и значение мы узнаем по ходу изучения языка, а пока что выучите их названия, чтобы грамотно употреблять в своей речи Символ Название $ доллар # шарп &amp; амперсанд (решетка) / прямой слэш \\ обратный слэш | пайп (вертикальная черта) ^ циркумфлекс (крышечка) @ эт (собачка) ~ тильда '' одинарные кавычки \"\" двойные кавычки `` обратные кавычки Ссылка на пособие Если этот курс лекций оказался полезным для вас, и вы хотите процитировать его с списке литературы вашей работы, то ссылку можно оформить по следующей форме: Самсонов Т.Е. Визуализация и анализ географических данных на языке R. М.: Географический факультет МГУ, 2020. DOI: 10.5281/zenodo.901911 "],
["data-types.html", "Глава 1 Типы данных, условия, ввод и вывод 1.1 Типы данных 1.2 Манипуляции с типами 1.3 Ввод и вывод данных в консоли 1.4 Условный оператор 1.5 Оператор переключения 1.6 Прерывание программы 1.7 Технические детали 1.8 Краткий обзор 1.9 Контрольные вопросы и упражнения", " Глава 1 Типы данных, условия, ввод и вывод Программный код главы 1.1 Типы данных Тип данных — это класс данных, характеризуемый членами класса и операциями, которые могут быть к ним применены1. С помощью типов данных мы можем представлять привычные нам сущности, такие как числа, строки и т.д. В языке R существует 5 базовых типов данных: Название Тип данных complex комплексные числа character строки integer целые числа logical логические (булевы) numeric числа с плавающей точкой Помимо этого есть тип Date, который позволяет работать с датами. Рассмотрим использование каждого из перечисленных типов. 1.1.1 Числа Числа — основной тип данных в R. К ним относятся числа c плавающей точкой и целые числа. В терминологии R такие данные называются интервальными, поскольку к ним применимо понятие интервала на числовой прямой. Целые числа относятся к дискретным интервальным, а числа с плавающей точкой — к непрерывным интервальным. Числа можно складывать, вычитать и умножать: 2 + 3 ## [1] 5 2 - 3 ## [1] -1 2 * 3 ## [1] 6 Разделителем целой и дробной части является точка, а не запятая: 2.5 + 3.1 ## [1] 5.6 Существует также специальный оператор для возведения в степень. Для этого вы можете использовать или двойной знак умножения (**) или циркумфлекс (^), который в обиходе называют просто “крышечкой”: 2 ^ 3 ## [1] 8 2 ** 3 ## [1] 8 Результат деления по умолчанию имеет тип с плавающей точкой: 5 / 3 ## [1] 1.666667 5 / 2.5 ## [1] 2 Если вы хотите чтобы деление производилось целочисленным образом (без дробной части) необходимо использовать оператор %/%: 5 %/% 3 ## [1] 1 Остаток от деления можно получить с помощью оператора %%: 5 %% 3 ## [1] 2 Вышеприведенные арифметические операции являются бинарными, то есть требуют наличия двух чисел. Числа называются “операндами”. Отделять операнды от оператора пробелом или нет — дело вкуса. Однако рекомендуется все же отделять, так как это повышает читаемость кода. Следующие два выражения эквивалентны. Однако сравните простоту их восприятия: 5%/%3 ## [1] 1 5 %/% 3 ## [1] 1 Как правило, в настоящих программах числа в явном виде встречаются лишь иногда. Вместо этого для их обозначения используют переменные. В вышеприведенных выражениях мы неоднократно использовали число 3. Теперь представьте, что вы хотите проверить, каковы будут результаты, если вместо 3 использовать 4. Вам придется заменить все тройки на четверки. Если их много, то это будет утомительная работа, и вы наверняка что-то пропустите. Конечно, можно использовать поиск с автозаменой, но что если тройки надо заменить не везде? Одно и то же число может выполнять разные функции в разных выражениях. Чтобы избежать подобных проблем, в программе вводят переменные и присваивают им значения. Оператор присваивания значения выглядит как = a = 5 b = 3 Чтобы вывести значение переменной на экран, достаточно просто ввести его: a ## [1] 5 b ## [1] 3 Мы можем выполнить над переменными все те же операции что и над константами: a + b ## [1] 8 a - b ## [1] 2 a / b ## [1] 1.666667 a %/% b ## [1] 1 a %% b ## [1] 2 Легко меняем значение второй переменной с 3 на 4 и выполняем код заново. b = 4 a + b ## [1] 9 a - b ## [1] 1 a / b ## [1] 1.25 a %/% b ## [1] 1 a %% b ## [1] 1 Нам пришлось изменить значение переменной только один раз в момент ее создания, все последующие операции остались неизменны, но их результаты обновились! Новую переменную можно создать на основе значений существующих переменных: c = b d = a+c Посмотрим, что получилось: c ## [1] 4 d ## [1] 9 Вы можете комбинировать переменные и заданные явным образом константы: e = d + 2.5 e ## [1] 11.5 Противоположное по знаку число получается добавлением унарного оператора - перед константой или переменной: f = -2 f ## [1] -2 f = -e f ## [1] -11.5 Операция взятия остатка от деления бывает полезной, например, когда мы хотим выяснить, является число четным или нет. Для этого достаточно взять остаток от деления на 2. Если число является четным, остаток будет равен нулю. В данном случае c равно 4, d равно 9: c %% 2 ## [1] 0 d %% 2 ## [1] 1 1.1.1.1 Числовые функции Прежде чем мы перейдем к рассмотрению прочих типов данных и структур данных нам необходимо познакомиться с функциями, поскольку они встречаются буквально на каждом шагу. Понятие функции идентично тому, к чему мы привыкли в математике. Например, функция может называться Z, и принимать 2 аргумента: x и y. В этом случае она записывается как Z(x,y). Чтобы получить значение функции, необходимо подставить некоторые значения вместо x и y в скобках. Нас даже может не интересовать, как фактически устроена функция внутри, но важно понимать, что именно она должна вычислять. С созданием функций мы познакомимся позднее. Важнейшие примеры функций — математические. Это функции взятия корня sqrt(x), модуля abs(x), округления round(x, digits), натурального логарифма abs(x), тригонометрические функции sin(x), cos(x), tan(x), обратные к ним asin(y), acos(y), atan(y) и многие другие. Основные математические функции содержатся в пакете base, который по умолчанию доступен в среде R и не требует подключения. В качестве аргумента функции можно использовать переменную, константу, а также выражения: sqrt(a) ## [1] 2.236068 sin(a) ## [1] -0.9589243 tan(1.5) ## [1] 14.10142 abs(a + b - 2.5) ## [1] 6.5 Вы также можете легко вкладывать функции одна в одну, если результат вычисления одной функции нужно подставить в другую: sin(sqrt(a)) ## [1] 0.7867491 sqrt(sin(a) + 2) ## [1] 1.020331 Также как и с арифметическими выражениями, результат вычисления функции можно записать в переменную: b = sin(sqrt(a)) b ## [1] 0.7867491 Если переменной b ранее было присвоено другое значение, оно перезапишется. Вы также можете записать в переменную результат операции, выполненной над ней же. Например, если вы не уверены, что a — неотрицательное число, а вам это необходимо в дальнейших расчетах, вы можете применить к нему операцию взятия модуля: b = sin(a) b ## [1] -0.9589243 b = abs(b) b ## [1] 0.9589243 1.1.2 Строки Строки — также еще один важнейший тип данных. Строки состоят из символов. Чтобы создать строковую переменную, необходимо заключить текст строки в кавычки: s = &quot;В историю трудно войти, но легко вляпаться (М.Жванецкий)&quot; s ## [1] &quot;В историю трудно войти, но легко вляпаться (М.Жванецкий)&quot; Длину строки в символах можно узнать с помощью функции nchar() nchar(s) ## [1] 56 Строки можно складывать так же как и числа. Эта операция называется конкатенацией. В результате конкатенации строки состыковываются друг с другом и получается одна строка. В отличие от чисел, конкатенация производится не оператором +, а специальной функцией paste(). Состыковываемые строки нужно перечислить через запятую, их число может быть произвольно s1 = &quot;В историю трудно войти,&quot; s2 = &quot;но легко вляпаться&quot; s3 = &quot;(М.Жванецкий)&quot; Посмотрим содержимое подстрок: s1 ## [1] &quot;В историю трудно войти,&quot; s2 ## [1] &quot;но легко вляпаться&quot; s3 ## [1] &quot;(М.Жванецкий)&quot; А теперь объединим их в одну: s = paste(s1, s2) s ## [1] &quot;В историю трудно войти, но легко вляпаться&quot; s = paste(s1, s2, s3) s ## [1] &quot;В историю трудно войти, но легко вляпаться (М.Жванецкий)&quot; Настоящая сила конкатенации проявляется когда вам необходимо объединить в одной строке некоторое текстовое описание (заранее известное) и значения переменных, которые у вас вычисляются в программе (заранее неизвестные). Предположим, вы нашли в программе что максимальная численность населения в Детройте пришлась на 1950 год и составила 1850 тыс. человек. Найденный год записан у вас в переменную year, а население в переменную pop. Вы их значения пока что не знаете, они вычислены по табличным данным в программе. Как вывести эту информацию на экран “человеческим”\" образом? Для этого нужно использовать конкатенацию строк. Условно запишем значения переменных, как будто мы их знаем year = 1950 pop = 1850 s1 = &quot;Максимальная численность населения в Детройте пришлась на&quot; s2 = &quot;год и составила&quot; s3 = &quot;тыс. чел&quot; s = paste(s1, year, s2, pop, s3) s ## [1] &quot;Максимальная численность населения в Детройте пришлась на 1950 год и составила 1850 тыс. чел&quot; Обратите внимание на то что мы конкатенировали строки с числами. Конвертация типов осуществилась автоматически. Помимо этого, функция сама вставила пробелы между строками. Функция paste() содержит параметр sep, отвечающий за символ, который будет вставляться между конкатенируемыми строками. По умолчанию sep = \" \", то есть, между строками будет вставляться пробел. Подобное поведение желательно не всегда. Например, если после переменной у вас идет запятая, то между ними будет вставлен пробел. В таком случае при вызове paste() необходимо указать sep = \"\", то есть пустую строку: paste(... sep = \"\"). Вы также можете воспользоваться функцией paste0(), которая делает [почти] то же самое, что и paste(..., sep = \"\"), но избавляет вас от задания параметра sep. 1.1.3 Даты Даты являются необходимыми при работе с временными данными. В географическом анализе подобные задачи возникают сплошь и рядом. Точность указания времени может быть самой различной. От года до долей секунды. Чаще всего используются даты, указанные с точностью до дня. Для создания даты используется функция as.Date(). В данном случае точка — это лишь часть названия функции, а не какой-то особый оператор. В качестве аргумента функции необходимо задать дату, записанную в виде строки. Запишем дату рождения автора (можете заменить ее на свою): birth = as.Date(&#39;1986/02/18&#39;) birth ## [1] &quot;1986-02-18&quot; Сегодняшнюю дату вы можете узнать с помощью специальной функции Sys.Date(): current = Sys.Date() current ## [1] &quot;2020-02-10&quot; Даты также можно складывать и вычитать. В зависимости от дискретности данных, вы получите результат в часах, днях, годах и т.д. Например, узнать продолжительность жизни в днях можно так: livedays = current - birth livedays ## Time difference of 12410 days Вы также можете прибавить к текущей дате некоторое значение. Например, необходимо узнать, какая дата будет через 40 дней: current + 40 ## [1] &quot;2020-03-21&quot; 1.1.4 Логические Логические переменные возникают там, где нужно проверить условие. Переменная логического типа может принимать значение TRUE (истина) или FALSE (ложь). Для их обозначения также возможны более компактные константы T и F соответственно. Следующие операторы приводят к возникновению логических переменных: РАВНО (==) — проверка равенства операндов НЕ РАВНО (!=) — проверка неравенства операндов МЕНЬШЕ (&lt;) — первый аргумент меньше второго МЕНЬШЕ ИЛИ РАВНО (&lt;=) — первый аргумент меньше или равен второму БОЛЬШЕ (&gt;) — первый аргумент больше второго БОЛЬШЕ ИЛИ РАВНО (&gt;=) — первый аргумент больше или равен второму Посмотрим, как они работают: a = 1 b = 2 a == b ## [1] FALSE a != b ## [1] TRUE a &gt; b ## [1] FALSE a &lt; b ## [1] TRUE Если необходимо проверить несколько условий одновременно, их можно комбинировать с помощью логических операторов. Наиболее популярные среди них: И (&amp;&amp;) - проверка истинности обоих условий ИЛИ (||) - проверка истинности хотя бы одного из условий НЕ (!) - отрицание операнда (истина меняется на ложь, ложь на истину) c = 3 (b &gt; a) &amp;&amp; (c &gt; b) ## [1] TRUE (a &gt; b) &amp;&amp; (c &gt; b) ## [1] FALSE (a &gt; b) || (c &gt; b) ## [1] TRUE !(a &gt; b) ## [1] TRUE Более подробно работу с логическими переменными мы разберем далее при знакомстве с условным оператором if. 1.2 Манипуляции с типами 1.2.1 Определение типа данных Определение типа данных осуществляется с помощью функции class() (см. раздел Диагностические функции во Введении) class(1) ## [1] &quot;numeric&quot; class(0.5) ## [1] &quot;numeric&quot; class(1 + 2i) ## [1] &quot;complex&quot; class(&quot;sample&quot;) ## [1] &quot;character&quot; class(TRUE) ## [1] &quot;logical&quot; class(as.Date(&#39;1986-02-18&#39;)) ## [1] &quot;Date&quot; В вышеприведенном примере видно, что R по умолчанию “повышает” ранг целочисленных данных до более общего типа чисел с плавающей точкой, тем самым закладываясь на возможность точного деления без остатка. Если вы хотите, чтобы данные в явном виде интерпретировались как целочисленные, их нужно принудительно привести к этому типу. Операторы преобразования типов рассмотрены ниже. 1.2.2 Преобразование типов данных Преобразование типов данных осуществляется с помощью функций семейства as(d, type), где d — это входная переменная, а type — название типа данных, к которому эти данные надо преобразовать (см. таблицу в начале главы). Несколько примеров: k = 1 print(k) ## [1] 1 class(k) ## [1] &quot;numeric&quot; l = as(k, &quot;integer&quot;) print(l) ## [1] 1 class(l) ## [1] &quot;integer&quot; m = as(l, &quot;character&quot;) print(m) ## [1] &quot;1&quot; class(m) ## [1] &quot;character&quot; n = as(m, &quot;numeric&quot;) print(n) ## [1] 1 class(n) ## [1] &quot;numeric&quot; Для функции as() существуют обертки (wrappers), которые позволяют записывать такие преобразования более компактно и выглядят как as.&lt;dataype&gt;(d), где datatype — название типа данных: k = 1 l = as.integer(k) print(l) ## [1] 1 class(l) ## [1] &quot;integer&quot; m = as.character(l) print(m) ## [1] &quot;1&quot; class(m) ## [1] &quot;character&quot; n = as.numeric(m) print(n) ## [1] 1 class(n) ## [1] &quot;numeric&quot; d = as.Date(&#39;1986-02-18&#39;) print(d) ## [1] &quot;1986-02-18&quot; class(d) ## [1] &quot;Date&quot; Если преобразовать число c плавающей точкой до целого, то дробная часть будет отброшена: as.integer(2.7) ## [1] 2 После преобразования типа данных, разумеется, к переменной будут применимы только те функции, которые определены для данного типа данных: a = 2.5 b = as.character(a) b + 2 ## Error in b + 2: нечисловой аргумент для бинарного оператора nchar(b) ## [1] 3 1.2.3 Проверка типов данных и пустых значений Для проверки типа данных можно использовать функции семейства is.&lt;datatype&gt;: is.integer(2.7) ## [1] FALSE is.numeric(2.7) ## [1] TRUE is.character(&#39;Привет!&#39;) ## [1] TRUE Особое значение имеют функции проверки пустых переменных (имеющих значение NA - not available), которые могут получаться в результате несовместимых преобразований или соответствовать пропускам в исходных данных: as.integer(&#39;Привет!&#39;) ## [1] NA is.na(as.integer(&#39;Привет!&#39;)) ## [1] TRUE 1.3 Ввод и вывод данных в консоли 1.3.1 Ввод данных Для ввода данных через консоль можно воспользоваться функцией readline(), которая будет ожидать пользовательский ввод и нажатие клавиши Enter, после чего вернет введенные данные в виде строки. Предположим, пользователь вызывает эту функцию и вводит с клавиатуры 1024: a = readline() Выведем результат на экран: a ## [1] &quot;1024&quot; Функция readline() всегда возвращает строку, поэтому если вы ожидаете ввод числа, полученное значение необходимо явным образом преобразовать к числовому типу. Весьма полезной особенностью readline() является возможность указания строки запроса (чтобы пользователь понимал, что от него хотят). Строку запроса можно указать при вызове функции: lat = readline(&#39;Введите широту точки:&#39;) ## Введите широту точки: ## 54 lat ## [1] &quot;54&quot; 1.3.2 Вывод данных Для вывода данных в консоль можно воспользоваться тремя способами: Просто напечатать название переменной с новой строки (не работает при запуске программы командой Source) Вызвать функцию print() Вызвать функцию cat() Заключить выражение в круглые скобки () Первый способ мы уже регулярно использовали ранее в настоящей главе. Следует обратить внимание на то, что он хорош для отладки программы, но выглядит некрасиво в рабочих программах, поскольку просто печатая название переменной с новой строки вы как бы явно не говорите о том, что хотите вывести ее значение в консоль, а лишь подразумеваете это. Более того, если скрипт запускается командой Source, данный метод вывода переменной просто не сработает, интерпретатор его проигнорирует. Поэтому после отладки следует убрать из программы все лишние выводы в консоль, а оставшиеся (действительно нужные) оформить с помощью функций print() или cat(). Функция print() работает точно так же, как и просто название переменной с новой строки, отличаясь лишь двумя особенностями: print() явным образом говорит о том, что вы хотите вывести в консоль некую информацию print() работает при любых методах запуска программы, в том числе методом Source. Например: a = 1024 a ## [1] 1024 print(a) ## [1] 1024 b = &quot;Fourty winks in progress&quot; b ## [1] &quot;Fourty winks in progress&quot; print(b) ## [1] &quot;Fourty winks in progress&quot; print(paste(&quot;2 в степени 10 равно&quot;, 2^10)) ## [1] &quot;2 в степени 10 равно 1024&quot; print(paste(&quot;Сегодняшняя дата - &quot;, Sys.Date())) ## [1] &quot;Сегодняшняя дата - 2020-02-10&quot; Функция cat() отличается от print() следующими особенностями: cat() выводит значение переменной, и не печатает ее измерения и внешние атрибуты типа двойных кавычек вокруг строки. Это означает, что cat() можно использовать и для записи данных в файл (на практике этим мало кто пользуется, но знать такую возможность надо). cat() принимает множество аргументов и может осуществлять конкатенацию строк аналогично функции paste() cat() не возвращает никакого значений, в то время как print() возвращает значение, переданное ей в качестве аргумента. cat() можно использовать только для атомарных типов данных. Для классов (таких как Date) она будет выводит содержимое объекта, которое может не совпадать с тем, что пользователь ожидает вывести Например: cat(a) ## 1024 cat(b) ## Fourty winks in progress cat(&quot;2 в степени 10 равно&quot;, 2^10) ## 2 в степени 10 равно 1024 cat(&quot;Сегодняшнаяя дата -&quot;, Sys.Date()) ## Сегодняшнаяя дата - 18302 Можно видеть, что в последнем случае cat() напечатала отнюдь не дату в ее привычном представлении, а некое число, которое является внутренним представлением даты в типе данных Date. Такие типы данных являются классами объектов в R, и у них есть своя функция print(), которая и выдает содержимое объекта в виде, который ожидается пользователем. Поэтому пользоваться функцией cat() надо с некоторой осторожностью. Заключительная возможность — вывод с помощью заключения выражения в круглые скобки — очень удобна на стадии отладки программы. При этом переменная, которая создается в выражении, остается доступной в программе: (a = rnorm(5)) # сгенерируем 5 случайных чисел, запишем их в переменную a и выведем на экран ## [1] -0.15913670 1.70515173 -0.76674491 -1.03324277 -0.01202082 (b = 2 * a) # переменная a доступна, ее можно использовать и далее для вычислений ## [1] -0.31827340 3.41030347 -1.53348983 -2.06648554 -0.02404163 1.4 Условный оператор Проверка условий позволяет осуществлять так называемое ветвление в программе. Ветвление означает, что при определенных условиях (значениях переменных) будет выполнен один программный код, а при других условиях — другой. В R для проверки условий используется условный оператор if — else if — else следующего вида: if (condition) { statement1 } else if (condition) { statement2 } else { statement3 } Сначала проверяется условие в выражении if (condition), и если оно истинно, то выполнится вложенный в фигурные скобки программный код statement1, после чего оставшиеся условия не будут проверяться. Если первое условие ложно, программа перейдет к проверке следующего условия else if (condition). Далее, если оно истинно, то выполнится вложенный код statement2, если нет — проверка переключится на следующее условие и так далее. Заключительный код statement3, следующий за словом else, выполнится только если ложными окажутся все предыдущие условия. Конструкций else if может быть произвольное количество, конструкции if и else могут встречаться в условном операторе только один раз, в начале и конце соответственно. При этом условный оператор может состоять только из конструкции if, а else if и else не являются обязательными. Например, сгенерируем случайное число, округлим его до одного знака после запятой и проверим относительно нуля: (a = round(rnorm(1), 1)) ## [1] -0.9 if (a &lt; 0) { cat(&#39;Получилось отрицательное число!&#39;) } else if (a &gt; 0) { cat(&#39;Получилось положительное число!&#39;) } else { cat(&#39;Получился нуль!&#39;) } ## Получилось отрицательное число! Условия можно использовать, в частности, для того чтобы обрабатывать пользовательский ввод в программе. Например, охарактеризуем положение точки относительно Полярного круга: phi = as.numeric(readline(&#39;Введите широту вашей точки:&#39;)) Пользователь вводит 68, а мы оцениваем результат: if (!is.na(phi)) { # проверяем, является ли введенное значение числом if (abs(phi) &gt;= 66.562 &amp;&amp; abs(phi) &lt;= 90) { # выполняем проверку на заполярность cat(&#39;Точка находится в Заполярье&#39;) } else { cat(&#39;Точка не находится в Заполярье&#39;) } } else { cat(&#39;Необходимо ввести число!&#39;) # оповещаем о некорректном вводе } ## Точка находится в Заполярье 1.5 Оператор переключения Оператор переключения (switch) является удобной заменой условному оператору в тех случаях, когда надо вычислить значение переменной в зависимости от значения другой переменной, которая может принимать ограниченное (заранее известное) число значений. Например: name = readline(&#39;Введите название федерального округа:&#39;) Пользователь вводит: Приволжский # Определим центр в зависимости от названия: capital = switch(name, &#39;Центральный&#39; = &#39;Москва&#39;, &#39;Северо-Западный&#39; = &#39;Санкт-Петербург&#39;, &#39;Южный&#39; = &#39;Ростов-на-Дону&#39;, &#39;Северо-Кавказский&#39; = &#39;Пятигорск&#39;, &#39;Приволжский&#39; = &#39;Нижний Новгород&#39;, &#39;Уральский&#39; = &#39;Екатеринбург&#39;, &#39;Сибирский&#39; = &#39;Новосибирск&#39;, &#39;Дальневосточный&#39; = &#39;Хабаровск&#39;) print(capital) ## [1] &quot;Нижний Новгород&quot; 1.6 Прерывание программы В процессе выполнения программы могут возникнуть ситуации, при которых дальнейшее выполнение программы невозможно или недопустимо. Например, пользователь вместо числа ввёл в консоли букву. Хорошим тоном разработчика в данном случае будет не пускать ситуацию на самотёк и ждать пока программа сама споткнется и выдаст системное сообщение об ошибке, а обработать некорректный ввод сразу, сообщить об этом пользователю и остановить программу явным образом. Прервать выполнение программы можно разными способами. Рассмотрим две часто используемые для этого функции: stop(...) выводит на экран объекты, перечисленные через запятую в ... и завершает выполнение программы. При ручном вызове этой функции в ... целесообразно передать текстовую строку с сообщением о причине остановки программы. Вызов stop() происходит обычно после проверки некоторого условия оператором if-else. stopifnot(...) вызывает stop(), если хотя бы одно из выражений, перечисленных через запятую в ... имеет значение FALSE. При этом в stop() передается первое выражение, которое было оценено в FALSE. Реализуем вышеописанный пример с контролем пользовательского ввода: n = as.numeric(readline(&#39;Введите число:&#39;)) stopifnot(is.numeric(n)) # остановим выполнение, если получилось не число cat(n^2) # возведем в квадрат и выведем на экран, если все ОК Если пользователь введет abc, программа остановит выполнение: ## Error: is.numeric(n) is not TRUE Обратите внимание, что R напечатал также и само выражение, которое было оценено как FALSE. Вышеприведенный код можно сделать более дружелюбным для пользователя, если воспользоваться непосредственно функцией stop(): n = as.numeric(readline(&#39;Введите число:&#39;)) if (!is.numeric(n)) stop(&#39;Введенная строка не является числом&#39;) # остановим выполнение cat(n^2) # возведем в квадрат и выведем на экран, если все ОК Вывод программы в случае ввода строки abc будет следующим: ## Error in eval(expr, envir, enclos): Введенная строка не является числом 1.7 Технические детали Когда вы присваиваете значение переменной другой переменной, копирования не происходит. Оба имени будут ссылаться на один и тот же объект, до тех пор, пока через одно из имен не будет предпринята попытка модифицировать объект. Это можно легко проверить с помощью функции tracemem(): a = 1 b = a cat(&#39;a:&#39;, tracemem(a), &#39;\\n&#39;) ## a: &lt;0x7fee57268628&gt; cat(&#39;b:&#39;, tracemem(b), &#39;\\n&#39;) ## b: &lt;0x7fee57268628&gt; a = 2 cat(&#39;a:&#39;, tracemem(a), &#39;\\n&#39;) # объект скопирован в другую область памяти ## a: &lt;0x7fee57331ed8&gt; cat(&#39;b:&#39;, tracemem(b), &#39;\\n&#39;) ## b: &lt;0x7fee57268628&gt; Подобное поведение называется copy-on-modify. Оно позволяет экономить на вычислениях в случае, когда копия и оригинал остаются неизменными. Аналогичное правило применяется когда вы копируете структуры данных, такие как векторы, списки и фреймы данных (см. Главу 2). Более подробно см. параграф 2.3 в (Wickham 2019). 1.8 Краткий обзор Для просмотра презентации щелкните на ней один раз левой кнопкой мыши и листайте, используя кнопки на клавиатуре: Презентацию можно открыть в отдельном окне или вкладке браузере. Для этого щелкните по ней правой кнопкой мыши и выберите соответствующую команду. 1.9 Контрольные вопросы и упражнения 1.9.1 Вопросы Какие типы данных поддерживаются в R? Каковы их англоязычные наименования? Что такое переменная? Какой оператор используется для записи значения в переменную? С помощью какой функции можно узнать тип переменной? С помощью какого семейства функций можно преобразовывать типы переменных? Можно ли использовать ранее созданное имя переменной для хранения новых данных другого типа? Можно ли записать в переменную результат выполнения выражения, в котором она сама же и участвует? Какая функция позволяет прочитать пользовательский ввод с клавиатуры в консоли? Какой тип данных будет иметь возвращаемое значение? Какую функцию можно использовать для вывода значения переменной в консоль? Чем отличается использование этой функции от случая, когда вы просто пишете название переменной в строке программы? Какой символ является разделителем целой и дробной части при записи чисел с плавающей точкой? Что такое операторы и операнды? Приведите примеры бинарных и унарных операторов. Какое значение будет имет результат деления на ноль? Какие функции выполняют операторы %%, %/%, ^, **? Как проверить, является ли число четным? Как определить количество символов в строке? Как называется операция состыковки нескольких строк и с помощью какой функции она выполняется? Как добиться того, чтобы при этом не добавлялись пробелы между строками? С помощью какой функции можно создать дату из строки? Как извлечь из даты год? Месяц? День? Какая функция позволяет получить дату сегодняшнего дня? Можно ли складывать даты и числа? Если да, то в каких единицах измерения будет выражен результат? Какова краткая форма записи логических значений TRUE и FALSE? Каким числам соответствуют логические значения TRUE и FALSE? Сколько операндов должно быть верно, чтобы оператор логического И (&amp;&amp;) принял значение TRUE? Что можно сказать в этом отношении об операторе ИЛИ (||)? Можно ли применять арифметические операции к логическим переменным? Что произойдет, если прибавить или вычесть из числа a значение TRUE? А если заменить TRUE на FALSE? Что такое условный оператор и для каких сценариев обработки данных необходимы условные операторы? Перечислите ключевые слова, которые могут быть использованы для организации условных операторов При каких сценариях целесообразно использовать оператор переключения? 1.9.2 Упражнения Запишите условие проверки неравенства чисел a и b не менее чем тремя способами. Напишите программу, которая запрашивает в консоли целое число и определяет, является ли оно чётным или нечетным. Программа должна предварительно определить, является ли введенное число а) числом и б) целым числом. Подсказка: результат конвертации строки в целое число и число с плавающей точкой отличается. Вы можете использовать это для проверки, является ли введенное число целым. Напишите программу, которая считывает из консоли введенную пользователем строку и выводит в консоль количество символов в этой строке. Вывод оформите следующим образом: \"Длина введенной строки равняется ... символам\", где вместо многоточия стоит вычисленная длина. В программе в виде переменных задайте координаты населенного пункта А (x1, y1), а также дирекционный угол D и расстояние L до населенного пункта B. Напишите код, который определяет координаты населенного пункта B (x2, y2). Функция atan2() позволяет найти математический азимут (полярный угол), если известны координаты вектора между двумя точками. Используя эту функцию, напишите программу, которая вычисляет географический азимут между точками А (x1, y1) и B (x2, y2). Координаты точек задайте в виде переменных непосредственно в коде. Математический азимут отсчитывается от направления на восток против часовой стрелки. Географический азимут отсчитывается от направления на север по часовой стрелке). Самсонов Т.Е. Визуализация и анализ географических данных на языке R. М.: Географический факультет МГУ, 2020. DOI: 10.5281/zenodo.901911 References "],
["data-structures.html", "Глава 2 Структуры данных и циклы 2.1 Однородные структуры данных 2.2 Разнородные структуры данных 2.3 Факторы 2.4 Описание структуры данных 2.5 Циклы 2.6 Технические детали 2.7 Краткий обзор 2.8 Контрольные вопросы и упражнения", " Глава 2 Структуры данных и циклы Программный код главы Структура данных — это программная единица, позволяющая хранить и обрабатывать множество однотипных и/или логически связанных данных. Структуры данных также являются типами данных, но не простыми, а составными. Поэтому обычно, когда говорят “тип данных”, подразумевают именно простые типы данных, рассмотренные в предыдущей главе. В R общеупотребительны следующие структуры данных: векторы, матрицы, массивы, фреймы данных, списки и факторы. С использованием структур данных тесно связаны циклы — разновидность управляющей конструкции, предназначенная для многократного повторения определенного набора инструкций. 2.1 Однородные структуры данных 2.1.1 Векторы Вектор представляет собой упорядоченную последовательность объектов одного типа. Вектор может состоять только из чисел, только из строк, только из дат или только из логических значений и т.д. Числовой вектор легко представить себе в виде набора цифр, выстроенных в ряд и пронумерованных согласно порядку их расстановки. Вектор является простейшей и одновременно базовой структурой данных в R. Понимание принципов работы с векторами необходимо для дальнейшего знакомства с более сложными структурами данных, такими как матрицы, массивы, фреймы данных, тибблы, списки и факторы. 2.1.1.1 Создание Существует множество способов создания векторов. Среди них наиболее употребительны: Явное перечисление элементов Создание пустого вектора (“болванки”), состоящего из заданного числа элементов Генерация последовательности значений Генерация случайного множества значений Для создания вектора путем перечисления элементов используется функция c(): # вектор из строк — цвета некоторых веток Московского метро colors = c(&quot;Красная&quot;, &quot;Зеленая&quot;, &quot;Синяя&quot;, &quot;Коричневая&quot;, &quot;Оранжевая&quot;) colors ## [1] &quot;Красная&quot; &quot;Зеленая&quot; &quot;Синяя&quot; &quot;Коричневая&quot; &quot;Оранжевая&quot; # вектор из чисел — длина веток в километрах (в той же последовательности) lengths = c(28, 40, 45, 19, 38) lengths ## [1] 28 40 45 19 38 # вектор из булевых переменных — наличие открытых наземных участков (в той же последовательности) opens = c(FALSE, TRUE, TRUE, FALSE, FALSE) opens ## [1] FALSE TRUE TRUE FALSE FALSE Внимание: не используйте латинскую букву ‘c’ в качестве названия переменной! Это приведет к конфликту названия встроенной функции c() и определенной вами переменной Помимо этого, распространены сценарии, когда вам нужно создать вектор, но заполнять его значениями вы будете по ходу выполнения программы — скажем, при последовательной обработке строк таблицы. В этом случае вам известно только предполагаемое количество элементов вектора и их тип. Здесь лучше всего подойдет создание пустого вектора, которое выполняется функцией vector(). Функция принимает 2 параметра: mode отвечает за тип данных и может принимать значения равные \"logical\", \"integer\", \"numeric\" (или \"double\"), \"complex\", \"character\" и \"raw\" length отвечает за количество элементов Например: # Вектор из 5 элементов, который предполагается заполнить целыми числами intvalues = vector(mode = &quot;integer&quot;, length = 5) intvalues # по умолчанию заполнен нулями ## [1] 0 0 0 0 0 # Вектор из 10 элементов, который предполагается заполнить символьными данными (строками) charvalues = vector(&quot;character&quot;, 10) charvalues # по умолчанию заполнен пустыми строками ## [1] &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; Обратите внимание на то, что в первом случае подстановка параметров произведена в виде параметр = значение, а во втором указаны только значения. В данном примере оба способа эквивалентны. Однако первый способ безопаснее и понятнее. Если вы указываете только значения параметров, нужно помнить, что интерпретатор будет подставлять их именно в том порядке, в котором они перечислены в описании функции. Описание функции можно посмотреть, набрав ее название в консоли ее название со знаком вопроса в качестве префикса. Например, для вышеуказанной функции надо набрать ?vector Наконец, третий распространенный способ создания векторов — это генерация последовательности. Чтобы сформировать вектор из натуральных чисел от M до N, можно воспользоваться специальной конструкцией: M:N: index = 1:5 # эквивалентно c(1,2,3,4,5) index ## [1] 1 2 3 4 5 index = 2:4 # эквивалентно c(2,3,4) index ## [1] 2 3 4 Существует и более общий способ создания последовательности — функция seq(), которая позволяет генерировать вектора значений нужной длины и/или с нужным шагом: seq(from = 1, by = 2, length.out = 10) # 10 нечетных чисел, начиная с единицы ## [1] 1 3 5 7 9 11 13 15 17 19 seq(from = 2, to = 20, by = 3) # от 2 до 20 с шагом 3 (сколько поместится) ## [1] 2 5 8 11 14 17 20 seq(length.out = 10, to = 2, by = -2) # убывающая последовательность из 10 четных чисел с последним элементом, равным 2 ## [1] 20 18 16 14 12 10 8 6 4 2 Как видно, параметры функции seq() можно комбинировать различными способами и указывать в произвольном порядке (при условии, что вы используете полную форму (параметр = значение). Главное, чтобы их совокупность однозначно описывала последовательность. Хотя, скажем, последний пример убывающей последовательности нельзя признать удачным с точки зрения наглядности. Аналогичным образом можно создавать последовательности дат: seq(from = as.Date(&#39;2016/09/01&#39;), by = 1, length.out = 7) # Даты первой недели учебного 2016/2017 года ## [1] &quot;2016-09-01&quot; &quot;2016-09-02&quot; &quot;2016-09-03&quot; &quot;2016-09-04&quot; &quot;2016-09-05&quot; ## [6] &quot;2016-09-06&quot; &quot;2016-09-07&quot; seq(from = Sys.Date(), by = 7, length.out = 5) # Пять дат через неделю, начиная с сегодняшнего дня ## [1] &quot;2020-02-10&quot; &quot;2020-02-17&quot; &quot;2020-02-24&quot; &quot;2020-03-02&quot; &quot;2020-03-09&quot; Часто оказывается полезным такая функция как генерация множества случайных значений, подчиненных определенному закону распределения. Наиболее часто испольщуются функции runif() (равномерное распределение) и rnorm() (нормальное распределение): runif(5, 0, 100) # 5 чисел равномерного распределения в диапазоне от 0 до 100 ## [1] 83.393056 90.619003 4.212001 75.343746 10.073880 rnorm(5, 10, 5) # 5 чисел нормального распределения со средним = 10 и СКО = 5 ## [1] 10.5430443 -0.9393301 14.2914776 11.7041869 16.8262912 2.1.1.2 Индексирование К отдельным элементам вектора можно обращаться по их индексам: colors[1] # первый элемент вектора ## [1] &quot;Красная&quot; colors[3] # третий элемент ## [1] &quot;Синяя&quot; ВНИМАНИЕ: элементы векторов и других структур данных в языке R индексируются от 1 до N, где N — это длина вектора. Это отличает R от широко распространенных Си-подобных языков программирования (C, C++, C#, Java, Python), в которых индексы элементов начинаются с 0 и заканчиваются N-1. Например, первый элемент списка (аналог вектора в R) на языке Python извлекался бы как colors[0]. Будьте внимательны, особенно если программируете на нескольких языках. Количество элементов (длину) вектора можно узнать с помощью функции length(): length(colors) ## [1] 5 Последний элемент вектора можно извлечь, если мы знаем его длину: n = length(colors) colors[n] ## [1] &quot;Оранжевая&quot; Последовательности удобно использовать для извлечения подвекторов. Предположим, нужно извлечь первые 4 элемента. Для этого запишем: lengths[1:4] ## [1] 28 40 45 19 Индексирующий вектор можно создать заранее. Это удобно, если номера могут меняться в программе: m = 1 n = 4 index = m:n lengths[index] ## [1] 28 40 45 19 Обратите внимание на то что по сути один вектор используется для извлечения элементов из другого вектора. Это означает, что мы можем использовать не только простые последовательности натуральных чисел, но и векторы из прозвольных индексов. Например: index = c(1, 3, 4) # хотим извлечь 1, 3 и 4 элемент списка lengths[index] ## [1] 28 45 19 index = c(5, 1, 4, 2) # индексы могут располагаться в произвольном порядке lengths[index] ## [1] 38 28 19 40 2.1.1.3 Преобразование К числовым векторам можно применять множество функций. Прежде всего, нужно знать функции вычисления базовых параметров статистического ряда — минимум, максимум, среднее, медиана, дисперсия, размах вариации, среднеквадратическое отклонение, сумма: min(lengths) # минимум ## [1] 19 max(lengths) # максимум ## [1] 45 range(lengths) # размах вариации = максимум - минимум ## [1] 19 45 mean(lengths) # среднее арифметическое ## [1] 34 median(lengths) # медиана ## [1] 38 var(lengths) # дисперсия (по английски - вариация, variation) ## [1] 108.5 sd(lengths) # среднеквадратическое отклонение (standard deviation) ## [1] 10.41633 sum(lengths) # сумма ## [1] 170 Одной из мощнейших особенностей R является то что он не проводит различий между числами и векторами чисел. Поскольку R является матричным языком, каждое число представляется как вектор длиной 1 (или матрица \\(1х1\\)). Это означает, что любая математическая функция, применимая к числу, будет применима и к вектору: lengths * 1000 # преобразуем длины линий в метры ## [1] 28000 40000 45000 19000 38000 sqrt(lengths) # квадратный корень из длины каждого элемента ## [1] 5.291503 6.324555 6.708204 4.358899 6.164414 stations = c(20, 21, 22, 12, 24) # количество станций dens = stations / lengths # плотность станций по веткам метро = кол-во станций / длина dens ## [1] 0.7142857 0.5250000 0.4888889 0.6315789 0.6315789 2.1.1.4 Поиск и сортировка К важнейшим преобразованиям векторов относится их сортировка: lengths2 = sort(lengths) # сортировка по возрастанию значений lengths2 # отсортированный вектор ## [1] 19 28 38 40 45 lengths # сравним с исходным ## [1] 28 40 45 19 38 lengths2 = sort(lengths, decreasing = TRUE) # сортировка по убыванию значений. Нужно задать параметр decreasing lengths2 # отсортированный вектор ## [1] 45 40 38 28 19 lengths # сравним с исходным ## [1] 28 40 45 19 38 Другая распространенная задача — это поиск индекса элемента по его значению. Например, вы хотите узнать, какая ветка Московского метро (среди рассматриваемых) является самой длинной. Вы, конечно, легко найдете ее длину с помощью функции max(lengths). Однако это не поможет вам узнать ее название, поскольку оно находится в другом векторе, и его индекс в массиве неизвестен. Поскольку векторы упорядочены одинаково, нам достаточно узнать, под каким индексом в массиве lengths располагается максимальный элемент, и затем извлечь цвет линии метро под тем же самым индексом. Дл поиска индекса элемента используется функция match(): l = max(lengths) # находим максимальное значение idx = match(l, lengths) # находим индекс элемента, равного l, в списке lengths color = colors[idx] # извлекаем цвет ветки метро color ## [1] &quot;Синяя&quot; Здесь непохо бы лишний раз потренироваться в конкатенации строк, чтобы вывести результат красиво! s = paste(color, &quot;ветка Московского метро — самая длинная. Ее протяженность составляет&quot;, l, &quot;км&quot;) s ## [1] &quot;Синяя ветка Московского метро — самая длинная. Ее протяженность составляет 45 км&quot; Ну и напоследок пример “матрешки”\" из функций — как найти название самой плотной линии одним выражением: colors[match(max(dens),dens)] ## [1] &quot;Красная&quot; 2.1.1.5 Проверка условий Проверка условия для вектора приводит к получению вектора логических значений: lengths &gt; 20 ## [1] TRUE TRUE TRUE FALSE TRUE Такого рода условия используются для фильтрации фреймов данных (см. далее) Для векторов существует специальная форма векторизованного условного оператора – функция ifelse(). Она позволяет создать вектор, каждый элемент которого вычисляется по-разному в зависимости от значения элемента другого вектора в соответствующей позиции. Например, мы можем охарактеризовать каждую линию метро как длинную или короткую, установив порог в 20 км: (line_type = ifelse(lengths &gt; 20, &#39;Длинная&#39;, &#39;Короткая&#39;)) ## [1] &quot;Длинная&quot; &quot;Длинная&quot; &quot;Длинная&quot; &quot;Короткая&quot; &quot;Длинная&quot; 2.1.1.6 Описательные статистики Можно получить краткую статистическую сводку по вектору (и любой другой структуре данных) с использованием функции summary(). Для качественных переменных выдаются частоты вхождения каждого случая, для количественных — набор основных описательных статистик: summary(lengths) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 19 28 38 34 40 45 summary(opens) ## Mode FALSE TRUE ## logical 3 2 2.1.2 Матрицы Матрица — это обобщение понятия вектора на 2 измерения. С точки зрения анализа данных матрицы ближе к реальным данным, посколько каждая матрица по сути представляет собой таблицу со столбцами и строками. Однако матрица, как и вектор, может содержать только элементы одного типа (числовые, строковые, логические и т.д.). Позже мы познакомимся с фреймами данных, которые не обладают подобным ограничением. Матрица, как правило, создается с помощью функции matrix, которая принимает 3 обязательных аргумента: вектор исходных значений, количество строк и количество столбцов: v = 1:12 # создадим вектор из натуральных чисел от 1 до 12 m = matrix(v, nrow = 3, ncol = 4) m ## [,1] [,2] [,3] [,4] ## [1,] 1 4 7 10 ## [2,] 2 5 8 11 ## [3,] 3 6 9 12 По умолчанию матрица заполняется данными вектора по столбцам, что можно видеть в выводе программы. Если вы хотите заполнить ее по строкам, необходимо указать параметр byrow = TRUE: m = matrix(v, nrow = 3, ncol = 4, byrow = TRUE) m ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 ## [2,] 5 6 7 8 ## [3,] 9 10 11 12 Доступ к элементам матрицы осуществляется аналогично вектору, за исключением того что нужно указать положение ячейки в строке и столбце: m[2,4] # 2 строка, 4 толбец ## [1] 8 m[3,1] # 3 строка, 1 столбец ## [1] 9 Помимо этого, из матрицы можно легко извлечь одну строку или один столбец. Для этого достаточно указать только номер строки или столбца, а номер второго измерения пропустить до или после запятой. Результат является вектором: m[2,] # 2 строка ## [1] 5 6 7 8 m[,3] # 3 cтолбец ## [1] 3 7 11 К матрицам можно применять операции, аналогичные операциям над векторами: log(m) # натуральный логарифм ото всех элементов ## [,1] [,2] [,3] [,4] ## [1,] 0.000000 0.6931472 1.098612 1.386294 ## [2,] 1.609438 1.7917595 1.945910 2.079442 ## [3,] 2.197225 2.3025851 2.397895 2.484907 sum(m) # сумма всех элементов матрицы ## [1] 78 median(m) # медиана ## [1] 6.5 B и получать по ним описательные статистики: summary(m) ## V1 V2 V3 V4 ## Min. :1 Min. : 2 Min. : 3 Min. : 4 ## 1st Qu.:3 1st Qu.: 4 1st Qu.: 5 1st Qu.: 6 ## Median :5 Median : 6 Median : 7 Median : 8 ## Mean :5 Mean : 6 Mean : 7 Mean : 8 ## 3rd Qu.:7 3rd Qu.: 8 3rd Qu.: 9 3rd Qu.:10 ## Max. :9 Max. :10 Max. :11 Max. :12 А вот сортировка матрицы приведет к тому что будет возвращен обычный вектор: sort(m) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 К матрицам также применимы специальные функции, известные из линейной алгебры, такие как транспонирование и вычисление определителя: t(m) # транспонированная матрица ## [,1] [,2] [,3] ## [1,] 1 5 9 ## [2,] 2 6 10 ## [3,] 3 7 11 ## [4,] 4 8 12 m2=matrix(-3:3,nrow = 3, ncol = 3) m2 ## [,1] [,2] [,3] ## [1,] -3 0 3 ## [2,] -2 1 -3 ## [3,] -1 2 -2 det(m2) # определитель матрицы ## [1] -21 det(m) # ошибка! определитель вычисляется только для квадратных матриц ## Error in determinant.matrix(x, logarithm = TRUE, ...): &#39;x&#39; must be a square matrix Матрицы также можно перемножать с помощью специального оператора %*%. При этом, как мы помним, число столбцов в первой матрице должно равняться числу строк во второй: m2 %*% m ## [,1] [,2] [,3] [,4] ## [1,] 24 24 24 24 ## [2,] -24 -28 -32 -36 ## [3,] -9 -10 -11 -12 m %*% m2 # ошибка! ## Error in m %*% m2: неподобные аргументы Функция match(), которую мы использовали для поиска элементов в векторе, не работает для матриц. Вместо этого необходимо использовать функцию which(). Если мы хотим найти в матрице m позицию числа \\(8\\), то вызов функции будет выглядеть так: which(m == 8, arr.ind = TRUE) ## row col ## [1,] 2 4 В данном случае видно, что результат возвращен в виде матрицы \\(1 \\times 2\\). Обратите внимание на то, что колонки матрицы имеют названия. Попробуем использовать найденные индексы, чтобы извлечь искомый элемент: indexes = which(m == 8, arr.ind = TRUE) row = indexes[1,1] col = indexes[1,2] m[row,col] ## [1] 8 Ура! Найденный элемент действительно равен \\(8\\). Еще один полезный способ создания матрицы — это собрать ее из нескольких векторов, объединив их по строкам. Для этого можно использовать функции cbind() и rbind(). На предыдущем занятии мы создали векторы с длиной и количеством станций на разных ветках метро. Можно объединить их в одну матрицу: lengths = c(28, 40, 45, 19, 38) stations = c(20, 21, 22, 12, 24) cbind(lengths, stations) # соединим вектора в качестве столбцов ## lengths stations ## [1,] 28 20 ## [2,] 40 21 ## [3,] 45 22 ## [4,] 19 12 ## [5,] 38 24 rbind(lengths, stations) # соединим вектора в качестве строк ## [,1] [,2] [,3] [,4] [,5] ## lengths 28 40 45 19 38 ## stations 20 21 22 12 24 Cтроки и столбцы матрицы можно использовать как векторы при выполнении арифметических операций: mm = cbind(lengths, stations) mm[,2]/mm[,1] # количество станций на 1 км пути ## [1] 0.7142857 0.5250000 0.4888889 0.6315789 0.6315789 Результат можно присоединить к уже созданной матрице: dens = mm[,2]/mm[,1] mm=cbind(mm, dens) mm ## lengths stations dens ## [1,] 28 20 0.7142857 ## [2,] 40 21 0.5250000 ## [3,] 45 22 0.4888889 ## [4,] 19 12 0.6315789 ## [5,] 38 24 0.6315789 Содержимое матрицы можно просмотреть в более привычном табличном виде для этого откройте вкладку Environment и щелкните на строку с матрицей в разделе Data Матрицы, однако, не дотягивают по функциональности до представления таблиц, и не предназначены для объединения разнородных данных в один набор (как мы это сделали). Если вы присоедините к матрице столбец с названиями веток метро, система не выдаст сообщение об ошибке, но преобразует матрицу в текстовую, так как текстовый тип данных способен представить любой другой тип данных: colors = c(&quot;Красная&quot;, &quot;Зеленая&quot;, &quot;Синяя&quot;, &quot;Коричневая&quot;, &quot;Оранжевая&quot;) mm2=cbind(mm,colors) mm2 # обратите внимание на то, что вокруг чисел добавились кавычки ## lengths stations dens colors ## [1,] &quot;28&quot; &quot;20&quot; &quot;0.714285714285714&quot; &quot;Красная&quot; ## [2,] &quot;40&quot; &quot;21&quot; &quot;0.525&quot; &quot;Зеленая&quot; ## [3,] &quot;45&quot; &quot;22&quot; &quot;0.488888888888889&quot; &quot;Синяя&quot; ## [4,] &quot;19&quot; &quot;12&quot; &quot;0.631578947368421&quot; &quot;Коричневая&quot; ## [5,] &quot;38&quot; &quot;24&quot; &quot;0.631578947368421&quot; &quot;Оранжевая&quot; При попытке выполнить арифметическое выражение над прежде числовыми полями, вы получите сообщение об ошибке: mm2[,2]/mm2[,1] ## Error in mm2[, 2]/mm2[, 1]: нечисловой аргумент для бинарного оператора 2.1.3 Массивы Массивы (arrays) — это многомерные структуры данных, с колчеством измерений 3 и более. Трехмерный массив представляет собой куб однородных данных. Для создания массива используется функция array(): z = array(1:36, c(3,4,2)) # вектор значений для заполнения массива, а также длина каждого измерения print(z) ## , , 1 ## ## [,1] [,2] [,3] [,4] ## [1,] 1 4 7 10 ## [2,] 2 5 8 11 ## [3,] 3 6 9 12 ## ## , , 2 ## ## [,1] [,2] [,3] [,4] ## [1,] 13 16 19 22 ## [2,] 14 17 20 23 ## [3,] 15 18 21 24 Массивы возникают тогда, например, когда имеются многомерные данные, зафиксированные по регулярной сетке географичесих локаций (это типично для геофизических данных). При этом 2 измерения отвечают за местоположение, а третье измерение — за временной срез или показатель. 2.2 Разнородные структуры данных 2.2.1 Фреймы данных Фреймы данных — это обобщение понятия матрицы на данные смешанных типов. Фреймы данных - наиболее распространенный формат представления табличных данных. Для краткости мы иногда будем называть их просто фреймами. Мы специально не используем для перевода слова data.frame термин ‘таблица’, поскольку таблица — это достаточно общая категория, которая описывает концептуальный способ упорядочивания данных. В том же языке R для представления таблиц могут быть использованы как минимум две структуры данных: фрейм данных (data.frame) и тиббл (tibble), доступный в соответствующем пакете. Мы не будем использовать тибблы в настоящем курсе, но после его освоения вы вполне сможете ознакомиться с ними самостоятельною Для создания фреймов данных используется функция data.frame(): df = data.frame(colors,lengths,stations) df # как мы видим, уже никаких кавычек вокруг чисел ## colors lengths stations ## 1 Красная 28 20 ## 2 Зеленая 40 21 ## 3 Синяя 45 22 ## 4 Коричневая 19 12 ## 5 Оранжевая 38 24 К фреймам также можно пристыковывать новые столбцы: df = cbind(df, dens) df ## colors lengths stations dens ## 1 Красная 28 20 0.7142857 ## 2 Зеленая 40 21 0.5250000 ## 3 Синяя 45 22 0.4888889 ## 4 Коричневая 19 12 0.6315789 ## 5 Оранжевая 38 24 0.6315789 Когда фрейм данных формируется посредством функции data.frame() и cbind(), названия столбцов берутся из названий векторов. Обратите внимание на то, что листинге выше столбцы имеют заголовки, а строки — номера. Как и прежде, к столбцам и строкам можно обращаться по индексам: df[2,2] ## [1] 40 df[,3] ## [1] 20 21 22 12 24 df[4,] ## colors lengths stations dens ## 4 Коричневая 19 12 0.6315789 Вы можете обращаться к отдельным столбцам фрейма данных по их названию, используя оператор $ (доллар): df$lengths ## [1] 28 40 45 19 38 df$stations ## [1] 20 21 22 12 24 Так же как и ранее, можно выполнять различные операции над столбцами: max(df$stations) ## [1] 24 df$lengths / df$stations ## [1] 1.400000 1.904762 2.045455 1.583333 1.583333 Названия столбцов можно получить с помощью функции colnames() colnames(df) ## [1] &quot;colors&quot; &quot;lengths&quot; &quot;stations&quot; &quot;dens&quot; Чтобы присоединить строку, сначала можно создать фрейм данных из одной строки: row = data.frame(&quot;Фиолетовая&quot;, 40.5, 22, 22/45) Далее нужно убедиться, что столбцы в этом мини-фрейме называются также как и в том фрейме, куда мы хотим присоединить строку. Для этого нужно перезаписать результат, возвращаемый функцией colnames(): colnames(row) = colnames(df) Обратите внимание на синтаксис вышеприведенного выражения. Когда функция возвращает результат, она обнаруживает свойство самого объекта, и мы можем его перезаписать. После того как столбцы приведены в соответствие, можно присоединить новую строку: df = rbind(df,row) Чтобы отсортировать фрейм данных по значению определенного поля, необходимо узнать порядок элементов в этом поле с помощью функции order() и проиндексировать им первое измерение фрейма: df[order(df$lengths), ] ## colors lengths stations dens ## 4 Коричневая 19.0 12 0.6315789 ## 1 Красная 28.0 20 0.7142857 ## 5 Оранжевая 38.0 24 0.6315789 ## 2 Зеленая 40.0 21 0.5250000 ## 6 Фиолетовая 40.5 22 0.4888889 ## 3 Синяя 45.0 22 0.4888889 Чтобы отфильтровать фрейм данных по значению определенного поля, необходимо передать условие в первое измерение фрейма: df[df$lengths &gt; 40, ] ## colors lengths stations dens ## 3 Синяя 45.0 22 0.4888889 ## 6 Фиолетовая 40.5 22 0.4888889 Поскольку названия столбцов хранятся как вектор из строк, мы можем их переделать: colnames(df) = c(&quot;Цвет&quot;,&quot;Длина&quot;,&quot;Станции&quot;,&quot;Плотность&quot;) colnames(df) ## [1] &quot;Цвет&quot; &quot;Длина&quot; &quot;Станции&quot; &quot;Плотность&quot; Обратимся по новому названию столбца: df$Длина ## [1] 28.0 40.0 45.0 19.0 38.0 40.5 К фреймам данных, так же как и к однородным структурам, можно применять функцию summary() для получения описательных статистик. При этом отчет формируется по каждому столбцу: summary(df) ## Цвет Длина Станции Плотность ## Зеленая :1 Min. :19.00 Min. :12.00 Min. :0.4889 ## Коричневая:1 1st Qu.:30.50 1st Qu.:20.25 1st Qu.:0.4979 ## Красная :1 Median :39.00 Median :21.50 Median :0.5783 ## Оранжевая :1 Mean :35.08 Mean :20.17 Mean :0.5800 ## Синяя :1 3rd Qu.:40.38 3rd Qu.:22.00 3rd Qu.:0.6316 ## Фиолетовая:1 Max. :45.00 Max. :24.00 Max. :0.7143 2.2.2 Списки Список — это наиболее общий тип контейнера в R. Список отличается от вектора тем, что он может содержать набор объектов произвольного типа. В качестве элементов списка могут быть числа, строки, вектора, матрицы, фреймы данных — и все это в одном контейнере. Списки используются чтобы комбинировать разрозненную информацию. Результатом выполнения многих функций является список. Например, можно создать список из текстового описания фрейма данных, самого фрейма данных и обобщающей статистики по нему: d = &quot;Этот фрейм данных содержит данные по 6 линиям Московского метро&quot; s = summary(df) # summary() выдает обобщающую статистику вектору, матрице или фрейму данных Сооружаем список из трех элементов: metrolist = list(d, df, s) metrolist ## [[1]] ## [1] &quot;Этот фрейм данных содержит данные по 6 линиям Московского метро&quot; ## ## [[2]] ## Цвет Длина Станции Плотность ## 1 Красная 28.0 20 0.7142857 ## 2 Зеленая 40.0 21 0.5250000 ## 3 Синяя 45.0 22 0.4888889 ## 4 Коричневая 19.0 12 0.6315789 ## 5 Оранжевая 38.0 24 0.6315789 ## 6 Фиолетовая 40.5 22 0.4888889 ## ## [[3]] ## Цвет Длина Станции Плотность ## Зеленая :1 Min. :19.00 Min. :12.00 Min. :0.4889 ## Коричневая:1 1st Qu.:30.50 1st Qu.:20.25 1st Qu.:0.4979 ## Красная :1 Median :39.00 Median :21.50 Median :0.5783 ## Оранжевая :1 Mean :35.08 Mean :20.17 Mean :0.5800 ## Синяя :1 3rd Qu.:40.38 3rd Qu.:22.00 3rd Qu.:0.6316 ## Фиолетовая:1 Max. :45.00 Max. :24.00 Max. :0.7143 Можно дать элементам списка осмысленные названия при создании: metrolist = list(desc = d, table = df, summary = s) metrolist ## $desc ## [1] &quot;Этот фрейм данных содержит данные по 6 линиям Московского метро&quot; ## ## $table ## Цвет Длина Станции Плотность ## 1 Красная 28.0 20 0.7142857 ## 2 Зеленая 40.0 21 0.5250000 ## 3 Синяя 45.0 22 0.4888889 ## 4 Коричневая 19.0 12 0.6315789 ## 5 Оранжевая 38.0 24 0.6315789 ## 6 Фиолетовая 40.5 22 0.4888889 ## ## $summary ## Цвет Длина Станции Плотность ## Зеленая :1 Min. :19.00 Min. :12.00 Min. :0.4889 ## Коричневая:1 1st Qu.:30.50 1st Qu.:20.25 1st Qu.:0.4979 ## Красная :1 Median :39.00 Median :21.50 Median :0.5783 ## Оранжевая :1 Mean :35.08 Mean :20.17 Mean :0.5800 ## Синяя :1 3rd Qu.:40.38 3rd Qu.:22.00 3rd Qu.:0.6316 ## Фиолетовая:1 Max. :45.00 Max. :24.00 Max. :0.7143 Теперь можно обратиться к элементу списка по его названию: metrolist$summary ## Цвет Длина Станции Плотность ## Зеленая :1 Min. :19.00 Min. :12.00 Min. :0.4889 ## Коричневая:1 1st Qu.:30.50 1st Qu.:20.25 1st Qu.:0.4979 ## Красная :1 Median :39.00 Median :21.50 Median :0.5783 ## Оранжевая :1 Mean :35.08 Mean :20.17 Mean :0.5800 ## Синяя :1 3rd Qu.:40.38 3rd Qu.:22.00 3rd Qu.:0.6316 ## Фиолетовая:1 Max. :45.00 Max. :24.00 Max. :0.7143 Поскольку summary сама является фреймом данных, из нее можно извлечь столбец: metrolist$summary[,3] ## ## &quot;Min. :12.00 &quot; &quot;1st Qu.:20.25 &quot; &quot;Median :21.50 &quot; &quot;Mean :20.17 &quot; ## ## &quot;3rd Qu.:22.00 &quot; &quot;Max. :24.00 &quot; К элементу списка можно также обратиться по его порядковому номеру или названию, заключив их в двойные квадратные скобки: metrolist[[1]] ## [1] &quot;Этот фрейм данных содержит данные по 6 линиям Московского метро&quot; metrolist[[&quot;desc&quot;]] ## [1] &quot;Этот фрейм данных содержит данные по 6 линиям Московского метро&quot; Использование двойных скобок отличает списки от векторов. Вызов функции summary() в приложении к списку выведет статистику по типам и количеству элементов списка: summary(metrolist) ## Length Class Mode ## desc 1 -none- character ## table 4 data.frame list ## summary 24 table character 2.3 Факторы Понятие фактора в терминологии R используется для обозначения категориальной (качественной) переменной. Как известно, такие переменные могут быть номинальными (с неопределенным порядком) и порядковыми (с заданным отношением порядка). Проблема взаимодействия с категориальными переменными заключается в том, что они могут приобретать разнообразные формы: быть выражены в виде чисел и строк. Эта форма может быть обманчивой. Например, модели самолетов Boeing и Sukhoi SuperJet обознаются числами (747, 100 и т.д.). Однако очевидно, что складывать и вычитать такие числа смысла нет, они являются формой представления номинальной переменной. Другой пример: названия месяцев записываются в виде строк. Если попытаться отсортировать месяцы цветения различных видов деревьев, то получится бессмысленный алфавитный порядок, в котором апрель следует за августом. В данном случае проблема заключается в том, что мы имеем дело с категориальной переменной, в которой задан порядок следования допустимых значений. В географических данных категориальные переменные тоже достаточно распространены. К номинальной шкале измерений относятся всевозможные числовые коды: почтовые, ОКАТО и т.д. К порядковой шкале - административный статус населенного пункта, сила землетрясения по шкале Рихтера. Для того, чтобы соответствующие данные в среде R правильно обрабатывались статистическими функциями и отображались в виде подходящих графических способов, необходимо явным образом проинформировать об этом программу. Для этого и создаются факторы. Фактор построен по принципу ассоциативного массива и является надстройкой над вектором, в которой каждому значению вектора присваивается некий код. Вы можете управлять этими кодами, а можете оставить их на усмотрение программы. Например, каждая линия Московского метро имеет свой номер. Создадим небольшей фрейм данных с электродепо по интересующим нас веткам метро и рассчитаем по ним описательные статистики: depots = data.frame( depot = c(&#39;Северное&#39;, &#39;Черкизово&#39;, &#39;Сокол&#39;, &#39;Замоскворецкое&#39;, &#39;Братеево&#39;, &#39;Измайлово&#39;, &#39;Фили&#39;, &#39;Митино&#39;, &#39;Красная Пресня&#39;, &#39;Калужское&#39;, &#39;Свиблово&#39;), year_opened = c(1935, 1990, 1938, 1969, 2014, 1950, 1962, 2016, 1954, 1962, 1978), line_number = c(1, 1, 2, 2, 2, 3, 3, 3, 5, 6, 6) ) print(depots) ## depot year_opened line_number ## 1 Северное 1935 1 ## 2 Черкизово 1990 1 ## 3 Сокол 1938 2 ## 4 Замоскворецкое 1969 2 ## 5 Братеево 2014 2 ## 6 Измайлово 1950 3 ## 7 Фили 1962 3 ## 8 Митино 2016 3 ## 9 Красная Пресня 1954 5 ## 10 Калужское 1962 6 ## 11 Свиблово 1978 6 summary(depots) ## depot year_opened line_number ## Братеево :1 Min. :1935 Min. :1.000 ## Замоскворецкое:1 1st Qu.:1952 1st Qu.:2.000 ## Измайлово :1 Median :1962 Median :3.000 ## Калужское :1 Mean :1970 Mean :3.091 ## Красная Пресня:1 3rd Qu.:1984 3rd Qu.:4.000 ## Митино :1 Max. :2016 Max. :6.000 ## (Other) :5 Как видно, R посчитал нам средний номер линии метро - 3.091, что выглядит, мягко говоря, странновато. Чтобы этого не происходило, укажем в явном виде с помощью функции factor(), что номер линии метров является номинальной переменной: depots$line_number = as.factor(depots$line_number) print(depots$line_number) ## [1] 1 1 2 2 2 3 3 3 5 6 6 ## Levels: 1 2 3 5 6 Мы видим, что у переменной появился дополнительный атрибут Levels, который отвечает за список уникальных значений номинальной переменной. Отношение порядка мы здесь не вводим, поскольку номер является условным обозначением. Попробуем теперь посчитать описательные статистики по переменной и таблице в целом: mean(depots$line_number) ## [1] NA summary(depots) ## depot year_opened line_number ## Братеево :1 Min. :1935 1:2 ## Замоскворецкое:1 1st Qu.:1952 2:3 ## Измайлово :1 Median :1962 3:3 ## Калужское :1 Mean :1970 5:1 ## Красная Пресня:1 3rd Qu.:1984 6:2 ## Митино :1 Max. :2016 ## (Other) :5 Теперь мы видим, что вместо стандартных статистик R для переменной line_number выдает таблицу частот, из которой ясно, что на первой линии два депо, на второй линии три депо и так далее. 2.4 Описание структуры данных Для описания структуры данных можно использовать две широко используемые диагностические функции: class() выведет тип структуры, а str() выведет детальную выписку по компонентам этой структуры: class(depots) # тип объекта ## [1] &quot;data.frame&quot; str(depots) # структура объекта ## &#39;data.frame&#39;: 11 obs. of 3 variables: ## $ depot : Factor w/ 11 levels &quot;Братеево&quot;,&quot;Замоскворецкое&quot;,..: 8 11 9 2 1 3 10 6 5 4 ... ## $ year_opened: num 1935 1990 1938 1969 2014 ... ## $ line_number: Factor w/ 5 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;5&quot;,..: 1 1 2 2 2 3 3 3 4 5 ... 2.5 Циклы Цикл — это разновидность управляющей конструкции, предназначенная для организации многократного исполнения набора инструкций. В R циклы наиболее часто используются для пакетной обработки данных, ввода и вывода. Типичными примерами использования циклов являются чтение множества файлов входных данных, а также построение серий графиков и карт одного типа по различным данным. При этом обработка множества строк таблиц в R обычно организуется не средствами циклов, а средствами функций семейства lapply, о которых мы поговорим в главе, посвященной техникам программирования на R. Циклы обычно связаны с проходом по элементам списка/вектора либо с созданием такого списка/вектора. Поэтому они излагаются в настоящей главе. В R, как и во многих других языках программирования, существует несколько вариантов циклов. Первый вид циклов — это конструкция for с синтаксисом for (x in X) statement. Она означает, что: переменная x должна пробежать по всем элементам последовательности X. В качестве последовательности может выступать любой вектор или список. каждый раз, когда x будет присвоено значение очередного элемента из X, будет выполнено выражение statement, которое называют телом цикла. Соответственно, цикл выполнится столько раз, сколько элементов содержится в последовательности X. Выполнение тела цикла на каждом проходе называют итерацией. Например, с помощью цикла можно вывести на экран числа от 1 до 10, по одному с каждой строки: ## ЦИКЛЫ for (i in 1:10) print(i) ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 ## [1] 6 ## [1] 7 ## [1] 8 ## [1] 9 ## [1] 10 Если тело цикла содержит более одной инструкции R, оно должно быть заключено в фигурные скобки, иначе выполнится только первое выражение, а оставшиеся будут запущены один раз после выхода из цикла: for (i in 1:10) { a = factorial(i) # факториал i b = exp(i) # e в степени i print(a/b) # факториал растет быстрее экспоненты } ## [1] 0.3678794 ## [1] 0.2706706 ## [1] 0.2987224 ## [1] 0.4395753 ## [1] 0.8085536 ## [1] 1.784702 ## [1] 4.595885 ## [1] 13.52585 ## [1] 44.78295 ## [1] 164.7473 Другой вариант цикла организуется с помощью конструкции while, имеющей синтаксис while (condition) statement. Такая конструкция означает, что тело цикла будет выполняться, пока значение выражения condition (условия) равно TRUE. Как правило, в теле цикла обновляется некоторая переменная, которая участвует в проверке условия, и предполагается, что рано или поздно оно станет равным FALSE, что приведет к выходу из цикла. Например, вышеприведенный цикл, печатающий числа от 1 до 10, можно переписать на while следуюшим образом: i = 0 while(i &lt; 10) { i = i+1 print(i) } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 ## [1] 6 ## [1] 7 ## [1] 8 ## [1] 9 ## [1] 10 Обратите внимание на то, что мы внутри цикла обновляем значение переменной i. Увеличение значения переменной цикла называется инкрементом, а уменьшение — декрементом. Одной из самых распространенных ошибок программистов (особенно начинающих, но и професионалы ее не избегают) является забытая инструкция инкремента (или декремента) переменной цикла, в результате чего цикл становится бесконечным. В этом плане конструкция for более надежна. В качестве примера приведем проход по столбцам фрейма данных и вычисление медианного значения для каждого столбца таблицы линий метро: n = ncol(df) medians = vector(&#39;numeric&#39;, n) for (i in 1:n) { if(is.numeric(df[, i])){ medians[i] = median(df[, i]) } else { medians[i] = NA } } colnames(df) # Переменные ## [1] &quot;Цвет&quot; &quot;Длина&quot; &quot;Станции&quot; &quot;Плотность&quot; medians # Медианные значения ## [1] NA 39.0000000 21.5000000 0.5782895 Существуют специальные операторы, позволяющие принудительно прервать текущую итерацию цикла и перейти на следующую, а также выйти из цикла вообще. Они называются next и break. Они бывают полезны, когда в теле цикла может произойти событие, делающее невозможным (или бессмысленным) его дальнейшее выполнение. Например, мы можем выводить информацию об электродепо, имеющихся на линии метро с введенным пользователем номером, до тех пор, пока он не введет символ q. Чтобы цикл был бесконечным, используем специальную форму while (TRUE): while (TRUE) { cat(&#39;Введите номер ветки метро:&#39;) input = readline() if (input == &#39;q&#39;) break else { n = as.numeric(input) if (!is.na(n)) depots[depots$line_number == n, ] } } Оператор next используется реже, так как в принципе он взаимозаменяем с конструкцией if-else. Он бывет удобен, когда в длинном цикле имеется несколько мест, в которых возможен переход на следующую итерацию. При использовании next последующий код нет необходимости табулировать и забирать в скобки. Следующие паттерны идентичны, но вариант с next позволяет остаться на том же уровне вложенности: Паттерн 1: while (...) { if (condition1) next ... # сюда попадем, только если condition1 == FALSE if (condition2) next ... # сюда попадем, только если condition2 == FALSE } Паттерн 2: while (...) { if (!condition1) { ... # сюда попадем, только если condition1 == FALSE if (!condition2) { ... # сюда попадем, только если condition2 == FALSE } } } 2.6 Технические детали Внутреннюю структуру и размер объекта можно исследовать с помощью пакета lobstr. Например, посмотрим, как организован в пямяти объект metrolist: library(lobstr) ref(metrolist) ## █ [1:0x7fee60534078] &lt;named list&gt; ## ├─desc = [2:0x7fee61d63688] &lt;chr&gt; ## ├─table = █ [3:0x7fee5734cc28] &lt;df[,4]&gt; ## │ ├─Цвет = [4:0x7fee67c6ee88] &lt;fct&gt; ## │ ├─Длина = [5:0x7fee70791878] &lt;dbl&gt; ## │ ├─Станции = [6:0x7fee70751a78] &lt;dbl&gt; ## │ └─Плотность = [7:0x7fee707913a8] &lt;dbl&gt; ## └─summary = [8:0x7fee96c21070] &lt;table&gt; obj_size(metrolist) ## 5,696 B 2.7 Краткий обзор Для просмотра презентации щелкните на ней один раз левой кнопкой мыши и листайте, используя кнопки на клавиатуре: Презентацию можно открыть в отдельном окне или вкладке браузере. Для этого щелкните по ней правой кнопкой мыши и выберите соответствующую команду. 2.8 Контрольные вопросы и упражнения 2.8.1 Вопросы На какие две большие группы можно разделить структуры данных в R? Чем он отличаются? Что такое вектор в языке R? Какие способы создания векторов существуют? Можно ли хранить в векторе данные разных типов? Как определить длину вектора? Как извлечь из вектора элемент по его индексу? Как извлечь из вектора множество элементов по их индексам? Как извлечь из вектора последний элемент? С помощью какой функции можно сгенерировать последовательность чисел или дат с заданным шагом? Как сгенерировать последовательность целых чисел с шагом 1, не прибегая к функциям? Можно ли применять к векторам арифметические операторы и математические функции? Что будет результатом их выполнения? С помощью какой функции можно отсортировать вектор? Как изменить порядок сортировки на противоположный? С помощью какой функции можно найти индекс элемента вектора по его значению? Что вернет функция, если этот элемент встречается в векторе несколько раз? Как работает функция ifelse() и для чего она используется? Как работает функция summary() и для чего она используется? Какая функция позволяет создать матрицу? По строкам или по столбцам заполняется матрица при использовании вектора как источника данных по умолчанию? Как извлечь элемент по его индексам из матрицы, массива, фрейма данных, списка? Как извлечь строку или столбец из матрицы или фрейма данных? С помощью какого специального символа можно обратиться к столбцу фрейма данных по его названию? Как получить или записать названия столбцов фрейма данных? Как получить или записать названия строк фрейма данных? Какая структура данных является результатом сортировки матрицы? Какая функция позволяет осуществить транспонирование матрицы? Какой оператор используется для умножения матриц? Каким критериям должны отвечать перемножаемые матрицы, чтобы эта операция была осуществима? Как добавить новый столбец в фрейм данных? Опишите несколько вариантов. Как добавить новую строку в фрейм данных? Что произойдет, если к целочисленной матрице прибавить столбец, заполненный строками? Какая функция позволяет находить индексы элементов матрицы или фрейма данных по их значениям? Что такое цикл и для каких сценариев обработки данных могут быть полезны циклы? Перечислите несколько способов организации циклов в R, необходимые ключевые слова и параметры. Что такое инкремент и декремент? Какое ключевое слово позволяет прервать цикл и выйти из него принудительно? Какое ключевое слово позволяет прекратить текущую итерацию цикла и перейти сразу к новой итерации? Являются ли необходимыми фигурные скобки в случае когда цикл или условный оператор содержит только одно выражение? Что говорит об этом стиль программирования на R? 2.8.2 Упражнения Создайте вектор temp, в котором хранятся значения среднемесячных температур воздуха в городе Санкт-Петербурге (данные можно взять здесь). Напишите программный код, который вычисляет следующие вектора: количественное изменение температуры от месяца к месяцу (в градусах) качественное изменение температуры от месяца к месяцу ('потепление' или 'похолодание'); номера зимних месяцев (со среднемесячной температурой ниже нуля); описательные статистики среднемесячных температур (summary); Выведите исходные и вычисленные данные в консоль (с пояснением что они означают). Подсказка: для вычисления разностей между элементами вектора используйте функцию diff(). На местности задан прямоугольник с координатами левого нижнего (x1, y1) и правого верхнего (x2, y2) угла. Напишите программу, которая размещает внутри этого прямоугольника случайным образом N точек и представляет результат в виде матрицы координат coords с двумя столбцами и N строками. Вызовите в конце программы plot(coords), чтобы посмотреть на результат. Координаты можно не вводить, а задать прямо в программе в виде переменных. Подсказка: координаты случайно размещенных точек имеют равномерное распределение. Вам необходимо сначала сформировать случайные векторы координат X и Y, и после этого объединить их в матрицу. Высотная поясность на северном склоне Западного Кавказа, согласно Большой Российской энциклопедии устроена следующим образом: до 500 м — степь и лесостепь до 800 м — низкогорные широколиственные леса (дуб, граб) до 1300 м — среднегорные широколиственные леса (бук) до 1600 м — смешанные леса (ель, пихта, бук) до 2300 м — криволесия (береза, бук, клён) до 2500 м — субальпийские и альпийские луга до 3300 м — субнивальная зона (фрагментарная растительность) выше (условно до 5000 м) — гляциально-нивальная зона Создайте фрейм данных, включающий три столбца: минимальная высота пояса (Hmin), максимальная высота пояса (Hmax) и название высотного пояса (Zone). Минимальную высоту надо вычислить на основе максимальной, приняв, что для нижнего пояса она условно равна \\(400~м\\). Напишите программу, которая просит пользователя ввести высоту и возвращает высотный пояс, соответствующую введенной высоте (достаточно вывести строчку фрейма данных). Подсказка: Организуйте обход строчек фрейма данных с помощью цикла от \\(1\\) до \\(N\\), где \\(N\\) — количество строк. Искомый пояс будет найден, как только введенное значение станет меньше чем Hmax. После этого можно вывести результат на экран. Если введенное значение больше максимума в столбце Hmax или меньше \\(400\\), программа должна выдавать ошибку. [advanced] Решите задачу №3, используя только операции над векторами и поиск элементов, и не используя циклы. [advanced] Модифицируйте программу, написанную для решения задачи №2 таким образом, чтобы запретить точкам сближаться более чем на заданное расстояние k (это называется регулярным распределением с расстоянием ингибиции k). Сохраните результат в виде фрейма данных points со столбцами X, Y и D, где D – это расстояние до ближайшей точки. Выведите верхние строчки полученной таблицы в консоль, а также полученные точки с помощью команды plot(coords$X, coords$Y). Подсказка: вам придется генерировать в цикле по одной точке и проверять условие на каждой итерации до тех пор, пока вы не наберете требуемое количество точек. Задавайте значение k малым по отношению к размерам прямоугольника, чтобы избежать излишне долгого выполнения программы. Самсонов Т.Е. Визуализация и анализ географических данных на языке R. М.: Географический факультет МГУ, 2020. DOI: 10.5281/zenodo.901911 "],
["tables.html", "Глава 3 Табличные данные 3.1 Предварительные требования 3.2 Структуры данных 3.3 Чтение 3.4 Просмотр 3.5 Столбцы, строки и ячейки 3.6 Преобразования 3.7 Соединение 3.8 Запись 3.9 Рекомендации по подготовке таблиц для чтения в R 3.10 Краткий обзор 3.11 Контрольные вопросы и упражнения", " Глава 3 Табличные данные 3.1 Предварительные требования Для работы по теме текущей лекции вам понадобятся пакеты из tidyverse, а также writexl. Установите их, используя следующую команду: install.packages(&#39;tidyverse&#39;) install.packages(&#39;writexl&#39;) Внимание: установка пакетов выполняется один раз из консоли. Вызов функции install.packages() не должен присутствовать в ваших скриптах tidyverse – это не самостоятельный пакет, а набор пакетов R, которые позволяют автоматизировать решение рутинных задач по обработке данных (то, что принято называть data science). В комплект tidyverse входят следующие пакеты: Пакет Назначение tibble Усовершенствованный вариант фрейма данных dplyr Грамматика манипуляций над табличными данными tidyr Приведение таблиц в аккуратный вид, удобный для обработки readr Чтение табличных данных из текстовых файлов readxl Чтение табличных данных из файлов Microsoft Excel haven Чтение табличных данных из файлов SPSS, Stata и SAS purrr Функциональное программирование stringr Работа со строками forcats Автоматизация работы с факторами ggplot2 Построение графиков на основе правил грамматики Вы можете подключать эти пакеты по одному, или сделать их все доступными в текущей сессии R, используя команду library(tidyverse). В текущей лекции мы будем подключать их по мере необходмости, чтобы акцентировать внимание на принадлежности функций к соответствующим пакетам. Вы можете вызвать функцию из любого пакета, не подключая его целиком в текущую сессию R. Это бывает особенно полезно, когда вы редко используете функции из пакета. В этом случае вызов функции будет выглядеть как package::function(), где package – название пакета, а function - название функции. Подобный синтаксис бывает особенно удобным, когда в разных пакетах имеются функции с одинаковым именем, и при вызове R использует не ту, которая нужна (по умолчанию будет использована функция из пакета, который был подключен позже). 3.2 Структуры данных Стандартным средством представления табличных данных в R являются фреймы данных (data.frame), кратко рассмотренные в предыдущей лекции. В современных пакетах типа tidyverse используется разновидность фрейма данных, которая называется тиббл (tibble). Создать тиббл можно напрямую, либо путем конвертации фрейма данных: library(tibble) tibble( a = 1:3, b = 1, c = -1:1 ) ## # A tibble: 3 x 3 ## a b c ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1 1 -1 ## 2 2 1 0 ## 3 3 1 1 dfr = data.frame(a = 1:3, b = 1, c = -1:1) as_tibble(dfr) ## # A tibble: 3 x 3 ## a b c ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1 1 -1 ## 2 2 1 0 ## 3 3 1 1 Тиббл является расширением класса фрейма данных, то есть любая операция, применимая к фрейму, применима и к тибблу. Однако, тиббл поддерживает дополнительные возможности, которые оказываются очень удобны в анализе: При выводе в консоль тиббл печатает только те столбцы, которые помещаются на экран, и только первые 10 строк (что позволяет избежать переполнения консоли при печати больших таблиц) Тибблы поддерживают имена столбцов, которые недопустимы в фреймах данных (например, начинающиеся с цифры). Так называть столбцы, вообще говоря, неправильно, но это позволяет сохранить именно те названия, которые даны в исходных файлах. Например, географические таблицы часто содержат данные за разные года, и столбцы названы по этим годам. Тибблы поддерживают внутренние группировки данных. Установив группировку по одной или нескольким переменным, можно эффективным и компактным путем считать агрегирующие статистики по группам измерений. Тибблы можно создавать вручную не только по столбцам, но и по строкам. Для реализации последней возможности можно использовать функцию tribble() (переводится как transposed tibble — транспонированный тиббл), указав имена столбцов с помощью тильды (~): tribble( ~a, ~b, ~c, 1, 1, -1, 2, 1, 0, 3, 1, 1 ) ## # A tibble: 3 x 3 ## a b c ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 -1 ## 2 2 1 0 ## 3 3 1 1 В данной и последующих лекциях понятия мы будем использовать понятия таблица, фрейм данных и тиббл как взаимозаменяемые. 3.3 Чтение Существует множество способов получить набор табличных данных в текущей сессии R. Эти способы варьируются от загрузки данных из пакета до извлечения таблиц из текстовых документов и веб-страниц. В настоящей главе мы рассмотрим наиболее распространенные способы, нацеленные на работу с готовыми таблицами. 3.3.1 Встроенные данные Пакеты R часто содержат тестовые наборы данных. Эти данные, как правило, предназначены для ознакомления с возможностями пакета. Чтобы узнать, какие данные есть в пакете, вы можете вызвать функцию data(package = 'packagename'), где packagename — это имя интересующего вас пакета. Например, посмотрим, какие данные есть в пакете dplyr, который мы далее будем использовать для манипуляций с таблицами: data(package = &#39;dplyr&#39;) Данные, доступные в пакете dplyr На рисунке можно видеть перечень наборов данных и их краткие описания. Для загрузки набора данных передайте его название в качестве первого параметра функции data(). Ну-ка, что там с персонажами из Star Wars: data(starwars, package = &#39;dplyr&#39;) starwars ## # A tibble: 87 x 13 ## name height mass hair_color skin_color eye_color birth_year gender ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Luke… 172 77 blond fair blue 19 male ## 2 C-3PO 167 75 &lt;NA&gt; gold yellow 112 &lt;NA&gt; ## 3 R2-D2 96 32 &lt;NA&gt; white, bl… red 33 &lt;NA&gt; ## 4 Dart… 202 136 none white yellow 41.9 male ## 5 Leia… 150 49 brown light brown 19 female ## 6 Owen… 178 120 brown, gr… light blue 52 male ## 7 Beru… 165 75 brown light blue 47 female ## 8 R5-D4 97 32 &lt;NA&gt; white, red red NA &lt;NA&gt; ## 9 Bigg… 183 84 black light brown 24 male ## 10 Obi-… 182 77 auburn, w… fair blue-gray 57 male ## # … with 77 more rows, and 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, ## # films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt; Обратите внимание, что после подключения набора данных он становится доступным в текущей сесси R именно с тем именем, с которым он сохранен в пакете Если вызвать функцию data() без параметров, будет выведен список данных со всех пакетов, которые подключены в текущей сессии R: data() Данные, доступные в текущей сессии R По умолчанию в RStudio всегда подключен пакет datasets, который устанавливается вместе с базовым дистрибутивом R. Если пакет подключен в текущую сессию, то можно получить набор данных по его имени, не указывая название пакета. Например, в пакете datasets есть набор данных quakes о землетрясениях на о. Фиджи: data(quakes) head(quakes) # просмотрим макушку таблицы ## lat long depth mag stations ## 1 -20.42 181.62 562 4.8 41 ## 2 -20.62 181.03 650 4.2 15 ## 3 -26.00 184.10 42 5.4 43 ## 4 -17.97 181.66 626 4.1 19 ## 5 -20.42 181.96 649 4.0 11 ## 6 -19.68 184.31 195 4.0 12 Таким образом, если вы используйете пакет dplyr в своей программе, данные о героях Звездных Войн можно загрузить не указывая пакет, т.к. он был ранее подключен через функцию library(): library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union data(starwars) 3.3.2 Текстовые таблицы Текстовые таблицы бывают, как правило, двух типов: с разделителем (CSV) и с фиксированной шириной столбца. 3.3.2.1 Файлы с разделителем CSV (Comma-separated value) — общее название для формата представления таблиц в виде текстовых файлов, организованных по следующему принципу: Каждая строка в файле соответствует строке в таблице. Ячейки отделяются друг от друга символом-разделителем. Если ячейка пустая, то между соседними разделителями не должно быть никаких символов. Стандартным разделителем ячеек является запятая (,), а десятичным разделителем — точка (.). Однако это не является строгим правилом. Например, в ряде локалей (например, русской) запятая используется в качестве десятичного разделителя, поэтому колонки часто разделяют точкой с запятой (;). Формат CSV никак не оговаривает наличие заголовочной строки с названиями столбцов в начале файла — она может как отсутствовать, так и присутствовать. Поэтому при чтении таблиц из файлов необходимо информировать программу о наличии заголовка путем указания соответствующего параметра. Любая функция, используемая вами для чтения файлов, вне зависимости от пакета, который вы используете, как правило, содержит параметры, с помощью которых можно задать символы, отвечающие за десятичный разделитель и разделитель столбцов, а также наличие или отсутствие строки-заголовка и кодировку файла. Если таблица читается некорректно, ознакомьтесь со справкой к функции и при необходимости замените стандартные значения этих параметров на те, что соответствуют формату вашей таблицы. Например, вот так выглядит текстовая таблица в формате CSV с данными по численности населения в Федеральных округах Российской Федерации за 2005 и 2010-2013 гг. (по данным Росстата): N,Region,Year05,Year10,Year11,Year12,Year13 1,Центральный,4341,3761,3613,3651,3570 2,Северо-Западный,3192,3088,2866,2877,2796 3,Южный федеральный,1409,1446,1436,1394,1321 4,Северо-Кавказский,496,390,397,395,374 5,Приволжский,3162,2883,2857,2854,2849 6,Уральский,1681,1860,1834,1665,1624 7,Сибирский,2575,2218,2142,2077,1941 8,Дальневосточный,871,870,821,765,713 Таблицы в формате CSV можно прочесть как с помощью стандартных средств языка R, так и с помощью пакета readr, который входит в набор пакетов tidyverse. Мы будем использовать последние, а стандартные средства языка оставим на самостоятельное изучение. Для чтения таблиц с разделителем в readr имеется несколько функций: read_csv() читает файлы с разделителем запятой read_csv2() читайт файоы с разделителем точкой-с-запятой (может быть особенно актуально для русских файлов) read_tsv() читает файлы с разделителем табуляцией или пробелом read_delim() читает файлы с произвольным разделителем (указывается в качестве параметра) Вышеуказанный файл сохранен с разделителем запятой, поэтому мы можем прочесть его посредством первой функции из списка: library(readr) (okruga = read_csv(&#39;data/okruga.csv&#39;)) ## Parsed with column specification: ## cols( ## `№` = col_double(), ## Регион = col_character(), ## `2005` = col_double(), ## `2010` = col_double(), ## `2011` = col_double(), ## `2012` = col_double(), ## `2013` = col_double() ## ) ## # A tibble: 8 x 7 ## `№` Регион `2005` `2010` `2011` `2012` `2013` ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 Центральный 4341 3761 3613 3651 3570 ## 2 2 Северо-Западный 3192 3088 2866 2877 2796 ## 3 3 Южный федеральный 1409 1446 1436 1394 1321 ## 4 4 Северо-Кавказский 496 390 397 395 374 ## 5 5 Приволжский 3162 2883 2857 2854 2849 ## 6 6 Уральский 1681 1860 1834 1665 1624 ## 7 7 Сибирский 2575 2218 2142 2077 1941 ## 8 8 Дальневосточный 871 870 821 765 713 Как видно, функции пакета readr выдают диагностическую информацию о том, к какому типу были приведены столбцы таблицы при чтении. Помимо этого, первая строка была использована в качестве заголовочной. 3.3.2.2 Файлы с фиксированной шириной столбца В файлах с фиксированной шириной на каждый столбец резервируется определенное количество символов. При этом данные выравниваются по правому краю, а короткие строки отбиваются слева пробелами. Такой формат часто используется в численных моделях (например, метеорологических) для представления входных данных или результатов расчетов. Например, файл ниже содержит данные об энергии ветра (\\(Вт/м^2\\)) на высотах 50 и 110 м по точкам вдоль побережья Черного моря: 1 43.500000 28.000000 111.05298 178.41447 2 43.500000 28.500000 187.38620 301.05331 3 44.000000 28.500000 168.82031 271.22421 4 44.500000 28.500000 157.22586 252.59746 5 44.500000 29.000000 189.46452 304.39597 6 45.000000 29.000000 170.40709 273.77536 7 45.000000 29.500000 198.92389 319.58777 8 45.500000 29.500000 188.64406 303.07242 9 46.000000 30.000000 180.10541 289.35379 10 46.000000 30.500000 207.91818 334.03564 Для чтения таких файлов в readr есть функции: read_fwf() читает файлы с фиксированной шириной столбца, позволяя задавать ширины столбцов (через fwf_widths()) или начальные позиции каждого столбца (через fwf_positions()) read_table() читает наиболее распространенный вариант файла с фиксированной шириной столбца, в котором колонки разделены пробелами. Позиции столбцов определяются автоматически, что очень удобно. Прочитаем вышеприведенный файл с данными о ветровой энергии: (wenergy = read_table(&#39;data/wind_energy.txt&#39;, col_names = c(&#39;id&#39;, &#39;lat&#39;, &#39;lon&#39;, &#39;energy50&#39;, &#39;energy110&#39;))) ## Parsed with column specification: ## cols( ## id = col_double(), ## lat = col_double(), ## lon = col_double(), ## energy50 = col_double(), ## energy110 = col_double() ## ) ## # A tibble: 92 x 5 ## id lat lon energy50 energy110 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 43.5 28 111. 178. ## 2 2 43.5 28.5 187. 301. ## 3 3 44 28.5 169. 271. ## 4 4 44.5 28.5 157. 253. ## 5 5 44.5 29 189. 304. ## 6 6 45 29 170. 274. ## 7 7 45 29.5 199. 320. ## 8 8 45.5 29.5 189. 303. ## 9 9 46 30 180. 289. ## 10 10 46 30.5 208. 334. ## # … with 82 more rows 3.3.3 Таблицы Microsoft Excel Для чтения таблиц Microsoft Excel, так же как и для текcтовых файлов, существуют множество пакетов, таких как xlsx, openxlsx и readxl. D настоящем курсе мы будем пользоваться пакетом readxl, поскольку он не имеет внешних зависимостей, а его функции концептуально идентичны функциям пакета readr. Прочтем данные о лесовосстановлении (в тысяч га), полученные из регионального ежегодника Росстата за 2017 год. Эта таблица содержит колонку с названием субъекта и еще 8 колонок с данными по годам. Поскольку в таблице есть пропущенные значения, необходимо определить типы столбцов (в противном случае они могут быть определены как текстовые): library(readxl) (reforest = read_excel(&#39;data/reforest.xlsx&#39;, col_types = c(&#39;text&#39;, rep(&#39;numeric&#39;, 8)))) ## # A tibble: 89 x 9 ## Region `2005` `2010` `2011` `2012` `2013` `2014` `2015` `2016` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Российская Федерация 812. 812. 860 842. 872. 863 803. 840. ## 2 Центральный федераль… 52.6 62.7 60.9 60.3 70.9 71.2 72.6 77 ## 3 Белгородская область 0.4 0.1 0.3 0.3 0.4 0.4 0.2 0.2 ## 4 Брянская область 2.9 2.8 3 3.2 3.5 3.3 3.1 3 ## 5 Владимирская область 4.4 5.3 5.7 6 7.1 5.9 6 4.9 ## 6 Воронежская область 1.1 1.1 1.8 3 2.7 2.7 2.6 2.3 ## 7 Ивановская область 2.1 1.6 2.2 3.1 4 4.8 4.6 4.2 ## 8 Калужская область 2.2 2.3 2.3 2.5 2.4 3.1 3.2 3.2 ## 9 Костромская область 10 25.2 11 11.8 15.3 13.6 15.1 16.4 ## 10 Курская область 0.5 0.3 0.4 0.6 0.6 0.6 0.5 0.4 ## # … with 79 more rows 3.3.4 Параметры Функции пакетов readr и readxl имеют идентичный набор параметров, позволяющих управлять процедурой чтения данных (многоточие используется вместо перечисления параметров): skip = n позволяет пропустить первые n строк таблицы (например, если в них содержатся какие-то комментарии) col_names = FALSE позволяет не интерпретировать первую строку как заголовочную (вместо этого она будет читаться как строка с данными) col_names = c(...) позволяет задать имена столбцов (удобно, если в файле они длинные) col_types = cols(...) позволяет задать типы столбцов (необходимо, если функция неправильно определяет их сама) na = '-' позволяет указать символ, который используется для указания пропущенных значений (в данном случае указан прочерк-дефис) locale = locale(...) управляет локалью (в том числе позволяет указать кодировку файла) Стандартной кодировкой для представления текста в UNIX-подобных системах (Ubuntu, macOS и т.д.) является UTF-8 (Unicode), в русскоязычных версиях Windows — CP1251 (Windows-1251). Текстовый файл CSV, созданный в разных операционных системах, будет по умолчанию сохраняться в соответствующей кодировке, если вы не указали ее явным образом. Если при загрузке таблицы в R вы видите вместо текста нечитаемые символы — кракозябры — то, скорее всего, вы читаете файл не в той кодировке, в которой он был сохранен. Если вы не знаете, что такое кодировка и Юникод, то вам сюда По умолчанию файлы читаются в той кодировке, которая соответствует операционной системе, на которой запущен R. Если файл создан в другой кодировке, придется указать ее при чтении. Например, вы пользуетесь macOS (UTF-8), а ваш коллега — Windows (CP1251), то для чтения созданного им файла вам, скорее всего, понадобится указать что-то вроде locale = locale(encoding = 'CP1251') 3.4 Просмотр Для просмотра фрейма данных в консоли RStudio вы можете использовать несколько опций. Пусть наш фрейм данных называется reforest. Тогда: print(reforest) — выводит фрейм в консоль целиком (можно написать просто tab в консоли). head(reforest, n) — отбирает первые \\(n\\) строк фрейма tail(reforest, n) — отбирает последние \\(n\\) строк фрейма По умолчанию для функций head() и tail() \\(n=6\\). Обычно этот параметр опускают, поскольку нужно просмотреть только первые несколько строк и шести вполне достаточно. Если вы напечатаете в консоли head(reforest) или tail(reforest), то для выбранных строк будет вызвана функция print(), аналогично выводу всего фрейма: # ПРОСМОТР ТАБЛИЦЫ print(reforest) ## # A tibble: 89 x 9 ## Region `2005` `2010` `2011` `2012` `2013` `2014` `2015` `2016` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Российская Федерация 812. 812. 860 842. 872. 863 803. 840. ## 2 Центральный федераль… 52.6 62.7 60.9 60.3 70.9 71.2 72.6 77 ## 3 Белгородская область 0.4 0.1 0.3 0.3 0.4 0.4 0.2 0.2 ## 4 Брянская область 2.9 2.8 3 3.2 3.5 3.3 3.1 3 ## 5 Владимирская область 4.4 5.3 5.7 6 7.1 5.9 6 4.9 ## 6 Воронежская область 1.1 1.1 1.8 3 2.7 2.7 2.6 2.3 ## 7 Ивановская область 2.1 1.6 2.2 3.1 4 4.8 4.6 4.2 ## 8 Калужская область 2.2 2.3 2.3 2.5 2.4 3.1 3.2 3.2 ## 9 Костромская область 10 25.2 11 11.8 15.3 13.6 15.1 16.4 ## 10 Курская область 0.5 0.3 0.4 0.6 0.6 0.6 0.5 0.4 ## # … with 79 more rows head(reforest) ## # A tibble: 6 x 9 ## Region `2005` `2010` `2011` `2012` `2013` `2014` `2015` `2016` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Российская Федерация 812. 812. 860 842. 872. 863 803. 840. ## 2 Центральный федеральн… 52.6 62.7 60.9 60.3 70.9 71.2 72.6 77 ## 3 Белгородская область 0.4 0.1 0.3 0.3 0.4 0.4 0.2 0.2 ## 4 Брянская область 2.9 2.8 3 3.2 3.5 3.3 3.1 3 ## 5 Владимирская область 4.4 5.3 5.7 6 7.1 5.9 6 4.9 ## 6 Воронежская область 1.1 1.1 1.8 3 2.7 2.7 2.6 2.3 tail(reforest) ## # A tibble: 6 x 9 ## Region `2005` `2010` `2011` `2012` `2013` `2014` `2015` `2016` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Хабаровский край 107. 70.2 68.7 67.2 58.4 50.5 59.6 60.3 ## 2 Амурская область 33.3 29.8 32.2 33.6 35.5 37.7 28.5 27.7 ## 3 Магаданская область 2.7 2.6 2.6 2.8 3 2.5 0.4 NA ## 4 Сахалинская область 13.1 12.7 12.5 4.6 4.7 4.9 4.7 4.1 ## 5 Еврейская автономная … 2.9 NA 2.6 2.5 2.3 NA NA 2.4 ## 6 Чукотский автономный … 0.3 NA NA NA NA NA NA NA RStudio предоставляет графический интерфейс для просмотра таблиц, в котором таблицу можно сортировать и фильтровать. Чтобы его активировать, надо вызвать функцию View(): View(tab) Поскольку функции head() и tail() возвращают строки с хвоста или начала фрейма данных, их можно и подать на вход функции View(): View(head(reforest, 3)) Как правило, не следует оставлять вызовы функции View() в тексте законченной программы. Это приведет к тому, что при запуске будут открываться новые вкладки с просмотром таблиц, что может раздражать пользователя (в том числе и вас самих). Используйте View() для вывода окончательного результата в конце программы или при отладке программы. Все вызовы View() в программе можно легко закомментировать или раскомментировать, выполнив поиск с заменой 'View(' на '# View(' и наоборот. 3.5 Столбцы, строки и ячейки 3.5.1 Названия Столбцы, строки и ячейк представляют собой основные структурные элементы фрейма данных или тиббла. Перед тем как мы поднимемся на уровень выше и рассмотрим обобщенные операции преобразования таблиц, необходимо посмотреть, как извлекать структурные элементы таблиц. Столбцы и строки таблицы имеют названия, которые можно читать и записывать с помощью функций colnames() и rownames(): # Чтение названий столбцов и строк colnames(okruga) ## [1] &quot;№&quot; &quot;Регион&quot; &quot;2005&quot; &quot;2010&quot; &quot;2011&quot; &quot;2012&quot; &quot;2013&quot; rownames(okruga) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; &quot;7&quot; &quot;8&quot; # Замена названий столбцов и строк colnames(okruga) &lt;- c(&quot;N&quot;, &quot;Region&quot;, &quot;Year05&quot;, &quot;Year10&quot;, &quot;Year11&quot;, &quot;Year12&quot;, &quot;Year13&quot;) print(okruga) ## # A tibble: 8 x 7 ## N Region Year05 Year10 Year11 Year12 Year13 ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 Центральный 4341 3761 3613 3651 3570 ## 2 2 Северо-Западный 3192 3088 2866 2877 2796 ## 3 3 Южный федеральный 1409 1446 1436 1394 1321 ## 4 4 Северо-Кавказский 496 390 397 395 374 ## 5 5 Приволжский 3162 2883 2857 2854 2849 ## 6 6 Уральский 1681 1860 1834 1665 1624 ## 7 7 Сибирский 2575 2218 2142 2077 1941 ## 8 8 Дальневосточный 871 870 821 765 713 Названия строк редко заменяются, поскольку с точки зрения реляционной алгебры большого смысла они не имеют. 3.5.2 Обращение к столбцам К столбцу можно обращаться по номеру и названию (с помощью оператора $ или в кавычках внутри скобок). Если вы указываете в квадратных скобках номер без запятой, он трактуется именно как номер столбца, а не строки. Тип возвращаемого значения зависит от синтаксиса: обращение через $ возвращает вектор; обращение в скобках с запятой к одному столбцу возвращает вектор; обращение в скобках с запятой к нескольким столбцам возвращает фрейм данных; обращение в скобках без запятой возвращает фрейм данных. Несколько примеров: # Один столбец - результат зависит от запятой okruga$Year05 # столбец в виде вектора okruga[, &quot;Year05&quot;] # столбец в виде вектора okruga[, 2] # столбец в виде вектора okruga[&quot;Year05&quot;] # столбец в виде фрейма данных/тиббла okruga[2] # столбец в виде фрейма данных/тиббла # Несколько столбцов - всегда фрейм данных/тиббл okruga[, c(1, 4)] okruga[, c(&quot;Region&quot;, &quot;Year11&quot;)] okruga[c(&quot;Region&quot;, &quot;Year11&quot;)] okruga[c(1, 4)] 3.5.3 Обращение к строкам Обращаться к строкам можно по их номерам. В этом случае в качестве индекса можно передать номер (номера) интересующих строк, либо вектор логических значений, в котором интересующие строки помечены как TRUE, а остальные — FALSE (в этом случае длина вектора должна равняться количеству строк в таблице): okruga[5, ] # Одна строка okruga[2:4, ] # Несколько строк okruga[okruga$Year10 &gt; 2000, ] # Несколько строк через TRUE/FALSE В отличие от работы со столбцами, выбор строк всегда возвращает таблицу (фрейм или тиббл). 3.5.4 Обращение к ячейкам Чтобы выбрать конкретные ячейки в таблице, необходимо задать оба измерения: okruga[2:3, c(&quot;Year11&quot;, &quot;Year12&quot;)] ## # A tibble: 2 x 2 ## Year11 Year12 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 2866 2877 ## 2 1436 1394 Обратите внимание на то, что при этом возвращаются все комбинации строк и столбцов. То есть, нельзя выбрать ячейки 2,\"Year11\" и 3,\"Year2\" — вместе с ними также будут выбраны ячейки 3,\"Year11\" и 2,\"Year2\". Впрочем, подобные задачи возникают довольно редко 3.6 Преобразования 3.6.1 Грамматика манипуляций Если проанализировать наиболее типичные манипуляции, которые осуществляются над таблицами, то их окажется совсем немного. К таким манипуляциям относятся выбор переменных, фильтрация строк, сортировка, вычисление новых столбцов, агрегирующие статистики и группировка. Все эти задачи можно решать стандартными средствами R (и мы увидим, как это делается). Однако некоторые из них достаточно громоздки в реализации (например, группировка). К счастью, экосистема R предлагает готовые средства, позволяющие справляться с подобными задачами простым и элегантным путем. Эти средства предоставляет пакет dplyr (произносится как deep liar — ‘диплáйер’), входящий в набор инструментов tidyverse. В основе конецепции dplyr лежит понятие о грамматике табличных манипуляций, которая включает в себя ограниченное число наиболее используемых операций, а также ряд вспомогательных функций. Основные функции пакета dplyr представлены в таблице ниже: Функция Назначение select() Выбор переменных по их названиям filter() Выбор строк по заданному критерию (запросу) arrange() Упорядочение по указанным переменным mutate() Вычисление новых переменных (мутирование) summarise() Агрегирование значений переменных group_by() Группировка строк (для последующего агрегирования) Как можно видеть, этих функций совсем немного. Дополнительно к ним пакет dplyr содержит еще множество вспомогательных функций, которые применяются при выполнении основных манипуляций. Рассмотрим применение этих функций на примере работы с таблицей по восстановлению лесного фонда в регионах России. Для начала переименуем столбцы с годами, чтобы их названия начинались с буквы y: old_names = colnames(reforest) colnames(reforest) = c(old_names[1], paste(&#39;y&#39;, old_names[2:9], sep = &#39;&#39;)) Начнем с выбора нужных переменных, используя select(). Оставим только название региона и данные за 2010 и 2015 гг: library(dplyr) (rdf = select(reforest, Region, y2010, y2015)) ## # A tibble: 89 x 3 ## Region y2010 y2015 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Российская Федерация 812. 803. ## 2 Центральный федеральный округ 62.7 72.6 ## 3 Белгородская область 0.1 0.2 ## 4 Брянская область 2.8 3.1 ## 5 Владимирская область 5.3 6 ## 6 Воронежская область 1.1 2.6 ## 7 Ивановская область 1.6 4.6 ## 8 Калужская область 2.3 3.2 ## 9 Костромская область 25.2 15.1 ## 10 Курская область 0.3 0.5 ## # … with 79 more rows Ту же самую задачу можно решить от противного — указать со знаком - те столбцы, которые надо убрать: (rdf = select(reforest, -y2005, -y2011:-y2014, -y2016)) ## # A tibble: 89 x 3 ## Region y2010 y2015 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Российская Федерация 812. 803. ## 2 Центральный федеральный округ 62.7 72.6 ## 3 Белгородская область 0.1 0.2 ## 4 Брянская область 2.8 3.1 ## 5 Владимирская область 5.3 6 ## 6 Воронежская область 1.1 2.6 ## 7 Ивановская область 1.6 4.6 ## 8 Калужская область 2.3 3.2 ## 9 Костромская область 25.2 15.1 ## 10 Курская область 0.3 0.5 ## # … with 79 more rows Обратите внимание на то, что можно указывать еще и диапазоны названий столбцов, если они идут друг за другом. Названия столбцов в функциях dplyr указываются без кавычек, что позволяет сделат код проще и читаемее. Этот прием называется квотацией, с ним мы познакомимся подробнее в следующей лекции. Чтобы осуществить фильтрацию, необходимо задать условие, накладываемое на строки. Текущая таблица содержит данные по субъектам, федеральным округам и России в целом. Поскольку данные по округам и стране являются избыточными (их можно получить путем агрегирования данных по субъектам), выполним фильтрацию таблицы, убрав строки, в которых содержатся слова Федерация и федеральный округ. Для этого используем функцию str_detect() из пакета stringr, который также входит в tidyverse: flt = !stringr::str_detect(rdf$Region, &#39;Федерация|федеральный округ&#39;) # готовим фильтр для строк (regdf = filter(rdf, flt)) # применяем фильтр ## # A tibble: 80 x 3 ## Region y2010 y2015 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Белгородская область 0.1 0.2 ## 2 Брянская область 2.8 3.1 ## 3 Владимирская область 5.3 6 ## 4 Воронежская область 1.1 2.6 ## 5 Ивановская область 1.6 4.6 ## 6 Калужская область 2.3 3.2 ## 7 Костромская область 25.2 15.1 ## 8 Курская область 0.3 0.5 ## 9 Липецкая область 0.4 1.1 ## 10 Московская область 2.7 8.9 ## # … with 70 more rows Условие можно прописать непосредственно при вызове filter(). Например, выберем регионы, в которых объем лесовосстановительных работ в 2015 году был более 50 тыс. га: filter(regdf, y2015 &gt; 50) ## # A tibble: 4 x 3 ## Region y2010 y2015 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Архангельская область 39.4 57.6 ## 2 Красноярский край 49 50.4 ## 3 Иркутская область 80.4 117. ## 4 Хабаровский край 70.2 59.6 Для сортировки таблицы посредством arrange() необходимо указать столбцы, по которым будет осуществлено упорядочение строк. Чаще всего это один столбец, например y2015: arrange(regdf, y2015) # по возрастанию ## # A tibble: 80 x 3 ## Region y2010 y2015 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Орловская область 0 0.1 ## 2 Астраханская область 0.1 0.1 ## 3 Кабардино-Балкарская Республика 0.1 0.1 ## 4 Карачаево-Черкесская Республика 0.2 0.1 ## 5 Республика Северная Осетия – Алания NA 0.1 ## 6 Ставропольский край 0.4 0.1 ## 7 Белгородская область 0.1 0.2 ## 8 Тульская область 0.1 0.2 ## 9 Магаданская область 2.6 0.4 ## 10 Курская область 0.3 0.5 ## # … with 70 more rows arrange(regdf, desc(y2015)) # по убыванию ## # A tibble: 80 x 3 ## Region y2010 y2015 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Иркутская область 80.4 117. ## 2 Хабаровский край 70.2 59.6 ## 3 Архангельская область 39.4 57.6 ## 4 Красноярский край 49 50.4 ## 5 Вологодская область 32.3 49 ## 6 Республика Коми 33.3 36.7 ## 7 Пермский край 22.9 32.5 ## 8 Кировская область 26 31.1 ## 9 Амурская область 29.8 28.5 ## 10 Томская область 9.3 25.6 ## # … with 70 more rows Добавление новых переменных (столбцов) осуществляется посредством mutate(). Например, определим, как изменился объем лесовосстановительных работ в 2015 году по сравнению с 2010 годом: (regdf = mutate(regdf, delta = y2015 - y2010)) ## # A tibble: 80 x 4 ## Region y2010 y2015 delta ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Белгородская область 0.1 0.2 0.1 ## 2 Брянская область 2.8 3.1 0.3 ## 3 Владимирская область 5.3 6 0.7 ## 4 Воронежская область 1.1 2.6 1.5 ## 5 Ивановская область 1.6 4.6 3.00 ## 6 Калужская область 2.3 3.2 0.9 ## 7 Костромская область 25.2 15.1 -10.1 ## 8 Курская область 0.3 0.5 0.2 ## 9 Липецкая область 0.4 1.1 0.7 ## 10 Московская область 2.7 8.9 6.2 ## # … with 70 more rows Существует редко используемая разновидность мутирования, при которой сохраняются только столбцы, указанные в параметрах. Она называется transmute() — по сути это комбинация mutate() и select(). Если вы хотите просто сохранить какой-то из столбцов, то укажите его через оператор равенства: transmute(regdf, Region = Region, delta = y2015 - y2010) # сохраняем только Region и delta ## # A tibble: 80 x 2 ## Region delta ## &lt;chr&gt; &lt;dbl&gt; ## 1 Белгородская область 0.1 ## 2 Брянская область 0.3 ## 3 Владимирская область 0.7 ## 4 Воронежская область 1.5 ## 5 Ивановская область 3.00 ## 6 Калужская область 0.9 ## 7 Костромская область -10.1 ## 8 Курская область 0.2 ## 9 Липецкая область 0.7 ## 10 Московская область 6.2 ## # … with 70 more rows Вы можете выполнять агрегирование данных и вычислять суммы, средние значения и т.д. используя summarise(). После того как мы избавились от избыточных данных в таблице, мы всегда можем получить их через агрегирование. Например, посчитаем суммарный, минимальный и максимальный объем лесовосстановительных работ по всей стране: summarise(regdf, sumforest = sum(y2015, na.rm = TRUE), minforest = min(y2015, na.rm = TRUE), maxforest = max(y2015, na.rm = TRUE)) ## # A tibble: 1 x 3 ## sumforest minforest maxforest ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 801. 0.1 117. Как правило, summarise() используется в паре с агрегирующими функциями, которые берут вектор значений и возвращают одно значение. К таким функциям относятся стандартные операции типа min(), max(), mean(), sum() и т.д. В пакете dplyr также имеются полезные агрегирующие функции: n() вычисляет количество элементов. n_distinct() вычисляет количество уникальных элементов. first(x), last(x) и nth(x, n) извлекают, соответственно, первый, последний и n-ный элемент (они бывают особенно удобны, если вы сортируете строки по какому-то критерию). Достаточно часто данные надо агрегировать не по всей таблице, а по группам измерений. В этом случае сначала делается группировка, затем агрегирование данных в каждой группе. Предположим, что нам нужно найти регион с наибольшим объемом лесовосставновительных работ в каждом Федеральном округе. Для этого нам потребуется: Дополнить каждую строку региона информацией о принадлежности к федеральному округу Сгруппировать субъекты по федеральным округам — Отсортировать каждую группу по убыванию значения поля Взять первую строку в каждой группе Объединить строки в одну таблицу Для начала вернемся на этап, когда мы избавлялись от федеральных округов в таблице. Поскольку в исходной таблице данные были упорядочены по округам, эту информацию можно использовать для создания нового столбца с названием округа каждого субъекта. В этом нам поможет функция fill() из пакета tidyr: flt2 = stringr::str_detect(rdf$Region, &#39;федеральный округ&#39;) # ищем округа (rdf2 = mutate(rdf, okrug = if_else(flt2, Region, NULL))) # перенесем названия округов в новый столбец ## # A tibble: 89 x 4 ## Region y2010 y2015 okrug ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Российская Федерация 812. 803. &lt;NA&gt; ## 2 Центральный федеральный округ 62.7 72.6 Центральный федеральный округ ## 3 Белгородская область 0.1 0.2 &lt;NA&gt; ## 4 Брянская область 2.8 3.1 &lt;NA&gt; ## 5 Владимирская область 5.3 6 &lt;NA&gt; ## 6 Воронежская область 1.1 2.6 &lt;NA&gt; ## 7 Ивановская область 1.6 4.6 &lt;NA&gt; ## 8 Калужская область 2.3 3.2 &lt;NA&gt; ## 9 Костромская область 25.2 15.1 &lt;NA&gt; ## 10 Курская область 0.3 0.5 &lt;NA&gt; ## # … with 79 more rows (rdf2 = tidyr::fill(rdf2, okrug)) # заполним все пустые строчки предыдущим значением ## # A tibble: 89 x 4 ## Region y2010 y2015 okrug ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Российская Федерация 812. 803. &lt;NA&gt; ## 2 Центральный федеральный округ 62.7 72.6 Центральный федеральный округ ## 3 Белгородская область 0.1 0.2 Центральный федеральный округ ## 4 Брянская область 2.8 3.1 Центральный федеральный округ ## 5 Владимирская область 5.3 6 Центральный федеральный округ ## 6 Воронежская область 1.1 2.6 Центральный федеральный округ ## 7 Ивановская область 1.6 4.6 Центральный федеральный округ ## 8 Калужская область 2.3 3.2 Центральный федеральный округ ## 9 Костромская область 25.2 15.1 Центральный федеральный округ ## 10 Курская область 0.3 0.5 Центральный федеральный округ ## # … with 79 more rows (regdf = filter(rdf2, flt)) # оставим только регионы ## # A tibble: 80 x 4 ## Region y2010 y2015 okrug ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Белгородская область 0.1 0.2 Центральный федеральный округ ## 2 Брянская область 2.8 3.1 Центральный федеральный округ ## 3 Владимирская область 5.3 6 Центральный федеральный округ ## 4 Воронежская область 1.1 2.6 Центральный федеральный округ ## 5 Ивановская область 1.6 4.6 Центральный федеральный округ ## 6 Калужская область 2.3 3.2 Центральный федеральный округ ## 7 Костромская область 25.2 15.1 Центральный федеральный округ ## 8 Курская область 0.3 0.5 Центральный федеральный округ ## 9 Липецкая область 0.4 1.1 Центральный федеральный округ ## 10 Московская область 2.7 8.9 Центральный федеральный округ ## # … with 70 more rows Теперь мы можем определить регион с максимальным объемом лесовосстановительных работ в каждом Федеральном округе, используя вспомогательную функцию row_number() которая возвращает номер для каждой строки таблицы: regdf_gr = group_by(regdf, okrug) regdf_arr = arrange(regdf_gr, desc(y2015)) (regdf_res = filter(regdf_arr, row_number() == 1)) ## # A tibble: 8 x 4 ## # Groups: okrug [8] ## Region y2010 y2015 okrug ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Иркутская область 80.4 117. Сибирский федеральный округ ## 2 Хабаровский край 70.2 59.6 Дальневосточный федеральный округ ## 3 Архангельская область 39.4 57.6 Северо-Западный федеральный округ ## 4 Пермский край 22.9 32.5 Приволжский федеральный округ ## 5 Свердловская область 25.6 24.4 Уральский федеральный округ ## 6 Костромская область 25.2 15.1 Центральный федеральный округ ## 7 Волгоградская область 1.8 0.9 Южный федеральный округ ## 8 Чеченская Республика 0.9 0.7 Северо-Кавказский федеральный округ group_by() часто используется в паре с summarise(). Например мы можем получить суммарный объем лесовосстановительных работ по каждому федеральному округу: regdf_gr = group_by(regdf, okrug) summarise(regdf_gr, total = sum(y2015, na.rm = TRUE)) ## # A tibble: 8 x 2 ## okrug total ## &lt;chr&gt; &lt;dbl&gt; ## 1 Дальневосточный федеральный округ 108. ## 2 Приволжский федеральный округ 110. ## 3 Северо-Западный федеральный округ 194. ## 4 Северо-Кавказский федеральный округ 1.1 ## 5 Сибирский федеральный округ 259. ## 6 Уральский федеральный округ 52.9 ## 7 Центральный федеральный округ 72.7 ## 8 Южный федеральный округ 3.3 Использование dplyr целым обладает рядом преимуществ по сравнению с применением стандартных средств R: вызов функций с говорящими названиями операции более понятными; код выглядит более чистым и легко читаемым за счет отсутствия обращений к фреймам данных через квадратные скобки, доллары и «закавыченные» названия переменных; код с использованием функций dplyr часто оказывается короче, чем его традиционные аналоги; операции dplyr можно выстраивать в конвейеры с помощью пайп-оператора %&gt;%. Последнюю возможность мы рассмотрим в следующем параграфе. 3.6.2 Конвейер манипуляций В предыдущем параграфе было показано как найти регион-лидер в каждой группе по выбранному показателю. При этом, несмотря на то что интерес представляет только конечный результат, нам пришлось шесть раз осуществить запись промежуточного результата в соответствующую переменную. Чтобы избежать подобного многословия в программах, в R реализована возможность организации конвейера манипуляций (pipeline) посредством использования пайп-оператора %&gt;%. Пайп-оператор %&gt;% предназначен для компактной и наглядной записи последовательностей обработки данных. Работает он следующим образом: x %&gt;% f эквивалентно f(x) x %&gt;% f(y) эквивалентно f(x, y) x %&gt;% f %&gt;% g %&gt;% h эквивалентно h(g(f(x))) Коротко говоря, пайп оператор берет результат вычисления выражения слева и подставляет его в качестве первого аргумента в выражение справа. С помощью этого оператора вышеприведенный код по нахождению региона-лидера можно записать так: regdf = rdf %&gt;% mutate(okrug = if_else(flt2, Region, NULL)) %&gt;% tidyr::fill(okrug) %&gt;% filter(flt) leaders = regdf %&gt;% group_by(okrug) %&gt;% arrange(desc(y2015)) %&gt;% filter(row_number() == 1) print(leaders) ## # A tibble: 8 x 4 ## # Groups: okrug [8] ## Region y2010 y2015 okrug ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Иркутская область 80.4 117. Сибирский федеральный округ ## 2 Хабаровский край 70.2 59.6 Дальневосточный федеральный округ ## 3 Архангельская область 39.4 57.6 Северо-Западный федеральный округ ## 4 Пермский край 22.9 32.5 Приволжский федеральный округ ## 5 Свердловская область 25.6 24.4 Уральский федеральный округ ## 6 Костромская область 25.2 15.1 Центральный федеральный округ ## 7 Волгоградская область 1.8 0.9 Южный федеральный округ ## 8 Чеченская Республика 0.9 0.7 Северо-Кавказский федеральный округ Если бы мы попытались написать те же последовательности операций одним выражением в традиционной «матрешечной» парадигме, это выглядело так: regdf = filter( tidyr::fill( mutate( rdf, okrug = if_else(flt2, Region, NULL) ), okrug ), flt ) result = filter( arrange( group_by( regdf, okrug ), desc(y2015) ), row_number() == 1 ) Выглядит несколько устрашающе. К тому же, читать такой код приходится задом наперед (изнутри наружу), чтобы понять последовательность действий. Таким образом, организация конвейера манипуляций с использованием пайп-оператора позволяет: упорядочить операции по обработке данных слева направо (в противоположность направлению изнутри наружу); избежать вложенных вызовов функций (матрёшки); минимизировать количество переменных для храненния промежуточных результатов; упростить добавление новых операций по обработке данных в любое место последовательности. Пайп-оператор %&gt;% можно быстро набрать в RStudio, нажав клавиатурное сочетание Ctrl + Shift + M (Cmd + Shift + M на помпьютерах Mac) 3.6.3 Преобразование структуры Одни и те же данные можно предствить в табличной форме по-разному. Одна форма будет удобной для ручного заполнения таблицы. Другая форма будет удобной для программной обработки и анализа. Большинство же остальных форм не будут оптимальными ни для того, ни для другого. Наш курс посвящен автоматизированной обработке данных на языке R, поэтомы мы должны определить, какая форма таблицы удобна для этих целей. В экосистеме R такие данные принято называть «аккуратными», или по-английски tidy data. Аккуратные таблицы отвечают следующим требованиям: Каждый столбец представляет переменную Каждая строка представляет измерение Каждая ячейка представляет значение С некоторой долей условности можно говорить, что это третья нормальная форма реляционного отношения. Таблицы, с которыми мы работали до настоящего момента в этой главе, не отвечают данным требованиям. В частности, данные по лесовосстановлению содержат столбцы, в которых приведены данные за соответствующие года. Это одна переменная, разбитая на несколько столбцов. При этом год измерения является второй переменной. Такая форма удобна для заполнения и визуального анализа, но неудобна для программной обработки. Предположим, что нам надо найти все регионы, у которых в промежутке между 2012 и 2015 годами лесовосстановительные работы хотя бы в один год не производились (их объем был равен нулю). В текущей форме таблицы нам придется сделать 4 условия — по одному на каждый год-столбец. Это при том, что мы должны быть уверены, что все промежуточные года в таблице присутствуют. Приведя таблицу к аккуратному виду, мы можем решить задачу более компактно, отправив всего 2 запроса: один на год измерения и второй на величину показателя. Приведение таблицы к аккуратному виду можно сделать, используя функции из пакета tidyr. Основных функций в этом пакете всего две2: pivot_longer() берет несколько колонок и преобразует их к виду «ключ—значение»: широкие таблицы становятся длинными. pivot_wider() берет две колонки, соответствующие ключу и значению, и распределяет их на множество колонок: длинные таблицы становятся широкими. Помимо этого, есть еще 2 полезных функции, которые позволяют «распиливать» или «склеивать» колонки: separate() разделяет колонку на несколько колонок, используя заданный символ-разделитель или позицию. unite() скливает несколько колонок, используя заданный символ-разделитель. Функция pivot_longer() имеет четыре основных параметра: data — входная таблица (фрейм данных или тиббл) cols — перечисление столбцов, которые необходимо подвергнуть преобразованию names_to — имя нового столбца, который будет хранить ключи (бывшие названия столбцов) values_to — имя нового столбца, который будет хранить значения Рассмотрим на примере таблицы reforest приведение к аккуратному виду: library(tidyr) (reforest_tidy = reforest %&gt;% pivot_longer(cols = y2005:y2016, names_to = &#39;year&#39;, values_to = &#39;value&#39;)) ## # A tibble: 712 x 3 ## Region year value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Российская Федерация y2005 812. ## 2 Российская Федерация y2010 812. ## 3 Российская Федерация y2011 860 ## 4 Российская Федерация y2012 842. ## 5 Российская Федерация y2013 872. ## 6 Российская Федерация y2014 863 ## 7 Российская Федерация y2015 803. ## 8 Российская Федерация y2016 840. ## 9 Центральный федеральный округ y2005 52.6 ## 10 Центральный федеральный округ y2010 62.7 ## # … with 702 more rows Обратите внимание на то, что параметры names_to и values_to надо передавать как строки, поскольку они содержат еще не существующие объекты. Полученный результат еще не вполне пригоден для анализа, поскольку в переменной year мы имеем строковые значения, начинающиеся с y. Чтобы избавиться от этого префикса, можно при вызове pivot_longer() указать параметр names_prefix. Поскольку по умолчанию ключи конвертируются в строковый столбец, а год — это целочисленное значение, следует дополнительно указать параметр names_ptypes. Помимо этого, конвертации подвергаются все столбцы, кроме Region — это означает, что можно пойти от обратного в параметре cols. Резюмируя перечисленные соображения, вышеприведенный вызов можно оптимизировать следующим образом: (reforest_tidy2 = reforest %&gt;% pivot_longer(cols = -Region, names_to = &#39;year&#39;, names_prefix = &#39;y&#39;, names_ptypes = list(year = integer()), values_to = &#39;value&#39;)) ## # A tibble: 712 x 3 ## Region year value ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Российская Федерация 2005 812. ## 2 Российская Федерация 2010 812. ## 3 Российская Федерация 2011 860 ## 4 Российская Федерация 2012 842. ## 5 Российская Федерация 2013 872. ## 6 Российская Федерация 2014 863 ## 7 Российская Федерация 2015 803. ## 8 Российская Федерация 2016 840. ## 9 Центральный федеральный округ 2005 52.6 ## 10 Центральный федеральный округ 2010 62.7 ## # … with 702 more rows Если по какой-то причине вам уже досталась таблица, в которой в ячейках сцеплены несколько сущностей, разделить их можно с помощью функции separate(). Вышеприведенный тиббл reforest_tidy можно “довести до ума” последовательным вызовом separate(), select() и mutate(): (reforest_tidy = reforest_tidy %&gt;% separate(year, c(&#39;y&#39;, &#39;year&#39;), 1) %&gt;% select(-y) %&gt;% mutate(year = as.integer(year))) ## # A tibble: 712 x 3 ## Region year value ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Российская Федерация 2005 812. ## 2 Российская Федерация 2010 812. ## 3 Российская Федерация 2011 860 ## 4 Российская Федерация 2012 842. ## 5 Российская Федерация 2013 872. ## 6 Российская Федерация 2014 863 ## 7 Российская Федерация 2015 803. ## 8 Российская Федерация 2016 840. ## 9 Центральный федеральный округ 2005 52.6 ## 10 Центральный федеральный округ 2010 62.7 ## # … with 702 more rows Теперь можно выполнять любые запросы, комбинирующие год измерения и величину показателя. Найдем субъекты, в которых с 2012 по 2015 год не производились лесовосстановительные работы: reforest_tidy %&gt;% filter(year &gt; 2011 &amp; year &lt; 2016 &amp; value == 0) ## # A tibble: 2 x 3 ## Region year value ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Орловская область 2013 0 ## 2 Республика Адыгея 2014 0 “Длинная” форма данных удобна для программного анализа, но может быть неудобна для ручного редактирования, визуальной оценки или передачи в другие программы, ожидающие на входе данные в “широком” формате. В этих случаях будет полезна функция pivot_wider(), которая по своему действию противоположна pivot_longer(). Данная функция имеет три основных параметра: data — входная таблица (фрейм данных или тиббл) names_from — имя переменной, из которой будут браться названия столбцов values_from — имя переменной, из которой будут браться значения в ячейках Преобразуем ранее удлиненную таблицу к “широкому” виду: (reforest = reforest_tidy %&gt;% pivot_wider(names_from = year, values_from = value)) ## # A tibble: 89 x 9 ## Region `2005` `2010` `2011` `2012` `2013` `2014` `2015` `2016` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Российская Федерация 812. 812. 860 842. 872. 863 803. 840. ## 2 Центральный федераль… 52.6 62.7 60.9 60.3 70.9 71.2 72.6 77 ## 3 Белгородская область 0.4 0.1 0.3 0.3 0.4 0.4 0.2 0.2 ## 4 Брянская область 2.9 2.8 3 3.2 3.5 3.3 3.1 3 ## 5 Владимирская область 4.4 5.3 5.7 6 7.1 5.9 6 4.9 ## 6 Воронежская область 1.1 1.1 1.8 3 2.7 2.7 2.6 2.3 ## 7 Ивановская область 2.1 1.6 2.2 3.1 4 4.8 4.6 4.2 ## 8 Калужская область 2.2 2.3 2.3 2.5 2.4 3.1 3.2 3.2 ## 9 Костромская область 10 25.2 11 11.8 15.3 13.6 15.1 16.4 ## 10 Курская область 0.5 0.3 0.4 0.6 0.6 0.6 0.5 0.4 ## # … with 79 more rows Обратите внимание на то, что параметры names_from и values_from можно задавать как имена переменных, а не как строки. В качестве примера операции с широкой таблицей вычислим разности по сравнению с предыдущим годом: diffs = reforest %&gt;% select(`2011`:`2016`) - reforest %&gt;% select(`2010`:`2015`) diffs %&gt;% mutate(Region = reforest$Region) %&gt;% select(Region, `2011`:`2016`) %&gt;% head() # Посмотрим шапку таблицы ## Region 2011 2012 2013 2014 2015 2016 ## 1 Российская Федерация 48.5 -18.3 30.6 -9.3 -60.1 37.0 ## 2 Центральный федеральный округ -1.8 -0.6 10.6 0.3 1.4 4.4 ## 3 Белгородская область 0.2 0.0 0.1 0.0 -0.2 0.0 ## 4 Брянская область 0.2 0.2 0.3 -0.2 -0.2 -0.1 ## 5 Владимирская область 0.4 0.3 1.1 -1.2 0.1 -1.1 ## 6 Воронежская область 0.7 1.2 -0.3 0.0 -0.1 -0.3 3.7 Соединение Данные, с которыми мы работаем, часто распределены по нескольким таблицам. Если возникает задача их совместного использования (сравнения, вычисления производных показателей), таблицы необходимо соединить. В процессе соединения в обеих таблицах находятся строки, соответствующие одному и тому же измерению (например, региону). После этого столбцы второй таблицы пристыковываются к столбцам первой таблицы, а строки — к соответствующим строкам (мутирующее соединение), либо же происходит фильтрация строк первой таблицы на основе нахождения соответствующих строк во второй таблице (фильтрующее соединение). Чтобы найти соответствие, в обеих таблицах должен быть по крайней мере один столбец, идентифицирующий каждую строку. В первой таблице он называется первичным ключом (primary key), во второй таблице — внешним ключом (foreign key). Для выполнения соедининия в пакете dplyr имеется несколько функций. Мутирующее соединение: inner_join(x, y, by = ) возвращает все строки из x, для которых имеются соответствующие строки в y, а также все столбцы из x и y. left_join(x, y, by = ) возвращает все строки из x, а также все столбцы из x и y. Строки в x, для которых не найдены соответствия в y, будут иметь значения NA в присоединенных столбцах right_join(x, y, by = ) возвращает все строки из y, а также все столбцы из x и y. Строки в y, для которых не найдены соответствия в x, будут иметь значения NA в присоединенных столбцах full_join(x, y, by = ) возвращает все строки и колонки из x и y. В строках, для которых не найдено соответствие ячейки присоединяемых стольков будут заполнены значениями NA Фильтрующее соединение: semi_join(x, y, by = ) возвращает все строки из x, для которых имеются соответствующие строки в y, а также все столбцы из x anti_join(x, y, by = ) возвращает все строки из x, для которыхне найдены соответствующие строки в y, а также все столбцы из x Рассмотрим соединение таблиц на примере данных по лесовосстановлению и заготовкам древесины. Наша задача — оценить количество гектаров восстанавливаемой лесной площади (в га) на тысячу кубометров лесозаготовок (и таким образом оценить эффективность лесовосстановительных мероприятий). Подгрузим таблицу по лесозаготовкам: (timber = read_excel(&#39;data/timber.xlsx&#39;, col_types = c(&#39;text&#39;, rep(&#39;numeric&#39;, 8))) %&gt;% filter(!stringr::str_detect(Регион, &#39;Федерация|федеральный округ&#39;))) ## # A tibble: 75 x 9 ## Регион `2010` `2011` `2012` `2013` `2014` `2015` `2016` Место ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Белгородская область 30.4 39.6 27.7 37.4 34.1 45.6 30.4 60 ## 2 Брянская область 614. 616. 824. 850. 793. 739. 750. 27 ## 3 Владимирская область 1078 1335 1236 1142 1165 1272 1252 20 ## 4 Воронежская область 73.6 69.5 68.6 47.9 81.1 86.6 53.5 58 ## 5 Ивановская область 130. 140. 200. 199. 231. 326. 421. 38 ## 6 Калужская область 274. 244. 192. 198. 183 145. 204 44 ## 7 Костромская область 3000 3332 2797 2692 2564 2186 2515 14 ## 8 Курская область 22.8 55.4 49.7 50.1 65.9 74.6 80.7 55 ## 9 Липецкая область 163. 139 49.7 42.6 50.1 73.1 87.8 53 ## 10 Московская область 126. 265. 299. 108. 15.6 NA NA 74 ## # … with 65 more rows Приведем ее к аккуратному виду, который соответствует виду таблицы по лесовосстановлению: (timber_tidy = timber %&gt;% gather(year, harvest, `2010`:`2016`) %&gt;% transmute(Region = Регион, year = as.numeric(year), harvest = harvest)) ## # A tibble: 525 x 3 ## Region year harvest ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Белгородская область 2010 30.4 ## 2 Брянская область 2010 614. ## 3 Владимирская область 2010 1078 ## 4 Воронежская область 2010 73.6 ## 5 Ивановская область 2010 130. ## 6 Калужская область 2010 274. ## 7 Костромская область 2010 3000 ## 8 Курская область 2010 22.8 ## 9 Липецкая область 2010 163. ## 10 Московская область 2010 126. ## # … with 515 more rows Теперь нам осталось присоединить данные по лесозаготовкам к таблице по лесовосстановлению, используя имя региона (Region) и год (year) в качестве ключевых полей. Для этого мы используем функцию inner_join(), поскольку нас интересует сравнение по тем годам, для которых имеются данные в обеих таблицах: (compare = reforest_tidy %&gt;% inner_join(timber_tidy, by = c(&quot;Region&quot; = &quot;Region&quot;, &quot;year&quot; = &quot;year&quot;))) ## # A tibble: 511 x 4 ## Region year value harvest ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Белгородская область 2010 0.1 30.4 ## 2 Белгородская область 2011 0.3 39.6 ## 3 Белгородская область 2012 0.3 27.7 ## 4 Белгородская область 2013 0.4 37.4 ## 5 Белгородская область 2014 0.4 34.1 ## 6 Белгородская область 2015 0.2 45.6 ## 7 Белгородская область 2016 0.2 30.4 ## 8 Брянская область 2010 2.8 614. ## 9 Брянская область 2011 3 616. ## 10 Брянская область 2012 3.2 824. ## # … with 501 more rows Наконец, вычислим искомое отношние и упорядочим регионы по году (возрастание) и отношению (убывание): (compare = compare %&gt;% mutate(ratio = 1000 * value / harvest) %&gt;% select(Region, year, ratio, value, harvest) %&gt;% arrange(year, desc(ratio))) ## # A tibble: 511 x 5 ## Region year ratio value harvest ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Ставропольский край 2010 182. 0.4 2.2 ## 2 Ростовская область 2010 149. 1.5 10.1 ## 3 Магаданская область 2010 118. 2.6 22 ## 4 Сахалинская область 2010 63.8 12.7 199. ## 5 Республика Саха (Якутия) 2010 63.3 58 917. ## 6 Республика Тыва 2010 61.8 4.4 71.2 ## 7 Мурманская область 2010 52.2 3 57.5 ## 8 Волгоградская область 2010 48.4 1.8 37.2 ## 9 Камчатский край 2010 38.9 5.2 134. ## 10 Амурская область 2010 38.5 29.8 773. ## # … with 501 more rows Из этой таблицы видно, что площадь восстанавливаемых лесов далеко не всегда пропорциональна объему заготовок необработанной древесины. 3.8 Запись Запись файлов в текстовом формате можно осуществить посредством функций из пакета readr, таких как write_delim(), write_csv() и write_tsv(). Базовый синтаксис их предельно прост: write_csv(compare, &quot;data/output/timber_compare.csv&quot;) Для записи таблиц Microsoft Excel можно использовать возможности пакета writexl: library(writexl) write_xlsx(compare, &quot;data/output/timber_compare.xlsx&quot;) Каждая из этих функций содержит ряд дополнительных параметров, позволяющих управлять внешним видом выгружаемых таблиц. Более подробно с ними вы можете ознакомиться, вызвав справку для соответствующей функции. 3.9 Рекомендации по подготовке таблиц для чтения в R Несмотря на то, что каких-то четких правил подготовки таблиц для программной обработки не существует, можно дать несколько полезных рекомендаций по данному поводу: В первой строке таблицы должны располагаться названия столбцов. Во второй строке таблицы должны начинаться данные. Не допускайте многострочных заголовков. В названиях столбцов недопустимы объединенные ячейки, покрывающие несколько столбцов. Это может привести к неверному подсчету количества столбцов и, как следствие, некорректному чтению таблицы в целом. Названия столбцов должны состоять из латинских букв и цифр, начинаться с буквы и не содержать пробелов. Сложносочиненные названия выделяйте прописными буквами. Плохое название столбца: Валовый внутренний продукт за 2015 г.. Хорошее название столбца: GDP2015. Некоторые ошибки данных в таблицах (такие как неверные десятичные разделители), проще найти и исправить в табличном/текстовом редакторе, нежели после загрузки в R. Следование этим правилам значительно облегчит работу с табличными данными в среде R. 3.10 Краткий обзор Для просмотра презентации щелкните на ней один раз левой кнопкой мыши и листайте, используя кнопки на клавиатуре: Презентацию можно открыть в отдельном окне или вкладке браузере. Для этого щелкните по ней правой кнопкой мыши и выберите соответствующую команду. 3.11 Контрольные вопросы и упражнения 3.11.1 Вопросы Какая функция позволяет установить новый пакет в R? Как подключить пакет в текущую сессию R? Как вызвать функцию из пакета, не подключая его в текущей сессии R? Какие структуры данных используются для представления таблиц в среде R? Чем они отличаются друг от друга? Какая функция позволяет создавать тибблы по строкам, а не столбцам? Как загрузить в текущую сессию R набор данных из конкретного пакета? Под каким именем он будет доступен? Каковы основные принципы создания текстовых файлов с разделителем для хранения таблиц? Какой аббревиатурой они обозначаются? Чем отличаются файлы с фиксированной шириной столбца от файлов с разделителем? Какими спопообами можно указать границы колонок при чтении этих файлов? Перечислите функции из пакета readr, которые можно использовать для чтения текстовых файлов с табличными данными? Какой пакет позволяет читать данные в формате Microsoft Excel? Если прочитанный вами файл содержит нечитаемые символы, что это означает? Как решить проблему? Какие дополнительные параметры позволяют задавать функции чтения данных из пакетов readr и readxl, помимо имени файла? Перечислите основные возможности для отображения табличных данных в среде R? Можно ли заменять названия строк и столбцов таблицы? Если да, то какие функции для этого используются? Назовите возможные способы извлечения столбца (столбцов) из фрейма данных/тиббла. Какие из них приводят к получения вектора, а какие возвращают фрейм данных/тиббл? Как извлечь строки, удовлетворяющие некоторому критерию, используя стандартные средства R? Перечислите основные типы манипуляций над таблицами. Какой тип манипуляции всегда используется в сочетании с другими типами? Нужно ли заключать названия переменных в кавычки при использовании функций пакета dplyr? Какая функция dplyr позволяет выбирать нужные переменные? Как с помощью нее отобрать диапазон переменных? Можно ли пойти от обратного и исключить, а не выбрать переменные? Какая функция dplyr позволяет осуществлять фильтрацию строк? Как реализовать фильтрацию строк по нескольким условиям одновременно? Как найти строки, в которых встречаются заданные фрагменты текста? Какая функция позволяет это сделать? Назовите функцию dplyr, отвечающую за выполнение сортировки таблицы. Как с помощью нее упорядочить данные по нескольким столбцам? Сделать порядок сортировки по убыванию? Что такое мутирование и трансмутирование таблицы? Какая функция dplyr отвечает за добавление новых переменных? Можно ли с помощью нее добавить несколько переменных сразу? Как оставить только вновь создаваемые переменные? С помощью какой функции можно вычислить обобщающие статистики по всем строкам или группам строк? Как с помощью dplyr получить количество элементов и количество уникальных элементов в каждой группе? Как с помощью dplyr получить первый, последний и n-ный элемент в каждой группе? Что такое конвейер манипуляций и для чего он используется в R? Опишите приципы действия пайп-оператора. С помощью какого клавиатурного сочетания его можно быстро ввести в RStudio? Опишите требования, которым должны отвечать аккуратные табличные данные. Какой пакет R позволяет преборазовывать данные в такую форму? Какие две основных операции над таблицами позволяют добиться длинного и широкого вида таблицы? Можно ли говорить о том, что для всех задач удобна какая-то одна из этих двух форм? Как работают функции pivot_longer() и pivot_wider()? Что такое соединение таблиц? В каких случаях оно бывает необходимо? Какие разновидности соединения реализованы в dplyr? Каким требованиям должны отвечать таблицы для того чтобы их соединение было возможным? Что такое первичный и внешний ключ в операции соединения таблиц? Какие возможности существуют для записи табличных данных в текстовые файлы? Перечислите пакеты и функции, такие возможности реализующие. Опишите общие рекомендации для подготовки таблиц к чтению средствами R. 3.11.2 Упражнения Таблица quakes из пакета datasets содержит магнитуду землетрясений в поле mag. Используя функции dplyr и пайп-оператор, создайте на ее основе таблицу с частотой (количеством штук) землетрясений каждой магнитуды. Подсказка: при выполнении агрегирования используйте функцию n(), которая возвращает количество строк в группе. Таблица storms из пакета dplyr содержит увлекательные данные трекинга тропических циклонов c 1975 по 2015 год. Используя функции dplyr и пайп-оператор, создайте таблицу в которой зафиксировано: название циклона, дата начала, дата окончания, продолжительность в днях, максимальная скорость ветра, минимальное давление. Отсортируйте циклоны сначала по максимальной скорости ветра (по убыванию), затем по давлению (по возрастанию). Оформите результат в виде одного конвейера манипуляций. Подсказка: перед выполнением агрегирования на основе существующих полей создайте новое поле, в котором хранится дата события, имеющая тип Date. Это позволит вам правильно вычислить продолжительность в днях. Чтобы создать строку для преобразования в дату, используйте функцию paste(), подставив в нее поля, составляющие даты, и укажите необходимый разделитель в параметре sep(). После агрегирования данных и перед сортировкой вызовите ungroup(), иначе вы будете сортировать внутри каждой группы, а вам нужно сортировать результаты группировки. Загрузите файл с данными по энергии ветра вдоль Черноморского побережья на высотах 50 и 100 метров, который был использован в этой лекции. Данный файл имеет формат фиксированной ширины столбца (см. параграф 3.3.2.2). Произведите чтение данного файла и приведите его с помощью tidyr к аккуратному виду, разделив высоту и величину энергии на отдельные столбцы. Используя возможности dplyr, рассчитайте фрейм данных со средними значениями энергии на каждой высоте. Загрузите файл CSV с данными по населению федеральных округов России, который был использован в этой лекции. Прочтите данную таблицу, приведите ее с помощью tidyr к аккуратному виду (федеральный округ — год — население), а также вычислите в виде дополнительного столбца долю (в %), которую каждый округ занимает в общем населении России на каждый год (получится федеральный округ — год — население — доля). Оформите результат в виде одного конвейера манипуляций. Подсказка: используйте группировку таблицы по году и вычислите поле с долей путем деления поля населения на сумму по полю населения. Самсонов Т.Е. Визуализация и анализ географических данных на языке R. М.: Географический факультет МГУ, 2020. DOI: 10.5281/zenodo.901911 Ранее вместо pivot_longer() и pivot_wider() использовались функции gather() и spread() соответственно. Новые функции имеют более очевидный синтаксис и более широкие возможности, поэтому использование gather() и spread() начиная с версии 1.0.0 пакета tidyr более не рекомендуется.↩︎ "],
["tech.html", "Глава 4 Техники программирования 4.1 Функциональное программирование 4.2 Метапрограммирование 4.3 Краткий обзор 4.4 Контрольные вопросы и упражнения", " Глава 4 Техники программирования В настоящей главе мы кратко познакомимся с функциональным программированием и метапрограммированием, которые являются одними из основных техник программирования на R. 4.1 Функциональное программирование 4.1.1 Функции Функции в R можно использовать для структурирования кода на логически завершенные, автономные фрагменты кода, каждый из которых выполняет конкретную задачу. Синтаксис функции выглядит следующим образом: functionName = function(parameter1, parameter2, ...){ ... return(result) ... last_value = ... } Функция создается c помощью ключевого слова function, за которым в круглых скобках заключается произвольное количество параметров (столько, сколько вам нужно: от нуля и более). С помощью этих параметров вы сможете передавать внутрь функции значения переменных. Созданной функции необходимо дать имя, используя оператор присвоения &lt;- или =. Возврат значения функции осуществляется двумя способами: Если не указано иное, то будет возвращен результат вычисления последнего выражения, выполненного внутри функции (last_value в примере выше) Результат можно вернуть принудительно в любом месте функции, передав его в выражение return(). Выражение return() работает аналогично ключевому слову break в циклах: оно прерывает выполнение функции и осуществляет выход из нее. Как правило, return() используется, если возврат значения надо сделать где-то посередине или в начале функции. Однако я реккомендую использовать его всегда, поскольку это помогает читателю вашей функции быстро определить, что же именно возвращается из функции Как правило, функции оказываются полезны, если: Вы дублируете один и тот же код в разных частях программы Ваш код становится слишком длинным, при этом присутствует очевидная этапность решения задачи, позволяющая разбить программу на автономные блоки У вас есть фрагмент кода, который выполняет вспомогательную (второстепенную функцию), и не относится непосредственно к основной логике программы. Предположим, у нас есть линия, заданная координатами четырех точек, и нам надо вычислить длины каждого из трех отрезков. Без использования функции мы запишем это так: x = rnorm(4) y = rnorm(4) d12 = sqrt((x[1] - x[2]) ^ 2 + (y[1] - y[2]) ^ 2) d23 = sqrt((x[2] - x[3]) ^ 2 + (y[2] - y[3]) ^ 2) d31 = sqrt((x[3] - x[4]) ^ 2 + (y[3] - y[4]) ^ 2) cat(d12, d23, d31) ## 1.851594 2.693269 0.8051395 В правой части этих выражений стоит один и тот же код, который я скопировал и вставил, а далее заменил названия переменных. Это плохо сразу по двум причинам: дублирование фрагментов программы и возрастание вероятности опечаток в скопированой копии. Улучшить код можно, введя функцию вычисления расстояний: distance = function(x1, y1, x2, y2) { sqrt((x1 - x2) ^ 2 + (y1 - y2) ^ 2) } d12 = distance(x[1], y[1], x[2], y[2]) d23 = distance(x[2], y[2], x[3], y[3]) d31 = distance(x[3], y[3], x[4], y[4]) cat(d12, d23, d31) ## 1.851594 2.693269 0.8051395 Функция всегда возвращает один объект: значение, вектор, список и т.д. Например, мы можем сделать функцию следующего уровня, рассчитывающая сразу все расстояния для множества точек: distances = function(x, y) { n = length(x) distance(x[1:(n-1)], y[1:(n-1)], x[2:n], y[2:n]) } distances(x, y) ## [1] 1.8515939 2.6932686 0.8051395 Можно пойти еще дальше, и сделать функцию, выполняющую вычисление длины линии, заданной координатами: line_length = function(x, y) { sum(distances(x, y)) } line_length(x, y) ## [1] 5.350002 Обратите внимание на то, как мы используем одну ранее написанную функцию при создании другой функции! Это весьма распространенная практика: одна и та же функция может быть как самостоятельно полезной (вызываться непосредственно в программе полтьзователя), так и применяться для решения задач внутри других функций. При этом иногда даже относительно простые фрагменты кода имеет смысл оформлять в виде функций, так как это может улучшить читаемость программы и пояснить смысл выполняемых операций. Так, например, line_length(x, y) в более явном виде обозначает операцию вычисления длины по координатам, нежели sum(distances(x, y)). В то же время, здесь важно не переусердствовать и оформлять короткие фрагменты кода в виде функций только если они будут применяться вами неоднократно. Если вам нужно вернуть из функции несколько объектов, имеющих разный тип или смысл, заключите их в список и дайте каждому элементу списка “говорящее” имя. Например, помимо периметра, мы можем вернуть также извилистость линии (отношение длины линии к длине отрезка, соединяющего ее первую и последнюю точку): line_params = function(x, y) { n = length(x) l = line_length(x, y) s = l / distance(x[1], y[1], x[n], y[n]) list(length = l, sinuosity = s) } result = line_params(x, y) result$length ## [1] 5.350002 result$sinuosity ## [1] 2.847159 4.1.2 Функционалы Данные (в том числе географические) практически всегда носят множественный характер и организованы в определенные структуры (см. главу 2). Эта особенность данных выдвигает логичное желание иметь процедуры, которые можно применять к полному набору данных, а не к его отдельным компонентам. Это и есть процедуры векторизованных вычислений. Предположим, вам необходимо что-то вычислить для каждой строки таблицы, при этом порядок вычисления зависит от содержимого ячеек данной строки. Вы можете организовать подобные вычисления с помощью циклов, однако в R существуют специальные функции семейста apply, которые позволяют решать подобные задачи более элегантно и с высокой скоростью: Функция Назначение apply() применить функцию ко всем строкам или столбцам матрицы lapply() применить функцию к каждому компоненту вектора или списка и получить результат также в виде списка (l — list) sapply() применить функцию к каждому компоненту вектора или списка и получить результат в виде вектора (s — simplify) vapply() аналогична vapply, но требует явного задания типа данных возвращаемого вектора, за счет чего работает быстрее (v — velocity) mapply() применить функцию к каждому компоненту нескольких векторов или списков и вернуть результат в виде списка (m — multivariate) rapply() применить функцию рекурсивно ко всем элементам переданного списка и вернуть результат в аналогичной структур (r — recursive) tapply() применить функцию ко всем компонентам вектора или списка, сгруппировав их по значению переданного фактора Функции семейства apply, принимающие на вход списки, могут работать и с фреймами данных. В этом случае фрейм внутри функции будет преобразован с помощью функции as.list() в список, элементами которого являются столбцы (переменные) входного фрейма данных. Данные при этом не потеряются, их типы тоже не изменятся. Базовая функция apply() имеет следующие аргументы: X — массив любой размерности (включая вектор) MARGIN — измерения по которым необходимо вести вычисления. Для матрицы 1 означает строку, 2 означает столбец, c(1, 2) будет означать, что вычисления производятся по всем комбинациям строк и столбцов FUN — функция, которая будет применяться к каждому элементу указанных измерений ... — список аргументов, которые надо передать в функцию FUN (в этом случае массив должен передаваться обязательно в первый аргумент) Другие функции семейства apply в приложении к фреймам данных будут работать со столбцами (переменными), интерпретируя их как элементы списка. Наиболее часто из них используются lapply(), sapply() и vapply(). В отличие от apply(), они уже не принимаеют номера измерений и работают только с элементами переданного списка. Рассмотрим применение функций данного семейства на примере анализа основных социально-экономических характеристик столиц субъектов Северо-Западного округа за 2015 год: # Функционалы library(tidyverse) ## ── Attaching packages ─────────────────────────────────────────────────── tidyverse 1.3.0 ── ## ✓ ggplot2 3.2.1 ✓ stringr 1.4.0 ## ✓ purrr 0.3.3 ✓ forcats 0.4.0 ## ── Conflicts ────────────────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(readxl) (df = read_excel(&quot;data/sevzap.xlsx&quot;, col_types = c(&#39;text&#39;, rep(&#39;numeric&#39;, 17)))) ## # A tibble: 10 x 18 ## city pop birth death labor salary livspace doctors hosp assets business ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Петр… 277. 13 12.3 72.3 36268. 24.4 75 17 2.47e5 15856 ## 2 Сыкт… 259. 14.5 10.4 84.1 39790 22.8 79.5 17 2.17e5 10068 ## 3 Арха… 358. 11.8 11.6 97.9 40303. 22.7 82.3 19 2.79e5 13016 ## 4 Нарь… 24.5 18.1 7.6 12.7 69884. 23.6 65.2 2 1.05e5 704 ## 5 Воло… 313. 16.2 11.4 91 31483 24.7 60.9 18 8.27e5 21931 ## 6 Кали… 460. 13.3 13.4 126. 34142 27.7 69.8 25 3.27e5 38013 ## 7 Мурм… 302. 12.4 11.9 96.9 53240. 23.8 68.8 15 7.24e5 16041 ## 8 Вели… 222. 13.8 13.8 74.1 32377. 24.1 78.9 14 1.59e5 9583 ## 9 Псков 208. 13.2 13.7 59.6 27405. 25 59 13 1.31e5 8752 ## 10 Санк… 5226. 13.6 11.9 2055. 44187 23.6 73.8 112 4.10e6 374999 ## # … with 7 more variables: minerals &lt;dbl&gt;, manufact &lt;dbl&gt;, engaswat &lt;dbl&gt;, ## # construct &lt;dbl&gt;, apart &lt;dbl&gt;, retail &lt;dbl&gt;, invest &lt;dbl&gt; В данной таблице каждый столбец представляет независимую переменную со своими единицами измерения, поэтому ее необходимо оставить в “широкой” форме, не преобразуя в длинную. Используя apply, можно быстро получить максимальные значения каждой переменной: apply(df[-1], 2, max) ## pop birth death labor salary livspace doctors hosp ## 5225.7 18.1 13.8 2055.3 69883.5 27.7 82.3 112.0 ## assets business minerals manufact engaswat construct apart retail ## 4102243.8 374999.0 NA 1978634.0 173292.0 397229.0 3031.0 1144607.0 ## invest ## 521293.0 Что равносильно вызову sapply: sapply(df[-1], max) ## pop birth death labor salary livspace doctors hosp ## 5225.7 18.1 13.8 2055.3 69883.5 27.7 82.3 112.0 ## assets business minerals manufact engaswat construct apart retail ## 4102243.8 374999.0 NA 1978634.0 173292.0 397229.0 3031.0 1144607.0 ## invest ## 521293.0 В качестве функции можно использовать не только стандартные, но и пользовательские функции. Например, нам может быть интересно не максимальное значение показателя, а его отношение к среднему значению среди всех городов. Здесь уже одной функцией не обойдешься, так как нужно каждый столбец поделить на среднее значение по нему. Для этого определим небольшую пользовательскую функцию непосредственно при вызове sapply(): (normalized = sapply(df[-1], function(X) { round(X / mean(X, na.rm = TRUE), 2) })) ## pop birth death labor salary livspace doctors hosp assets business ## [1,] 0.36 0.93 1.04 0.26 0.89 1.01 1.05 0.67 0.35 0.31 ## [2,] 0.34 1.04 0.88 0.30 0.97 0.94 1.11 0.67 0.30 0.20 ## [3,] 0.47 0.84 0.98 0.35 0.99 0.94 1.15 0.75 0.39 0.26 ## [4,] 0.03 1.29 0.64 0.05 1.71 0.97 0.91 0.08 0.15 0.01 ## [5,] 0.41 1.16 0.97 0.33 0.77 1.02 0.85 0.71 1.16 0.43 ## [6,] 0.60 0.95 1.14 0.46 0.83 1.14 0.98 0.99 0.46 0.75 ## [7,] 0.39 0.89 1.01 0.35 1.30 0.98 0.96 0.60 1.02 0.32 ## [8,] 0.29 0.99 1.17 0.27 0.79 0.99 1.11 0.56 0.22 0.19 ## [9,] 0.27 0.94 1.16 0.22 0.67 1.03 0.83 0.52 0.18 0.17 ## [10,] 6.83 0.97 1.01 7.42 1.08 0.97 1.03 4.44 5.76 7.37 ## minerals manufact engaswat construct apart retail invest ## [1,] 0.06 0.05 0.52 0.13 0.45 0.23 0.11 ## [2,] 0.00 0.28 0.43 0.09 0.31 0.21 0.14 ## [3,] 0.00 0.06 0.49 0.09 0.17 0.17 0.15 ## [4,] 4.12 0.05 0.03 0.08 0.05 0.02 0.52 ## [5,] NA 0.15 0.63 0.09 0.52 0.23 0.13 ## [6,] 0.82 0.83 0.68 0.28 1.24 0.38 0.53 ## [7,] NA 0.23 0.42 0.07 0.02 0.29 0.75 ## [8,] NA 0.42 0.45 0.08 0.32 0.17 0.30 ## [9,] NA 0.08 0.22 0.04 0.27 0.17 0.10 ## [10,] 1.00 7.87 6.13 9.05 6.65 8.13 7.28 Полученный объект является матрицей. Таким образом, можно видеть, что функционалы бывают полезны не только для агрегирования таблиц, но и для преобразования данных, когда структура таблицы остается прежней. В приведенном выше коде мы сознательно исключили первый столбец, поскольку он является текстовым. Можно сделать более мощную и универсальную функцию, которая будет нормировать все числовые столбцы таблицы, а текстовые оставлять в оригинале. Для этого проверку типа данных надо внести внутрь функции. Поскольку код функции при этом вырастает, целесообразно определить ее заранее. Поскольку в этом случае часть векторов будет символьной, а не числовой, необходимо применять функцию lapply(), которая вернет список из векторов, а не матрицу и таким образом сохранит типы каждого столбца: normalize = function(X) { if (is.numeric(X)) round(X / mean(X, na.rm = TRUE), 2) else X } (normalized_df = df %&gt;% lapply(normalize) %&gt;% as_tibble()) ## # A tibble: 10 x 18 ## city pop birth death labor salary livspace doctors hosp assets business ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Петр… 0.36 0.93 1.04 0.26 0.89 1.01 1.05 0.67 0.35 0.31 ## 2 Сыкт… 0.34 1.04 0.88 0.3 0.97 0.94 1.11 0.67 0.3 0.2 ## 3 Арха… 0.47 0.84 0.98 0.35 0.99 0.94 1.15 0.75 0.39 0.26 ## 4 Нарь… 0.03 1.29 0.64 0.05 1.71 0.97 0.91 0.08 0.15 0.01 ## 5 Воло… 0.41 1.16 0.97 0.33 0.77 1.02 0.85 0.71 1.16 0.43 ## 6 Кали… 0.6 0.95 1.14 0.46 0.83 1.14 0.98 0.99 0.46 0.75 ## 7 Мурм… 0.39 0.89 1.01 0.35 1.3 0.98 0.96 0.6 1.02 0.32 ## 8 Вели… 0.290 0.99 1.17 0.27 0.79 0.99 1.11 0.56 0.22 0.19 ## 9 Псков 0.27 0.94 1.16 0.22 0.67 1.03 0.83 0.52 0.18 0.17 ## 10 Санк… 6.83 0.97 1.01 7.42 1.08 0.97 1.03 4.44 5.76 7.37 ## # … with 7 more variables: minerals &lt;dbl&gt;, manufact &lt;dbl&gt;, engaswat &lt;dbl&gt;, ## # construct &lt;dbl&gt;, apart &lt;dbl&gt;, retail &lt;dbl&gt;, invest &lt;dbl&gt; В качестве альтернативы функциям apply можно также воспользоваться вычислениями посредством функций семейства map из пакета purrr (еще один пакет из tidyverse). Эти функции работают аналогично sapply(): map() возвращает список. map_lgl() возвращает вектор логических значений. map_int() возвращает вектор целочисленных значений. map_dbl() возвращает вектор чисел с плавающей точкой. map_chr() возвращает вектор строк. Например, вышеприведенные операции можно осуществить средствами purrr вот так: map_dbl(df[-1], max) ## pop birth death labor salary livspace doctors hosp ## 5225.7 18.1 13.8 2055.3 69883.5 27.7 82.3 112.0 ## assets business minerals manufact engaswat construct apart retail ## 4102243.8 374999.0 NA 1978634.0 173292.0 397229.0 3031.0 1144607.0 ## invest ## 521293.0 df %&gt;% map(normalize) %&gt;% as_tibble() ## # A tibble: 10 x 18 ## city pop birth death labor salary livspace doctors hosp assets business ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Петр… 0.36 0.93 1.04 0.26 0.89 1.01 1.05 0.67 0.35 0.31 ## 2 Сыкт… 0.34 1.04 0.88 0.3 0.97 0.94 1.11 0.67 0.3 0.2 ## 3 Арха… 0.47 0.84 0.98 0.35 0.99 0.94 1.15 0.75 0.39 0.26 ## 4 Нарь… 0.03 1.29 0.64 0.05 1.71 0.97 0.91 0.08 0.15 0.01 ## 5 Воло… 0.41 1.16 0.97 0.33 0.77 1.02 0.85 0.71 1.16 0.43 ## 6 Кали… 0.6 0.95 1.14 0.46 0.83 1.14 0.98 0.99 0.46 0.75 ## 7 Мурм… 0.39 0.89 1.01 0.35 1.3 0.98 0.96 0.6 1.02 0.32 ## 8 Вели… 0.290 0.99 1.17 0.27 0.79 0.99 1.11 0.56 0.22 0.19 ## 9 Псков 0.27 0.94 1.16 0.22 0.67 1.03 0.83 0.52 0.18 0.17 ## 10 Санк… 6.83 0.97 1.01 7.42 1.08 0.97 1.03 4.44 5.76 7.37 ## # … with 7 more variables: minerals &lt;dbl&gt;, manufact &lt;dbl&gt;, engaswat &lt;dbl&gt;, ## # construct &lt;dbl&gt;, apart &lt;dbl&gt;, retail &lt;dbl&gt;, invest &lt;dbl&gt; 4.2 Метапрограммирование Метапрограммирование — это техника программирования, при которой программный код может генерировать другой код. Широкая поддержка и интенсивное использование метапрограммирования – одна из удивительных черт R, которая ставит его особняком на фоне многих других языков, включая Python. Метапрограммирование позволяет во многих случаях сделать код более компактным и подойти к решению задачи элегантным путем. Вы уже сталкивались с метапрограммированием, когда работали с функциями dplyr. Например, сравните следующие два способа извлечь столбец из фрейма данных: df[&quot;salary&quot;] ## # A tibble: 10 x 1 ## salary ## &lt;dbl&gt; ## 1 36268. ## 2 39790 ## 3 40303. ## 4 69884. ## 5 31483 ## 6 34142 ## 7 53240. ## 8 32377. ## 9 27405. ## 10 44187 select(df, salary) ## # A tibble: 10 x 1 ## salary ## &lt;dbl&gt; ## 1 36268. ## 2 39790 ## 3 40303. ## 4 69884. ## 5 31483 ## 6 34142 ## 7 53240. ## 8 32377. ## 9 27405. ## 10 44187 В обоих случаях мы получили один и тот же результат. В первом случае было указано название столбца в кавычках. Во втором мы передали название столбца без кавычек, точно так же как было передано название фрейма данных. Однако фрейм данных с названием df был создан перед вызовом select. Вас не смущает, что объекта salary в нашем скрипте не существует, а мы его передаем в качестве аргумента функции? Мы ведь не создавали такой переменной в программе. Как же функция догадывается о том, что его надо интерпретировать не как переменную, а как название столбца? Для начала разберемся с тем, что происходит в программном коде: select() представляет собой вызов (call) функции df и salary представляют собой символы, обозначающие объекты в программе. \"salary\" представляет собой константу R — это функциональный язык программирования. Любая программа на R состоит из вызовов функций, которые применяются к символам и константам. Привычные нам арифметические операции на самом деле тоже являются вызовами функций. Это выглядит довольно неожиданно: a = 78 # стандартная запись `=`(a, 78) # функциональная запись a + 4 # стандартная запись ## [1] 82 `+`(a, 4) # функциональная запись ## [1] 82 df[&#39;salary&#39;] # стандартная запись ## # A tibble: 10 x 1 ## salary ## &lt;dbl&gt; ## 1 36268. ## 2 39790 ## 3 40303. ## 4 69884. ## 5 31483 ## 6 34142 ## 7 53240. ## 8 32377. ## 9 27405. ## 10 44187 `[`(df, &#39;salary&#39;) # функциональная запись ## # A tibble: 10 x 1 ## salary ## &lt;dbl&gt; ## 1 36268. ## 2 39790 ## 3 40303. ## 4 69884. ## 5 31483 ## 6 34142 ## 7 53240. ## 8 32377. ## 9 27405. ## 10 44187 Таким образом, бинарный оператор в R представляет собой вызов функции с двумя аргументами. Программный код a + 4 с точки зрения R является выражением (expression). Выражение может состоять вообще из одного символа, то есть a — это тоже выражение. Когда интерпретатор доходит до выражения a + 4, он выполняет следующее: Оценка (evaluation) выражения a. Результатом оценки является константа 78 Вызов (call) функции +, которая складывает константы 78 и 4 Не все символы и выражения в программе необходимо оценивать. Некоторые из них необходимо квотировать, то есть использовать в качестве имени объекта. Квотацию можно условно рассматривать как простановку кавычек вокруг выражения. Для обозначения квотации в явном виде используются обратные кавычки: ` Мы уже сталкивались с квотацией при вызове функции сложения: `+`(a, 4). В данном случае квотация была нужна чтобы + интерпретировался как имя функции. Явная квотация бывает необходима, когда объекты R имеют недопустимые имена, например начинаются с цифры или содержат пробелы. Для начала рассмотрим искусственный пример: `f + 17` = 87 # создаем объект с именем f + 17 f + 17 # ошибка: переменной f не существует ## [1] 5.5 `f + 17` # обращаемся к объекту путем явной квотации ## [1] 87 Теперь более жизнеспособный пример: данные о населении федеральных округов: library(readr) (okruga = read_csv(&#39;data/okruga.csv&#39;)) ## Parsed with column specification: ## cols( ## `№` = col_double(), ## Регион = col_character(), ## `2005` = col_double(), ## `2010` = col_double(), ## `2011` = col_double(), ## `2012` = col_double(), ## `2013` = col_double() ## ) ## # A tibble: 8 x 7 ## `№` Регион `2005` `2010` `2011` `2012` `2013` ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 Центральный 4341 3761 3613 3651 3570 ## 2 2 Северо-Западный 3192 3088 2866 2877 2796 ## 3 3 Южный федеральный 1409 1446 1436 1394 1321 ## 4 4 Северо-Кавказский 496 390 397 395 374 ## 5 5 Приволжский 3162 2883 2857 2854 2849 ## 6 6 Уральский 1681 1860 1834 1665 1624 ## 7 7 Сибирский 2575 2218 2142 2077 1941 ## 8 8 Дальневосточный 871 870 821 765 713 Обратите внимание на обратные кавычки вокруг названий столбцов. Они проставлены потому что числа в среде R по умолчанию оцениваются, и не могут использоваться в качестве символов для объектов. Чтобы разрешить это, используется принудительная квотация. Как мы уже знаем, чтобы обратиться к такому объекту, надо использовать обратные кавычки: okruga$2010 # ошибка: 2010 - константа, которая оценивается ## Error: &lt;text&gt;:1:8: неожиданная числовая константа ## 1: okruga$2010 ## ^ okruga$`2010` # правильно: `2010` -- символ, полученный путем квотации ## [1] 3761 3088 1446 390 2883 1860 2218 870 Теперь вернемся к примеру с использованием функции select(). Данная функция оценивает первый аргумент (фрейм данных) и квотирует все оставшиеся аргументы, которые отвечают за названия столбцов. Это позволяет избежать использования кавычек и использовать символы для наименования объектов. Чтобы понять, использует ли функция оценку или квотацию ее аргументов, необходимо ознакомиться с ее справкой. Когда функция применяет квотацию аргументов, говорят что осуществляется нестандартная оценка (NSE – non-standard evaluation). Если аргументы функции оцениваются, то происходит стандартная оценка (SE – standard evaluation) Иногда бывает необходимо использовать строковые названия столбцов (например, если они записаны у вас в переменные). В таком случае можно использовать функцию select_() (с подчеркиванием в конце), которая будет выполнять оценку ее аргументов вместо квотации: f1 = &#39;salary&#39; f2 = &#39;birth&#39; select_(df, f1, f2) # ОК ## # A tibble: 10 x 2 ## salary birth ## &lt;dbl&gt; &lt;dbl&gt; ## 1 36268. 13 ## 2 39790 14.5 ## 3 40303. 11.8 ## 4 69884. 18.1 ## 5 31483 16.2 ## 6 34142 13.3 ## 7 53240. 12.4 ## 8 32377. 13.8 ## 9 27405. 13.2 ## 10 44187 13.6 select_(df, salary, birth) # ошибка: функция пыьтается оценить несуществующие объекты salary и birth ## Error in compat_lazy_dots(.dots, caller_env(), ...): объект &#39;salary&#39; не найден Однако кавычки в данном случае усложняют внешний вид программы и затрудняют написание ее текста. Если вы передаете константы в качестве аргументов, они будут работать в обоих случаях: select(df, &#39;salary&#39;, &#39;birth&#39;) ## # A tibble: 10 x 2 ## salary birth ## &lt;dbl&gt; &lt;dbl&gt; ## 1 36268. 13 ## 2 39790 14.5 ## 3 40303. 11.8 ## 4 69884. 18.1 ## 5 31483 16.2 ## 6 34142 13.3 ## 7 53240. 12.4 ## 8 32377. 13.8 ## 9 27405. 13.2 ## 10 44187 13.6 select_(df, &#39;salary&#39;, &#39;birth&#39;) ## # A tibble: 10 x 2 ## salary birth ## &lt;dbl&gt; &lt;dbl&gt; ## 1 36268. 13 ## 2 39790 14.5 ## 3 40303. 11.8 ## 4 69884. 18.1 ## 5 31483 16.2 ## 6 34142 13.3 ## 7 53240. 12.4 ## 8 32377. 13.8 ## 9 27405. 13.2 ## 10 44187 13.6 Функции dplyr имеют парные к ним функции с символом подчеркивания на конце, которые производят оценку, а не квотацию аргументов. Иногда выражения бывает необходимо создать, а оценивать уже потом. Для этого существуеют объекты выражений, которые создаются с помощью функции expression(): (d = expression(b^2 - 4*a)) # создаем выражение ## expression(b^2 - 4 * a) a = 2 b = 7 eval(d) # оцениваем значение выражения ## [1] 41 Все символы в объекте выражения по умолчанию квотируются и выражение хранится в статичном виде до тех пор пока не будет произведена его оценка (подстановка значений переменных вместо их символов). Выражения используются в формулах, используемых для статистического анализа в R 4.3 Краткий обзор 4.4 Контрольные вопросы и упражнения 4.4.1 Вопросы Что такое функция? Какое ключевое слово ипользуется для создания функции? В каких случаях целесообразно применение функций? Сколько аргументов может принимать функция? Можно ли из одной функции вызывать другую функцию? Как осуществить принудительный выход из функции с возвратом результата? Что необходимо сделать, если надо передать несколько объектов из функции? Для чего нужны функционалы семейства apply? В каких задачах они бывают полезны? Перечислите функции семейства apply, назовите их отличия и сферы применения. Какая функция семейства apply позволяет обабатывать заданные измерения? Какой объект первым передается в функцию, подставляемую в параметр FUN, если применяется lapply к фрейму данных? Назовите аналоги функций apply из пакета purrr Что такое метапрограммирование? Из каких объектов состоят выражения в R? Что из себя по на самом деле представляют бинарные операторы в R? Как обратиться к объекту, символ которого не является допустимым именем переменной? Что такое оценка и квотация выражения? Для чего они используются? Как понять, будет ли используемая вами функция квотрировать или оценивать ее аргументы? Как называются функции dplyr, осуществляющие оценку, а не квотацию аргументов? Как создать и оценить объект выражения в R? 4.4.2 Упражнения Напишите функцию is_leap(year), которая определяет, является ли указанный год високосным. Протестируйте ее в вашем скрипте, используя чтение года из консолии Подсказка: високосным считается год, кратный 400, либо кратный 4, но не кратный 100. Функция Тоблера показывает зависимость скорости пешего маршрута (в км/ч) от угла наклона на местности. Предположим, в вашем распоряжении имеется матрица профиля рельефа, в которой в одном столбце указано расстояние от начала маршрута, а во втором — абсолютная отметка точки. Напишите функцию hiking_time(profile), которая вычисляет время прохождения маршрута на основе переданной ей матрицы. Используйте для тестирования функции маршрут из 10 точек с шагом в 1 км и случайным разбросом высот в диапазоне от 500 до 1000 метров (равномерное распределение). Подсказка: угол наклона на каждом участке считается постоянным. Для вычисления экспоненты используйте встроенную функцию exp(). Создайте на основе данных по Москве с сайта pogodaiklimat таблицу Excel с повторяемостью различных направлений ветра. Не преобразовывая структуру данных, вычислите на ее основе с помощью lapply() преобладающее направление для каждого месяца. Представьте результат как фрейм данных. В текущей лекции мы работали с данными по характеристикам центров субъектов СЗФО. Напишите функцию get_extremes(df), которая определяет названия переменных, по которым каждая строчка фрейма данных (в нашем случае — город) занимает максимальное и минимальное положение относительно среднего значения по всем городам. Например, Петрозаводск имеет максимальный рейтинг по показателю doctors (1.05) — количество врачей на 10000 чел и минимальный по показателю manufact (0.05) — продукции обрабатывающей промышленность (в млн руб). Результирующая таблица должна содержать первое по счету поле, а также поля minvar и maxvar: Region minvar maxvar Петрозаводск doctors manufact ... ... Подсказка: для начала вам надо нормировать значения всех переменных с помощью lapply(). Затем нужно определить номер столбца, имеющего максимальное и минимальное значений для каждой строки таблицы. Используйте для этого функции which.min() и which.max() возвращающие индекс максимального и минимального элемента вектора, в комбинации с функцией colnames(), возвращающей названия переменных. Применяйте функцию apply(), которая умеет ходить по строкам. Самсонов Т.Е. Визуализация и анализ географических данных на языке R. М.: Географический факультет МГУ, lubridate::year(Sys.Date()). DOI: 10.5281/zenodo.901911 "],
["graphics.html", "Глава 5 Базовая графика 5.1 Стандартные графики 5.2 Гистограммы 5.3 Столбчатые графики 5.4 Круговые (секторные) диаграммы 5.5 Цвет и прозрачность 5.6 Настройки отображения 5.7 Легенда 5.8 Контрольные вопросы и упражнения", " Глава 5 Базовая графика Программный код главы Данный модуль посвящен введению в работу с графическим представлением информации в R. Построение графиков на языке R сродни работе с конструктором: вы собираете изображение по кирпичикам из множества настроек и компонент. Поняв основные принципы базовой графической подсистемы R из пакета graphics, вы сможете освоить дополнительные библиотеки lattice, ggplot2 и plotly, предоставляющие еще более интересные возможности с точки зрения функциональности и дизайна. Прежде чем мы приступим к построению графиков, необходимо подготовить исходные данные. Мы будем работать с региональной статистикой Росстата: экспорт/импорт продукции по регионам России (млн долл. США) и объем сброса сточных вод по морям России (млрд м\\(^3\\)): library(readxl) # Прочтем таблицу по экспорту/импорту продукции в регионах России types = c(&quot;text&quot;, rep(&quot;numeric&quot;, 12)) tab = as.data.frame(read_excel(&quot;data/ExpImp.xlsx&quot;, 1, col_types = types)) str(tab) ## &#39;data.frame&#39;: 96 obs. of 13 variables: ## $ Регион : chr &quot;Российская Федерация&quot; &quot;Центральный федеральный округ&quot; &quot;Белгородская область&quot; &quot;Брянская область&quot; ... ## $ ПродЭкспорт: num 16196.2 4552.9 221.9 28.5 177.9 ... ## $ ПродИмпорт : num 43076 22954 614 650 454 ... ## $ ТЭКЭкспорт : num 371791.8 204331.7 64.7 5 0.9 ... ## $ ТЭКИмпорт : num 3613.6 1660.3 24.1 20.5 16.7 ... ## $ ХимЭкспорт : num 30739.2 8442.7 33.3 24.5 87.7 ... ## $ ХимИмпорт : num 50129.5 34870.4 242.8 71.7 419 ... ## $ ДревЭкспорт: num 10965.8 1101.6 6.2 23.4 57.1 ... ## $ ДревИмпорт : num 6641.5 3942.6 43.3 44.9 9 ... ## $ МетЭкспорт : num 40859.3 9877 2014.1 50.5 29 ... ## $ МетИмпорт : num 22017.4 11763.6 1207.3 68.3 56.6 ... ## $ МашЭкспорт : num 28338.5 12845.9 84.1 143.2 286.1 ... ## $ МашИмпорт : num 154371 96196 1710 823 469 ... # Выгрузим данные по федеральным округам в отдельную таблицу filter = grep(&quot;федеральный округ&quot;, tab$Регион) okr = tab[filter, ] # Отсортируем данные по федеральным округам в алфавитном порядке: okr = okr[order(okr$Регион), ] # Выгрузим данные по субъектам в отдельную таблицу filter = grepl(&quot;федеральный округ|Федерация|числе&quot;,tab$Регион) sub = tab[!filter, ] 5.1 Стандартные графики Графики (точечные и линейные) – базовый и наиболее часто используемый способ визуализации. Универсальная функция plot() позволяет строить графики по координатам \\(X\\) и \\(Y\\), которые передаются, соответственно, в первый и второй аргумент. Если переменные \\(X\\) и \\(Y\\) не связаны друг с другом явным образом, то такой график называется диаграммой рассеяния. 5.1.1 Диаграммы рассеяния Диаграмма рассеяния позволяет установить, есть ли зависимость между переменными, а также понять, как объекты дифференцируются по значениям переменных. par(mar=c(4,4,3,2)) # Диаграмма рассеяния по экспорту и импорту: plot(sub$МетЭкспорт, sub$МетИмпорт, col=&quot;red&quot;, xlab=&quot;Экспорт, млн. долл. США&quot;, ylab = &quot;Импорт, млн. долл. США&quot;, main = &quot;Экспорт/импорт металлов и изделий из них по субъектам РФ&quot;) В данном случае четко выделяется группа субъектов вблизи начала координат, не отличающихся интенсивным экспортом и импортом продукции металлургии, а также очевидно преобладание экспорта над импортом при больших объемах товарооборота. При построении диаграмм рассеяния важно сохранить одинаковый масштаб по осям \\(X\\) и \\(Y\\). Чтобы обеспечить это условие, необходимо использовать параметр asp = 1: plot(sub$МетЭкспорт, sub$МетИмпорт, col=&quot;red&quot;, xlab=&quot;Экспорт, млн. долл. США&quot;, ylab = &quot;Импорт, млн. долл. США&quot;, main = &quot;Экспорт/импорт металлов и изделий из них по субъектам РФ&quot;, asp = 1) Попробуйте изменить размер окна на вкладке Plots. Вы увидите, что масштаб по осям сохраняется пропорциональным. Размер и тип значка можно изменить, используя параметры pch = и cex =. Размеры масштабируются параметром cex относительно условной единицы — стандартного размер значка. Сам значок можно выбрать, используя его код в соответствии с нижеприведенным рисунком (на самом деле, вы можете выбирать произвольные символы для визуализации точек): Типы символов R plot(sub$МетЭкспорт, sub$МетИмпорт, col=&quot;red&quot;, xlab=&quot;Экспорт, млн. долл. США&quot;, ylab = &quot;Импорт, млн. долл. США&quot;, main = &quot;Экспорт/импорт металлов и изделий из них по субъектам РФ&quot;, asp = 1, pch = 2, cex = 0.5) plot(sub$МетЭкспорт, sub$МетИмпорт, col=&quot;red&quot;, xlab=&quot;Экспорт, млн. долл. США&quot;, ylab = &quot;Импорт, млн. долл. США&quot;, main = &quot;Экспорт/импорт металлов и изделий из них по субъектам РФ&quot;, asp = 1, pch = 20, cex = 1.2) 5.1.2 Линейные графики Линейные графики отражают связь между зависимой и независимой переменной. Существует два способа нанесения линий на график: явное рисование линий поверх уже построенного графика с помощью функции lines(), или создание нового линейного графика с помощью функции plot() с дополнительным параметром type =. Для иллюстрации принципов работы первого способа откроем еще раз данные по объему сброса загрязненных сточных вод по морям России (млрд куб. м): tab = read.csv2(&quot;data/oxr_vod.csv&quot;, encoding = &#39;UTF-8&#39;) plot(tab$Год, tab$Каспийское, pch=20) # для начала нанесем точки lines(tab$Год, tab$Каспийское) # теперь нанесем линии По умолчанию функция plot() рисует именно точки. Однако если точки не нужны, а достаточно только линий, или требуется иной подход к построению графиков, можно задать параметр type =, который принимает следующие значения: \"p\" for points, \"l\" for lines, \"b\" for both, \"c\" for the lines part alone of “b”, \"o\" for both ‘overplotted’, \"h\" for ‘histogram’ like (or ‘high-density’) vertical lines, \"s\" for stair steps, \"S\" for other steps, see ‘Details’ below, \"n\" for no plotting. Попробуем разные методы визуализации: plot(tab$Год, tab$Карское,pch=20) plot(tab$Год, tab$Каспийское, type=&quot;p&quot;) plot(tab$Год, tab$Каспийское, type=&quot;l&quot;) plot(tab$Год, tab$Каспийское, type=&quot;b&quot;) plot(tab$Год, tab$Каспийское, type=&quot;c&quot;) plot(tab$Год, tab$Каспийское, type=&quot;o&quot;) plot(tab$Год, tab$Каспийское, type=&quot;h&quot;) plot(tab$Год, tab$Каспийское, type=&quot;s&quot;) Толщину и тип линии можно изменить, используя параметры lwd = и lty = соответственно. Работают они аналогично параметрам pch и cex для точечных символов. Типов линий по умолчанию в стандартной библиотеке R не так много, но в сочетании с цветовым кодированием и толщиной их оказывается вполне достаточно: Попробуем разные варианты представления линий: plot(tab$Год, tab$Каспийское, type=&quot;l&quot;, lwd = 2, lty = 1) plot(tab$Год, tab$Каспийское, type=&quot;l&quot;, lwd = 3, lty = 2) plot(tab$Год, tab$Каспийское, type=&quot;l&quot;, lwd = 1, lty = 3) 5.1.3 Совмещение графиков Часто бывает необходимо совместить на одном графике несколько рядов данных. Для этого можно поступить двумя путями: Нарисовать один ряд данных c помощью функции plot(), а затем добавить к нему другие ряды с помощью функций points() и lines(). Нарисовать пустой график, а затем добавить к нему все ряды данных с помощью функций points() и lines(). При совмещении нескольких рядов данных на одном графике в первом же вызове функции plot() необходимо заложить диапазон значений по осям \\(X\\) и \\(Y\\), охватывающий все ряды данных. В противном случае будет учтен только разброс значений первого ряда данных, и остальные ряды могут не поместиться в поле графика. Вариант №1 реализуется следующим образом: plot(tab$Год, tab$Каспийское, pch=20, type=&quot;o&quot;, ylim = c(0,12), col=&quot;red3&quot;) # Добавим теперь на существующий график новый ряд данных, используя функции points() и lines(): points(tab$Год, tab$Карское, pch=20, col=&quot;forestgreen&quot;) lines(tab$Год, tab$Карское, pch=20, col=&quot;forestgreen&quot;) Обратите внимание на то, что если бы мы вызвали еще одну инструкцию plot() с новым рядом данных, это привело бы к построению нового графика, а не к добавлению его на существующий. Теперь рассмотрим второй вариант. Заодно устраним недостаток предыдущего кода, в котором диапазон значений по оси \\(Y\\) указывался вручную. xrange = range(tab$Год) # вычислим диапазон по оси X yrange = range(tab$Каспийское, tab$Карское, tab$Азовское) # вычислим диапазон по оси Y # Построим пустой график, охватывающий полный диапазон данных, и имеющий все необходимые сопроводительные элементы plot(xrange, yrange, main=&quot;Объем сброса загрязненных сточных вод&quot;, xlab=&quot;Год&quot;, ylab=&quot;млрд.куб.м&quot;, type = &quot;n&quot;) # n означает, что ряд данных рисоваться не будет # Теперь добавим на график ряды данных points(tab$Год, tab$Каспийское, pch=20, col=&quot;red3&quot;) lines(tab$Год, tab$Каспийское, pch=20, col=&quot;red3&quot;) points(tab$Год, tab$Карское, pch=20, col=&quot;forestgreen&quot;) lines(tab$Год, tab$Карское, pch=20, col=&quot;forestgreen&quot;) points(tab$Год, tab$Азовское, pch=20, col=&quot;steelblue&quot;) lines(tab$Год, tab$Азовское, pch=20, col=&quot;steelblue&quot;) 5.1.4 Функциональные параметры Графические параметры при построении графиков на самом деле могут быть не константами, а функцией данных. Например, вы можете сказать, что размер точки при построении диаграммы рассеяния должен быть функцией отношения экспорта к импорту, что усилит наглядность отображения: plot(okr$МетЭкспорт, okr$МетИмпорт, col=rgb(1,0,0,0.5), xlab=&quot;Экспорт, млн. долл. США&quot;, ylab = &quot;Импорт, млн. долл. США&quot;, main = &quot;Экспорт/импорт металлов и изделий из них по ФО РФ (2013 г.)&quot;, asp = 1, pch = 20, cex = 2+log(sub$МетИмпорт/sub$МетЭкспорт)) # размер кружка зависит от соотношения импорта и экспорта 5.2 Гистограммы Гистограммы распределения строятся с помощью функции hist(). Чтобы изменить ширину кармана (столбца) гистограммы, необходимо задать параметр breaks =, а цвет задается в параметре col: hist(sub$ПродЭкспорт) # Карманы будут от 0 до 3000 через 100. Заодно добавим цвет: hist(sub$ПродЭкспорт, breaks = seq(0,3000,100), col=&quot;olivedrab3&quot;) При построении гистограммы (как и любого другого типа графика) вы можете использовать не весь массив данных, а только его подмножество Например, можно посмотреть гистограмму только для субъектов с объемом экспорта менее 300: hist(sub$ПродЭкспорт[sub$ПродЭкспорт &lt; 300], col = &quot;olivedrab3&quot;, breaks = seq(0, 300, 20)) Наконец, вы можете осуществить преобразование ряда данных перед построением гистограммы. Например, взять логарифм, чтобы проверить,похоже ли распределение на логнормальное: hist(log(sub$ПродЭкспорт), col = &quot;olivedrab3&quot;) 5.3 Столбчатые графики Столбчатые графики — barplot — отображают вектор числовых данных в виде столбиков. Это простейший вид графика (наряду с dotchart), который используется для сравнения абсолютных величин. Для построения необходимо вызвать функцию barplot() и передать ей столбец таблицы: barplot(okr$ХимЭкспорт) # Или даже просто вектор натуральных чисел от -5 до 5: barplot(-5:5) # Если у каждого столбика есть название, # нужно передать вектор названий в аргумент names.arg = barplot(okr$ХимЭкспорт, names.arg = okr$Регион) # при наличии длинных подписей удобнее столбчатую диаграмму разместить горизонтально, используя параметр horiz = TRUE. barplot(okr$ХимЭкспорт, names.arg = okr$Регион, horiz=TRUE) Чтобы развернуть подписи перпендикулярно столбцам, следует использовать параметр las =. Справка__R__говорит нам о том, что этот параметр дает следующее поведение подписей: 0: всегда параллельно осям (по умолчанию), 1: всегда горизонтально, 2: всегда перпендикулярно осям, 3: всегда вертикально. Выберем вариант, при котором подписи всегда горизонтальны: barplot(okr$ХимЭкспорт, names.arg = okr$Регион, horiz=TRUE, las = 1) В данном случае очень массивные названия федеральных не умещаются в пространство графика. Можно было бы вполне убрать словосочетание “федеральный округ”. Для этого используем уже знакомую нам sub(). names = sub(&quot;федеральный округ&quot;, &quot;&quot;, okr$Регион) # &quot;&quot; - означает пустая строка barplot(okr$ХимЭкспорт, names.arg = names, horiz = TRUE, las = 1) И снова содержимое не поместилось в поле графика. Проблема в том, что вокруг любого графика резервируются поля ограниченного размера для размещения подписей координат и т.д. Автоматически эти поля не пересчитываются, зарезервировать их — ваша задача. Наберите в консоли ?par. Откроется список всевозможных графических параметров, которые управляют компоновкой и порядком построения графиков. Эти параметры можно установить, вызвав функцию par(). Все дальнейшие вызовы инструкций построения графиков будут учитывать установленные параметры Пролистайте страницу справки вниз и найдите параметр mar = — он отвечает за установку полей в условных единицах. Есть также параметр mai =, который позволяет установить поля графика в дюймах. Обратите внимание на то, что означают параметры этой функции: # mar=c(bottom, left, top, right) # The default is c(5, 4, 4, 2) + 0.1. Поскольку в нашем примере проблемы возникают в левым полем, необходимо увеличить второй параметр. margins.default = par(&quot;mar&quot;) # запишем текущее значение, чтобы восстановить его потом par(mar = c(5, 10, 4, 2)) # увеличим поле left до 10 условных единиц barplot(okr$ХимЭкспорт, names.arg = names, horiz=TRUE, las = 1) Добавим заголовок с помощью параметра main =, а подпись единиц измерения по оси \\(X\\) — с помощью параметра xlab =. Поскольку количество параметров функции уже достаточно велико, введем каждый из них с новой строчки, чтобы улучшить читаемость кода: barplot(okr$ХимЭкспорт, names.arg = names, main = &quot;Экспорт продукции химической промышленности&quot;, xlab = &quot;млн долл. США&quot;, horiz = TRUE, las = 1) # Чтобы увеличить диапазон оси X, можно использовать параметр xlim = c(min, max): barplot(okr$ХимЭкспорт, names.arg = names, main = &quot;Экспорт продукции химической промышленности&quot;, xlab = &quot;млн долл. США&quot;, horiz = TRUE, las = 1, xlim = c(0,12000)) Работа с цветом на столбчатых диаграммах рассмотрена ниже в отдельном разделе. 5.4 Круговые (секторные) диаграммы Круговые диаграммы (англ. piechart) строятся с помощью функции pie(): par(mar = c(5, 5, 5, 5)) # установим поля pie(okr$ХимЭкспорт) # вместо номеров можно использовать подписи секторов, добавив второй параметр: pie(okr$ХимЭкспорт, names) # в каждую метку можно добавить процент данного округа в общей массе. Для этого его нужно сначала посчитать: percentage = 100 * okr$ХимЭкспорт / sum(okr$ХимЭкспорт) # и округлить до 1 знака после запятой: percentage = round(percentage, digits = 1) Можно присоединить проценты к названиям округов, добавив обрамляющие скобки. Чтобы функция paste не добавляя пробелы между присоединяемыми строками, необходимо задать параметр sep = , передав ему пустую строку — \"\": names2=paste(names, &quot; (&quot;, percentage, &quot;%)&quot;, sep = &quot;&quot;) # Используем для аннотирования круговых секторов: pie(okr$ХимЭкспорт, names2) # Добавить заголовок можно также с помощью параметра main = pie(okr$ХимЭкспорт, names2, main = &quot;Доля федеральных округов в экспорте продукции химической промышленности&quot;) Чтобы перенести часть заголовка на вторую строку, вы можете использовать управляющий символ перевода строки \\n, вставив его в требуемое место: pie(okr$ХимЭкспорт, names2, main = &quot;Доля федеральных округов в экспорте \\n продукции химической промышленности&quot;) Управляющие символы играют большое значение в программировании и используются для управления поведением текстового вывода. Нотация \\n называется escape-последовательностью. Помимо перевода строки, есть и другие полезные управляющие символы. Кстати, именно из-за того, что escape-последовательности начинаются с обратной косой черты (\\), при указании системных путей в функции setwd() всегда следует использовать прямую косую черту (/). Например, следующий путь не будет найдет, поскольку он содержит управляющие последовательности \\n и \\t: C:\\data\\tables\\new. Наконец, при использовании секторных диаграмм важно уметь менять порядок секторов. По умолчанию сектора откладываются против часовой стрелки начиная с восточного направления. Чтобы сектора откладывались по часовой стрелке с северного направления, следует задать параметр clockwise = TRUE. pie(okr$ХимЭкспорт, names2, main = &quot;Доля федеральных округов в экспорте \\n продукции химической промышленности&quot;, clockwise = TRUE) Работа с цветом на круговых диаграммах рассмотрена ниже в отдельном разделе. 5.5 Цвет и прозрачность Цвет — одно из основных графических средств, используемых на графиках и диаграммах, поэтому данная тема рассмотрена более подробно в отдельном разделе. Определить цвет можно различными способами. Во-первых, в R есть палитра предопределенных цветов, которые можно выбирать по их названию). Список названий цветов можно посмотреть, вызвав функцию colors(): head(colors()) ## [1] &quot;white&quot; &quot;aliceblue&quot; &quot;antiquewhite&quot; &quot;antiquewhite1&quot; ## [5] &quot;antiquewhite2&quot; &quot;antiquewhite3&quot; Основной цвет любого графика или диаграмма задается параметром col =. Это цвет (или цвета) с помощью которых будут отображаться данные. Попробуем изменить цвет графика с серого на пастельно-синий: par(mar = c(5, 10, 4, 2)) # увеличим поле left до 10 условных единиц barplot(okr$ХимЭкспорт, names.arg = names, main = &quot;Экспорт продукции химической промышленности&quot;, xlab = &quot;млн долл. США&quot;, horiz = TRUE, las = 1, xlim = c(0,12000), col = &quot;steelblue&quot;) Помимо этого вы можете задать цвет с помощью цветовых компонент в различных пространствах. Для этого вы должны быть знакомы с основами теории цвета (посмотрите презентацию UsingColorInR.pdf. Например, фиолетовый цвет в пространстве RGB можно задать с помощью функции rgb(), смешав синюю и красную компоненты: violet = rgb(0.4, 0, 0.6) barplot(okr$ХимЭкспорт, names.arg = names, main = &quot;Экспорт продукции химической промышленности&quot;, xlab = &quot;млн долл. США&quot;, horiz = TRUE, las = 1, xlim = c(0,12000), col = violet) Чтобы сделать цвет полупрозрачным, есть две возможности: При создании нового цвета — передать в функцию rgb() дополнительный параметр alpha =, который задает долю прозрачности в диапазоне от 0 до 1. При модификации существующего цвета — вызвать функцию adjustcolor() с параметром alpha = Например: violet.transp = adjustcolor(violet, alpha = 0.5) barplot(okr$ХимЭкспорт, names.arg = names, main = &quot;Экспорт продукции химической промышленности&quot;, xlab = &quot;млн долл. США&quot;, horiz = TRUE, las = 1, xlim = c(0,12000), col = violet.transp) green.transp = rgb(0, 1, 0, 0.5) # появился четвертый параметр barplot(okr$ХимЭкспорт, names.arg = names, main = &quot;Экспорт продукции химической промышленности&quot;, xlab = &quot;млн долл. США&quot;, horiz = TRUE, las = 1, xlim = c(0,12000), col = green.transp) Функция adjustcolor() позволяет модифицировать все компоненты цвета, не только прозрачность. На графике типа barplot вы имеете фактически несколько переменных, которые представлены столбиками. А это означает что для них можно использовать различные цвета. Вы можете передать в параметр col = вектор из цветов, соответствующих столбикам: colors = c(&quot;red&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;orange&quot;, &quot;yellow&quot;, &quot;pink&quot;, &quot;white&quot;,&quot;black&quot;) barplot(okr$ХимЭкспорт, names.arg = names, main = &quot;Экспорт продукции химической промышленности&quot;, xlab = &quot;млн долл. США&quot;, horiz = TRUE, las = 1, xlim = c(0,12000), col = colors) На самом деле, такой винегрет из цветов на столбчатых диаграммах использовать не принято. Но вы должны понимать, что при необходимости можно поменять цвет отдельно выбранных столбиков. Например, мы можем показать красным цветом Центральный и Приволжский округа, которые являются лидерами по экспорту продукции химической промышленности: colors = rep(&quot;gray&quot;, 8) # сделаем 8 серых цветов colors[2] = &quot;red&quot; colors[7] = &quot;red&quot; barplot(okr$ХимЭкспорт, names.arg = names, main = &quot;Экспорт продукции химической промышленности&quot;, xlab = &quot;млн долл. США&quot;, horiz = TRUE, las = 1, xlim = c(0,12000), col = colors) Еще одна интересная особенность использования цвета заключается в том, что количество указанных цветом может не совпадать с количеством рядов данных. Вы можете указать 2 или 3 цвета, и они будут циклически повторяться при визуализации данных: colors=c(&quot;gray&quot;,&quot;steelblue&quot;) barplot(okr$ХимЭкспорт, names.arg = names, main = &quot;Экспорт продукции химической промышленности&quot;, xlab = &quot;млн долл. США&quot;, horiz =TRUE, las = 1, xlim = c(0, 12000), col = colors) Наконец, вещь, которой совершенно необходимо уметь пользоваться при работе с цветом в R — это цветовые палитры. Палитры чрезвычайно удобны, когда необходимо сгенерировать множество цветов, зная лишь основные оттенки. Для этого нужно создать палитру, используя функцию colorRampPalette(): # задаем 2 опорных цвета: черный белый palet=colorRampPalette(c(&quot;black&quot;,&quot;white&quot;)) # и автоматически генерируем 8 цветов между ними: colors=palet(8) # используем их для отображения: barplot(okr$ХимЭкспорт, names.arg = names, main = &quot;Экспорт продукции химической промышленности&quot;, xlab = &quot;млн долл. США&quot;, horiz = TRUE, las = 1, xlim = c(0, 12000), col= colors) # вы можете включить в палитру произвольное количество цветов: palet=colorRampPalette(c(&quot;steelblue&quot;,&quot;white&quot;,&quot;purple4&quot;)) colors=palet(8) barplot(okr$ХимЭкспорт, names.arg = names, main = &quot;Экспорт продукции химической промышленности&quot;, xlab = &quot;млн долл. США&quot;, horiz=TRUE, las = 1, xlim = c(0, 12000), col= colors) В R существует множество стандартных палитр, их список можно найти в справке и документации. Наиболее полезные из них: colors() gray() rainbow() heat.colors() topo.colors() terrain.colors() Например, вы можете изменить цвета диаграммы, взяв их из одной из палитр или выбрав случайным образом из полной палитры цветов, используя функцию sample(): pie(okr$ХимЭкспорт, names2, main = &quot;Доля федеральных округов в экспорте \\n продукции химической промышленности&quot;, col=rainbow(length(names2))) pie(okr$ХимЭкспорт, names2, main = &quot;Доля федеральных округов в экспорте \\n продукции химической промышленности&quot;, col=sample(colors(),5)) Более богатый набор палитр можно найти в библиотеке RColorBrewer, которая представляет собой интерпретацию палитр, доступных на сайте colorbrewer2.org library(RColorBrewer) # Откроем библиотеку RColorBrewer: display.brewer.all() # Посмотрим, какие в ней имеются палитры К каждой из этих палитр можно обратиться по названию с помощью функции brewer.pal(). Поскольку нам необходимы цвета для категориальных данных, следует использовать палитры из средней части (Set3 - Accent) # выберем цвета из палитры Set2 по количеству секторов в круге: colors = brewer.pal(length(names2),&quot;Set1&quot;) # И используем их при визуализации par(mar = c(5, 5, 5, 5)) # установим поля pie(okr$ХимЭкспорт, names2, main = &quot;Доля федеральных округов в экспорте \\n продукции химической промышленности&quot;, col=colors) # Попробуем палитру Accent: pie(okr$ХимЭкспорт, names2, main = &quot;Доля федеральных округов в экспорте \\n продукции химической промышленности&quot;, col=brewer.pal(length(names2),&quot;Accent&quot;)) 5.6 Настройки отображения 5.6.1 Графические параметры Изменять размеры элементов графика можно независимо друг от друга, используя следующие параметры: cex — общий масштаб элементов на графике cex.axis — масштаб подписей координат на оси cex.lab — масштаб подписей названий осей cex.main — масштаб заголовка графика cex.sub — масштаб подзаголовка графика cex.names — масштаб подписей факторов (для некоторых типов диаграмм) Например: plot(tab$Год, tab$Каспийское, pch=20, type=&quot;o&quot;, ylim = c(0,12), col=&quot;red3&quot;, main=&quot;Объем сброса загрязненных сточных вод&quot;, xlab=&quot;Год&quot;, ylab=&quot;млрд.куб.м&quot;, cex.axis=0.8, cex.lab=0.7, cex.main=0.9, cex = 0.8) points(tab$Год, tab$Карское, pch=20, col=&quot;forestgreen&quot;,cex = 0.8) lines(tab$Год, tab$Карское, pch=20, col=&quot;forestgreen&quot;) points(tab$Год, tab$Азовское, pch=20, col=&quot;steelblue&quot;,cex = 0.8) lines(tab$Год, tab$Азовское, pch=20, col=&quot;steelblue&quot;) Аналогично происходит тонкая настройка цвета: col цвет графика col.axis цвет подписей координат col.lab цвет названий осей col.main цвет заголовка col.sub цвет подзаголовка fg цвет элементов переднего плана (оси, рамка и т.д.) bg цвет фона графика (background) plot(tab$Год, tab$Каспийское, pch=20, type=&quot;o&quot;, ylim = c(0,12), col=&quot;red3&quot;, main=&quot;Объем сброса загрязненных сточных вод&quot;, xlab=&quot;Год&quot;, ylab=&quot;млрд.куб.м&quot;, cex.axis=0.8, cex.lab=0.7, cex.main=0.9, col.lab = &quot;grey50&quot;, fg = &quot;grey40&quot;) points(tab$Год, tab$Карское, pch=20, col=&quot;forestgreen&quot;) lines(tab$Год, tab$Карское, pch=20, col=&quot;forestgreen&quot;) points(tab$Год, tab$Азовское, pch=20, col=&quot;steelblue&quot;) lines(tab$Год, tab$Азовское, pch=20, col=&quot;steelblue&quot;) 5.6.2 Разметка осей, рамка, сетка координат и произвольные линии По умолчанию R подбирает оптимальный с точки зрения него шаг разметки осей, в зависимости от разброса значений по осям \\(X\\) и \\(Y\\), а также размеров графического устройства, на котором производится рисование. Изменяя размер окна прорисовки, вы получите различную разметку осей. В то же время, часто возникает желание (или необходимость) самостоятельно управлять шагом разметки сетки. Для этого необходимо: Вызвать функцию plot(), передав ей дополнительно параметр axes = FALSE (убирает при рисовании обе оси) или один из параметров xaxt=\"n\" / yaxt=\"n\" (убирают оси \\(X\\) и \\(Y\\) соответственно) Вызвать столько раз функцию axis(), сколько вы хотите нарисовать осей, передав ей параметры для рисования каждой оси. Функция axis() принимает следующие параметры: side — сторона графика, на которой будет нарисована ось (1=bottom, 2=left, 3=top, 4=right) at — вектор значений, в которых должны быть нарисованы метки оси labels — вектор подписей, которые будут нарисованы в местоположениях, указанных в параметре at. Этот параметр можно пропустить, если подписи совпадают с местоположениями меток pos — координата, вдоль которой будет нарисована ось lty — тип линии col — цвет линии и меток las — расположение подписей параллельно (\\(0\\)) или перпендикулярно (\\(2\\)) оси tck — длина метки относительно размера графика. Отрицательные значения дают метки, выходящие за пределы графика. положительные — внутрь графика. \\(0\\) убирает метки, \\(1\\) рисует линии сетки. При ручном построении осей полезно сразу же нарисовать рамку вокруг графика, используя функцию box(). Например: plot(tab$Год, tab$Каспийское, type = &quot;l&quot;, axes = FALSE) axis(side = 1, at = seq(min(tab$Год), max(tab$Год), 1), tck = -0.02, labels = FALSE) # разметим ось X через 1 год, но рисовать подписи не будем axis(side = 1, at = seq(min(tab$Год), max(tab$Год), 3), # а подписи расставим через 3 года tck = 0) # но рисовать метки не будем # разметим ось Y через 1 млрд куб. м., округлив предварительно минимальное и максимальное значение до ближайшего целого снизу и сверху соответственно axis(side = 2, at = seq(floor(min(tab$Каспийское)), ceiling(max(tab$Каспийское)), 1), tck = -0.02) box() # добавим рамку для красоты Для размещения сетки координат существует функция grid(nx = NULL, ny = nx, col = \"lightgray\", lty = \"dotted\", lwd = par(\"lwd\"), equilogs = TRUE). Как видно из набора ее параметров, сетка определяется количеством линий в горизонтальном и вертикальном направлении. Это не всегда бывает удобно, поскольку как правило мы хотим задать шаг сетки конкретной величины. По умолчанию, однако, линии сетки выбираются автоматически, как и метки: plot(tab$Год, tab$Каспийское, type = &quot;l&quot;, col = &quot;red&quot;) grid() Вы, разумеется, можете поменять их количество, однако R не будет за вас согласовывать шаг сетки и шаг меток осей, поскольку метки генерируются на стадии рисования plot() или axis() и не запоминаются. plot(tab$Год, tab$Каспийское, type = &quot;l&quot;, col = &quot;red&quot;) grid(10, 5) Функция grid() на самом деле является оберткой функции abline(), которая позволяет рисовать произвольные линии на графике. Дана функция предоставляет следующие возможности построения линий и серий линий: a, b — коэффициенты уравнения \\(y = ax + b\\). Таким образом можно определить только одну линию. coef — принимает вектор из двух значений, которые интерпретируются как a и b. То есть, это альтернативная форма записи предыдущего случая. h — значение (значения) координат \\(y\\) для горизонтальной линии (серии горизонтальных линий). То есть, вы можете передать в этот параметр как одиночное значение, так и вектор значений. В зависимости это этого нарисуется одна горизонтальная линия или серия горизонтальных линий. v — значение (значения) координат \\(x\\) для вертикальной линии (серии вертикальных линий). Работает аналогично параметру h. reg — сюда можно передать объект, обладающий методом coef(). Этот способ можно использовать для рисования линий регрессии. Предположим теперь, что вы хотите нарисовать сетку с шагом в 1 год по горизонтальной оси и шагом 1 млрд. куб. м по оси вертикальной. При этом вы также хотите, чтобы линии сетки располагались под графиком, а не поверх его. Также необходимо выделить особым цветом значение в 10 млрд м\\(^3\\) по оси \\(Y\\). Для этого выполним следующую последовательность действий: plot(tab$Год, tab$Каспийское, type=&quot;n&quot;) # режим &#39;n&#39; позволяет ничего не рисовать, но заложить поле графика в соответствии с данными, указанными в параметрах x и y # Вычисляем линии сетки xlines = seq(min(tab$Год), max(tab$Год), 1) ylines = seq(ceiling(min(tab$Каспийское)), floor(max(tab$Каспийское)), 1) # Рисуем линии сетки abline(h = ylines, v = xlines, col = &quot;lightgray&quot;) # Рисуем график lines(tab$Год, tab$Каспийское, col=&quot;red3&quot;) points(tab$Год, tab$Каспийское, pch = 20, col=&quot;red3&quot;) # Выделяем значение 10 по оси Y: abline(h = 10, col = &quot;blue&quot;, lwd = 2) # Рисуем дополнительно рамку, т.к. сетку координат мы рисовали после графика box() 5.6.3 Аннотации данных (текст на графике) Аннотации данных добавляются на график с помощью функции text(). В качестве трех обязательных аргументов ей необходимо передать координаты точек размещения текста, и вектор подписей. Также полезным будет указать параметр pos=, отвечающий за размещение аннотации относительно точки. Значения pos, равные 1, 2, 3 и 4, соответствуют размещению снизу, слева, сверху и справа от точки: text(tab$Год, tab$Каспийское, labels = tab$Каспийское, cex = 0.75, pos = 3) К сожалению, стандартный механизм размещения аннотаций пакета graphics не обладает возможностью устранения конфликтов подписей. Однако это возможно для графиков, построенных с помощью библиотек lattice и ggplot2. Для этого можно воспользоваться пакетом directlabels или ggrepel. 5.7 Легенда Легенда к графику размещается с помощью функции legend(). Эта функция принимает несколько аргументов, включая: местоположение, заголовок, названия элементов, графические параметры. Местоположение может быть задано координатами \\((x,y)\\) в системе координат графика, но удобнее пользоваться следующими предопределенными константами: \"bottomright\", \"bottom\", \"bottomleft\", \"left\", \"topleft\", \"top\", \"topright\", \"right\", \"center\". Чтобы в легенде появились точки, необходимо задать параметр pch=. Для линейной легенды, следует задать, соответственно, параметр lty = и/или lwd =. Каждый из этих параметров должен быть вектором по количеству элементов легенды: par(mar = margins.default) # Найдем ограничивающий прямоугольник вокруг всех рядов данных xrange = range(tab$Год) yrange = range(tab$Каспийское, tab$Карское, tab$Азовское) # Построим пустой график с разметкой осей и всеми заголовками plot(xrange, yrange, type=&quot;n&quot;, main=&quot;Объем сброса загрязненных сточных вод&quot;, xlab=&quot;Год&quot;, ylab=&quot;млрд.куб.м&quot;, cex.axis=0.8, cex.lab=0.7, cex.main=0.9, col.lab = &quot;grey50&quot;, fg = &quot;grey40&quot;) # Добавим на график сетку координат grid() # Добавим на график данные points(tab$Год, tab$Каспийское, pch=20, col=&quot;red3&quot;) lines(tab$Год, tab$Каспийское, pch=20, col=&quot;red3&quot;) points(tab$Год, tab$Карское, pch=20, col=&quot;forestgreen&quot;) lines(tab$Год, tab$Карское, pch=20, col=&quot;forestgreen&quot;) points(tab$Год, tab$Азовское, pch=20, col=&quot;steelblue&quot;) lines(tab$Год, tab$Азовское, pch=20, col=&quot;steelblue&quot;) # Определим положение, названия и цвета: main = &quot;Море&quot; location = &quot;topright&quot; labels = c(&quot;Каспийское&quot;, &quot;Карское&quot;, &quot;Азовское&quot;) colors = c(&quot;red3&quot;, &quot;forestgreen&quot;, &quot;steelblue&quot;) # Если цвет передать в параметр fill, то по умолчанию # нарисуются цветовые плашки: legend(location, labels, title = main, fill=colors) pts = c(20, 20, 20) # каждый элемент показывается точкой типа 20 lns = c(1, 1, 1) # каждый элемент показывается линией толщиной 1 # теперь посмотрим на легенду (она нарисуется поверх старой) legend(location, labels, title = main, col = colors, pch = pts, lwd = lns) Более подробно с разнообразными опциями размещения легенды на графике вы можете познакомиться, набрав в консоли команду ?legend. 5.8 Контрольные вопросы и упражнения 5.8.1 Вопросы Какая функция базового пакета R отвечает за построение стандартных графиков (диаграмм рассеяния, линейных)? Какие функции стандартной библиотеки R позволяют построить: столбчатые диаграммы, круговые секторные диаграммы, гистограммы? Как задать интервал или количество интервалов гистограммы? Можно ли разместить столбчатую диаграмму горизыонтально? Если да, то как? Какая функция отвечает за установку параметров графической подсистемы? Как установить поля вокруг графиков? Как развернуть подписи на столбчатой диаграмме перпендикулярно оси? Как установить запрет на экспоненциальное представление больших чисел при рисовании графиков? Какой параметр отвечает за установку цвета в функциях построения графиков стандартной библиотеки R? Какие параметры отвечают за установку толщины и типа линии на графиках? Какие параметры отвечают за установку размера и типа значка на диаграммах рассеяния? Как совместить несколько графиков на одной сетке координат? Какая функция рисует рамку вокруг графика? Какая функция отвечает за рисование сетки координат? Как установить равный масштаб по осям графика? Какие параметры позволяют масштабировать текст элементов графика, таких как подписи координат, осей, заголовков и подзаголовков? Назовите способы задания цвета в R. Как сделать цвет в R полупрозрачным? Назовите стандартные цветовые палитры R. Как сгенерировать последовательность из нужного количества цветов между заданными опорными цветами? Какая функция позволяет разместить легенду на графике? Как сделать так, чтобы в легенде показывались точки? Линии? Цветовые плашки? 5.8.2 Упражнения Постройте для набора данных quakes пакета datasets гистограммы распределения глубин и магнитуд, а также диаграмму рассеяния для двух этих характеристик. На портале открытых данных Тульской области есть данные о распределении площади лесов и запасов древесины по преобладающим породам и группам возраста. Скачайте эти данные в виде таблицы CSV и постройте по ним столбчатую диаграмму для категории Площадь земель, занятых лесными насаждениями (покрытых лесной растительностью), всего. Подберите цвета, попробуйте изменить ориентировку столбцов на горизонтальную. Таблица storms из пакета dplyr содержит данные трекинга тропических циклонов c 1975 по 2015 год. Извлеките из нее данные по одному выбранному циклону и постройте на основе график, показывающий трек прохождения циклона по координатам (линии), поверх которой точками показана скорость ветра (чем больше скорость, тем больше диаметр кружка). Добавьте координатную сетку на график и аннотации скорости. Загрузите файл CSV с данными по населению федеральных округов России. Постройте график изменения численности населения округов (8 графиков на одном рисунке) с легендой. Постройте круговую диаграмму распределения населения по федеральным округам за один из годов. Самсонов Т.Е. Визуализация и анализ географических данных на языке R. М.: Географический факультет МГУ, 2020. DOI: 10.5281/zenodo.901911 "],
["advgraphics.html", "Глава 6 Продвинутая графика 6.1 Предварительные требования 6.2 Загрузка данных Евростата 6.3 Загрузка данных NASA POWER 6.4 Базовый шаблон ggplot 6.5 Геометрические типы и преобразования 6.6 Графические переменные и группировки 6.7 Системы координат 6.8 Названия осей и легенды 6.9 Разметка осей 6.10 Подписи и аннотации 6.11 Фасеты 6.12 Темы 6.13 Контрольные вопросы и упражнения", " Глава 6 Продвинутая графика 6.1 Предварительные требования Для работы по теме текущей лекции вам понадобятся пакеты ggplot2, dplyr и tidyr из tidyverse. Помимо этого, мы будем работать напрямую с данными Евростата и NASA POWER, к которым можно обращаться напрямую с использованием пакетов eurostat и nasapower: library(&#39;dplyr&#39;) library(&#39;tidyr&#39;) library(&#39;ggplot2&#39;) library(&#39;eurostat&#39;) library(&#39;nasapower&#39;) В настоящей главе мы кратко познакомимся с системой ggplot2. gg расшифровывается как grammar of graphics. Под этим понимается определенная (какая — мы узнаем далее) система правил, позволяющих описывать и строить графики. ggplot довольно сильно отличается от стандартной графической подсистемы R. Прежде всего — модульным подходом к построению изображений. В ggplot вы собираете графики «по кирпичикам», отдельно определяя источник данных, способы изображения, параметры системы координат и т.д. – путем вызова и сложения результатов соответствующих функций. При построении элементарных графиков ggplot может показаться (и по факту так и есть) сложнее, чем стандартная графическая подсистема. Однако при усложнении требований к внешнему виду и информационному насыщению графика сложность ggplot оказывается преимуществом, и с ее помощью относительно просто можно получать элегантные и информативные визуализации, на создание которых с помощью стандартной подсистемы пришлось бы затратить невероятные усилия! В этой главе мы кратко познакомимся с ggplot, а далее на протяжении курса будем регулярно ее использовать, осваивая новые возможности. 6.2 Загрузка данных Евростата Таблицы данных Евростата имеют уникальные коды, по которым их можно загружать, используя API (Application programming interface). В этой лекции мы будем работать с данными о крупнейших международных партнерах Евросоюза по импорту и экспорту основных видов товаров. Например, таблица данных по продуктам питания, напиткам и табаку имеет код tet00034. Для чтения таблиц по кодам в пакете eurostat имеется функция get_eurostat(). Чтобы год измерения получить в виде числа, а не объекта типа Date, используем второй параметр time_format = num. Для перехода от кодов продукции и стран к их полным наименованиям, дополнительно вызовем функцию label_eurostat() из того же пакета: library(eurostat) tables = c(&#39;tet00034&#39;, &#39;tet00033&#39;, &#39;tet00032&#39;, &#39;tet00031&#39;,&#39;tet00030&#39;, &#39;tet00029&#39;) trades = lapply(tables, function(X) { # прочтем несколько таблиц в список get_eurostat(X) %&gt;% label_eurostat() }) %&gt;% bind_rows() %&gt;% # объединим прочитанные таблицы в одну select(-geo) %&gt;% # убираем столбец с территорией торговли, т.к. там только Евросоюз filter(stringr::str_detect(indic_et, &#39;Exports in|Imports in&#39;)) %&gt;% # оставим только экспорт и импорт pivot_wider(names_from = indic_et, values_from = values) %&gt;% # вынесем данные по экспорту и импорту в отдельные переменные rename(export = `Exports in million of ECU/EURO`, # дадим им краткие названия import = `Imports in million of ECU/EURO`) %&gt;% mutate(partner = as.factor(partner)) 6.3 Загрузка данных NASA POWER NASA POWER — это проект NASA, предоставляющий метеорологические, климатические и энергетические данные для целей исследования возобновляемых источников энергии, энергетической эффективности зданий и сельскохозяйственных приложений. Доступ к этим данным, как и Евростату, можно получить через программный интерфейса (API), используя пакет nasapower. В основе выгрузки данных лежат реанализы с разрешением \\(0.5^\\circ\\) Выгрузим данные по температуре, относительной влажности и осадкам в Екатеринбурге (\\(60.59~в.д.\\), \\(56.84~с.ш.\\)) за период с 1 по 30 апреля 1995 года: # TODO: set eval TRUE after server becomes available. library(nasapower) daily_single_ag &lt;- get_power( community = &quot;AG&quot;, lonlat = c(60.59, 56.84), pars = c(&quot;RH2M&quot;, &quot;T2M&quot;, &quot;PRECTOT&quot;), dates = c(&quot;1995-04-01&quot;, &quot;1995-04-30&quot;), temporal_average = &quot;DAILY&quot; ) daily_single_ag Аналогичным путем можно выгрузить данные, осредненные по годам. Например, можно получить данные по суммарной и прямой солнечной радиации (\\(кВт/ч/м^2/день\\)) для той же точки с 1995 по 2015 год: interannual_sse &lt;- get_power( community = &quot;SSE&quot;, lonlat = c(60.59, 56.84), dates = 1995:2015, temporal_average = &quot;INTERANNUAL&quot;, pars = c(&quot;CLRSKY_SFC_SW_DWN&quot;, &quot;ALLSKY_SFC_SW_DWN&quot;) ) interannual_sse 6.4 Базовый шаблон ggplot Для начала посмотрим, как можно показать суммарный экспорт по годам: trades_total = trades %&gt;% group_by(time) %&gt;% summarise(export = sum(export), import = sum(import)) ggplot(data = trades_total) + geom_point(mapping = aes(x = time, y = export)) Базовый (минимально необходимый) шаблон построения графика через ggplot выглядит следующим образом: ggplot(data = &lt;DATA&gt;) + &lt;GEOM_FUNCTION&gt;(mapping = aes(&lt;MAPPINGS&gt;)) где: DATA — источник данных (фрейм, тиббл) GEOM_FUNCTION — функция, отвечающая за геометрический тип графика (точки, линии, гистограммы и т.д.) MAPPINGS — перечень соответствий между переменными данных (содержащихся в DATA) и графическими переменными (координатами, размерами, цветами и т.д.) 6.5 Геометрические типы и преобразования ggplot предлагает несколько десятков различных видов геометрий для отображения данных. С их полным перечнем можно познакомиться тут. Мы рассмотрим несколько наиболее употребительных, а геометрии, связанные со статистическими преобразованиями, оставим для следующей темы. В первом примере мы отображали данные по экспорту за разные года, однако точечный тип не очень подходит для данного типа графика, поскольку он показывает динамику изменения. А это означает, что желательно соединить точки линиями. Для этого используем геометрию geom_line(): ggplot(data = trades_total) + geom_line(mapping = aes(x = time, y = export)) Поскольку в данном случае величина является агрегированной за год, более правильным может быть показ ее изменений в виде ступенчатого линейного графика, который получается через геометрию geom_step(): ggplot(data = trades_total) + geom_step(mapping = aes(x = time, y = export)) Можно совместить несколько геометрий, добавив их последовательно на график: ggplot(data = trades_total) + geom_line(mapping = aes(x = time, y = export)) + geom_point(mapping = aes(x = time, y = export)) Если у нескольких геометрий одинаковые отображения, их можно вынести в вызов функции ggplot() (чтобы не дублировать): ggplot(data = trades_total, mapping = aes(x = time, y = export)) + geom_line() + geom_point() Наглядность линейного графика можно усилить, добавив “заливку” области с использованием geom_area(): ggplot(data = trades_total, mapping = aes(x = time, y = export)) + geom_area(alpha = 0.5) + # полигон с прозрачностью 0,5 geom_line() + geom_point() Для построения столбчатой диаграммы следует использовать геометрию geom_col(). Например, вот так выглядит структура экспорта продукции машиностроения из Евросоюза по ведущим партнерам: trades %&gt;% dplyr::filter(sitc06 == &#39;Machinery and transport equipment&#39;, time == as.Date(&#39;2017-01-01&#39;)) %&gt;% ggplot(mapping = aes(x = partner, y = export)) + geom_col() Развернуть диаграмму можно, используя функцию coord_flip(): trades %&gt;% dplyr::filter(sitc06 == &#39;Machinery and transport equipment&#39;, time == as.Date(&#39;2017-01-01&#39;)) %&gt;% ggplot(mapping = aes(x = partner, y = export)) + geom_col() + coord_flip() 6.6 Графические переменные и группировки Графические переменные — это параметры, определяющие внешний вид символов. К ним относятся цвет (тон, насыщенность и светлота), размер, форма, ориентировка, внутренняя структура символа. В ggplot значения графических переменных могут быть едиными для всех измерений, а могут зависеть от величины измерений. С точки зрения управления здесь все просто: если вы хотите, чтобы какой-то графический параметр зависел от значения показателя, он должен быть указан внутри конструкции mapping = aes(...). Если необходимо, чтобы этот параметр был одинаковым для всех измерений, вы должны его указать внутри &lt;GEOM_FUNCTION&gt;(...), то есть не передавать в mapping. Для управления цветом, формой и размером (толщиной) графического примитива следует использовать параметры color, shape и size соответственно. Посмотрим, как они работают внутри и за пределами функции aes(): # один цвет для графика (параметр за пределами aes) ggplot(trades_total) + geom_line(mapping = aes(x = time, y = export), color = &#39;blue&#39;) trade_russia = trades %&gt;% filter(partner == &#39;Russia&#39;) ggplot(trade_russia) + # у каждой группы данных свой цвет (параметр внутри aes) geom_line(mapping = aes(x = time, y = export, color = sitc06)) ggplot(trade_russia, mapping = aes(x = time, y = export, color = sitc06)) + # а теперь и с точками geom_line() + geom_point() Аналогичным образом работает параметр формы значка: # один значок для графика ggplot(trades_total) + geom_point(mapping = aes(x = time, y = export), shape = 15) ggplot(trade_russia) + # у каждой группы данных свой значок geom_point(mapping = aes(x = time, y = export, shape = sitc06)) Для изменения размера значка или линии используйте параметр size: # изменение размера значка и линии ggplot(trades_total, mapping = aes(x = time, y = export)) + geom_point(size = 5) + geom_line(size = 2) Если вы используете зависимые от значений графические переменные и при этом хотите добавить на график еще одну геометрию (c постоянными параметрами), то вам необходимо сгруппировать объекты второй геометрии по той же переменной, по которой вы осуществляете разбиение в первой геометрии. Для этого используйте параметр group: ggplot(trade_russia, aes(x = time, y = export)) + geom_point(aes(shape = sitc06)) + geom_line(aes(group = sitc06)) Для изменения цвета столбчатых диаграмм следует использовать параметр fill, а цвет и толщина обводки определяются параметрами color и size: trades %&gt;% dplyr::filter(sitc06 == &#39;Machinery and transport equipment&#39;, time == as.Date(&#39;2017-01-01&#39;)) %&gt;% ggplot(mapping = aes(x = partner, y = export)) + geom_col(fill = &#39;plum4&#39;, color = &#39;black&#39;, size = 0.2) + coord_flip() Цвет на столбчатых диаграммах можно использовать для отображения дополнительных переменных, например типа экспортируемой продукции. По умолчанию столбики будут образовывать стек trades %&gt;% dplyr::filter(time == as.Date(&#39;2017-01-01&#39;)) %&gt;% ggplot(mapping = aes(x = partner, y = export, fill = sitc06)) + geom_col(color = &#39;black&#39;, size = 0.2) + coord_flip() Если вам важно не абсолютное количество, а процентное соотношение величин, вы можете применить вид группировки position == 'fill: trades %&gt;% dplyr::filter(time == as.Date(&#39;2017-01-01&#39;)) %&gt;% ggplot(mapping = aes(x = partner, y = export, fill = sitc06)) + geom_col(color = &#39;black&#39;, size = 0.2, position = &#39;fill&#39;) + coord_flip() Еще один вид группировки — это группировка по соседству. Чтобы использовать ее, применить метод position == 'dodge: trade_russia %&gt;% filter(time &gt;= as.Date(&#39;2013-01-01&#39;)) %&gt;% ggplot(mapping = aes(x = time, y = export, fill = sitc06)) + geom_col(color = &#39;black&#39;, size = 0.2, position = &#39;dodge&#39;) 6.7 Системы координат ggplot поддерживает множество полезных преобразований координат, таких как смена осей X и Y, переход к логарифмическим координатам и использование полярной системы вместо декартовой прямоугольной. Смена переменных происходит благодаря уже знакомой нам функции coord_flip(). Рассмотрим, например, как изменилась структура экспорта/импорта по годам: trades_type = trades %&gt;% group_by(sitc06, time) %&gt;% summarise(export = sum(export), import = sum(import)) ggplot(trades_type) + geom_point(mapping = aes(x = export, y = import, color = sitc06, size = time), alpha = 0.5) ggplot(trades_type) + geom_point(mapping = aes(x = export, y = import, color = sitc06, size = time), alpha = 0.5) + coord_flip() Поскольку объемы продукции различаются на порядки, для различимости малых объемов целесообразно перейти к логарифмической шкале. Для этого используем scale_log_x() и scale_log_y(): ggplot(trades_type, mapping = aes(x = export, y = import, color = sitc06, size = time)) + geom_point(alpha = 0.5) + scale_x_log10() + scale_y_log10() Преобразование в полярную систему координат используется для того чтобы получить круговую секторную диаграмму Найтингейл (coxcomb chart): trades %&gt;% dplyr::filter(sitc06 == &#39;Machinery and transport equipment&#39;, time == as.Date(&#39;2017-01-01&#39;)) %&gt;% ggplot(mapping = aes(x = partner, y = export, fill = partner)) + geom_col() + coord_polar() Разумеется, здесь тоже можно использовать преобразование шкалы по оси Y (которая теперь отвечает за радиус). Применим правило квадратного корня, добавив вызов функции scale_y_sqrt(): trades %&gt;% dplyr::filter(sitc06 == &#39;Machinery and transport equipment&#39;, time == as.Date(&#39;2017-01-01&#39;)) %&gt;% ggplot(mapping = aes(x = partner, y = export, fill = partner)) + geom_col() + coord_polar() + scale_y_sqrt() Чтобы построить классическую секторную диаграмму, необходимо, чтобы угол поворота соответствовал величине показателя (оси Y), а не названию категории (оси X). Для этого при вызове функции coord_polar() следует указать параметр theta = 'y', а при вызове geom_col() оставить параметр x пустым: trades %&gt;% dplyr::filter(sitc06 == &#39;Machinery and transport equipment&#39;, time == as.Date(&#39;2017-01-01&#39;)) %&gt;% ggplot(mapping = aes(x = &#39;&#39;, y = export, fill = partner), color = &#39;black&#39;, size = 0.2) + geom_col() + coord_polar(theta = &#39;y&#39;) 6.8 Названия осей и легенды ggplot предоставляет ряд функций для аннотирования осей и легенды. Для этого можно использовать одну из следующих функций: labs(...) модифицирует заголовок легенды для соответствующей графической переменной, либо заголовок/подзаголовок графика xlab(label) модифицирует подпись оси X ylab(label) модифицирует подпись оси Y ggtitle(label, subtitle = NULL) модифицирует заголовок и подзаголовок графика Создадим подписи легенд, отвечающих за цвет и размер значка на графике соотношения импорта и экспорта разных видов продукции: ggplot(trades_type) + geom_point(mapping = aes(x = export, y = import, color = sitc06, size = time), alpha = 0.5) + labs(color = &quot;Вид продукции&quot;, size = &#39;Год&#39;) Добавим заголовок и подзаголовок графика: ggplot(trades_type) + geom_point(mapping = aes(x = export, y = import, color = sitc06, size = time), alpha = 0.5) + labs(color = &quot;Вид продукции&quot;, size = &#39;Год&#39;) + ggtitle(&#39;Соотношение импорта и экспорта в странах Евросоюза (млн долл. США)&#39;, subtitle = &#39;Данные по ключевым партнерам&#39;) Изменим подписи осей: ggplot(trades_type) + geom_point(mapping = aes(x = export, y = import, color = sitc06, size = time), alpha = 0.5) + labs(color = &quot;Вид продукции&quot;, size = &#39;Год&#39;) + ggtitle(&#39;Соотношение импорта и экспорта в странах Евросоюза (млн долл. США)&#39;, subtitle = &#39;Данные по ключевым партнерам&#39;) + xlab(&#39;Экспорт&#39;) + ylab(&#39;Импорт&#39;) 6.9 Разметка осей Первое, что вам скорее всего захочется убрать — это экспоненциальная запись чисел. На самом деле, эта запись не является параметром ggplot или стандартной системы graphics. Количество значащих цифр, после которых число автоматически представляется в экспоненциальном виде, управляется параметром scipen. Мы можем задать его достаточно большим, чтобы запретить переводить любые разумные числа в экспоненциальный вид: options(scipen = 999) ggplot(trades_type) + geom_point(mapping = aes(x = export, y = import, color = sitc06, size = time), alpha = 0.5) + labs(color = &quot;Вид продукции&quot;, size = &#39;Год&#39;) + ggtitle(&#39;Соотношение импорта и экспорта в странах Евросоюза (млн долл. США)&#39;, subtitle = &#39;Данные по ключевым партнерам&#39;) + xlab(&#39;Экспорт&#39;) + ylab(&#39;Импорт&#39;) Для управления разметкой осей необходимо использовать функции scale_x_continuous(), scale_y_continuous(), scale_x_log10(...), scale_y_log10(...), scale_x_reverse(...), scale_y_reverse(...), scale_x_sqrt(...), scale_y_sqrt(...), которые, с одной стороны, указывают тип оси, а с другой стороны — позволяют управлять параметрами сетки координат и подписями. Для изменения координат линий сетки и подписей необходимо использовать, соответственно, параметры breaks и labels: ggplot(trades_type, mapping = aes(x = export, y = import, color = sitc06, size = time)) + geom_point(alpha = 0.5) + scale_x_log10(breaks = seq(0, 500000, 100000)) + scale_y_log10(breaks = seq(0, 500000, 100000)) В данном случае, как раз, будет достаточно полезным параметр labels, поскольку метки можно сделать более компактными, поделив их на 1000 (и не забыть потом указать, что объемы теперь указаны не в миллионах, а в миллиардах долларов): brks = seq(0, 500000, 100000) ggplot(trades_type, mapping = aes(x = export, y = import, color = sitc06, size = time)) + geom_point(alpha = 0.5) + scale_x_log10(breaks = brks, labels = brks / 1000) + scale_y_log10(breaks = brks, labels = brks / 1000) Для обычной шкалы используйте функции scale_x_continuous() и scale_y_continuous(): ggplot(trades_type, mapping = aes(x = export, y = import, color = sitc06, size = time)) + geom_point(alpha = 0.5) + scale_x_continuous(breaks = brks, labels = brks / 1000) + scale_y_continuous(breaks = brks, labels = brks / 1000) Для того чтобы принудительно указать диапазоны осей и графических переменных, следует использовать функции lims(...), xlim(...) и ylim(...). Например, мы можем приблизиться в левый нижний угол графика, задав диапазон 0-200000 по обеим осям: ggplot(trades_type, mapping = aes(x = export, y = import, color = sitc06, size = time)) + geom_point(alpha = 0.5) + xlim(0, 75000) + ylim(0, 75000) Функция lims() работает еще хитрее: она позволяет применять графические переменные только к ограниченному набору значений исходных данных. Например, таким путем я могу выделить на графике продукцию машиностроения: ggplot(trades_type, mapping = aes(x = export, y = import, color = sitc06, size = time)) + geom_point(alpha = 0.5) + lims(color = &#39;Machinery and transport equipment&#39;) 6.10 Подписи и аннотации С точки зрения ggplot текст на графике, отображающий входные данные, является одной из разновидностей геометрии. Размещается он с помощью функции geom_text(). Как и в случае с другими геометриями, параметры, зависящие от исходных данных, должны быть переданы внутри mapping = aes(...): ggplot(data = trades_total, mapping = aes(x = time, y = export)) + geom_area(alpha = 0.5) + # полигон с прозрачностью 0,5 geom_line() + geom_point() + geom_text(aes(label = floor(export / 1000))) # добавляем подписи Выравнивание подписи относительно якорной точки (снизу, сверху, справа, слева) по горизонтали и вертикали управляется параметрами hjust и vjust, а смещения по осям X (в координатах графика) — параметрами nudge_x и nudge_y: ggplot(data = trades_total, mapping = aes(x = time, y = export)) + geom_area(alpha = 0.5) + # полигон с прозрачностью 0,5 geom_line() + geom_point() + geom_text(aes(label = floor(export / 1000)), vjust = 0, nudge_y = 40000) # добавляем подписи Подписи с фоновой плашкой добавляются через функцию geom_label(), которая имеет аналогичный синтаксис: trades %&gt;% dplyr::filter(sitc06 == &#39;Machinery and transport equipment&#39;, time == as.Date(&#39;2017-01-01&#39;)) %&gt;% ggplot(mapping = aes(x = partner, y = export)) + geom_col(fill = &#39;plum4&#39;, color = &#39;black&#39;, size = 0.2) + coord_flip() + geom_label(aes(y = export / 2, label = floor(export / 1000))) # добавляем подписи Аннотации представляют собой объекты, размещаемые на графике вручную, и используемые, как правило, для выделения объектов и областей. Для размещения аннотаций используется функция annotate(): ggplot(data = trades_total, mapping = aes(x = time, y = export)) + geom_area(alpha = 0.5) + # полигон с прозрачностью 0,5 geom_line() + geom_point() + geom_text(aes(label = floor(export / 1000)), vjust = 0, nudge_y = 40000) + annotate(&quot;text&quot;, x = as.Date(&#39;2009-01-01&#39;), y = 550000, label = &quot;Это провал&quot;, color = &#39;red&#39;) Аннотировать можно не только подписями, но и регионами. Например, мы можем выделить область, которая соответствует импорту/экспорту продукции химической промышленности: ggplot(trades_type, mapping = aes(x = export, y = import, color = sitc06, size = time)) + annotate(&quot;rect&quot;, xmin = 100000, xmax = 250000, ymin = 75000, ymax = 175000, alpha = .2, color = &#39;black&#39;, size = 0.1) + geom_point(alpha = 0.5) + annotate(&quot;text&quot;, x = 175000, y = 190000, label = &quot;Chemicals&quot;, color = &#39;coral&#39;) 6.11 Фасеты Фасеты представляют собой множество графиков, каждый из которых отображает свою переменную или набор значений. Для разбиения на фасеты используется функция facet_wrap(), которой необходимо передать переменную разбиения с тильдой. Например, рассмотрим изменение структуры импорта по годам: brks = c(0, 50, 100, 150, 200) trades %&gt;% dplyr::filter(sitc06 == &#39;Machinery and transport equipment&#39;) %&gt;% ggplot(mapping = aes(x = partner, y = import)) + geom_col() + scale_y_continuous(breaks = brks * 1e3, labels = brks) + ggtitle(&#39;Импорт продукции машиностроения (мдрд долл. США)&#39;, subtitle = &#39;Данные по ключевым партнерам&#39;) + coord_flip() + facet_wrap(~time) 6.12 Темы Система ggplot интересна также тем, что для нее существует множество предопределенных “тем” или скинов для оформления графиков. Часть из них входит в состав самой библиотеки. Дополнительные темы можно установить через пакет ggthemes. Чтобы изменить тему оформления ggplot, достаточно прибавить в конце построения графика соответствующую функцию. Например, классическая черно-белая тема получается прибавлением функции theme_bw(): ggplot(data = trades_total, mapping = aes(x = time, y = export)) + geom_area(alpha = 0.5) + # полигон с прозрачностью 0,5 geom_line() + geom_point() + geom_text(aes(label = floor(export / 1000)), vjust = 0, nudge_y = 40000) + theme_bw() ggplot(trades_type) + geom_point(mapping = aes(x = export, y = import, color = sitc06, size = time), alpha = 0.5) + labs(color = &quot;Вид продукции&quot;, size = &#39;Год&#39;) + ggtitle(&#39;Соотношение импорта и экспорта в странах Евросоюза (млн долл. США)&#39;, subtitle = &#39;Данные по ключевым партнерам&#39;) + xlab(&#39;Экспорт&#39;) + ylab(&#39;Импорт&#39;) + theme_bw() 6.13 Контрольные вопросы и упражнения 6.13.1 Вопросы Назовите три основных компоненты шаблона построения графика в ggplot2. Как называются геометрии ggplot2, отвечающие за построение точек, линий и ступенчатых линий? Как называется геометрия ggplot2, отвечающая за построение столбчатой диаграммы? Как сделать так, чтобы графический параметр ggplot2 был постоянным для всех измерений? Как сделать так, чтобы графический параметр ggplot2 зависел от значения переменной? Перечислите названия параметров, отвечающих за цвет, размер, заливку и тип значка графического примитива. Если вы используете зависимые от значений графические переменные и при этом хотите добавить на график еще одну геометрию с постоянными параметрами, то как это можно реализовать? Перечислите названия режимов группировки столбчатых диаграмм и пути их реализации. Какая функция ggplot2 позволяет поменять местами оси координат? Перечислите типы шкал для осей координат, которые доступны в ggplot2. Назовите функцию, позволяющую перейти к полярной системе координат при построении графика в ggplot2. В чем отличие построения розы-диаграммы (coxcomb chart) и секторной диаграммы (pie chart) средствами ggplot2? Что делает функция labs()? Какие функции позволяют определить названия осей и заголовок графика? Что делает функция lims()? Как ограничить область построения графика заданным диапазоном значений координат? Как ограничить применение графических переменных только к определенным значениям измерений? Назовите геометрии, которые позволяют размещать подписи и подписи с плашками (фоном) на графиках ggplot2. Чем отличаются аннотации от геометрии подписей в ggplot? Какие виды аннотаций можно создавать? Каким образом можно построить фасетный график, на котором каждое изображение соответствует значению переменной? Каков синтаксис вызова соответствующей функции? Как поменять стиль отображения (тему) графика ggplot2? Как получить программный доступ к таблицам Евростата, не прибегая к закачке файлов? Какой пакет можно использовать для этого? Что является уникальным идентификатором таблицы в данных Евростата и как его узнать? Как преобразовать коды Евростата в загруженных таблицах в человеко-читаемые обозначения? 6.13.2 Упражнения Постройте для набора данных quakes пакета datasets точечный график, на котором в качестве координат используются широты и долготы (lat, long), цветом кружка показана глубина землетрясения, а диаметром — его магнитуда. Цвет кружков сделайте полупрозрачным Сделайте заголовок графика, подписи осей координат и легенды. Постройте графики хода метеовеличин на примере данных NASA POWER, загруженных в разделе 6.3. Для суточных данных используйте линейный график, для осредненных по месяцам — столбчатую диаграмму. Таблица storms из пакета dplyr содержит данные трекинга тропических циклонов c 1975 по 2015 год. Извлеките из нее данные по одному выбранному циклону и постройте на их основе диаграмму рассеяния, на которой за оси X и Y отвечают давление и скорость ветра, а цвет кружка соответствует типу циклона из поля status. Загрузите таблицу данных по импорту/экспорту продуктов питания, напитков и табака с портала Евростата (с использованием пакета eurostat). Постройте линейный график изменения суммарных величин импорта и экспорта по данному показателю (у вас должно получиться 2 графика на одном изображении). Используйте цвет для разделения графиков. Добавьте текстовые подписи величин импорта и экспорта. Самсонов Т.Е. Визуализация и анализ географических данных на языке R. М.: Географический факультет МГУ, 2020. DOI: 10.5281/zenodo.901911 "],
["stat-analysis.html", "Глава 7 Основы статистики 7.1 Предварительные требования 7.2 Введение 7.3 Одна переменная 7.4 Две переменных 7.5 Контрольные вопросы и упражнения", " Глава 7 Основы статистики 7.1 Предварительные требования Для работы по теме текущей лекции вам понадобятся пакеты из tidyverse. Помимо этого, мы будем работать с данными через интерфейс Google Sheets напрямую с использованием пакетов googledrive и googlesheets4. Также в лекции используется пакет ggrepel, позволяющий устранять конфликты подписей на графиках ggplot: library(tidyverse) library(googledrive) library(googlesheets4) library(ggrepel) Внимание: пакет googlesheets4 в настоящий момент не доступен на CRAN. Для его установки вам необходимо сначала стандартным путём установить пакет devtools, а затем вызвать в консоли команду devtools::install_github(\"tidyverse/googlesheets4\"). Эта команда устанавливает пакет из репозитория GitHub. 7.2 Введение Математическая статистика — раздел математики, посвящённый математическим методам систематизации, обработки и использования статистических данных для научных и практических выводов. Под статистическими данными обычно понимают числовую информацию, извлекаемую из результатов выборочных обследований, результаты серии неточных измерений и вообще любую систему количественных данных (Прохоров 2011). Статистический метод представляет собой важнейший инструмент исследования, применяющийся во всех без исключения областях науки и технологий. Математическая статистика тесно связана с теорией вероятностей – разделом математики, изучающим математические модели случайных явлений. В силу огромного разнообразия статистических методов и специфики их применения в разных приложения, в одной лекции нет возможности (и смысла) представить их в одной лекции. В связи с этим в настоящем разделе представляются основные инструменты статистики, такие как: простейшие приемы статистического описания (описательные статистики), проверка статистических гипотез, оценка плотности распределения, корреляция и регрессия. Помимо этого, в настоящем разделе большое внимание уделено построению специализированных графиков, отражающих особенности распределения величины: гистограмм, диаграмм размаха, линий регрессии и локальной регрессии, кривых и поверхностей плотности распределения. 7.2.1 Источники данных 7.2.1.1 База данных Gapminder В данной лекции мы будем работать с базой данных Gapminder, которая содержит уникальный набор показателей по странам мира, агрегированный из различных источников (многие показатели имеют ряды на несколько столетий!): База данных Gapminder Gapminder отлично подходит для знакомства со основами статистического анализа в R, поскольку эта база данных содержит показатели с разным видом распределения, которые сгруппированы по макрорегионам и континентам, и, разумеется, имеют между собой ряд взаимосвязей, совместное поведение которых можно изучать посредством корреляционного и регрессионного анализа. Данные Gapminder можно загружать в текстовом формате и формате Microsoft Excel, но куда интереснее делать это непосредственно онлайн через программный интерфейс Google Sheets. Для этого нам потребуется знать ключ каждой таблицы, которую мы загружаем. Ключ можно определить, нажав “лупу” для просмотра данных и скопировав его из адресной строки (см. выделение): Ключ таблицы Google Sheets из базы данных Gapminder 7.2.1.2 Пакет googlesheets Доступ к облачным таблицам — удобный способ работы с табличными данными, который позволяет избавиться от манипуляций с локальными файлами. Свои данные вы тоже можете хранить в таблицах Google. Если таблицы регулярно обновляются держателем данных, загрузка их из облачного хранилища будет гарантировать вам актуальность анализируемой информации. Ограниченем такого режима работы является то, что для доступа к данным вам нужен Интернет. Пакет googlesheets4 разработан профессором статистики Дженнифер Брайан для обеспечения онлайн-доступа к таблицам Google. С кратким руководством по использованию пакета вы можете ознакомиться тут. Данный пакет использует версию 4.x Google Sheets API (отсюда цифра 4 в навании) и рекомендуется к использованию вместо устаревшего пакета googlesheets. Пакет googlesheets4 работает в связке с пакетом googledrive, обеспечивающим общие методы доступа к Google Drive. Стандартная последовательность действий чтобы получить в текущей сессии таблицу с Google Drive, выглядит так: Подключить библиотеки googledrive и googlesheets4. Выполнить авторизацию пользователя путем вызова drive_auth(). При вызове этой функции откроется браузер на странице аутентификации Google. Вам необходимо будет войти в систему под своей учетной записью Google. Загрузить таблицу с помощью функции drive_get(), передав ей в качестве аргумента название таблицы (в этом случае она будет искаться на вашем диске Google) или идентификатор таблицы (этим способом можно выгрузить в среду R таблицу из любого открытого хранилища Google Drive). Если передается идентификатор таблицы, его необходимо обернуть в класс drive_id путем вызова функции as_id(). Рассмотрим как это работает на примере загрузки данных из хранилища Gapminder. 7.3 Одна переменная 7.3.1 Оценка распределения Для оценки распределения случайной величины можно использовать графические и статистические способы. Выявление типа распределения важно, поскольку статистические методы не универсальны, и во многих случаях предполагают, что изучаемая переменная подчиняется определенному закону распределения (как правило, нормальному). В качестве примера возьмем данные по ВВП на душу населения, они содержатся в таблице gapminder с ниже приведенным кодом (&#39;1cxtzRRN6ldjSGoDzFHkB8vqPavq1iOTMElGewQnmHgg&#39; %&gt;% ### ВВП на душу населения as_id() %&gt;% # преобразуем идентификатор в класс drive_id чтобы отличать его от пути drive_get() %&gt;% read_sheet() -&gt; gdpdf) # выгружаем данные по ВВП на душу населения и сохраняем в переменную incdf ## Using an auto-discovered, cached token. ## To suppress this message, modify your code or options to clearly consent to the use of a cached token. ## See gargle&#39;s &quot;Non-interactive auth&quot; vignette for more details: ## https://gargle.r-lib.org/articles/non-interactive-auth.html ## The googledrive package is using a cached token for iamste@yandex.ru. ## Using an auto-discovered, cached token. ## To suppress this message, modify your code or options to clearly consent to the use of a cached token. ## See gargle&#39;s &quot;Non-interactive auth&quot; vignette for more details: ## https://gargle.r-lib.org/articles/non-interactive-auth.html ## The googlesheets4 package is using a cached token for iamste@yandex.ru. ## # A tibble: 260 x 256 ## `GDP per capita… `1764` `1765` `1766` `1767` `1768` `1769` `1770` `1771` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Abkhazia NA NA NA NA NA NA NA NA ## 2 Afghanistan NA NA NA NA NA NA NA NA ## 3 Akrotiri and Dh… NA NA NA NA NA NA NA NA ## 4 Albania NA NA NA NA NA NA NA NA ## 5 Algeria NA NA NA NA NA NA NA NA ## 6 American Samoa NA NA NA NA NA NA NA NA ## 7 Andorra NA NA NA NA NA NA NA NA ## 8 Angola NA NA NA NA NA NA NA NA ## 9 Anguilla NA NA NA NA NA NA NA NA ## 10 Antigua and Bar… NA NA NA NA NA NA NA NA ## # … with 250 more rows, and 247 more variables: `1772` &lt;dbl&gt;, `1773` &lt;dbl&gt;, ## # `1774` &lt;dbl&gt;, `1775` &lt;dbl&gt;, `1776` &lt;dbl&gt;, `1777` &lt;dbl&gt;, `1778` &lt;dbl&gt;, ## # `1779` &lt;dbl&gt;, `1780` &lt;dbl&gt;, `1781` &lt;dbl&gt;, `1782` &lt;dbl&gt;, `1783` &lt;dbl&gt;, ## # `1784` &lt;dbl&gt;, `1785` &lt;dbl&gt;, `1786` &lt;dbl&gt;, `1787` &lt;dbl&gt;, `1788` &lt;dbl&gt;, ## # `1789` &lt;dbl&gt;, `1790` &lt;dbl&gt;, `1791` &lt;dbl&gt;, `1792` &lt;dbl&gt;, `1793` &lt;dbl&gt;, ## # `1794` &lt;dbl&gt;, `1795` &lt;dbl&gt;, `1796` &lt;dbl&gt;, `1797` &lt;dbl&gt;, `1798` &lt;dbl&gt;, ## # `1799` &lt;dbl&gt;, `1800` &lt;dbl&gt;, `1801` &lt;dbl&gt;, `1802` &lt;dbl&gt;, `1803` &lt;dbl&gt;, ## # `1804` &lt;dbl&gt;, `1805` &lt;dbl&gt;, `1806` &lt;dbl&gt;, `1807` &lt;dbl&gt;, `1808` &lt;dbl&gt;, ## # `1809` &lt;dbl&gt;, `1810` &lt;dbl&gt;, `1811` &lt;dbl&gt;, `1812` &lt;dbl&gt;, `1813` &lt;dbl&gt;, ## # `1814` &lt;dbl&gt;, `1815` &lt;dbl&gt;, `1816` &lt;dbl&gt;, `1817` &lt;dbl&gt;, `1818` &lt;dbl&gt;, ## # `1819` &lt;dbl&gt;, `1820` &lt;dbl&gt;, `1821` &lt;dbl&gt;, `1822` &lt;dbl&gt;, `1823` &lt;dbl&gt;, ## # `1824` &lt;dbl&gt;, `1825` &lt;dbl&gt;, `1826` &lt;dbl&gt;, `1827` &lt;dbl&gt;, `1828` &lt;dbl&gt;, ## # `1829` &lt;dbl&gt;, `1830` &lt;dbl&gt;, `1831` &lt;dbl&gt;, `1832` &lt;dbl&gt;, `1833` &lt;dbl&gt;, ## # `1834` &lt;dbl&gt;, `1835` &lt;dbl&gt;, `1836` &lt;dbl&gt;, `1837` &lt;dbl&gt;, `1838` &lt;dbl&gt;, ## # `1839` &lt;dbl&gt;, `1840` &lt;dbl&gt;, `1841` &lt;dbl&gt;, `1842` &lt;dbl&gt;, `1843` &lt;dbl&gt;, ## # `1844` &lt;dbl&gt;, `1845` &lt;dbl&gt;, `1846` &lt;dbl&gt;, `1847` &lt;dbl&gt;, `1848` &lt;dbl&gt;, ## # `1849` &lt;dbl&gt;, `1850` &lt;dbl&gt;, `1851` &lt;dbl&gt;, `1852` &lt;dbl&gt;, `1853` &lt;dbl&gt;, ## # `1854` &lt;dbl&gt;, `1855` &lt;dbl&gt;, `1856` &lt;dbl&gt;, `1857` &lt;dbl&gt;, `1858` &lt;dbl&gt;, ## # `1859` &lt;dbl&gt;, `1860` &lt;dbl&gt;, `1861` &lt;dbl&gt;, `1862` &lt;dbl&gt;, `1863` &lt;dbl&gt;, ## # `1864` &lt;dbl&gt;, `1865` &lt;dbl&gt;, `1866` &lt;dbl&gt;, `1867` &lt;dbl&gt;, `1868` &lt;dbl&gt;, ## # `1869` &lt;dbl&gt;, `1870` &lt;dbl&gt;, `1871` &lt;dbl&gt;, … Для дальнейшей работы целесообразно привести данные к аккуратному виду, избавившись от множества столбцов с годом измерения. Сразу получим данные за 2015 год для анализа: (gdpdf_tidy = gdpdf %&gt;% pivot_longer(cols = `1764`:`2018`, names_to = &#39;year&#39;, values_to = &#39;gdp&#39;) %&gt;% rename(Country = 1)) ## # A tibble: 66,300 x 3 ## Country year gdp ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Abkhazia 1764 NA ## 2 Abkhazia 1765 NA ## 3 Abkhazia 1766 NA ## 4 Abkhazia 1767 NA ## 5 Abkhazia 1768 NA ## 6 Abkhazia 1769 NA ## 7 Abkhazia 1770 NA ## 8 Abkhazia 1771 NA ## 9 Abkhazia 1772 NA ## 10 Abkhazia 1773 NA ## # … with 66,290 more rows gdpdf15 = filter(gdpdf_tidy, year == 2015) Для визуальной проверки вида распределения можно использовать геометрию geom_histogram(): ggplot(gdpdf15, aes(x = gdp)) + geom_histogram() Изменить ширину кармана можно, используя параметр binwidth: ggplot(gdpdf15, aes(x = gdp)) + geom_histogram(binwidth = 5000, color = &#39;black&#39;, fill = &#39;steelblue&#39;, size = 0.2) Аналогично рассмотрим показатель ожидаемой продолжительности жизни: (&#39;1H3nzTwbn8z4lJ5gJ_WfDgCeGEXK3PVGcNjQ_U5og8eo&#39; %&gt;% # продолжительность жизни as_id() %&gt;% # преобразуем идентификатор в класс drive_id чтобы отличать его от пути drive_get() %&gt;% read_sheet() -&gt; lifedf) # выгружаем данные по ВВП на душу населения и сохраняем в переменную lifedf ## # A tibble: 260 x 218 ## `Life expectanc… `1800` `1801` `1802` `1803` `1804` `1805` `1806` `1807` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Abkhazia NA NA NA NA NA NA NA NA ## 2 Afghanistan 28.2 28.2 28.2 28.2 28.2 28.2 28.2 28.1 ## 3 Akrotiri and Dh… NA NA NA NA NA NA NA NA ## 4 Albania 35.4 35.4 35.4 35.4 35.4 35.4 35.4 35.4 ## 5 Algeria 28.8 28.8 28.8 28.8 28.8 28.8 28.8 28.8 ## 6 American Samoa NA NA NA NA NA NA NA NA ## 7 Andorra NA NA NA NA NA NA NA NA ## 8 Angola 27.0 27.0 27.0 27.0 27.0 27.0 27.0 27.0 ## 9 Anguilla NA NA NA NA NA NA NA NA ## 10 Antigua and Bar… 33.5 33.5 33.5 33.5 33.5 33.5 33.5 33.5 ## # … with 250 more rows, and 209 more variables: `1808` &lt;dbl&gt;, `1809` &lt;dbl&gt;, ## # `1810` &lt;dbl&gt;, `1811` &lt;dbl&gt;, `1812` &lt;dbl&gt;, `1813` &lt;dbl&gt;, `1814` &lt;dbl&gt;, ## # `1815` &lt;dbl&gt;, `1816` &lt;dbl&gt;, `1817` &lt;dbl&gt;, `1818` &lt;dbl&gt;, `1819` &lt;dbl&gt;, ## # `1820` &lt;dbl&gt;, `1821` &lt;dbl&gt;, `1822` &lt;dbl&gt;, `1823` &lt;dbl&gt;, `1824` &lt;dbl&gt;, ## # `1825` &lt;dbl&gt;, `1826` &lt;dbl&gt;, `1827` &lt;dbl&gt;, `1828` &lt;dbl&gt;, `1829` &lt;dbl&gt;, ## # `1830` &lt;dbl&gt;, `1831` &lt;dbl&gt;, `1832` &lt;dbl&gt;, `1833` &lt;dbl&gt;, `1834` &lt;dbl&gt;, ## # `1835` &lt;dbl&gt;, `1836` &lt;dbl&gt;, `1837` &lt;dbl&gt;, `1838` &lt;dbl&gt;, `1839` &lt;dbl&gt;, ## # `1840` &lt;dbl&gt;, `1841` &lt;dbl&gt;, `1842` &lt;dbl&gt;, `1843` &lt;dbl&gt;, `1844` &lt;dbl&gt;, ## # `1845` &lt;dbl&gt;, `1846` &lt;dbl&gt;, `1847` &lt;dbl&gt;, `1848` &lt;dbl&gt;, `1849` &lt;dbl&gt;, ## # `1850` &lt;dbl&gt;, `1851` &lt;dbl&gt;, `1852` &lt;dbl&gt;, `1853` &lt;dbl&gt;, `1854` &lt;dbl&gt;, ## # `1855` &lt;dbl&gt;, `1856` &lt;dbl&gt;, `1857` &lt;dbl&gt;, `1858` &lt;dbl&gt;, `1859` &lt;dbl&gt;, ## # `1860` &lt;dbl&gt;, `1861` &lt;dbl&gt;, `1862` &lt;dbl&gt;, `1863` &lt;dbl&gt;, `1864` &lt;dbl&gt;, ## # `1865` &lt;dbl&gt;, `1866` &lt;dbl&gt;, `1867` &lt;dbl&gt;, `1868` &lt;dbl&gt;, `1869` &lt;dbl&gt;, ## # `1870` &lt;dbl&gt;, `1871` &lt;dbl&gt;, `1872` &lt;dbl&gt;, `1873` &lt;dbl&gt;, `1874` &lt;dbl&gt;, ## # `1875` &lt;dbl&gt;, `1876` &lt;dbl&gt;, `1877` &lt;dbl&gt;, `1878` &lt;dbl&gt;, `1879` &lt;dbl&gt;, ## # `1880` &lt;dbl&gt;, `1881` &lt;dbl&gt;, `1882` &lt;dbl&gt;, `1883` &lt;dbl&gt;, `1884` &lt;dbl&gt;, ## # `1885` &lt;dbl&gt;, `1886` &lt;dbl&gt;, `1887` &lt;dbl&gt;, `1888` &lt;dbl&gt;, `1889` &lt;dbl&gt;, ## # `1890` &lt;dbl&gt;, `1891` &lt;dbl&gt;, `1892` &lt;dbl&gt;, `1893` &lt;dbl&gt;, `1894` &lt;dbl&gt;, ## # `1895` &lt;dbl&gt;, `1896` &lt;dbl&gt;, `1897` &lt;dbl&gt;, `1898` &lt;dbl&gt;, `1899` &lt;dbl&gt;, ## # `1900` &lt;dbl&gt;, `1901` &lt;dbl&gt;, `1902` &lt;dbl&gt;, `1903` &lt;dbl&gt;, `1904` &lt;dbl&gt;, ## # `1905` &lt;dbl&gt;, `1906` &lt;dbl&gt;, `1907` &lt;dbl&gt;, … Преобразуем в аккуратный вид и строим гистограмму распределения: lifedf_tidy = lifedf %&gt;% pivot_longer(cols = `1800`:`2016`, names_to = &#39;year&#39;, values_to = &#39;lifexp&#39;) %&gt;% rename(Country = 1) lifedf15 = filter(lifedf_tidy, year == 2015) ggplot(lifedf15, aes(x = lifexp)) + geom_histogram(binwidth = 2, color = &#39;black&#39;, fill = &#39;olivedrab&#39;, size = 0.2) Для графической оценки распределения удобно использовать не только гистограмму, но также метод ядерного сглаживания (kernel density), который позволяет строить аппроксимацию функции плотности вероятности. Условно говоря, ядро является функцией, которая позволяет распространить потенциал каждого элемента выборки на его ближайшую окрестность. Чем больше элементов выборки сконцентрировано вблизи данной точки, тем сильнее будет их совокупно наведенный потенциал в данной точке, и тем, соответственно, выше оценка плотности распределения, которая получается суперпозицией этих потенциалов. Математически операция ядерной оценки плотности в точке \\(x\\) определяется как: \\[ \\hat f_h (x) = \\frac{1}{nh}\\sum_{i=1}^{n}K\\Big(\\frac{x - x_i}{h}\\Big) \\] где \\(K\\) — ядерная функция, \\(h &gt; 0\\) — сглаживающий параметр, \\(x_i\\) — элементы выборки, \\(n\\) — размер выборки. Ядерная функция должна удовлетворять двум критериям: \\(K(x) \\geq 0\\), \\(\\int_{-\\infty}^{+\\infty} K(x) dx = 1\\). Отсюда ясно, что любая модель функции плотности распределения может быть использована в качестве ядра: равномерное, нормальное и т.д. Как правило, ядерная функция носит бесконечно убывающий характер: чем дальше мы находимся от точки, тем меньше ее вклад в плотность распределения. В ggplot за аппроксимацию плотности распределения методом ядерного сглаживания отвечает геометрия geom_density(): ggplot(gdpdf15, aes(x = gdp)) + geom_density(color = &#39;black&#39;, fill = &#39;steelblue&#39;, alpha = 0.5) ggplot(lifedf15, aes(x = lifexp)) + geom_density(color = &#39;black&#39;, fill = &#39;olivedrab&#39;, alpha = 0.5) Вы можете комбинировать гистограммы и оценку плотности распределения, но для этого гистограмма по оси Y должна отражать не фактическое количество элементов в каждом классе, а долю или плотность вероятности (y = stat(density)): ggplot(gdpdf15, aes(x = gdp)) + geom_histogram(aes(y = stat(density)), fill = &#39;grey&#39;, color = &#39;black&#39;, size = 0.1) + geom_density(color = &#39;black&#39;, fill = &#39;steelblue&#39;, alpha = 0.5) ggplot(lifedf15, aes(x = lifexp)) + geom_histogram(aes(y = stat(density)), fill = &#39;grey&#39;, color = &#39;black&#39;, size = 0.1) + geom_density(color = &#39;black&#39;, fill = &#39;olivedrab&#39;, alpha = 0.5) При построении гистограмм и оценке плотности распределения мы допустили ошибку: приняли, что все измерения являются равнозначными. Однако в данном случае это не так. Население Люксембурга и Пакистана отличается на два порядка — это означает, что Пакистан должен иметь соответственно больший вес при построении гистограммы. Для учета этой характеристики подгрузим из Gapminder данные по численности населения и присоединим их к нашим таблицам по ВВП и продолжительности жизни: &#39;1IbDM8z5XicMIXgr93FPwjgwoTTKMuyLfzU6cQrGZzH8&#39; %&gt;% # численность населения as_id() %&gt;% # преобразуем идентификатор в класс drive_id чтобы отличать его от пути drive_get() %&gt;% read_sheet() %&gt;% # первый лист pivot_longer(cols = `1800`:`2015`, names_to = &#39;year&#39;, values_to = &#39;pop&#39;) %&gt;% rename(Country = 1) -&gt; popdf_tidy (tab = gdpdf_tidy %&gt;% inner_join(lifedf_tidy) %&gt;% inner_join(popdf_tidy)) ## # A tibble: 19,359 x 5 ## Country year gdp lifexp pop ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Abkhazia 1800 NA NA NA ## 2 Abkhazia 1810 NA NA NA ## 3 Abkhazia 1820 NA NA NA ## 4 Abkhazia 1830 NA NA NA ## 5 Abkhazia 1840 NA NA NA ## 6 Abkhazia 1850 NA NA NA ## 7 Abkhazia 1860 NA NA NA ## 8 Abkhazia 1870 NA NA NA ## 9 Abkhazia 1880 NA NA NA ## 10 Abkhazia 1890 NA NA NA ## # … with 19,349 more rows Теперь мы можем произвести взвешенную оценку плотности распределения: tab15 = filter(tab, year == 2015) %&gt;% drop_na() # все веса должны быть непустыми! ggplot(tab15, aes(x = gdp, y = stat(density), weight = pop/sum(pop))) + geom_histogram(binwidth = 5000, fill = &#39;grey&#39;, color = &#39;black&#39;, size = 0.1) + geom_density(color = &#39;black&#39;, fill = &#39;steelblue&#39;, alpha = 0.5) ggplot(tab15, aes(x = lifexp, y = stat(density), weight = pop/sum(pop))) + geom_histogram(binwidth = 2.5, fill = &#39;grey&#39;, color = &#39;black&#39;, size = 0.1) + geom_density(color = &#39;black&#39;, fill = &#39;olivedrab&#39;, alpha = 0.5) Графики плотности распределения удобны тем, что их, в отличие от гистограмм, удобно комбинировать на одном изображении, используя цвет для разделения по еще одной переменной. Например, мы можем оценить, как изменились мировые диспропорции в продолжительности жизни и доходов населения за последние 50 лет (обратите внимание на параметр fill = year в эстетике: tab85 = tab %&gt;% filter(year %in% c(1965, 2015)) %&gt;% drop_na() ggplot(tab85, aes(x = gdp, fill = year, weight = pop/sum(pop))) + geom_density(alpha = 0.5) ggplot(tab85, aes(x = lifexp, fill = year, weight = pop/sum(pop))) + geom_density(alpha = 0.5) 7.3.2 Описательные статистики Описательные статистики — это числовые характеристики, описывающие особенности статистического распределения изучаемой величины. К таким характеристикам относят выборочное среднее, медиану, минимум, максимум и ряд других величин. Можно вычислять эти характеристики для всей выборки, но для включения географического контекста мы стратифицируем ее по макрорегионам, которые используются в базе данных Gapminder. Подгрузим эту информацию (данные скачиваются отсюда): library(readxl) countries = read_excel(&#39;data/gapminder.xlsx&#39;, 2) %&gt;% select(Country = name, Region = eight_regions) %&gt;% mutate(Country = factor(Country, levels = Country[order(.$Region)])) # &#39;1IbDM8z5XicMIXgr93FPwjgwoTTKMuyLfzU6cQrGZzH8&#39; %&gt;% # численность населения # as_id() %&gt;% # преобразуем идентификатор в класс drive_id чтобы отличать его от пути # drive_get() %&gt;% # read_sheet(sheet = 2) -&gt; countries ggplot(countries, aes(x = Country, y = 1, fill = Region)) + geom_col() + geom_text(aes(y = 0.5, label = Country), size = 3) + facet_wrap(~Region, scales = &quot;free&quot;, ncol = 4) + theme_bw()+ theme(panel.grid = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank(), axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank()) + guides(fill=FALSE) + coord_flip() Присоединим эти данные к исходной таблице: (tabreg = tab %&gt;% left_join(countries) %&gt;% filter(year == 2015) %&gt;% drop_na()) ## # A tibble: 172 x 6 ## Country year gdp lifexp pop Region ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Afghanistan 2015 1418. 53.8 32526562 asia_west ## 2 Albania 2015 7343. 78 2896679 europe_east ## 3 Algeria 2015 6797. 76.4 39666519 africa_north ## 4 Angola 2015 6512. 59.6 25021974 africa_sub_saharan ## 5 Antigua and Barbuda 2015 14884. 76.4 91818 america_north ## 6 Argentina 2015 16640. 76.5 43416755 america_south ## 7 Armenia 2015 5561. 74.7 3017712 europe_east ## 8 Australia 2015 38085. 82.3 23968973 east_asia_pacific ## 9 Austria 2015 37811. 81.3 8544586 europe_west ## 10 Azerbaijan 2015 10475. 72.9 9753968 europe_east ## # … with 162 more rows Мы уже знакомы с функциями min(), max(), median(), mean(), sd(), которые дают значения соответствующих описательных статистик для векторов данных. Как представить их все одновременно? Для визуализации отличий в статистических параметрах исследуемой выборки удобно использовать тип графика, который называется boxplot (а по русски — диаграмма размаха, улей, или ящик с усами). В ggplot за него отвечает геометрия geom_boxplot(): ggplot(tabreg, aes(x = Region, y = gdp)) + geom_boxplot() + coord_flip() ggplot(tabreg, aes(x = Region, y = lifexp)) + geom_boxplot() + coord_flip() Данные графики наглядно показывают, что регионы отличаются по ряду статистических параметров исследуемой переменной: среднему значению, размаху вариации (разбросу значений), среднеквадратическому отклонению Эти статистики можно получить и в табличном виде: (tabreg %&gt;% group_by(Region) %&gt;% summarise(gdp_mean = mean(gdp), gdp_sd = sd(gdp), lifexp_mean = mean(lifexp), lifexp_sd = sd(lifexp))) ## # A tibble: 8 x 5 ## Region gdp_mean gdp_sd lifexp_mean lifexp_sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 africa_north 6897. 3386. 73 4.97 ## 2 africa_sub_saharan 3583. 4553. 62.3 5.31 ## 3 america_north 13835. 11451. 74.9 4.00 ## 4 america_south 10350. 4277. 75.1 3.50 ## 5 asia_west 16374. 20957. 73.7 6.51 ## 6 east_asia_pacific 14062. 16634. 72.4 6.68 ## 7 europe_east 13634. 7030. 75.9 2.86 ## 8 europe_west 33571. 11104. 81.5 1.24 7.3.3 Статистические тесты Прежде чем манипулировать вычисленными статистиками (говорить, что в Западной Европе ВВП на душу населения в 10 раз выше, чем в Южной Африке), необходимо убедиться, что их отличия являются статистически значимыми. На статистическую значимость влияет не только абсолютная разность средних, но также характер распределения и объем выборки — выборки малого объема не могут дать высокой статистической значимости. Для сравнения средних значений и дисперсий двух статистических выборок обычно используют тест Стьюдента и тест Фишера соответственно. Проведем тесты для сравнения средних по Европе и Южной Африке используя функцию t.test() (на самом деле это тест Уэлча, являющийся модификацией теста Стьюдента): t.test(tabreg %&gt;% filter(Region == &#39;africa_sub_saharan&#39;) %&gt;% pull(gdp), tabreg %&gt;% filter(Region == &#39;europe_west&#39;) %&gt;% pull(gdp)) ## ## Welch Two Sample t-test ## ## data: tabreg %&gt;% filter(Region == &quot;africa_sub_saharan&quot;) %&gt;% pull(gdp) and tabreg %&gt;% filter(Region == &quot;europe_west&quot;) %&gt;% pull(gdp) ## t = -11.384, df = 20.547, p-value = 0.0000000002487 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -35473.63 -24502.15 ## sample estimates: ## mean of x mean of y ## 3583.326 33571.214 t.test(tabreg %&gt;% filter(Region == &#39;africa_sub_saharan&#39;) %&gt;% pull(lifexp), tabreg %&gt;% filter(Region == &#39;europe_west&#39;) %&gt;% pull(lifexp)) ## ## Welch Two Sample t-test ## ## data: tabreg %&gt;% filter(Region == &quot;africa_sub_saharan&quot;) %&gt;% pull(lifexp) and tabreg %&gt;% filter(Region == &quot;europe_west&quot;) %&gt;% pull(lifexp) ## t = -23.037, df = 55.262, p-value &lt; 0.00000000000000022 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -20.87392 -17.53317 ## sample estimates: ## mean of x mean of y ## 62.25435 81.45789 p-значения для данных тестов очень малы, что позволяет нам принять (не отвергать) гипотезу о неравенстве средних для Западной Европы и Южной Африки. Проверим, так ли значимы отличия в средних для Северной и Южной Америки: t.test(tabreg %&gt;% filter(Region == &#39;america_north&#39;) %&gt;% pull(gdp), tabreg %&gt;% filter(Region == &#39;america_south&#39;) %&gt;% pull(gdp)) ## ## Welch Two Sample t-test ## ## data: tabreg %&gt;% filter(Region == &quot;america_north&quot;) %&gt;% pull(gdp) and tabreg %&gt;% filter(Region == &quot;america_south&quot;) %&gt;% pull(gdp) ## t = 1.1742, df = 23.283, p-value = 0.2522 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -2650.736 9620.806 ## sample estimates: ## mean of x mean of y ## 13834.72 10349.69 t.test(tabreg %&gt;% filter(Region == &#39;america_north&#39;) %&gt;% pull(lifexp), tabreg %&gt;% filter(Region == &#39;america_south&#39;) %&gt;% pull(lifexp)) ## ## Welch Two Sample t-test ## ## data: tabreg %&gt;% filter(Region == &quot;america_north&quot;) %&gt;% pull(lifexp) and tabreg %&gt;% filter(Region == &quot;america_south&quot;) %&gt;% pull(lifexp) ## t = -0.20306, df = 25.802, p-value = 0.8407 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -3.121651 2.560540 ## sample estimates: ## mean of x mean of y ## 74.86111 75.14167 В данном случае, несмотря на то, что вычисленные значения средних отличаются, тест показывает очень высокие p-значения (0.25 и 0.84 соответственно), что не позволяет нам говорить о том, что эти отличия статистически значимы. Соответственно, делать на их основе какие-либо научные выводы нельзя. Аналогичным образом можно проверить статистическую значимость отличий в дисперсии (вариации значений) для разных регионов. Для этого используем функцию var.test() применительно к регионам Западной и Восточной Европы: var.test(tabreg %&gt;% filter(Region == &#39;europe_east&#39;) %&gt;% pull(gdp), tabreg %&gt;% filter(Region == &#39;europe_west&#39;) %&gt;% pull(gdp)) ## ## F test to compare two variances ## ## data: tabreg %&gt;% filter(Region == &quot;europe_east&quot;) %&gt;% pull(gdp) and tabreg %&gt;% filter(Region == &quot;europe_west&quot;) %&gt;% pull(gdp) ## F = 0.40087, num df = 22, denom df = 18, p-value = 0.0434 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.1585416 0.9726112 ## sample estimates: ## ratio of variances ## 0.4008741 var.test(tabreg %&gt;% filter(Region == &#39;europe_east&#39;) %&gt;% pull(lifexp), tabreg %&gt;% filter(Region == &#39;europe_west&#39;) %&gt;% pull(lifexp)) ## ## F test to compare two variances ## ## data: tabreg %&gt;% filter(Region == &quot;europe_east&quot;) %&gt;% pull(lifexp) and tabreg %&gt;% filter(Region == &quot;europe_west&quot;) %&gt;% pull(lifexp) ## F = 5.3246, num df = 22, denom df = 18, p-value = 0.0006859 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 2.105831 12.918723 ## sample estimates: ## ratio of variances ## 5.324617 Данный тест показывает, что отличия в вариации значений ВВП на душу населения для Западной и Восточной Европы носят пограничный характер (p = 0.04), и принимать их можно только если стоит относительно высокое пороговое значение p = 0.05. В то же время, вариация продолжительности жизни для Западной Европы существенной меньше, чем для Восточной и при данной выборке это отличие обладает высокой статистической значимостью (p = 0.0007). Соответственно, его можно принимать с уверенностью. 7.4 Две переменных Достаточно часто в задачах анализа данных возникает необходимость совместного изучения нескольких переменных. Данный раздел посвящен анализу двух переменных. 7.4.1 Оценка распределения 7.4.1.1 Диаграмма рассеяния Первичный анализ производится путем оценки совместного распределения переменных на плоскости (для двух переменных) путем построения диаграммы рассеяния. С этим графиком мы уже хорошо знакомы: ggplot(tabreg, aes(gdp, lifexp)) + geom_point() Очевидно, что в данном случае мы имеем с нелинейной зависимостью. Чтобы упростить задачу по дальнейшему анализу, можно попробовать перейти к логарифмической шкале по оси X: options(scipen = 999) ggplot(tabreg, aes(gdp, lifexp)) + geom_point() + scale_x_log10() На диаграмме рассеяния важно показать не только местоположение точек, но также их весовую значимость, которая в данном случае определяется численностью населения в стране. Введем соответствующую графическую переменную — размер точки: ggplot(tabreg, aes(gdp, lifexp, size = pop)) + geom_point(alpha = 0.5) + scale_x_log10() Еще сильнее повысить информативность диаграммы рассеяния можно, используя цвет точек для обозначения региона принадлежности. Это позволит понять связь между введенной нами географической стратификацией и распределением элементов выборки на диаграмме рассеяния: ggplot(tabreg, aes(gdp, lifexp, size = pop, color = Region)) + geom_point(alpha = 0.5) + scale_x_log10() + theme_bw() Использование цвета наглядно показывает, что африканские страны занимают нижнюю левую часть диаграммы рассеяния с малой величиной ВВП и низкой продолжительностью жизни. Целесообразно также добавить подписи крупнейших стран мира с населением более 100 млн чел, а также страны, занимающие экстремальные позиции по обеим осям, чтобы понять положение ключевых игроков на диаграмме: tablab = tabreg %&gt;% # табличка для подписей filter( pop &gt; 1e8 | gdp == min(gdp) | gdp == max(gdp) | lifexp == min(lifexp) | lifexp == max(lifexp) ) ggplot(tabreg, aes(gdp, lifexp, color = Region)) + geom_point(aes(size = pop), alpha = 0.5) + geom_text(data = tablab, aes(label = Country), check_overlap = TRUE, show.legend = FALSE) + # убрать текст из легенды scale_x_log10() + theme_bw() Устранение перекрытий подписей можно осуществить, используя геометрию geom_text_repel() из пакета ggrepel вместо стандартной geom_text() ggplot(tabreg, aes(gdp, lifexp, color = Region)) + geom_point(aes(size = pop), alpha = 0.5) + geom_text_repel(data = tablab, aes(label = Country), box.padding = 0.7, # зазор вокруг подписи segment.size = 0.2, # толщина линии выноски show.legend = FALSE) + # убрать текст из легенды scale_x_log10() + labs(label = element_blank()) + theme_bw() 7.4.1.2 Плотность распределения Плотность совместного распределения двух случайных величин представляет собой уже не кривую, а поверхность, которую можно построить с использованием геометрии geom_density_2d(). По умолчанию эта геометрия визуализируется в форме изолиний: ggplot(tabreg, aes(gdp, lifexp)) + geom_point(alpha = 0.5) + geom_density_2d()+ scale_x_log10() + theme_bw() Усилить наглядность представления можно, добавив вспомогательную растровую поверхность плотности распределения (по которой, собственно, и строятся изолинии). Обратите внимание, что для растра используется функция stat_density(): ggplot(tabreg, aes(gdp, lifexp)) + stat_density_2d(geom = &quot;raster&quot;, aes(fill = stat(density)), contour = FALSE) + geom_density_2d(color = &#39;black&#39;, size = 0.2) + geom_point(alpha = 0.5) + scale_fill_gradient(low = &quot;white&quot;, high = &quot;red&quot;) + scale_x_log10() + theme_bw() График двумерной плотности распределения показывает, что мода распределения, т.е. наиболее часто встречающийся случай, примерно соответствует странам с продолжительностью жизни 75 лет и ВВП на душу населения $10000. В некоторых случаях удобнее оказывается не аппроксимация непрерывной поверхности плотности распределения, а подсчет количества измерений по ячейкам регулярной сетки — квадратным или гексагональным. Такой подход бывает особенно полезен, когда точек измерений очень много и из-за их количества оказывается проблематично разглядеть области их концентрации. Агрегирование данных по ячейкам осуществляется путем применения геометрий geom_bin2d() и geom_hex(): ggplot(tabreg, aes(gdp, lifexp)) + geom_bin2d(bins = 10)+ geom_point(alpha = 0.5) + scale_fill_gradient(low = &quot;white&quot;, high = &quot;red&quot;) + scale_x_log10() + theme_bw() ggplot(tabreg, aes(gdp, lifexp)) + geom_hex(bins = 10) + geom_point(alpha = 0.5) + scale_fill_gradient(low = &quot;white&quot;, high = &quot;red&quot;) + scale_x_log10() + theme_bw() 7.4.2 Корреляция и регрессия Корреляционный анализ позволяет дать численную характеристику статистической связи между двумя случайными величинами, а регрессионный анализ — моделировать эту взаимосвязь посредством построения функции взаимосвязи зависимой и множества независимых переменных. 7.4.2.1 Корреляция Коэффициент корреляции — это числовая характеристика совместного распределения двух случайных величин, характеризующая их взаимосвязь. Наиболее часто в статистике употребляется выборочный коэффициент корреляции Пирсона, в котором перебираются все пары соответствующих друг другу значений из рядов \\(X = \\{x_i\\}\\) и \\(Y = \\{y_i\\}\\): \\[ r_{xy} = \\frac{\\sum_{i=1}^{n}(x_i - \\bar x)(y_i - \\bar y)}{\\sqrt{\\sum_{i=1}^{n}(x_i - \\bar x)^2} \\sqrt{\\sum_{i=1}^{n}(y_i - \\bar y)^2}}, \\] где \\(\\bar x\\) и \\(\\bar y\\) соответствуют выборочным средним для \\(X\\) и \\(Y\\). Важно помнить, что коэффициент корреляции Пирсона характеризует силу линейной связи между двумя величинами. Поэтому, если наблюдаемая нами картина взаимосвязи носит нелинейный характер, необходимо предварительно линеаризовать ее, то есть выполнить преобразование над переменными, приводящее к получению линейной зависимости. В нашем в случае изучения ВВП на душу населения и продолжительности жизни мы видели, что линеаризация возможна путем логарифмирования показателя ВВП. Для вычисления коэффициента корреляции Пирсона в R с оценкой уровня значимости используется функция cor.test(): cor.test(tabreg$gdp, tabreg$lifexp) ## ## Pearson&#39;s product-moment correlation ## ## data: tabreg$gdp and tabreg$lifexp ## t = 11.376, df = 170, p-value &lt; 0.00000000000000022 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.5632175 0.7347928 ## sample estimates: ## cor ## 0.6574446 Результат теста в данном случае показывает, что коэффициент корреляции с вероятностью 0,95 находится в интервале от 0,56 до 0,73, и его математическое ожидание равно 0,66. Проверим, можно ли уточнить эту оценку, выполнив логарифмирование показателя ВВП: cor.test(log(tabreg$gdp), tabreg$lifexp) ## ## Pearson&#39;s product-moment correlation ## ## data: log(tabreg$gdp) and tabreg$lifexp ## t = 17.327, df = 170, p-value &lt; 0.00000000000000022 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.7375973 0.8473619 ## sample estimates: ## cor ## 0.7990415 Видим, что логарифмирование показателя позволяет повысить значение коэффициента корреляции до 0,8. При этом доверительный интервал, заключающий в себя эту величину с вероятностью 0,95 существенно сузился: с 0,17 до 0,11. Очевидно, мы получили более корректную оценку взаимосвязи. 7.4.2.2 Регрессия Для построения статистической модели этой зависимости, позволяющей по значениям независимой переменной вычислять значения зависимой переменной, необходимо провести регрессионный анализ. В общем случае кривая регрессии обычно выражается линейной комбинацией набора функций: \\[ y(x) = β_0φ_0(x)+ β_1φ_1(x)+...+ β_mφ_m(x) \\] Наиболее часто используется полиномиальная регрессия, при которой \\[ y(x) = β_0+β_1x+...+ β_mx^m. \\] В этом случае основная задача регрессионного анализа сводится к поиску неизвестных коэффициентов \\(β_0,...,β_m\\), который осуществляется методом наименьших квадратов. Результатом этого поиска являются выборочные коэффициенты регрессии \\(\\hat β_0,...,\\hat β_m\\), которые дают оценку искомых параметров \\(β_0,...,β_m\\). В итоге эмпирическая линия регрессии определяется многочленом \\[ \\hat y(x)=\\hat β_0+\\hat β_1x+...+\\hat β_mx_m, \\] который и служит статистической оценкой неизвестной формы функциональной зависимости между исследуемыми величинами. Для представления моделей в R существует специальный объект, который называется формула. Формула имеет вид f ~ x + y + ..., что интерпретируется соответствующими функциями как \\(f = β_0 + β_1x + β_2y + \\dots\\) Обратите внимание на символ тильды (~) — он является отличительной особенностью формулы и интерпретируется как «зависит от». Вместо переменных в формуле вы можете использовать функции от переменных. Например log(f) ~ log(x) + sqrt(y) означает модель \\(\\log f = β_0 + β_1 \\log x + β_2 \\sqrt y\\). Если необходимо выполнить алгебраические преобразования переменных или задать конкретное значение свободного члена, то их необходимо заключить в специальную функцию I(): f ~ log(x) + I(y ^ 2) + I(0) будет означать модель вида \\(f = β_1 \\log x + β_2 y^2\\). Для краткой записи полиномиальной зависимости можно использовать вспомогательную функцию poly(), которая в качестве второго аргумента принимает степень многочлена. Т.е. f ~ poly(x, 3) означает модель вида \\(f = β_0 + β_1x + β_2x^2 + β_3x^3\\). Оценка параметров линейных моделей осуществляется с помощью функции lm(). В нашем случае модель носит простой характер: model = lm(lifexp ~ log(gdp), data = tabreg) coef(model) ## (Intercept) log(gdp) ## 25.129347 5.261476 Полученные данные говорят нам о том, что уравнение имеет вид \\(lifexp = 25.13 + 5.26 \\log(gdp)\\). Чтобы получить подробную сводку о качестве модели, мы можем вызвать summary(): summary(model) ## ## Call: ## lm(formula = lifexp ~ log(gdp), data = tabreg) ## ## Residuals: ## Min 1Q Median 3Q Max ## -18.4327 -1.9398 0.6394 3.1638 10.1937 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 25.1293 2.7178 9.246 &lt;0.0000000000000002 *** ## log(gdp) 5.2615 0.3037 17.327 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.785 on 170 degrees of freedom ## Multiple R-squared: 0.6385, Adjusted R-squared: 0.6363 ## F-statistic: 300.2 on 1 and 170 DF, p-value: &lt; 0.00000000000000022 Результаты оценки говорят о том, что регрессия построена удовлетворительно. Коэффициент детерминации (квадрат коэффициента корреляции) равен 0,64. Для визуализации модели можно извлечь из нее значения используя функцию fitted(): df = tibble(lifexp = fitted(model), gdp = tabreg$gdp) ggplot(tabreg, aes(gdp, lifexp)) + geom_point(alpha = 0.5) + geom_line(data = df, aes(gdp, lifexp), color = &#39;red&#39;, size = 1) + theme_bw() Если вам нужно только построить линию регрессии, но не находить ее коэффициенты, то вы можете пропустить этап оценки параметров модели и вывести график линейной регрессии средствами ggplot, используя геометрию geom_smooth() с параметром method = lm: ggplot(tabreg, aes(gdp, lifexp)) + geom_point(alpha = 0.5) + geom_smooth(method = &#39;lm&#39;, color = &#39;red&#39;, size = 1) + scale_x_log10() + theme_bw() 7.4.2.3 Локальная регрессия Метод локальной регрессии изначально был разработан для построения кривых регрессии в случае когда зависимость между переменными ведет себя сложным образом и не может быть описана в терминах традиционной линейной и нелинейной регрессии — глобальных методов. В этом случае область значений независимой переменной \\(X\\) можно покрыть конечным числом отрезков, для каждого из которых далее находят регрессию традиционным методом — как правило, линейную или квадратичную. Данный метод получил название LOWESS (Locally weighted scatterplot smoothing). В дальнейшем эта аббревиатура была редуцирована до LOESS. В классической постановке метод LOESS реализуется следующим образом (Cleveland 1979). Пусть дано \\(n\\) точек исходных данных с координатами \\(x\\) (независимая переменная) и \\(y\\) (зависимая). Задается число \\(0 &lt; \\alpha \\leq 1\\), которое обозначает долю от общего количества точек \\(n\\), выбираемую в окрестности каждой точки для построения регрессии. В абсолютном исчислении количество ближайших точек будет равно \\(r = [\\alpha n]\\), где \\([\\cdot]\\) — округление до ближайшего целого. Тогда вес, который будет иметь каждая \\(k\\)-я точка исходных данных в уравнении регрессии для \\(i\\)-й точки исходных данных будет определяться по формуле: \\[w_k (x_i) = W\\big((x_k - x_i)h_i^{-1}\\big),\\] где \\(h_i\\) — расстояние до \\(r\\)-го по близости соседа точки \\(x_i\\), а \\(W\\) — весовая функция, отвечающая следующим условиям: \\(W(x) &gt; 0\\) если \\(|x| &lt; 1\\); \\(W(-x) = W(x)\\); \\(W(x)\\) невозрастающая функция для \\(x \\geq 0\\); \\(W(x) = 0\\) если \\(|x| \\geq 1\\). Одним из стандартных вариантов весовой функции является “трикубическая” функция, определяемая как: \\[ W(x) = \\begin{cases} (1 - |x|^3)^3, &amp; \\text{если } |x| &lt; 1, \\\\ 0, &amp; \\text{если } |x| \\geq 1. \\end{cases} \\] Согласно определению весовой функции более близкие к \\(x_i\\) точки оказывают большее влияние на коэффициенты регрессии. Помимо этого за пределами расстояния \\(h_i\\) веса всех точек исходных данных будут обнуляться. Сглаженная оценка \\(\\hat{y}_i\\) в точке \\(x_i\\) получается в виде полинома степени \\(d\\): \\[\\hat{y}_i = \\sum_{j=0}^d \\hat{\\beta}_j (x_i) x_i^j,\\] где коэффициенты \\(\\hat{\\beta}_j\\) находятся методом наименьших квадратов путем минимизации ошибки: \\[\\sum_{k=1}^n w_k (x_i) (y_k - \\beta_0 - \\beta_1 x_k - ... - \\beta_d x_k^d)^2\\] Процедура поиска коэффициентов регрессии посторяется для каждой из \\(n\\) точек. В методе LOESS используются степени регрессии \\(d = 0, 1, 2\\). Кубические и более высокие степени полиномов на практике не применяются. При степени равной 0 метод носит название сглаживающего среднего. Для построения линии локальной регрессии используйте функцию geom_smooth() без параметра method или с явным указанием параметра method = 'loess': ggplot(tabreg, aes(gdp, lifexp)) + geom_point(alpha = 0.5) + geom_smooth() + theme_bw() При визуализации линии локальной регрессии ggplot автоматически добавляет доверительные интервалы, показывающие диапазон нахождения искомой регрессионной кривой с вероятностью 0,95. Вы можете регулировать поведение локальной регрессии, задавая параметры n (количество ближайших точек \\(r\\)), span (доля ближайших точек \\(\\alpha\\)) и formula (формула аппроксимируемой зависимости). По умолчанию используется регрессия первой степени (formula = y ~ x), значения n = 80 и span = 0.75. Вы можете их изменить, например задать более компактный охват для поиска коэффициентов. В этом случае кривая будет более чувствительна к локальному разбросу элементов выборки: ggplot(tabreg, aes(gdp, lifexp)) + geom_point(alpha = 0.5) + geom_smooth(span = 0.3) + theme_bw() Вместо координат исходных точек для построения регрессии можно использовать и произвольные координаты \\(X\\). В этом случае кривая будет соединять точки, полученные локальной регрессионной оценкой в заданных координатах \\(X\\). Именно этот принцип используется в двумерном (и многомерном) случае. Пусть даны измерения показателя в \\(N\\) исходных точках и задано число \\(\\alpha\\) — сглаживающий параметр. Тогда аппроксимация показателя в каждом узле интерполяции получается путем построения поверхности тренда (см. выше) по \\(\\alpha N\\) ближайшим исходным точкам. Как и в одномерном случае, близкие точки будут оказывать более сильное влияние на коэффициенты регрессии, чем удаленные. Метод LOESS предоставляет широкие возможности настройки благодаря вариативности параметра сглаживания и степени регрессионного полинома. 7.5 Контрольные вопросы и упражнения 7.5.1 Вопросы Перечислите названия геометрий ggplot2, отвечающих за построение гистограммы и функции плотности распределения. Как работает метод ядерного сглаживания, используемый для аппроксимации функции плотности распределения? Каким критериям должна отвечать ядерная функция? Как совместить на одном графике гистограмму распределения и функцию плотности вероятности? Какой показатель должна отображать гистограмма высотой столбиков? Можно ли при построении графиков статистического характера определить различные веса для измерений? В какой параметр они должны передаваться? Какому критерию должны отвечать веса? С помощью какой геометрии можно построить диаграмму размаха средствами ggplot2? Как следует интерпретировать этот график? Как оценить статистическую значимость отличий в средних значениях и дисперсиях двух выборок? Какие тесты можно использовать для этого? Что из себя представляет плотность совместного распределения двух случайных величин? Какая геометрия ggplot2 позволяет аппроксимировать ее и нанести на диаграмму рассеяния? С помощью каких геометрий ggplot2 можно сгруппировать элементы диаграммы рассеяния ячейками ортогональной и гексагональной сеток? В каких случаях это оказывается полезно? Что такое коэффициент корреляции Пирсона, и какими ограничениями обладает этот показатель? Какая функция позволяет осуществить тест на корреляцию между двумя переменными в R? Что позволяет получить регрессионный анализ? Какой вид имеет уравнение регрессии в общем случае? Какой вид регрессии используется чаще всего? С помощью какого метода находят выборочные коэффициенты регрессии? Что такое формула в R, и для чего она используется? Как называется символ ~, и что он означает в формулах? Каким образов в формуле можно указать алгебраическое преобразование переменной? С помощью какой функции осуществляется оценка параметров линейных регрессионных моделей в R? Какие функции позволяют извлечь из модели выборочные коэффициенты регрессии, а также смоделированные (fitted) значения? Как на основе полученной модели нанести линию регрессии на график ggplot2? Опишите последовательность действий. Можно ли нанести линию регрессии на график ggplot2, не используя явное построение модели? Какую геометрию и с какими параметрами следует использовать для этого? Что такое локальная регрессия (LOESS), и как работает этот метод? Какая геометрия, и с какими параметрами используется для построения линии локальной регрессии на графике ggplot2? Что показывает полупрозрачная серая полоса вокруг линии регрессии на графике ggplot2? 7.5.2 Упражнения Изучите по данным Gapminder такие показатели как использование энергии и выбросы \\(CO_2\\) на душу населения. Постройте для них гистограммы и кривые плотности распределения. Какое распределение имеют данные показатели? Как изменилось оно с 1990 к 2010 году? Вычислите коэффициент корреляции между этими показателями и постройте регрессионную зависимость (на 2010 год). Дайте оценку статистической значимости полученных результатов. Изучите по данным Gapminder соотношение доли сельскохозяйсвенных земель в общей площади и доле водозабора на сельскохозяйственные нужды за 2002 год. Есть ли какая-то зависимость между этими переменными? Что можно сказать о том, как распределены страны мира по этим двум показателям? Постройте по ним диаграммы размаха, сгруппировав по 4, 6 или 8 регионам Gapminder. Дайте оценку статистической значимости отличий в средних значениях и дисперсии между двумя выбранными вами регионами по доле водозабора на сельскохозяйственные нужды. Самсонов Т.Е. Визуализация и анализ географических данных на языке R. М.: Географический факультет МГУ, 2020. DOI: 10.5281/zenodo.901911 References "],
["circular.html", "Глава 8 Дирекционные и временные данные 8.1 Предварительные требования 8.2 Статистика направлений 8.3 Временные ряды 8.4 Контрольные вопросы и упражнения", " Глава 8 Дирекционные и временные данные 8.1 Предварительные требования Для работы по теме текущей лекции вам понадобятся пакеты из tidyverse. Помимо этого, необходимы методы круговой статистики из пакетов circular и NPCirc, и методы из пакета pracma. Для работы с временными данными мы воспользуемся пакетом lubridate, который входит в tidyverse, но автоматически не подключается в сессию. Мы также воспользуемся пакетом gganimate, который позволяет анимировать графики, построенные с помощью ggplot: library(tidyverse) library(circular) library(readxl) library(NPCirc) library(pracma) library(lubridate) library(gganimate) 8.2 Статистика направлений 8.2.1 Теория 8.2.1.1 Распределение фон Мизеса В географии направления играют огромную роль. Ветер, морские течения, уличная сеть, перелеты птиц — все эти явления можно охарактеризовать их направленностью. Для того, чтобы эффективно анализировать такие данные, необходимо владеть специализированным математическим аппаратом. Обработкой данных о направлениях занимается особая область математической статистики — статистика направлений, или круговая (циркулярная) статистика (Mardia, Jupp, 2000; Pewsey et al., 2013). В круговой статистике каждое направление \\(\\theta \\in [0, 2\\pi)\\) представляется в виде вектора \\(x = (\\cos \\theta, sin \\theta)\\). Все операции производятся над подобными векторами и их координатами. Аналогом нормального распределения для круговой случайной величины является распределение фон Мизеса (von Mises, 1918), которое задается функцией плотности вероятности: \\[ f(θ)=\\frac{1}{2 \\pi I_0(\\kappa)} e^{\\kappa \\cos (\\theta - \\mu)}, \\] где \\(\\kappa \\geq 0\\) — параметр концентрации, \\(\\mu\\) — среднее значение (для \\(\\kappa &gt; 0\\)) и \\[ I_p(\\kappa) = \\frac{1}{2π} \\int_{0}^{2\\pi} \\cos (p \\theta) e^{\\kappa \\cos θ} d \\theta \\] есть модифицированная функция Бесселя первого рода и порядка \\(p\\). Из формул видно, что по своему эффекту параметр концентрации противоположен среднеквадратическому отклонению \\(\\sigma\\), которое является параметром нормального распределения. Чем больше значение \\(\\kappa\\), тем более сконцентрировано распределение относительно среднего значения — отсюда идет название этого параметра. Распределение фон Мизеса используется для построения ядра при аппроксимации плотности распределения направлений методом ядерной оценки (оценки по методу Парзена-Розенблатта). В метеорологии значения \\(\\cos \\theta\\) и \\(\\sin \\theta\\) определяют соотношение зональной и меридиональной составляющей скорости [ветра] (для получения самих составляющих их надо умножить на скорость ветра). 8.2.1.2 Вычисление статистических моментов Для вычисления статистических моментов круговой случайной величины требуется найти средний равнодействующий вектор первого порядка: \\[R = (C, S),\\] где \\[C = \\frac{1}{n} \\sum_{j=1}^{n} \\cos \\theta_j,\\\\ S = \\frac{1}{n} \\sum_{j=1}^{n} \\sin \\theta_j.\\] Данный вектор имеет направление \\(\\bar\\theta\\), которое является выборочным средним направлением исследуемой величины. Выборочная средняя равнодействующая длина \\(\\bar R = \\sqrt{C^2 + S^2}\\) принимает значения в диапазоне \\([0, 1]\\) и показывает меру концентрации направлений относительно \\(\\theta\\). \\(\\bar R = 1\\) означает, что все исходные направления совпадают, \\(\\bar R = 0\\) — что данные равномерно распределены по кругу, либо распределение имеет несколько мод, которые уравновешивают друг друга. Величина \\(\\bar R\\) дает важную информацию для предварительной диагностики картины направлений. Если значение \\(\\bar R\\) близко к единице, это означает, что распределение является унимодальным и в качестве основного направления можно принять значение \\(\\bar θ\\) (Mardia and Jupp 2000). Стандартное отклонение направлений \\(v\\) в радианах может быть найдено как \\(v=\\sqrt{-2 \\ln \\bar R}\\) . В ряде случаев противоположные направления считаются эквивалентными. Например, нельзя сказать, идет ли улица с юга на север или с севера на юг. Такие данные в теории круговой статистики называются аксиальными (Mardia, Jupp, 2000). Для аксиальных данных возможный диапазон значений лежит в интервале \\([0, \\pi)\\). Поскольку методы круговой статистики рассчитаны на круговое замыкание данных, стандартный подход к обработке аксиальных данных предполагает переход от направлений к их удвоенным значениям \\(\\theta&#39; = 2\\theta\\), обработку полученных значений стандартными методами и отображение полученных значение обратно на интервал \\([0, \\pi)\\). Для среднего, медианы и моды распределения это означает простое деление полученного значения пополам (Pewsey, Neuhäuser, and Ruxton 2013). 8.2.1.3 Определение модальных направлений Модальные направления могут быть определены как по гистограмме распределения, так и методом ядерной оценки. Основной вопрос поиска эффективного ядра заключается в параметризации функции \\(K\\). Для распределения фон Мизеса таким параметром является концентрация \\(\\kappa\\). Чем больше этот параметр, тем более локализованной будет оценка, тем сильнее будут проявляться в ней существующие моды распределения, но также будут и выделяться новые моды, которые на самом деле не значимы. Малые значения \\(\\kappa\\) приведут, наоборот, к «размыванию» плотности распределения в пределах полного круга. Как и в случае с количеством интервалов гистограммы, избыточно малые и большие значения κ нежелательны. В работе (Oliveira, Crujeiras, and Rod’riguez-Casal 2012) показано, что оптимальное значение \\(\\kappa\\) может быть подобрано также для оценки распределений, являющихся конечной суммой \\(M\\) распределений фон Мизеса, то есть, мультимодальных распределений, имеющих плотность : \\[g(\\theta)=\\sum_{i=1}^{M} \\alpha_i \\frac{\\exp\\lbrace{\\kappa_i \\cos(\\theta - \\mu_i)\\rbrace}}{2 \\pi I_0 (\\kappa_i)},\\] где \\(\\sum_{i=1}^{M} = 1\\). Поскольку в результате подбора определяется не только параметр концентрации, но и число компонент в сумме распределений (Oliveira, Crujeiras, and Rod’riguez-Casal 2014), его можно также использовать для определения количества искомых мод, если это необходимо. Когда подобрана функция ядра и ее параметры, оценка плотности распределения (вычисление функции \\(\\circ f _h (x)\\)) для круговых данных делается либо для исходных направлений \\(\\theta_j\\), либо с равным (достаточно малым) интервалом — например, через 1 градус (Pewsey, Neuhäuser, and Ruxton 2013). После того как произведена оценка, могут быть выбраны направления, в которых функция плотности распределения достигает локального максимума — первого и второго по величине. Эти направления и будут соответствовать первой и второй моде распределения направлений. 8.2.2 Практика В практической части данного раздела мы будем работать с массивом среднемесячных значений метеопараметров в пограничном слое атмосферы по полярным аэрологическим обсерваториям России. Массив данных ежемесячно обновляется на портале Аисори-М ВНИИГМИ-МЦД. В системе доступны данные по следующим обсерваториям: obs = readxl::read_excel(&#39;data/bound/scheme.xlsx&#39;, 2) Индекс Название Широта Долгота 20674 Остров Диксон 73.50 80.42 21824 Тикси 71.35 128.55 22113 Мурманск 68.59 33.07 22217 Кандалакша 67.09 32.21 22271 Шойна 67.53 44.09 23078 Норильск 69.20 88.18 23205 Нарьян-Мар 67.39 53.07 23330 Салехард 66.32 66.40 24125 Оленек 68.31 112.26 24266 Верхоянск 67.55 133.38 24343 Жиганск 66.46 123.21 89512 Новолазаревская -70.75 11.83 89592 Мирный -66.65 19.71 Для каждой обсерватории даны следующие параметры: Призначная часть/ метеоэлемент/число наблюдений Обозначение Число цифр Единицы измерения Константа отсутствия Индекс станции INDEX 5 - нет Год GGGG 5 - нет Месяц MM 3 - нет Срок HH 3 GMT нет Стандартное значение высоты Z 6 м нет Среднемесячные значения давления MP 6 10·гПа -9999 Среднеквадратические отклонения давления SP 6 10·гПа -9999 Число наблюдений для давления NP 3 - нет Среднемесячные значения температуры MT 6 10·°C -9999 Среднеквадратические отклонения температуры ST 6 10·°C -9999 Число наблюдений для температуры NT 3 - нет Среднемесячные значения дефицита точки росы MD 6 10·°C -9999 Среднеквадратические отклонения дефицита точки росы SD 6 10·°C -9999 Число наблюдений для дефицита точки росы ND 3 - нет Среднемесячные значения скалярной скорости ветра MS 6 10·м/с -9999 Среднеквадратические отклонения скалярной скорости ветра SS 6 10·м/с -9999 Число наблюдений для скалярной скорости ветра NS 3 - нет Среднемесячные значения зональной составляющей скорости ветра MU 6 10·м/с -9999 Среднеквадратические отклонения зональной составляющей скорости ветра SU 6 10·м/с -9999 Число наблюдений для зональной составляющей скорости ветра NU 3 - нет Среднемесячные значения меридиональной составляющей скорости ветра MV 6 10·м/с -9999 Среднеквадратические отклонения меридиональной составляющей скорости ветра SV 6 10·м/с -9999 Число наблюдений для меридиональной составляющей скорости ветра NV 3 - нет Загрузим данные по всем обсерваториям из текстовых файлов в папке bound: files = paste(&#39;data/bound&#39;, list.files(&#39;data/bound&#39;, &quot;*.txt&quot;), sep = &#39;/&#39;) (tab = lapply(files, function(X) { readr::read_table(X, col_names = params$Обозначение) }) %&gt;% bind_rows() %&gt;% left_join(obs, by = c(&#39;INDEX&#39; = &#39;Индекс&#39;))) # присоединим информацию о названиях станций ## # A tibble: 77,073 x 26 ## INDEX GGGG MM HH Z MP SP NP MT ST NT MD SD ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 20674 2007 1 0 2000 7629 78 27 -187 35 27 53 46 ## 2 20674 2007 1 0 1900 7732 79 27 -182 36 27 52 46 ## 3 20674 2007 1 0 1800 7836 79 27 -178 36 27 51 45 ## 4 20674 2007 1 0 1700 7942 80 27 -173 36 27 49 44 ## 5 20674 2007 1 0 1600 8048 81 27 -168 36 27 48 44 ## 6 20674 2007 1 0 1500 8157 81 27 -164 38 27 47 44 ## 7 20674 2007 1 0 1400 8266 82 27 -160 39 27 45 44 ## 8 20674 2007 1 0 1300 8376 82 27 -156 39 27 43 42 ## 9 20674 2007 1 0 1200 8488 83 27 -152 40 27 40 40 ## 10 20674 2007 1 0 1100 8601 83 27 -148 41 27 37 39 ## # … with 77,063 more rows, and 13 more variables: ND &lt;dbl&gt;, MS &lt;dbl&gt;, SS &lt;dbl&gt;, ## # NS &lt;dbl&gt;, MU &lt;dbl&gt;, SU &lt;dbl&gt;, NU &lt;dbl&gt;, MV &lt;dbl&gt;, SV &lt;dbl&gt;, NV &lt;dbl&gt;, ## # Название &lt;chr&gt;, Широта &lt;dbl&gt;, Долгота &lt;dbl&gt; Создадим объект типа circular (из пакета circular) с направлениями ветра для анализа, и запишем его в новую переменую таблицы. Предварительно определим вспомогательную функцию, вычисляющую географический азимут на основе компонент скорости: geo_azimuth = function(dx, dy) { a = atan2(dx, dy) ifelse(a &lt;= pi/2, pi/2 - a, 5*pi/2 - a) } (winds = tab %&gt;% mutate(wind = circular(geo_azimuth(MV, MU), template = &#39;geographics&#39;)) %&gt;% select(INDEX, name = Название, GGGG, MM, HH, Z, MU, MV, SS, wind)) ## # A tibble: 77,073 x 10 ## INDEX name GGGG MM HH Z MU MV SS wind ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;circular&gt; ## 1 20674 Остров Диксон 2007 1 0 2000 33 31 45 0.8166380 ## 2 20674 Остров Диксон 2007 1 0 1900 32 32 45 0.7853982 ## 3 20674 Остров Диксон 2007 1 0 1800 30 33 46 0.7378151 ## 4 20674 Остров Диксон 2007 1 0 1700 29 35 47 0.6919214 ## 5 20674 Остров Диксон 2007 1 0 1600 28 38 49 0.6350267 ## 6 20674 Остров Диксон 2007 1 0 1500 26 40 50 0.5763752 ## 7 20674 Остров Диксон 2007 1 0 1400 25 41 51 0.5475622 ## 8 20674 Остров Диксон 2007 1 0 1300 25 42 54 0.5369107 ## 9 20674 Остров Диксон 2007 1 0 1200 24 45 56 0.4899573 ## 10 20674 Остров Диксон 2007 1 0 1100 24 49 58 0.4554511 ## # … with 77,063 more rows Выберем данные по высоте 0 метров за 12 часов дня для поселка Тикси, сохранив только составляющие скорости и ее скалярную величину: (tiksi_wind = winds %&gt;% filter(name == &#39;Тикси&#39;, HH == 12, Z == 0)) ## # A tibble: 136 x 10 ## INDEX name GGGG MM HH Z MU MV SS wind ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;circular&gt; ## 1 21824 Тикси 2007 1 12 0 36 35 48 0.7994817 ## 2 21824 Тикси 2007 2 12 0 16 11 27 0.9685090 ## 3 21824 Тикси 2007 3 12 0 23 22 34 0.8076167 ## 4 21824 Тикси 2007 4 12 0 17 9 30 1.0838971 ## 5 21824 Тикси 2007 5 12 0 -17 -3 34 4.5377168 ## 6 21824 Тикси 2007 6 12 0 -23 -25 27 3.8853482 ## 7 21824 Тикси 2007 7 12 0 -5 -11 27 3.5682201 ## 8 21824 Тикси 2007 8 12 0 4 5 25 0.6747409 ## 9 21824 Тикси 2007 9 12 0 24 14 34 1.0427219 ## 10 21824 Тикси 2007 10 12 0 41 47 40 0.7173217 ## # … with 126 more rows Отобразим распределение направлений, розу-диаграмму и плотность распределения. Для построени графиков используем функции plot.circular() и rose.diag из пакета circular. Для аппроксимации плотности распределения направлений воспользуемся функцией kern.den.circ() из пакета NPCirc. Эта функция использует функцию плотности распределения фон Мизеса в качестве ядра и по умолчанию разбивает круг на 250 направлений, по которым производится оценка плотности (при необходимости это значение можно изменить в параметре len): plot.circular(tiksi_wind$wind, cex = 0.5, stack = TRUE, sep = 0.035, axes = FALSE, main = &#39;Среднемноголетняя роза ветров в Тикси&#39;, sub = &#39;Измерения за период с 2007 по 2018 г, высота 0 м&#39;) rose.diag(tiksi_wind$wind, bins = 8, col = &#39;gray70&#39;, border = &#39;gray30&#39;, prop = 1, add = TRUE, tick = FALSE, lwd = 0.5) kden = kern.den.circ(tiksi_wind$wind) lines(kden, shrink = 3, # параметр shrink отвечает за масштаб радиус-вектора join = F, col = &#39;steelblue&#39;) Параметр shrink отвечает за масштаб радиус-вектора на графиках из пакета circular. Чем больше его величина, тем сильнее будет сжат график относительно центра круга. Так же как и в случае с обычными данными, плотность распределения удобно использовать для определения модальных направлений, то есть наиболее часто встречающихся. Для этого воспользуемся функцией findpeaks() из пакета pracma: peak = findpeaks(kden$y, sortstr = T)[1,2] # находим индекс самого высокого пика плотности распределения (modal = kden$x[peak]) # извлекаем сам угол ## Circular Data: ## Type = angles ## Units = radians ## Template = geographics ## Modulo = asis ## Zero = 1.570796 ## Rotation = clock ## [1] 0.813786 # раскладываем на составляющие для отрисовки линии xp = sin(modal) yp = cos(modal) plot.circular(tiksi_wind$wind, cex = 0.5, stack = TRUE, sep = 0.035, axes = FALSE, main = &#39;Среднемноголетняя роза ветров в Тикси&#39;, sub = &#39;Измерения за период с 2007 по 2018 г, высота 0 м&#39;) rose.diag(tiksi_wind$wind, bins = 8, col = &#39;gray70&#39;, border = &#39;gray30&#39;, prop = 1, add = TRUE, tick = FALSE, lwd = 0.5) lines(kden, shrink = 3, join = F, col = &#39;steelblue&#39;) lines(c(0, xp), c(0, yp), lwd = 2, col = &#39;orangered&#39;) text(x = 1.4 * xp, y = 1.4 * yp, col = &#39;orangered&#39;, labels = paste0(round(180 * modal / pi, 0), &#39;°&#39;)) # приводим к целым градусам Проведем анализ направлений для всех станций. Для этого рассчитаем функции плотности распределения и разместим их в новом фрейме данных с лист-колонкой. Лист-колонка (list-column) позволяет хранить в ячейках таблицы данные произвольного типа. В частности, используя лист-колонку, вы можете хранить в каждой ячейке не один объект, а множество объектов, например записать в нее вектор. Лист-колонка имеет тип list, и каждая ячейка в этой колонке так же, соответственно, имеет тип list. Что (и в каком количестве) располагать внутри ячейки — уже ваше дело. Лист-колонки оказываются неожиданно удобны в самых разнообразных сценариях, в том числе для представления статистических моделей (соответствующих каждой строке таблицы) и для хранения пространственных данных (об этом — в следующей лекции). Вместо хранения этих данных в отдельных переменных вы можете записать их в ячейки. В приведенном ниже коде мы группируем все измерения по имени аэрологической обсерватории, вычисляем вектор плотности распределения, записываем его в список, и этот список уже помещается функцией summarise() в единственную ячейку столбца kden, соответствующую данной аэрологической станции. Далее полученная лист-колонка используется для нахождения модальных значений (тут оказывается полезно знание функционалов семейства apply): (dens = winds %&gt;% filter(HH == 12, Z == 0) %&gt;% group_by(name) %&gt;% summarise(kden = list(kern.den.circ(wind))) %&gt;% mutate(peak = sapply(kden, function(X) { peak = findpeaks(X$y, sortstr = T)[1,2] X$x[peak] }) ) ) ## # A tibble: 13 x 3 ## name kden peak ## &lt;chr&gt; &lt;list&gt; &lt;dbl&gt; ## 1 Верхоянск &lt;dnsty.cr&gt; -2.97 ## 2 Жиганск &lt;dnsty.cr&gt; -3.20 ## 3 Кандалакша &lt;dnsty.cr&gt; -0.347 ## 4 Мирный &lt;dnsty.cr&gt; -0.826 ## 5 Мурманск &lt;dnsty.cr&gt; 0.814 ## 6 Нарьян-Мар &lt;dnsty.cr&gt; 1.04 ## 7 Новолазаревская &lt;dnsty.cr&gt; -0.902 ## 8 Норильск &lt;dnsty.cr&gt; -0.877 ## 9 Оленек &lt;dnsty.cr&gt; -3.48 ## 10 Остров Диксон &lt;dnsty.cr&gt; -0.145 ## 11 Салехард &lt;dnsty.cr&gt; -2.82 ## 12 Тикси &lt;dnsty.cr&gt; 0.814 ## 13 Шойна &lt;dnsty.cr&gt; 0.561 После этого построим розы-диаграммы для всех станций. В данном случае оправдано использование обычного цикла, т.к. итераций немного: # устанавливаем параметры компоновки par(mar = c(1,1,1,1), mfrow = c(1,2)) # строим графики в цикле for (obs_name in dens$name) { wind_df = winds %&gt;% filter(name == obs_name, HH == 12, Z == 0) dens_df = dens %&gt;% filter(name == obs_name) modal = dens_df$peak xp = sin(modal) yp = cos(modal) plot.circular(wind_df$wind, shrink = 1.2, cex = 0.5, stack = TRUE, sep = 0.035, axes = FALSE, main = obs_name) rose.diag(wind_df$wind, bins = 8, col = &#39;gray70&#39;, border = &#39;gray30&#39;, prop = 1, add = TRUE, tick = FALSE, lwd = 0.5) lines(dens_df$kden[[1]], shrink = 3, join=F, col = &#39;steelblue&#39;) lines(c(0, xp), c(0, yp), lwd = 2, col = &#39;orangered&#39;) text(x = 1.4 * xp, y = 1.4 * yp, col = &#39;orangered&#39;, labels = paste0(round(180 * modal / pi, 0), &#39;°&#39;)) # приводим к целым градусам } Таким образом, мы провели графический и статистический анализ среднемноголетних направлений ветра по данным полярных аэрологических станций России. Выявлены модальные направлений, выполнена аппроксимация функции плотности вероятности направлений ветра. 8.2.3 Статистические тесты 8.2.4 Корреляция и регрессия Существуют методы расчета показателей связи между двумя переменными, по крайней мере одна из которых является циркулярной (или сферической, если положение задается двумя углами). Их можно поделить на три большие группы, в зависимости от того, какая из переменных отвечает за направление: линейная—циркулярная; циркулярная—циркулярная; сферическая—сферическая; 8.3 Временные ряды 8.3.1 Создание и преобразование дат и времени Напомним, что текущее время и дату можно получить с помощью системных функций Sys.Date() и Sys.time(): (date = Sys.Date()) ## [1] &quot;2020-02-10&quot; (time = Sys.time()) ## [1] &quot;2020-02-10 22:08:12 MSK&quot; Полученные объекты имеют типы Date и POSIXct: class(date) ## [1] &quot;Date&quot; class(time) ## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; Несмотря на то, что время и даты печатаются на экран в виде человекочитаемых строк, их внутреннее представление выражается в количестве дней (для дат) и секунд (для времени в форммате POSIXct) начиная с некоторой точки отсчета. Такой точкой отсчета по умолчанию является начало эпохи UNIX, соответстующее \\(1\\) января \\(1970\\) года по гринвичскому (UTC) времени. Чтобы убедиться в этом, воспользуемся функцией difftime, доступной в базовом R: as.integer(date) ## [1] 18302 difftime(date, as.Date(&#39;1970-01-01&#39;)) ## Time difference of 18302 days as.integer(time) ## [1] 1581361692 difftime(time, as.POSIXct(&#39;1970-01-01 00:00:00&#39;, tz = &#39;UTC&#39;), units = &#39;secs&#39;) ## Time difference of 1581361693 secs Работа с датами и временем может быть достаточно утомительной при отсутствии специализированных средств. Пакет lubridate(???) значительно облегчает эту работу. Основные функции lubridate включают синтаксический разбор (“парсинг”) дат в разных форматах, извлечение разных компонент даты и времени (секунд, минут, часов, суток, недель, годов), вычисление разностей и периодов, а также множество вспомогательных функций (хелперов), облегачающих преобразование временных данных. Рассмотрим базовые возможности пакета на нескольких примерах. Создание дат возможно на основе целочисленных и строковых значений: library(lubridate) ymd(20150515) ## [1] &quot;2015-05-15&quot; dmy(&#39;15052015&#39;) ## [1] &quot;2015-05-15&quot; Для создания отметки времени необходимо сформировать строку, которая можети быть интерпретирована должным образом. При необходимости указывается часовой пояс: ymd_hms(&#39;2015-05-15 22:15:34&#39;) # по умолчанию Гринвичское время ## [1] &quot;2015-05-15 22:15:34 UTC&quot; ymd_hms(&#39;2015-05-15 22:15:34&#39;, tz = &quot;Europe/Moscow&quot;) ## [1] &quot;2015-05-15 22:15:34 MSK&quot; Извлечение компоненты даты/времени — одна из самых удобных и востребованных функций lubridate. С помощью этих функций вы можете вытащить из объекта год, месяц, неделю, день, час и секунду: year(time) ## [1] 2020 month(time) ## [1] 2 week(time) ## [1] 6 day(time) ## [1] 10 hour(time) ## [1] 22 second(time) ## [1] 12.573 Обратите внимание на то, что недели отсчитываются от начала года, а не месяца. Отдельно следует отметить функцию yday(), которая позволяет определить номер дня в году: yday(date) ## [1] 41 Замена компонент даты/времени осуществляется с использованием тех же функций. Например, если мы хотим то же число и время, но за другой (заранее известный) год и месяц, мы можем заменить соответствующие компоненты, используя оператор &lt;-: year(time) &lt;- 2015 month(time) &lt;- 01 time ## [1] &quot;2015-01-10 22:08:12 MSK&quot; Округление дат и времени выполняется с помощью функций round_date(), floor_date() и ceiling_date() соответственно. Например, получить первый день в текущем году можно так: floor_date(Sys.Date(), unit = &#39;year&#39;) ## [1] &quot;2020-01-01&quot; Периоды (periods) — это промежутки дат, выраженные в годах, месяцах или днях. Их удобно использовать для того чтобы сместить текущую дату на заданный интервал. Например, к ранее определенной дате можно прибавить 1 год, 4 месяца, 3 недели и 2 дня: date ## [1] &quot;2020-02-10&quot; date + years(1) + months(4) + weeks(3) + days(2) ## [1] &quot;2021-07-03&quot; Длительности (durations) — это промежутки времени, выраженные в секундах. Работают они в целом аналогично периодам: dweeks(1) ## [1] &quot;604800s (~1 weeks)&quot; time ## [1] &quot;2015-01-10 22:08:12 MSK&quot; time + dweeks(1) ## [1] &quot;2015-01-17 22:08:12 MSK&quot; time + weeks(1) ## [1] &quot;2015-01-17 22:08:12 MSK&quot; Интервалы — это отрезки между двумя датами. Интервал можно преобразовывать в периоды и длительности: (int = interval(Sys.time(), time)) ## [1] 2020-02-10 22:08:12 MSK--2015-01-10 22:08:12 MSK as.period(int, &#39;days&#39;) ## [1] &quot;-1857d 0H 0M -0.118869066238403S&quot; as.duration(int) ## [1] &quot;160444800.118869s (~5.08 years)&quot; 8.3.2 Восстановление пропусков и проверка корректности дат Данные во временных рядах часто соответствуют равноотстоящим по времени срезам (раз в несколько часов, раз в день, раз в три месяца и т.д.), что обусловлено регулярным характером сбора информации (наблюдения, предоставление отчетности и т.д.). Соответствующее предположение лежит и в основе многих функций временного анализа (таких как автокорреляционная функция). Если в данных отсутствуют некоторые временные срезы, это нарушает регулярность временного ряда, что может привести к его некорректной интерпретации. Необходимо восстановить пропущенные сроки, явным образом указав, что данных на эти сроки нет. Помимо этого, дата может быть записана в некорректной форме. Например, оператор ввода данных перепутал месяц и день 18 марта, что привело к созданию несуществующей даты 03.18 в одной из строк. Подобные несовершенства временных рядов важно выявить на самых ранних стадиях анализа данных. Рассмотрим, как эту задачу можно решить средствами R. В качестве источника данных будем использовать данные3 об уровне воды на гидропосте Паялка (р. Умба, Мурманская область) с 1932 по 2014 год. Отсутствие информации в файле данных закодировано числом 9999: (src = read_delim(&#39;data/in_Umba.txt&#39;, delim = &#39; &#39;, col_names = c(&#39;day&#39;, &#39;month&#39;, &#39;year&#39;, &#39;level&#39;), na = &#39;9999&#39;)) ## # A tibble: 30,316 x 4 ## day month year level ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 1932 49.4 ## 2 2 1 1932 NA ## 3 3 1 1932 NA ## 4 4 1 1932 NA ## 5 5 1 1932 NA ## 6 6 1 1932 NA ## 7 7 1 1932 NA ## 8 8 1 1932 NA ## 9 9 1 1932 NA ## 10 10 1 1932 47 ## # … with 30,306 more rows Сформируем даты на основе первых трёх столбцов и проверим, все ли из них корректны. Если компоненты даты некорректны, то функция yms() вернет NA: tab = src %&gt;% mutate(Date = ymd(paste(year, month, day))) tab %&gt;% filter(is.na(Date)) ## # A tibble: 1 x 5 ## day month year level Date ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; ## 1 29 2 1941 27.4 NA Проверка показала, что преобразование в дату оказалось невозможно только для одной строки. В этой строке оператором была введена несуществующая дата — 29 февраля 1941 года. Этот год не является високосным, а значит количество дней в феврале должно равняться 28. Единственный выход в данной ситуациии — отбраковать запись: tab = tab %&gt;% filter(!is.na(Date)) После того как мы убедились, что в таблице присутствуют только корректные даты, можно проверять пропуски дат. Для этого упорядочим таблицу по возрастанию дат и используем функцию lag() из пакета dplyr, чтобы вычислить разницу между каждой датой и ее предшественницей. После этого отфильтруем строки, которым предшествует 1 или более пропущенных дней и сформируем отчетную таблицу, содержащую все найденные пропуски: tab %&gt;% arrange(Date) %&gt;% mutate(Gap = Date - lag(Date, 1) - 1) %&gt;% filter(Gap &gt; 0) %&gt;% transmute(start_date = Date - Gap, end_date = Date - 1, duration = Gap) ## # A tibble: 1 x 3 ## start_date end_date duration ## &lt;date&gt; &lt;date&gt; &lt;drtn&gt; ## 1 1941-12-31 1942-01-01 2 days Данная таблица говорит нам о том, что имеется один пропуск из двух дат: 31 декабря 1941 года и 01 января 1942 года. Чтобы восстановить пропущенные сроки, воспользуемся функцией complete() из пакета tidyr, указав ей, что переменная Date должна содержать все даты с шагом в один день, начиная с самой ранней и заканчивая самой поздней: tab_compl = tab %&gt;% complete(Date = seq(min(Date, na.rm = T), max(Date, na.rm = T), by = &#39;day&#39;)) Итак, полная процедура проверки корректности и восстановления пропущенных дат в виде одного конвейера манипуляций будет выглядеть следующим образом: tab = src %&gt;% mutate(Date = ymd(paste(year, month, day))) %&gt;% filter(!is.na(Date)) %&gt;% complete(Date = seq(min(Date, na.rm = T), max(Date, na.rm = T), by = &#39;day&#39;)) 8.3.3 Интерполяция по времени Одна из распространенных задач при работе с временными данными — это интерполяция по времени. Во-первых, интерполяция может использоваться для заполнения пропусков данных. Во-вторых, необходимость в интерполяции возникает когда неравномерно распределенные по времени данные надо перенести на регулярные сроки (скажем, через час), чтобы обеспечить их сравнимость с другими рядами данных. Заметим, что и в том и в другом случае необходимо учитывать автокорреляционные свойства временного ряда и с осторожностью подходить к интерполяции на длительных промежутках времени, поскольку такая интерполяция может не иметь под собой физических оснований. 8.3.3.1 Заполнение пропусков Рассмотрим заполнение пропусков данных на примере загруженных в предыдущем параграфе данных по уровням воды на гидропосте Паялка. На первом этапе анализа пропусков данных целесообразно получить сводную таблицу, которая бы систематизировала все пропуски и непрерывные ряды данных. Для этого сначала выставим маркер data/gap (данные/пропуск) на против каждой строки в новом поле type, а затем пронумеруем все группы последовательно идущих друг за другом меток совпадающего типа. Для реализации последнего шага выполним следующее: сформируем группы непрерывно идущих следом друг за другом меток одного типа, используя функцию rle (run-length encoding); полученный объект содержит вектор lengths, количество элементов которого равняется количеству групп, а значение каждого элемента равно количеству объектов соответствующей по порядку группы; номер каждой группы (от 1 до количества групп) продублируем столько раз, сколько элементов содержится в каждой группе После этого сгруппируем данные по номеру группы и вычислим дату начала, дату конца, продолжительность и тип каждого периода. Полученная таблица наглядно демонстрирует разбиение временного ряда на периоды наличия и отсутствия данных: timerep = tab %&gt;% mutate(type = if_else(is.na(level), &#39;gap&#39;, &#39;data&#39;), num = with(rle(type), rep(seq_along(lengths), lengths))) %&gt;% group_by(num) %&gt;% summarise(start_date = min(Date), end_date = max(Date), duration = end_date - start_date + 1, type = first(type)) Путём интерполяции можно заполнить все пропуски в данном ряду, однако достоверность (правдоподобие) интерполяции будет снижаться при увеличении длины пропуска. Критическую длину пропуска целесообразно связать с пороговым значением автокорреляции — коэффициента корреляции исходного ряда данных и его копии, полученной со сдвигом \\(\\tau\\). Автокорреляцию как правило рассчитываеют не при фиксированном сдвиге, а для серии сдвигов. Полученная функция показывает зависимость автокорреляции от величины сдвига и носит название автокорреляционной функции (АКФ): \\[\\Psi(\\tau) = \\int_{-\\infty}^{+\\infty} f(t) f^* (t - \\tau) dt,\\] где \\(^*\\) означает комплексное сопряжение (для вещественнозначных функций эту звездочку можно игнорировать, она нужна в целях обобщения понятия автокорреляции для случайных процессов, сечения которых являются комплексными случайными переменными). Автокорреляционная функция случайного процесса \\(X(t)\\) будет иметь вид: \\[K(\\tau) = \\mathbb E \\big[X(t) X^* (t - \\tau) \\big],\\] где \\(\\mathbb E \\big[~ \\big]\\) — математическое ожидание. Для нецикличных процессов, плавно изменяющихся во времени, при увеличении \\(\\tau\\) значение АКФ падает, а это означает, что установив минимально допустимое значение автокорреляции, можно выяснить соответствующий ему сдвиг по времени. Найденная величина и будет максимально допустимой при интерполяции длиной пропуска. Для вычисления АКФ найдем сначала максимальный период непрерывных наблюдений: (max_period = filter(timerep, type == &#39;data&#39;, duration == max(duration))) ## # A tibble: 1 x 5 ## num start_date end_date duration type ## &lt;int&gt; &lt;date&gt; &lt;date&gt; &lt;drtn&gt; &lt;chr&gt; ## 1 97 1946-01-01 1980-12-31 12784 days data После этого отфильтруем данные на найденный период и вычислим АКФ, используя встроенную в базовый R функцию acf(): par(mar = c(6,5,4,2)) autocorr = tab %&gt;% filter(between(Date, max_period$start_date, max_period$end_date)) %&gt;% pull(level) %&gt;% acf() Результат соответствует нашим ожиданиям: автокорреляционная функция монотонно убывает при увеличении сдвига по времени. Осталось устновить пороговое значение автокорреляции и найти соответствующий ему сдвиг. В гидрологии за допустимую величину автокорреляции при восстановлении рядов данных принято брать значение, равное \\(0.7\\). Найдем индекс первого элемента менее данной величины, используя функцию detect_index() из пакета purrr: (max_dur = purrr::detect_index(autocorr$acf, ~ .x &lt; 0.7)) ## [1] 15 Полученное значение говорит нам о том, что при заданном допуске допустимо интерполировать значения в пропусках данных короче, чем 15 дней. Для выполнения интерполяции воспользуемся функцией na.approx() из пакета zoo и округлим полученные значения до одного знака после запятой (что соответствует точности исходных данных): (tab_interp = tab %&gt;% mutate(level_interp = zoo::na.approx(level, maxgap = max_dur) %&gt;% round(1))) ## # A tibble: 30,317 x 6 ## Date day month year level level_interp ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1932-01-01 1 1 1932 49.4 49.4 ## 2 1932-01-02 2 1 1932 NA 49.1 ## 3 1932-01-03 3 1 1932 NA 48.9 ## 4 1932-01-04 4 1 1932 NA 48.6 ## 5 1932-01-05 5 1 1932 NA 48.3 ## 6 1932-01-06 6 1 1932 NA 48.1 ## 7 1932-01-07 7 1 1932 NA 47.8 ## 8 1932-01-08 8 1 1932 NA 47.5 ## 9 1932-01-09 9 1 1932 NA 47.3 ## 10 1932-01-10 10 1 1932 47 47 ## # … with 30,307 more rows В заключение проведем заново оценку ситуации с пропусками в данных timerep_interp = tab_interp %&gt;% mutate(type = if_else(is.na(level_interp), &#39;gap&#39;, &#39;data&#39;), num = with(rle(type), rep(seq_along(lengths), lengths))) %&gt;% group_by(num) %&gt;% summarise(start_date = min(Date), end_date = max(Date), duration = end_date - start_date + 1, type = first(type)) По результатам автокореляционного анализа и интерполяции удалось заполнить значительное число пропусков в данных. Однако по прежнему остаются значительные по длине пропуски, которые уже требуют привлечения дополнительных источников информации для их заполнения. 8.3.3.2 Пересчет на другую временную сетку Когда данные, поступающие из различных источников, привязаны к несовпадающим временным срезам, возникает задача приведения их к единой временной сетке. Как правило, эта сетка имеет регулярный шаг (каждый час, каждый месяц и т.д.), поскольку это упрощает выполнение статистического анализа. Одним из источников данных, не привязанных к жесткой временной сетке, является геосенсорная сеть домашних метеостанций NETATMO, которая собирает информацию с пользовательских устройств примерно каждый полчаса. Сроки, однако, четко не соблюдаются. Помимо этого, система, в силу её добровольно-волонтёрского характера, не предусматривает бесперебойное функционирование всех метеостанций: пользователь может отключить свой прибор на несколько часов или дней, в результате чего в данных могут образоваться дополнительные пропуски. Вследствие этого данные NETATMO характеризуются высокой степенью иррегулярности во времени. Загрузим в качестве примера данные по метеостанции с идентификатором 70_ee_50_00_8e_1a, расположенной в пределах Московского мегаполиса (данные выгружены посредством NETATMO Weather API): (tab = read_csv(&#39;data/70_ee_50_00_8e_1a.csv&#39;)) ## # A tibble: 1,405 x 11 ## altitude humidity id latitude longitude pressure temperature ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 189 55 70:e… 55.7 37.6 1014. 23.1 ## 2 189 56 70:e… 55.7 37.6 1013. 22.5 ## 3 189 57 70:e… 55.7 37.6 1014. 21.9 ## 4 189 59 70:e… 55.7 37.6 1014. 21.1 ## 5 189 62 70:e… 55.7 37.6 1014 20 ## 6 189 65 70:e… 55.7 37.6 1014. 19.7 ## 7 189 66 70:e… 55.7 37.6 1014. 19.6 ## 8 189 67 70:e… 55.7 37.6 1014. 19.5 ## 9 189 68 70:e… 55.7 37.6 1014. 19.2 ## 10 189 68 70:e… 55.7 37.6 1015. 19.2 ## # … with 1,395 more rows, and 4 more variables: time_humidity &lt;dttm&gt;, ## # time_pressure &lt;dttm&gt;, time_temperature &lt;dttm&gt;, timezone &lt;chr&gt; Визуальная инспекция данных подсказывает нам, что данные по температуре, влажности и давлению получены на произвольные сроки с дискретностью порядка \\(30\\) или \\(60\\) минут, при этом для всех трех метеопараметров эти сроки не совпадают: Чтобы осуществлять совместный анализ этих данных, необходимо привести их к единой временной сетке. Временная плотность данных NETATMO позволяет сделать такую сетку через каждые \\(30\\) минут. Алгоритм интерполяции данных для каждой из характеристик будет следующий: Определить минимальное и максимальное время измерений и округлить их до ближайшего времени, кратного \\(30\\) минутам в большую (для минимального времени) и меньшую (для максимального времени) сторону. Сформировать последовательность временных срезов между полученными границами \\(30\\)-минутной серии. Интерполировать величину показателя на новую сетку. Определим расчетные интервалы времени для каждой из характеристик: (time_bounds = tibble( type = c(&#39;temperature&#39;, &#39;humidity&#39;, &#39;pressure&#39;), tmin = ceiling_date(c(min(tab$time_temperature), min(tab$time_humidity), min(tab$time_pressure)), unit = &#39;30 minutes&#39;), tmax = floor_date(c(max(tab$time_temperature), max(tab$time_humidity), max(tab$time_pressure)), unit = &#39;30 minutes&#39;) )) ## # A tibble: 3 x 3 ## type tmin tmax ## &lt;chr&gt; &lt;dttm&gt; &lt;dttm&gt; ## 1 temperature 2019-09-04 14:30:00 2019-10-17 06:30:00 ## 2 humidity 2019-09-04 14:30:00 2019-10-17 06:30:00 ## 3 pressure 2019-09-04 14:30:00 2019-10-17 06:30:00 В данном случае видно, что возможные границы сроков интерполяции для всех трех переменных совпадают, что несколько облегачает задачу. Проинтерполуруем данные на единую регулярную временную сетку через \\(30\\) минут, используя функцию approx() из базового R. По умолчанию данная функция использует линейную интерполяцию по ближайшим значениям до и после интерполируемого: (time_interp = tibble( datetime = seq(min(time_bounds$tmin), max(time_bounds$tmax), by = &#39;30 min&#39;), temp = round(approx(tab$time_temperature, tab$temperature, xout = datetime)$y, 1), humd = round(approx(tab$time_humidity, tab$humidity, xout = datetime)$y, 1), pres = round(approx(tab$time_pressure, tab$pressure, xout = datetime)$y, 1) )) ## # A tibble: 2,049 x 4 ## datetime temp humd pres ## &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2019-09-04 14:30:00 22.8 55.5 1014. ## 2 2019-09-04 15:00:00 22.4 56.1 1013. ## 3 2019-09-04 15:30:00 22.1 56.6 1014. ## 4 2019-09-04 16:00:00 21.7 57.5 1014. ## 5 2019-09-04 16:30:00 20.8 59.8 1014. ## 6 2019-09-04 17:00:00 20 62.4 1014 ## 7 2019-09-04 17:30:00 19.8 63.9 1014. ## 8 2019-09-04 18:00:00 19.7 65.2 1014. ## 9 2019-09-04 18:30:00 19.6 66.2 1014. ## 10 2019-09-04 19:00:00 19.5 67.1 1014. ## # … with 2,039 more rows Надежность каждого интерполированного значения можно оценить, задав максимально допустимое расстояние по времени до ближайшего элемента исходных данных до и после интерполируемого времени. Предположим, валидными будут считаться значения, расположенные не далее чем \\(30\\) минут до ближайшего временного среза (до или после), при этом длина интервала, в который попадает интерполируемый срез, не должна превышать \\(90\\) минут. Задачу поиска временного интервала исходных данных, в который попадает каждый интерполируемый временной срез, удобно решить с помощью кусочно-линейной функции stepfun(), передав ей в качестве аргумента \\(X\\) упорядоченные по времени сроки исходных данных, а в качестве значений \\(Y\\) — порядковые номера исходных сроков: src_time = sort(tab$time_temperature) (tempfun = stepfun(src_time, 0:nrow(tab))) ## Step function ## Call: stepfun(src_time, 0:nrow(tab)) ## x[1:1405] = 1.5676e+09, 1.5676e+09, 1.5676e+09, ..., 1.5713e+09, 1.5713e+09 ## 1406 plateau levels = 0, 1, 2, ..., 1404, 1405 Созданная таким образом кусочно-линейная функция для переданного ей значения времени будет возвращать порядковый номер временного интервала исходных данных. Оценим с помощью нее временные расстояния до ближайших наблюдений и их соответствие выдвинутым условиям: (timediff = lapply(time_interp$datetime, function(time) { idx = tempfun(time) tibble(datetime = time, temp_before = time - src_time[idx], temp_after = src_time[idx + 1] - time, temp_valid = min(temp_before, temp_after) &lt;= minutes(30) &amp;&amp; temp_before + temp_after &lt;= minutes(90)) }) %&gt;% bind_rows()) ## # A tibble: 2,049 x 4 ## datetime temp_before temp_after temp_valid ## &lt;dttm&gt; &lt;drtn&gt; &lt;drtn&gt; &lt;lgl&gt; ## 1 2019-09-04 14:30:00 1113 secs 1296 secs TRUE ## 2 2019-09-04 15:00:00 504 secs 3135 secs TRUE ## 3 2019-09-04 15:30:00 2304 secs 1335 secs TRUE ## 4 2019-09-04 16:00:00 465 secs 1330 secs TRUE ## 5 2019-09-04 16:30:00 470 secs 1324 secs TRUE ## 6 2019-09-04 17:00:00 476 secs 3163 secs TRUE ## 7 2019-09-04 17:30:00 2276 secs 1363 secs TRUE ## 8 2019-09-04 18:00:00 437 secs 1358 secs TRUE ## 9 2019-09-04 18:30:00 442 secs 1403 secs TRUE ## 10 2019-09-04 19:00:00 397 secs 3499 secs TRUE ## # … with 2,039 more rows summary(timediff) ## datetime temp_before temp_after ## Min. :2019-09-04 14:30:00 Length:2049 Length:2049 ## 1st Qu.:2019-09-15 06:30:00 Class :difftime Class :difftime ## Median :2019-09-25 22:30:00 Mode :numeric Mode :numeric ## Mean :2019-09-25 22:30:00 ## 3rd Qu.:2019-10-06 14:30:00 ## Max. :2019-10-17 06:30:00 ## temp_valid ## Mode :logical ## FALSE:594 ## TRUE :1455 ## ## ## Полученные результаты говорят нам о том, что критериям соответствуют \\(1455\\) значений температур из \\(2049\\), остальные \\(594\\) значения либо попадают в слишком длинный интервал между исходными данными (более \\(90\\) минут), либо расположены слишком далеко от ближайшего наблюдения (более \\(30\\) минут). В заключение присоединим полученную информацию к таблице интерполированных значений: time_interp_checked = time_interp %&gt;% left_join(timediff, by = c(&#39;datetime&#39; = &#39;datetime&#39;)) Аналогичную проверку валидности следует выполнить для оставшихся переменных — влажности и давления. 8.3.4 Статистики Существует ряд статистик и статистических тестов, которые часто используются для временных данных. Среди них мы рассмотрим следующие: Тест Манна-Кендалла на значимость линейного тренда Тест Петтитт на точку перелома — Оценка тренда по методу Тейла-Сена В качестве примера возьмем данные межгодичных изменений характеристик стока реки Мезень на посту Малонисогорская4: library(readr) (tab = read_csv(&#39;data/Mezen.csv&#39;)) ## # A tibble: 75 x 57 ## year_number Year1 Year2 datestart datepolend Qy Qmax datemax Qygr ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; ## 1 1 1938 1939 2000-03-23 2000-06-08 98.1 747 2000-04-03 19.9 ## 2 2 1939 1940 2000-03-16 2000-07-11 66.9 487 2000-04-28 14.8 ## 3 3 1940 1941 2000-03-09 2000-07-12 97.4 995 2000-04-28 18.9 ## 4 4 1941 1942 2000-03-24 2000-07-21 214. 2030 2000-05-01 31.4 ## 5 5 1942 1943 2000-04-02 2000-07-31 242. 2790 2000-05-08 26.9 ## 6 6 1943 1944 2000-03-24 2000-06-15 71.3 451 2000-05-02 26.5 ## 7 7 1944 1945 2000-02-26 2000-06-30 89.0 530 2000-04-28 27.0 ## 8 8 1945 1946 2000-03-25 2000-07-13 128. 1220 2000-04-27 33.9 ## 9 9 1946 1947 2000-03-15 2000-06-30 179. 2150 2000-04-28 25.8 ## 10 10 1947 1948 2000-03-06 2000-07-15 153. 1720 2000-04-16 31.3 ## # … with 65 more rows, and 48 more variables: Qmmsummer &lt;dbl&gt;, ## # monmmsummer &lt;date&gt;, Qmmwin &lt;dbl&gt;, nommwin &lt;date&gt;, Q30s &lt;dbl&gt;, ## # date30s1 &lt;date&gt;, date30s2 &lt;date&gt;, Q30w &lt;dbl&gt;, date30w1 &lt;date&gt;, ## # date30w2 &lt;date&gt;, Q10s &lt;dbl&gt;, date10s1 &lt;date&gt;, date10s2 &lt;date&gt;, Q10w &lt;dbl&gt;, ## # date10w1 &lt;date&gt;, date10w2 &lt;date&gt;, Q5s &lt;dbl&gt;, date5s1 &lt;date&gt;, ## # date5s2 &lt;date&gt;, Q5w &lt;dbl&gt;, date5w1 &lt;date&gt;, date5w2 &lt;date&gt;, Wy &lt;dbl&gt;, ## # Wgr &lt;dbl&gt;, Wpol1 &lt;dbl&gt;, Wpol2 &lt;dbl&gt;, Wpol3 &lt;dbl&gt;, Wpavs1 &lt;dbl&gt;, ## # Wpavs2 &lt;dbl&gt;, Wpavthaw1 &lt;dbl&gt;, Wpavthaw2 &lt;dbl&gt;, WgrS &lt;dbl&gt;, WS &lt;dbl&gt;, ## # WgrW &lt;dbl&gt;, WW &lt;dbl&gt;, Qmaxpavs &lt;dbl&gt;, datemaxpavs &lt;date&gt;, ## # Qmaxpavthaw &lt;dbl&gt;, datemaxpavthaw &lt;date&gt;, SumProd &lt;dbl&gt;, DaysPavsSum &lt;dbl&gt;, ## # WinProd &lt;dbl&gt;, DaysThawWin &lt;dbl&gt;, CvWin &lt;dbl&gt;, CvSum &lt;dbl&gt;, ## # CountPavs &lt;dbl&gt;, CountThaws &lt;dbl&gt;, PolProd &lt;dbl&gt; Построим график межгодичной изменчивости объема грунтового стока (переменная Wgr в \\(км^3\\)): ggplot(tab, mapping = aes(Year1, Wgr)) + geom_line() + geom_area(alpha = 0.5) + geom_smooth() + labs(title = &#39;Объем грунтового стока на р. Мезень в д. Малонисогорская&#39;, x = &#39;Год&#39;, y = &#39;куб. км&#39;) Для выполнения тестов Манна-Кендалла, Петтитт и оценки тренда по методу Тейла-Сена подключим пакет trend: library(trend) (mk = mk.test(tab$Wgr)) ## ## Mann-Kendall trend test ## ## data: tab$Wgr ## z = 7.8129, n = 75, p-value = 0.000000000000005589 ## alternative hypothesis: true S is not equal to 0 ## sample estimates: ## S varS tau ## 1709.0000000 47791.6666667 0.6158559 (pt = pettitt.test(tab$Wgr)) ## ## Pettitt&#39;s test for single change-point detection ## ## data: tab$Wgr ## U* = 1324, p-value = 0.00000000004131 ## alternative hypothesis: two.sided ## sample estimates: ## probable change point at time K ## 38 (ts = sens.slope(tab$Wgr)) ## ## Sen&#39;s slope ## ## data: tab$Wgr ## z = 7.8129, n = 75, p-value = 0.000000000000005589 ## alternative hypothesis: true z is not equal to 0 ## 95 percent confidence interval: ## 0.01378903 0.02202750 ## sample estimates: ## Sen&#39;s slope ## 0.01810404 Все три теста в данном случе дают высокую статистическую значимость временных изменений (p-значения), при этом тест Петтитт говорит, что точка перелома находится в 38-й позиции ряда. Если разделить исследуемый временной ряд на две выборки этой точкой, то они будут иметь статистически значимое отличие в характеристиках среднего значения показателя. Метод Тейла-Сена также говорит нам, что грунтовый сток увеличивается ежегодно примерно на \\(1.8\\%\\) (величина тренда равна \\(0.0181\\)), что за период 70 лет даёт абсолютный прирост грунтового стока более чем в 2 раза. Для наглядности нанесем линию тренда и точку перелома на график: ggplot(tab, mapping = aes(Year1, Wgr)) + geom_line() + geom_area(alpha = 0.5) + geom_smooth(method = &#39;lm&#39;, color = &#39;red&#39;) + geom_vline(xintercept = tab$Year1[pt$estimate], color = &quot;red&quot;, size = 0.5) + annotate(&quot;text&quot;, label = tab$Year1[pt$estimate], x = tab$Year1[pt$estimate] + 4, y = max(tab$Wgr), size = 4, colour = &quot;red&quot;) + labs(title = &#39;Объем грунтового стока на р. Мезень в д. Малонисогорская&#39;, x = &#39;Год&#39;, y = &#39;куб. км&#39;) 8.3.5 Анимация Анимационная графика возволяет наглядно визуализировать изменения. Наиболее часто речь идет об изменениях по времени. В этом случае время работает в роли невидимой переменной, которая влияет на положение графических примитивов на изображении. Данный подход органично вписывается в концепцию грамматики графики, на основе которой построен пакет ggplot2 (см. Главу 6). Соответствующую реализацию грамматики анимаций предоставляет пакет gganimate(???). Возможности анимаций в gganimate реализуются посредством добавления новых грамматик к построенному графику ggplot2. К числу этих грамматик относятся: transition_*() — распределение данных по времени; view_*() — поведение осей координат во времени; shadow_*() — отображение данных, не относящихся к текущему временному срезу; enter_*()/exit_*() — характер появления/исчезновения данных в процессе анимации; ease_aes() — порядок смягчения (интерполяции) графических переменных в моменты перехода. В качестве первого примера используем уже знакомые нам данные реанализа NASA POWER суточного осреднения, выгрузив информацию по точкам в трех городах (Мурманск, Москва, Краснодар) за 2018 год: # TODO: set eval = TRUE after NASA POWER server is available library(nasapower) library(ggplot2) cities = list( Мурманск = c(33, 69), Москва = c(38, 56), Краснодар = c(39, 45) ) tab = purrr::imap(cities, function(coords, city){ get_power( community = &quot;AG&quot;, lonlat = coords, pars = c(&quot;RH2M&quot;, &quot;T2M&quot;, &quot;PRECTOT&quot;), dates = c(&quot;2018-01-01&quot;, &quot;2018-12-31&quot;), temporal_average = &quot;DAILY&quot; ) %&gt;% mutate(CITY = city, MONTH = month(YYYYMMDD)) }) %&gt;% bind_rows() 8.3.5.1 Переход по времени Рассмотрим колебания температуры по 12 месяцам посредством диаграммы размаха, реализовав анимационный переход по времени посредством функции transition_time(). Текущий временной срез передается в переменную окружения frame_time, которая подается в подзаголовок графика (см параметр subtitle функции labs()): ggplot(tab, aes(CITY, T2M)) + geom_boxplot() + labs(title = &quot;Температура воздуха в 2018 году по данным NASA POWER&quot;, subtitle = &#39;Месяц: {round(frame_time)}&#39;) + xlab(&#39;Город&#39;) + ylab(&#39;Т, °С&#39;) + transition_time(MONTH) Текущий срез при выполнении анимации по времени доступен в переменной окружения frame_time. Аналогичную анимацию можно провести и на примере функции плотности распределения: ggplot(tab, aes(T2M, fill = CITY)) + geom_density(alpha = 0.5) + labs(title = &quot;Температура воздуха в 2018 году по данным NASA POWER&quot;, subtitle = &#39;Месяц: {round(frame_time)}&#39;, fill = &#39;Город&#39;) + xlab(&#39;Т, °С&#39;) + ylab(&#39;Плотность распределения&#39;) + transition_time(MONTH) Загрузим ранее использованные в Главе @ref(stat_analysis) данные Gapminder по соотношению продолжительности жизни и ВВП на душу населения, но на этот раз не будем фильтровать их по времени: library(readxl) library(googledrive) library(googlesheets4) countries = read_excel(&#39;data/gapminder.xlsx&#39;, 2) %&gt;% select(Country = name, Region = eight_regions) %&gt;% mutate(Country = factor(Country, levels = Country[order(.$Region)])) gdpdf_tidy = &#39;1cxtzRRN6ldjSGoDzFHkB8vqPavq1iOTMElGewQnmHgg&#39; %&gt;% ### ВВП на душу населения as_id() %&gt;% # преобразуем идентификатор в класс drive_id чтобы отличать его от пути drive_get() %&gt;% read_sheet() %&gt;% pivot_longer(cols = `1764`:`2018`, names_to = &#39;year&#39;, values_to = &#39;gdp&#39;) %&gt;% rename(Country = 1) popdf_tidy = &#39;1IbDM8z5XicMIXgr93FPwjgwoTTKMuyLfzU6cQrGZzH8&#39; %&gt;% # численность населения as_id() %&gt;% # преобразуем идентификатор в класс drive_id чтобы отличать его от пути drive_get() %&gt;% read_sheet() %&gt;% # первый лист pivot_longer(cols = `1800`:`2015`, names_to = &#39;year&#39;, values_to = &#39;pop&#39;) %&gt;% rename(Country = 1) lifedf_tidy = &#39;1H3nzTwbn8z4lJ5gJ_WfDgCeGEXK3PVGcNjQ_U5og8eo&#39; %&gt;% # продолжительность жизни as_id() %&gt;% # преобразуем идентификатор в класс drive_id чтобы отличать его от пути drive_get() %&gt;% read_sheet() %&gt;% pivot_longer(cols = `1800`:`2016`, names_to = &#39;year&#39;, values_to = &#39;lifexp&#39;) %&gt;% rename(Country = 1) tab = gdpdf_tidy %&gt;% inner_join(lifedf_tidy) %&gt;% inner_join(popdf_tidy) %&gt;% inner_join(countries) %&gt;% mutate(year = as.integer(year)) %&gt;% drop_na() Теперь чтобы отобразить это соотношение в виде анимации, достаточно добавить новый переход по времени: options(scipen = 999) # убираем экспоненциальную форму записи числа ggplot(tab, aes(gdp, lifexp, size = pop, color = Region)) + geom_point(alpha = 0.5) + scale_x_log10() + labs(title = &#39;Year: {round(frame_time)}&#39;) + theme_bw() + transition_time(year) 8.3.5.2 Переход по состояниям В ряде случаев вместо перехода по времени целесообразно использовать переход по состояниям. В частности, такой подход оказывается удобен, когда сопоставляются данные за аналогичные временные срезы разных периодов. Например, 12 часов каждого дня недели с анимацией по неделям. Либо каждый день года с анимацией по годам. В этом случае координаты X будут фиксированы, а значение Y будет зависить от текущего состояния. Подобную стратегию можно использовать для визуализации изменений внутригодичного распределения величины между годами. Примером таких изменений являются данные о расходах воды на гидропосте Паялка, рассмотренные нами ранее в настоящей главе. В качестве результата мы хотим видеть анимацию гидрографа реки, в которой каждый кадр соответствует календарному году. Для составления такой анимации необходимо сначала убедиться, что в данных все года заполнены корректно (не пусты), и что нет годов, за которые вообще нет данных (такие года придется из анимации исключить, так как для них гидрограф построить невозможно). Помимо этого, чтобы обеспечить сопоставимость аналогичных дат за разные года, необходимо сохранить у них только месяц и день. Поскольку такого формата даты не существует, в качестве “трюка” можно просто заменить года всех дат на \\(2000\\) и записать результат в новое поле. Необходимые преобразования реализуются следующим образом: flt_tab = tab_interp %&gt;% filter(!is.na(year)) %&gt;% group_by(year) %&gt;% filter(!all(is.na(level_interp))) %&gt;% ungroup() %&gt;% mutate(yDate = Date) year(flt_tab$yDate) &lt;- 2000 # фиктивное поле, в котором аналогичные даты за разные года совпадают После выполнения необходимой подготовки таблица данных готова для анимации. Переход по состояниям реализуется посредством вызова функции transition_states(), при этом параметр state_length = 0 обеспечивает плавность анимации за счет нулевой задержки в каждом состоянии. Полученный график предварительно сохраняется в промежуточную переменную anim, чтобы в дальнейшем можно было управлять качеством анимации путем вызова функции animate(). В частности, мы устанавливаем общее число кадров в \\(10\\) раз больше количества состояний (годов), чтобы обеспечить плавный переход между ними посредством интерполяции (tweening), автоматически выполняемой функцией animate() между кадрами: anim = ggplot(flt_tab, mapping = aes(x = yDate, y = level_interp)) + geom_ribbon(aes(ymin = 0, ymax = level_interp), alpha = 0.5) + geom_line() + scale_x_date(date_breaks = &quot;1 month&quot;, date_labels = &quot;%b&quot;) + labs(title = &quot;Расход воды на гидропосту Паялка (р. Умба, Мурманская обл.)&quot;, subtitle = &#39;Год: {closest_state}&#39;) + xlab(&#39;Дата&#39;) + ylab(&#39;куб.м/с&#39;) + theme(text = element_text(size = 18, family = &#39;Open Sans&#39;)) + transition_states(year, state_length = 0) + view_follow(fixed_y = TRUE) animate(anim, fps = 20, # число кадров в секунду nframes = 10 * length(unique(flt_tab$year)), # общее число кадров width = 800, height = 600) Текущий срез при выполнении анимации по состояниям доступен в переменной окружения closest_state. В настоящей главе мы рассмотрели лишь базовые возможности создания анимаций средствами пакета gganimate. Более подробно с другими возможностями пакета можно ознакомиться в справочнике по его функциям. 8.4 Контрольные вопросы и упражнения 8.4.1 Вопросы В каком виде направления рассматриваются в круговой статистике? Какое распределение является аналогом нормального распределения для круговых данных? Что означают параметры \\(\\kappa\\) и \\(\\mu\\) в функции этого распределения? Как вычисляется равнодействующий вектор первого порядка и выборочная средняя равнодействующая длина этого вектора для направлений? Чем аксиальные данные отличаются от круговых данных в общем случае? Какие преобразования осуществляются над такими данными для того чтобы применять к ним стандартные методы циркулярной статистики? Какой класс данных (и пакет) можно использовать в R для представления направлений? Как указать, что направления отсчитываются географическим методом, то есть, по часовой стрелки от направления на север? Какую функцию можно использовать для для оценки плотности распределения круговых данных? В каком пакете она находится? Какую функцию можно использовать для выявления модальных направлений по данным функции плотности вероятности? Какие функции позволяют строить диаграммы и розы-диаграммы по круговым данным в среде R? Какой параметр управляет масштабом радиус-вектора на круговых графиках? Что такое лист-колонка в фрейме данных, и какого типа данные можно в ней хранить? 8.4.2 Упражнения Загрузите файл с данными по межгодичным изменениям стока на реке Мезень. Проанализируйте величину и значимость тренда, а также наличие переломного года для характеристик Wpol2 (объем половодья без грунтовой составляющей), а также Wy (суммарный сток). Что можно сказать об их соотношении с грунтовым стоком? Повторите эксперимент с построением анимационных графиков функции плотности распределения температуры и диаграмм размаха по данным NASA POWER (параграф @ref(circular_time_animation)), но выбрав координаты трех других географических локаций. Самсонов Т.Е. Визуализация и анализ географических данных на языке R. М.: Географический факультет МГУ, 2020. DOI: 10.5281/zenodo.901911 References "],
["spatial-data.html", "Глава 9 Пространственные данные 9.1 Предварительные требования 9.2 Модели пространственных данных 9.3 Пространственная привязка 9.4 Векторные данные 9.5 Растровые данные 9.6 Визуализация средствами ggplot2 9.7 Интерактивные карты 9.8 Контрольные вопросы и упражнения", " Глава 9 Пространственные данные 9.1 Предварительные требования Данный модуль посвящен введению в работу с пространственными данными в R. Рассмотрены общие вопросы моделирования реального мира средствами моделей пространственных данных. Рассматривается чтение векторных и растровых данных, их визуализация стандартными средствами. Необходимые для работы пакеты: library(sf) library(raster) library(mapview) library(tidyverse) 9.2 Модели пространственных данных Пространственные данные — это данные о пространственных объектах и их наборах. В свою очередь, пространственный объект определяется как цифровая модель материального или абстрактного объекта реального или виртуального мира с указанием его идентификатора, координатных и атрибутивных данных.5 Если говорить по сути, то пространственные данные можно определить как данные о географических объектах или явлениях, фиксирующие их местоположение и/или распределение в системе координат, привязанной к телу Земли или любого другого небесного тела. Таким образом, отличительной особенностью пространственных данных перед непространственными является координатное описание местоположения. Важно знать отличия между векторной и растровой моделью пространственных данных. Векторная модель пространственных данных включает описание координатных данных пространственных объектов и, возможно, топологических отношений между ними. Векторные данные фиксируют местоположение и форму объектов в виде геометрических примитивов, таких как точки, линии, полигоны, объемные тела. Выбор модели объекта (например, представить город точкой или полигоном) зависит от масштаба анализа и целей исследования. Векторная модель данных является объектно-ориентированной. Растровая модель описывает не объекты, а пространственное распределение некоторой (выбранной исследователем) характеристики. Пространство разбивается регулярной сеткой ячеек, в каждой ячейке фиксируется значение исследуемого параметра (путем статистического осреднения, семплирования в центре ячейки и т.п.). Растровые данные могут быть как количественными (например, поле температуры), так и качественными (например, растр классифицированного снимка, каждая ячейка которого фиксирует принадлежность к тому или иному типу объекта). Таким образом, растровая модель является пространственно-ориентированной (или феномен-ориентированной). Существуют и другие модели пространственных данных, однако их рассмотрение выходит за рамки настоящей лекции. В настоящей лекции мы познакомимся с чтением и визуализацией пространственных данных в векторном и растровом формате, а также рассмотрим вопросы связанные с использованием картографических проекций. 9.2.1 Векторные данные Simple Features (официально Simple Features Access) — это стандарт OGC 06-103, разработанный Open Geospatial Consortium (OGC) и реализованный также в виде международного стандарта ISO 19125, который определяет общую модель хранения и доступа к векторным объектам (точка, линия, многоугольник, мульти точечные, мультилинии и т. д.), в географических информационных системах. Геометрическое представление пространственных объектов базируется на следующих принципах: Все геометрии состоят из точек. Точки являются координатами в 2-, 3- или 4-мерном пространстве. Все точки в геометрии имеют одинаковую размерность. В дополнение к координатам \\(X\\) и \\(Y\\) имеются два дополнительных дополнительных параметра: координата \\(Z\\), обозначающая высоту координата \\(M\\), обозначающая некоторую меру, связанную с точкой, а не с признаком в целом (в этом случае это будет атрибут объекта). Измерение \\(M\\) может быть использовано, например, для представления времени или линейных координат (для маршрутов). Координаты простой геометрии всегда содержат компоненты \\(X\\) и \\(Y\\), поэтому все разнообразие возможных представлений определяется наличием или отсутствием дополнительных измерений \\(Z\\) и \\(M\\) Таким образом, получаем четыре варианта геометрии: двумерные точки \\(XY\\) трехмерные точки \\(XYZ\\) трехмерные точки \\(XYM\\) четырехмерные точки \\(XYZM\\) В случае использования широт и долгот \\(X\\) соответствует долготе, \\(Y\\) соответствует широте. Всего стандарт Simple Features включает в себя 17 типов геометрий. Из них наиболее употребительными являются следующие 7: Тип Описание POINT нуль-мерная геометрия, содержащая одну точку LINESTRING последовательность точек, соединенных прямыми, несамопересекающимися отрезками; одномерная геометрия POLYGON геометрия с положительной площадью (двумерная); последовательность точек, отрезки между которыми формируют замкнутое кольцо без самопересечений; первое кольцо является внешним, ноль и более остальных колец представляют дырки внутри полигона MULTIPOINT множество точек; геометрия типа MULTIPOINT называется простой если ни одна пара точек в MULTIPOINT не совпадает MULTILINESTRING множество линий MULTIPOLYGON множество полигонов GEOMETRYCOLLECTION множество геометрий произвольного типа за исключением GEOMETRYCOLLECTION Примеры различных видов геометрий представлены на рисунке ниже: Оставшиеся виды геометрий Simple Features включают: CIRCULARSTRING, COMPOUNDCURVE, CURVEPOLYGON, MULTICURVE, MULTISURFACE, CURVE, SURFACE, POLYHEDRALSURFACE, TIN, TRIANGLE. Существует два официально закрепленных формата представления SF: Well-Known Text (WKT) и Well-Known Binary (WKB), которые необходимы для чтения таких данных человеком и машиной соответственно. Well-Known Text (WKT) — стандарт представления геометрии в виде множества списков координат, в которых координаты вершин разделены пробелами, вершины разделены запятыми, а компоненты полигонов и мультигеометрий заключены в круглые скобки и также разделены запятыми. Вышеприведенной картинке соответствуют следующие строки WKT: ## MULTIPOINT (3.2 4, 3 4.6, 3.8 4.4, 3.5 3.8, 3.4 3.6, 3.9 4.5) ## LINESTRING (0 3, 0 4, 1 5, 2 5) ## MULTILINESTRING ((0 3, 0 4, 1 5, 2 5), (0.2 3, 0.2 4, 1 4.8, 2 4.8), (0 4.4, 0.6 5)) ## POLYGON ((0 0, 1 0, 3 2, 2 4, 1 4, 0 0), (1 1, 1 2, 2 2, 1 1)) ## MULTIPOLYGON (((0 0, 1 0, 3 2, 2 4, 1 4, 0 0), (1 1, 1 2, 2 2, 1 1)), ((3 0, 4 0, 4 1, 3 1, 3 0), (3.3 0.3, 3.3 0.8, 3.8 0.8, 3.8 0.3, 3.3 0.3)), ((3 3, 4 2, 4 3, 3 3))) ## GEOMETRYCOLLECTION (MULTIPOINT (3.2 4, 3 4.6, 3.8 4.4, 3.5 3.8, 3.4 3.6, 3.9 4.5), MULTIPOLYGON (((0 0, 1 0, 3 2, 2 4, 1 4, 0 0), (1 1, 1 2, 2 2, 1 1)), ((3 0, 4 0, 4 1, 3 1, 3 0), (3.3 0.3, 3.3 0.8, 3.8 0.8, 3.8 0.3, 3.3 0.3)), ((3 3, 4 2, 4 3, 3 3))), LINESTRING (0 3, 0 4, 1 5, 2 5)) Well-Known Binary (WKB) — бинарный формат хранения координат. Именно этот формат фактически используется в базах данных, поскольку он обеспечивает высокую скорость чтения и записи данных (в отличие от текстового). Однако внешний вид данных в формате WKB мало о чем говорит человеку, поскольку он предназначен для чтения компьютером. Например, вышеприведенная строка LINESTRING будет выглядеть так: ## 01 02 00 00 00 04 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 08 40 00 00 00 00 00 00 00 00 00 00 00 00 00 00 10 40 00 00 00 00 00 00 f0 3f 00 00 00 00 00 00 14 40 00 00 00 00 00 00 00 40 00 00 00 00 00 00 14 40 9.2.2 Растровые данные Растр представляет из себя матрицу значений. Каждой ячейке матрицы соответствует прямоугольная пространственная область фиксированного размера, которая называется пикселом. Различают растры непрерывные и категориальные (классифицированные). Также необходимо разделять одноканальные и многоканальные растры. Примером одноканального растра является цифровая модель рельефа. В виде многоканальных растров часто представляют космические снимки. В отличие от векторных данных, которые требуют указания координат для каждой вершины, регулярно-ячеистый характер растровой модели позволяет вычислять координаты пикселов на основе их индексов. Поэтому фактически растровые данные хранятся в виде линейно упорядоченного списка значений (raster values) и описания геометрии растра (raster geometry). Геометрия растра определяет, где именно располагаются в пространстве пикселы растра и может быть описана путем указания следующих компонент6: Параметр Назначение NCOLS Количество столбцов NROWS Количество строк XLLCENTER Координата \\(X\\) центра левой нижней ячейки растра YLLCENTER Координата \\(Y\\) центра левой нижней ячейки растра CELLSIZE Размер ячейки Иногда вместо параметров XLLCENTER/YLLCENTER указываются XLLCORNER/YLLCORNER, которые кодируют координаты левого нижнего угла, а не центра левой нижней ячейки растра. Выбор одного из двух этих вариантов определяет тип регистрации растра, а их значения указывают, в какое именно место необходимо “посадить” растр, чтобы его ячейки заняли соответствующие им области в системе координат. Если геометрия растра характеризуется анизотропией, то вместо одного значения CELLSIZE могут быть указаны разные размеры ячеек по осям координат CELLSIZEX и CELLSIZEY. В отличие от векторной модели, которая позволяет хранить данные только о нужных географических локациях, растровая модель такой свободы не предоставляет. Матрица ячеек растра всегда покрывает область данных целиком, и за простоту растровой структуры приходится расплачиваться ее неэкономичностью. Поскольку часто данные имеются не на всю территорию, возникает необходимость кодирования ячеек, для которых данные не известны, специальным числом (назовем его условно NODATA_VALUE). Значение этого числа хранится в метаданных растра и позволяет интерпретировать соответствующие ячейки как пустые. 9.3 Пространственная привязка 9.3.1 Компоненты пространственной привязки Пространственная привязка (spatial reference или georeference) — важнейшая составляющая пространственных данных, которая говорит нам о том, как правильно интерпретировать координаты объектов. Пространственная привязка в простейшем случае включает несколько фундаментальных компонент: Эллипсоид вращения — тело, по отношению к которому вычисляются геодезические координаты точек (широты и долготы) Исходные геодезические даты (датум) — параметры положения эллипсоида в теле Земли Географическая система координат — включает датум, положение начального меридиана и единицы измерения широт и долгот Проекция — математический способ перехода от географических координат на эллипсоиде к плоским прямоугольным координатам карты. Плоская прямоугольная система координат — включает проекцию, ее параметры и единицы измерения координат. Если точки имеют также координаты \\(Z\\), то для их правильной интерпретации необходимы дополнительные компоненты пространственной привязки: Система счета высот (геодезические, нормальные, ортометрические) - определяют содержательный смысл и порядок вычисления высот и глубин (координата Z) Модель геоида, квазигеоида или эллипсоида — определяет поверхность, относительно которой вычисляются высоты точек. Вертикальная система координат — фактическая реализация системы счета высот относительно конкретной поверхности относимости с заданным положением нулевого уровня. Например, в России это Балтийская система нормальных высот с нулем в г. Кронштадт. Аналогичным образом требуется введение системы счета дополнительных координат \\(M\\), если они используются в представлении координат. 9.3.2 Форматы описания пространственной привязки Существует три распространенных способа задания (хранения) пространственной привязки: PROJ.4 String — представление в виде строки. WKT (Well-Known Text) — представление в виде иерархического списка. EPSG (European Petroleum Survey Group) — представление в виде числового кода. Для поиска проекций в перечисленных форматах представления удобно воспользоваться порталом spatialreference.org. PROJ.4 String — строковый формат представления информации о пространственной привязки, используемый в библиотеке PROJ.4. Данная библиотека лежит в основе координатных систем пространственных данных, используется в R, Python, QGIS и прочих средах. Основные параметры строки: +datum Datum name (see `proj -ld`) +ellps Ellipsoid name (see `proj -le`) +lat_0 Latitude of origin +lat_1 Latitude of first standard parallel +lat_2 Latitude of second standard parallel +lat_ts Latitude of true scale +lon_0 Central meridian +proj Projection name (see `proj -l`) +units meters, US survey feet, etc. +vunits vertical units. +x_0 False easting +y_0 False northing +zone UTM zone Примеры записи координат в формате PROJ.4: Географические координаты в WGS84 (без проекции): ## +proj=longlat +datum=WGS84 +no_defs Координаты в проекции Web Mercator (проекция Google Maps, Яндекс.Карт и т.д.): ## +proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +wktext +no_defs Координаты в конической равнопромежуточной проекции: ## +proj=eqdc +lat_0=0 +lon_0=0 +lat_1=60 +lat_2=60 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs Координаты в проекции UTM, зона 37: ## +proj=utm +zone=37 +datum=WGS84 +units=m +no_defs Запись координат в формате WKT предполагает представление вышеуказанных компонент пространственной привязки к виде иерархического списка. Например, так будет выглядеть информация о полярной стереографической проекции для карт России: PROJCS[&quot;WGS 84 / EPSG Russia Polar Stereographic&quot;, GEOGCS[&quot;WGS 84&quot;, DATUM[&quot;WGS_1984&quot;, SPHEROID[&quot;WGS 84&quot;,6378137,298.257223563, AUTHORITY[&quot;EPSG&quot;,&quot;7030&quot;]], AUTHORITY[&quot;EPSG&quot;,&quot;6326&quot;]], PRIMEM[&quot;Greenwich&quot;,0, AUTHORITY[&quot;EPSG&quot;,&quot;8901&quot;]], UNIT[&quot;degree&quot;,0.0174532925199433, AUTHORITY[&quot;EPSG&quot;,&quot;9122&quot;]], AUTHORITY[&quot;EPSG&quot;,&quot;4326&quot;]], PROJECTION[&quot;Polar_Stereographic&quot;], PARAMETER[&quot;latitude_of_origin&quot;,90], PARAMETER[&quot;central_meridian&quot;,105], PARAMETER[&quot;scale_factor&quot;,0.994], PARAMETER[&quot;false_easting&quot;,2000000], PARAMETER[&quot;false_northing&quot;,2000000], UNIT[&quot;metre&quot;,1, AUTHORITY[&quot;EPSG&quot;,&quot;9001&quot;]], AXIS[&quot;X&quot;,EAST], AXIS[&quot;Y&quot;,NORTH], AUTHORITY[&quot;EPSG&quot;,&quot;5940&quot;]] EPSG (European Petroleum Survey Group) — европейская рабочая группа нефтегазовой области, которая ведет реестр систем координат с уникальными цифровыми кодами вида EPSG:xxxxxx. Коды EPSG оказались настолько удобны, что используются повсеместно для быстрой инициализации проекций со стандартными параметрами. Например, вышеприведенные проекции имеют следующие коды EPSG: WGS84: EPSG:4326 Web Mercator: EPSG:3857 UTM: EPSG:326.. , например для UTM 37N: EPSG:32637 9.3.3 Преобразование координат Преобразование координат включает три различных операции: Трансформирование — пересчет географических координат с одного датума на другой Проецирование — переход от географических координат к плоским прямоугольным Обратное проецирование — переход от плоских координат к географическим. Например, чтобы пересчитать координаты UTM в проекцию Гаусса-Крюгера, необходимо: Обратно проецировать координаты в географические WGS84 Трансформировать географические координаты c WGS84 в ГСК-2011 Проецировать координаты ГСК-2011 в проекцию Гаусса-Крюгера Несоответствие датумов часто является причиной того, что данные из разных наборов плохо совмещаются друг с другом 9.4 Векторные данные 9.4.1 Базовые библиотеки В R существует высоко развитая инфраструктура для работы с векторными данными, которая обеспечивается пакетом sf. Этот пакет появился совсем недавно (в 2016 году). Ранее поддержка пространственных данных обеспечивалась пакетом sp, который по прежнему активно используется, и на который “завязано” множество других библиотек. Существующая в настоящий момент инфраструктура кратко показана ниже: Архитектура программных библиотек для работы с пространственными данными в R Исторический пакет sp обеспечивал (и продолжает обеспечивать) поддержку пространственных данных в виде специальных классов данных типа Spatial, реализуя классы как для чисто геометрических объектов (SpatialPolygons), так и для пространственных объектов с атрибутами (SpatialPolygonsDataFrame). Во втором случае набор объектов имеет ассоциированную с ним таблицу атрибутов. С классами типа Spatial существуют несколько проблем. Во-первых, они не являются объектами типа data.frame (не расширяют их), а являются самостоятельным классом объектов, поэтому к ним часто невозможно корректно применить стандартные операции трансформации таблиц (типа тех, что доступны в пакете dplyr). Во-вторых, объекты типа Spatial не реализуют существующие стандарты представления пространственных данных (типа Simple Features), что накладывает ограничения на их интероперабельность с современными форматами данных (например, GeoPackage). Пакет sf решает все эти проблемы. Множество функций, которые были раньше разбросаны по нескольким пакетам R (sp, rgdal, rgeos), теперь доступны в одном интерфейсе: library(sf) methods(class = &quot;sf&quot;) # Посмотрим, какие методы доступных для объектов класса sf ## [1] [ [[&lt;- $&lt;- ## [4] aggregate anti_join arrange ## [7] as.data.frame cbind coerce ## [10] dbDataType dbWriteTable distinct ## [13] editFeatures extent extract ## [16] filter full_join gather ## [19] group_by group_map group_split ## [22] identify idw initialize ## [25] inner_join krige krige.cv ## [28] left_join mapView mask ## [31] merge mutate nest ## [34] plot print raster ## [37] rasterize rbind rename ## [40] right_join sample_frac sample_n ## [43] select selectFeatures semi_join ## [46] separate_rows separate show ## [49] slice slotsFromS3 spread ## [52] st_agr st_agr&lt;- st_area ## [55] st_as_sf st_as_stars st_bbox ## [58] st_boundary st_buffer st_cast ## [61] st_centroid st_collection_extract st_convex_hull ## [64] st_coordinates st_crop st_crs ## [67] st_crs&lt;- st_difference st_geometry ## [70] st_geometry&lt;- st_interpolate_aw st_intersection ## [73] st_intersects st_is st_join ## [76] st_line_merge st_nearest_points st_node ## [79] st_normalize st_point_on_surface st_polygonize ## [82] st_precision st_segmentize st_set_precision ## [85] st_simplify st_snap st_sym_difference ## [88] st_transform_proj st_transform st_triangulate ## [91] st_union st_voronoi st_wrap_dateline ## [94] st_write st_zm summarise ## [97] transmute ungroup unite ## [100] unnest ## see &#39;?methods&#39; for accessing help and source code Со многими из этих функций мы познакомимся в последующих разделах нашего курса. Некоторые из них (такие как arrange, filter, mutate из пакета dplyr), должны быть уже знакомы вам по предыдущим лекциям. Можно обратить внимание на то, что практически все функции начинаются с префикса st_, что означает “spatiotemporal”. Данные префиксы были выбраны для унификации с аналогичными названиями функций, используемых в широко распространенной СУБД PostgreSQL для оперирования объектами Simple Features. 9.4.2 Чтение Существует большое множество форматов хранения пространственных данных. Но в общем и целом их можно разделить на две категории: файловые форматы (наиболее привычные пользователям) и хранение данных в СУБД — системах управления базами данных. Благодаря библиотеке GDAL пакет sf имеет возможность читать и записывать более 90 различных форматов векторных даных. Исторически наиболее распространенным форматом был (и остается) ESRI Shapefile. Данный формат, однако не отвечает современным техническим требованиям с точки зрения гибкости, соответствия стандартам и возможностям хранения разнообразных типов геометрий (напомним, что в стандарте Simple Features их 17, а с учетом четырех вариантов размерности точек получается целых 68 ). Современный формат, который обеспечивает полную поддержку стандарта Simple Features (и не только) — это GeoPackage. Именно его мы и будем использовать в нашем практикуме. Для чтения данных средствами sf необходимо использовать функцию st_read(): countries = st_read(&#39;data/ne/countries.gpkg&#39;) ## Reading layer `admin_0_map_units&#39; from data source `/Users/tsamsonov/GitHub/r-geo-course/data/ne/countries.gpkg&#39; using driver `GPKG&#39; ## Simple feature collection with 183 features and 72 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: -180 ymin: -90 xmax: 180 ymax: 83.64513 ## epsg (SRID): 4326 ## proj4string: +proj=longlat +datum=WGS84 +no_defs Лог функции сообщил нам следующую информацию: Набор данных представляет собой коллекцию из 183 пространственных объектов с 72 атрибутами Тип геометрии MULTIPOLYGON Размерность геометрии \\(XY\\) Ограничивающий прямоугольник (разброс координат) по осям \\(X\\) и \\(Y\\) имеет диапазон \\([-180, 180] \\times [-90, 83.64513]\\) EPSG-код пространственной привязки равен 4326 PROJ.4-строка пространственной привязки равна +proj=longlat +datum=WGS84 +no_defs 9.4.3 Внутренняя структура Традиционно во всех ГИС-приложениях и базах пространственных данных множество пространственных объектов представляется в виде таблицы атрибутов, где каждая строка соответствует объекту, а каждый столбец — атрибуту объекта. С каждой строкой таблицы должна быть ассоциирована информация о геометрии объекта, которая, в зависимости от формата данных, может либо храниться непосредственно в таблице (в специальном столбце), либо быть вынесена в отдельную структуру данных, которая связана с таблицей атрибутов посредством ключа7. В R используется первый подход, в котором информация о геометрии хранится в специальном столбце таблицы. Каждая ячейка этого столбца соответствует геометрическому объекту Simple Features. Представление геометрических объектов реализовано стандартными средствами, такими как списки, матрицы и векторы. Эти структуры данных упорядоченным образом хранят координаты объектов и естественным образом соответствуют способу организации данных, который регламентируется стандартом Simple Features. Поскольку геометрический столбец хранит не обычные переменные, а структуры данных, он реализуется в виде так называемого списка-колонки (list-column), каждый элемент которой соответствует отдельному объекту. Исходя из этих соображений, представление пространственных объектов реализовано в R в виде иерархии из трех классов объектов: sf (simple features) — объект класса data.frame, представляющий множество пространственных объектов со списком-колонкой для хранения геометрии sfc (simple features geometry column) — список-колонка в объекте sf, представляющий множество геометрий пространственных объектов sfg (simple feature geometry) — геометрия пространственного объекта внутри списка sfc В соответствии с перечисленными спецификациями происходит работа с пространственными объектами. То что, объекты типа Simple Features реализованы в виде самых обычных фреймов данных, означает что любая операция, применимая к фрейму данных, будет также применима к объекту типа sf. Это очень важная особенность объектов типа sf, которой сильно не хватало в экосистеме исторического пакета sp. Посмотрим, как все это реализовано, на конкретном примере: class(countries) ## [1] &quot;sf&quot; &quot;data.frame&quot; Данная форма записи говорит о том, что прочитанный слой имеет класс sf, который, в свою очередь, является расширением класса data.frame. А теперь посмотрим на последние колонки в первых строках таблицы: head(countries[tail(colnames(countries))]) ## Simple feature collection with 6 features and 5 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: -73.41544 ymin: -55.25 xmax: 75.15803 ymax: 42.68825 ## epsg (SRID): 4326 ## proj4string: +proj=longlat +datum=WGS84 +no_defs ## tiny homepart min_zoom min_label max_label geometry ## 1 -99 1 0 3 7 MULTIPOLYGON (((61.21082 35... ## 2 -99 1 0 3 7 MULTIPOLYGON (((23.90415 -1... ## 3 -99 1 0 5 10 MULTIPOLYGON (((21.02004 40... ## 4 -99 1 0 4 9 MULTIPOLYGON (((51.57952 24... ## 5 -99 1 0 2 7 MULTIPOLYGON (((-66.95992 -... ## 6 -99 1 0 5 10 MULTIPOLYGON (((43.58275 41... Видно, что геометрия пространственных объектов хранится в заключительном столбце с названием geometry. Данный столбец можно быстро извлечь, применив функцию st_geometry(). Полученный объект будет иметь тип sfc (Simple Feature Geometry Column) outlines = st_geometry(countries) class(outlines) ## [1] &quot;sfc_MULTIPOLYGON&quot; &quot;sfc&quot; Полученный вывод говорит нам о том, что наши объекты имеют класс sfc_MULTIPOLYGON, который является расширением класса sfc (simple feature geometry column). Теперь если просмотреть начало данных, то мы увидим, что это больше не фрейм данных, а аннотированный список: head(outlines) ## Geometry set for 6 features ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: -73.41544 ymin: -55.25 xmax: 75.15803 ymax: 42.68825 ## epsg (SRID): 4326 ## proj4string: +proj=longlat +datum=WGS84 +no_defs ## First 5 geometries: Далее можно опуститься на базовый уровень геометрии, получив доступ к отдельному объекту. Поскольку объект класса sfc представляет собой список, любой элемент можно извлечь по его порядковому номеру. Класс полученного объекта будет: class(outlines[[8]]) ## [1] &quot;XY&quot; &quot;MULTIPOLYGON&quot; &quot;sfg&quot; Исходя из полученной информации можно сделать вывод, что геометрия 8-го объекта таблицы countries имеет класс sfg, реализованный в виде мультиполигонов (MULTIPOLYGON) с плоскими координатами (XY) Наконец, чтобы добраться до координат в чистом виде, необходимо развернуть иерархию списков, из которых состоит объект sfg. Количество уровней вложенности всегда зависит от конкретного объекта, их может быть достаточно много, особенно если объекты представлены мультиполигонами (несколько компонент связности), каждый из которых также состоит из полигонов с дырками. В нашем случае все достаточно просто, так как в слое countries дырок в полигонах нет, а 8-й по счету полигон состоит из одной-единственной геометрии, координаты которой в виде матрицы можно извлечь как: outlines[[8]][[1]] ## [[1]] ## [,1] [,2] ## [1,] 68.9350 -48.6250 ## [2,] 69.5800 -48.9400 ## [3,] 70.5250 -49.0650 ## [4,] 70.5600 -49.2550 ## [5,] 70.2800 -49.7100 ## [6,] 68.7450 -49.7750 ## [7,] 68.7200 -49.2425 ## [8,] 68.8675 -48.8300 ## [9,] 68.9350 -48.6250 9.4.4 Визуализация 9.4.4.1 Базовые возможности Если попытаться применить функцию plot() к геометрии объекта, она попытается нарисовать тематические карты по всем имеющимся атрибутам (но остановится, если их более 9): plot(countries) Если задача стоит нарисовать границы объектов, то нужно отображать объект sfc: plot(outlines, col = &#39;red&#39;) Для быстрого построения тематических карт по выбранному показателю необходимо при вызове функции plot() указать соответствующий атрибут фрейма данных: plot(countries[&#39;sovereignt&#39;], key.pos = NULL) # Здесь легенда не нужна Для отображения координатной сетки надо указать параметр graticule = TRUE, а подписей координат — axes = TRUE: plot(countries[&#39;gdp_md_est&#39;], graticule = TRUE, axes = TRUE) 9.4.4.2 Совмещение слоев Для совмещения нескольких слоев на одной карте необходимо при втором и последующих вызовах функции plot() указать параметр add = TRUE: oceans = st_read(&#39;data/ne/oceans.gpkg&#39;) ## Reading layer `ocean&#39; from data source `/Users/tsamsonov/GitHub/r-geo-course/data/ne/oceans.gpkg&#39; using driver `GPKG&#39; ## Simple feature collection with 2 features and 4 fields ## geometry type: POLYGON ## dimension: XY ## bbox: xmin: -180 ymin: -85.60904 xmax: 180 ymax: 90 ## epsg (SRID): 4326 ## proj4string: +proj=longlat +datum=WGS84 +no_defs rivers = st_read(&#39;data/ne/rivers.gpkg&#39;) ## Reading layer `rivers_lake_centerlines&#39; from data source `/Users/tsamsonov/GitHub/r-geo-course/data/ne/rivers.gpkg&#39; using driver `GPKG&#39; ## Simple feature collection with 13 features and 8 fields ## geometry type: LINESTRING ## dimension: XY ## bbox: xmin: -135.3134 ymin: -33.99358 xmax: 129.956 ymax: 72.90651 ## epsg (SRID): 4326 ## proj4string: +proj=longlat +datum=WGS84 +no_defs lakes = st_read(&#39;data/ne/lakes.gpkg&#39;) ## Reading layer `lakes&#39; from data source `/Users/tsamsonov/GitHub/r-geo-course/data/ne/lakes.gpkg&#39; using driver `GPKG&#39; ## Simple feature collection with 25 features and 8 fields ## geometry type: POLYGON ## dimension: XY ## bbox: xmin: -124.9536 ymin: -16.53641 xmax: 109.9298 ymax: 66.9693 ## epsg (SRID): 4326 ## proj4string: +proj=longlat +datum=WGS84 +no_defs plot(countries %&gt;% st_geometry, lwd = 0.5, border = &#39;gray&#39;) plot(oceans %&gt;% st_geometry, col = &#39;steelblue1&#39;, border = &#39;steelblue&#39;, add = TRUE) plot(lakes %&gt;% st_geometry, col = &#39;steelblue1&#39;, border = &#39;steelblue&#39;, add = TRUE) plot(rivers %&gt;% st_geometry, col = &#39;steelblue&#39;, add = TRUE) Внимание: чтобы слои совместились на карте, они должна иметь одинаковую систему координат. Ясно, что на полученных нами картах можно много что улучшить, однако это мы отложим до следующей главы, где подробно разбирается построение тематических карт в R. 9.4.5 Системы координат и проекции Работа с пространственной привязкой данных в R состоит в основном из четырех операций: чтение информации о системе координат создание информации о системе координат замена информации о системе координат изменение системы координат (проецирование) Первые три операции (чтение, создание, замена) осуществляются функцией st_crs(). Чтобы прочитать информацию о проекции, достаточно передать в качестве параметра объект типа sf: st_crs(countries) # Координатная система ## Coordinate Reference System: ## EPSG: 4326 ## proj4string: &quot;+proj=longlat +datum=WGS84 +no_defs&quot; Эта же функция позволяет создать новую координатную систему, путем передачи ей кода EPSG или строки PROJ.4: st_crs(3857) # Проекция Меркатора для карт мира ## Coordinate Reference System: ## EPSG: 3857 ## proj4string: &quot;+proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +wktext +no_defs&quot; st_crs(54030) # Проекция Робинсона для карт мира ## Coordinate Reference System: ## EPSG: 54030 ## proj4string: &quot;+proj=robin +lon_0=0 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs&quot; # Проекция UTM, зона 37. st_crs(&#39;+proj=utm +zone=37 +datum=WGS84 +units=m&#39;) ## Coordinate Reference System: ## EPSG: 32637 ## proj4string: &quot;+proj=utm +zone=37 +datum=WGS84 +units=m +no_defs&quot; Замена координатной системы требуется в тех случаях, когда слой не имеет пространственной привязки, или же она задана некорректно. В этом случае необходимо вызвать для слоя функцию st_crs() и перезаписать результат. st_crs(countries) = NA st_crs(countries) ## Coordinate Reference System: NA st_crs(countries) = st_crs(4326) st_crs(countries) ## Coordinate Reference System: ## EPSG: 4326 ## proj4string: &quot;+proj=longlat +datum=WGS84 +no_defs&quot; Внимание: замена координатной системы не осуществляет перепроецирования данных и не меняет координаты точек. Она лишь влияет на то, как эти координаты будут интерпретироваться. Если вместо проецирования выполнить замену информации о координатной системе, данные будут позиционироваться в неправильном месте. Для трансформирования данных в другую проекцию следует использовать функцию st_tranform(x, crs). Данная функция принимает в качестве параметров класс объектов sf и координатную систему, в которую необходимо проецировать данные. # Проекция Меркатора countries.merc = st_transform(countries, 3857) plot(st_geometry(countries.merc), col = &#39;lightgray&#39;, lwd = 0.5, graticule = TRUE, axes = TRUE) # Проекция Робинсона (используем dplyr) countries.rob = countries %&gt;% st_transform(54030) plot(st_geometry(countries.rob), col = &#39;lightgray&#39;, lwd = 0.5, graticule = TRUE, axes = TRUE) # Зарубежная Европа в Конической равнопромежуточной проекции. # Задаем только необходимые параметры проекции europe.conic = countries %&gt;% dplyr::filter(continent == &#39;Europe&#39; &amp; sovereignt != &#39;Russia&#39;) %&gt;% st_transform(&#39;+proj=eqdc +lon_0=10 +lat_1=30 +lat_2=60 +datum=WGS84 +units=m&#39;) plot(st_geometry(europe.conic), col = &#39;lightgray&#39;, lwd = 0.5, graticule = TRUE, axes = TRUE) Внимание: чтобы слои данных можно было совместно анализировать и наносить на одну карту, они должны иметь одну и ту же координатную систему (проекцию). 9.4.6 Атрибутивные операции Поскольку пространственные объекты хранятся в фреймах данных, к ним можно применять стандартные операции выборки по атрибутам и преобразования таблиц. Например, можно выбрать Италию и отобразить ее на отдельной карте: library(dplyr) italy = countries %&gt;% filter(sovereignt == &#39;Italy&#39;) plot(st_geometry(italy)) Следующий пример иллюстрирует как выбрать страны с населением более 100 млн человек: largest = countries %&gt;% dplyr::select(pop_est) %&gt;% filter(pop_est &gt; 100000000) plot(outlines, col = &#39;lightgrey&#39;) plot(largest, col = &#39;red&#39;, add = TRUE) Обратите внимание на то, что при вызове функции select() столбец geometry не был указан в числе выбираемых переменных. Тем не менее, то, что мы смогли построить карту по результатам выборки, говорит о том, что данный столбец был сохранен. Функции dplyr определены для объектов sf таким образом, чтобы всегда сохранять геометрический столбец. Еще интереснее работает агрегирование объектов по атрибутам. В случае, когда агрегируются пространственные объекты, необходимо объединять и их геометрию. При этом если у агрегируемых объектов имеется общая граница, ее необходимо удалить, а если объекты разнесены в пространстве, из них нужно собрать новый мульти-объект. Например, мы можем агрегировать валовой региональный продукт по континентам: continents = countries %&gt;% group_by(continent) %&gt;% summarise(gdp = sum(gdp_md_est)) plot(continents[&#39;gdp&#39;]) Потрясающе просто, не правда ли? Вдобавок, мы еще и получили границы континентов (достаточно условные, конечно), которых у нас раньше не было. Данный пример также показывает, что атрибутивные операции над пространственными объектами всегда учитывают их геометрию. 9.4.7 Пространственные операции Поиск объектов по местоположению базируется на проверке топологических отношений между объектами. Топологические отношения описывают взаимное расположение объектов. Различные варианты топологических отношений для площадных объектов представлены на следующем рисунке, где серым цветом показаны пересечения внутренних областей объектов \\(A\\) и \\(B\\), синим цветом — пересечения границ объектов \\(A\\) и \\(B\\): Отношение Пересекает (intersects) будет истинно для любого случая когда две геометрии имеют хотя бы одну общую точку, то есть во всех случаях кроме Не пересекает (disjoint). Для проверки этих, а также некоторых других отношений, в пакете sf существует ряд функций: Функция Топологическое отношение st_intersects(x, y) x имеет общие точки с y st_disjoint(x, y) x не имеет общих точек с y st_touches(x, y) x касается y (граница x имеет общие точки с границей y И внутренняя область x не имеет имеет общих точек с внутренней областью y) st_crosses(x, y) x пересекает y (граница x имеет общие точки с границей y, при этом размерность их пересечения меньше размерности хотя бы одного из исходных объектов) st_within(x, y) x внутри y (все точки x содержатся в y И внутренняя область x имеет общие точки с внутренней областью y) st_contains(x, y) x содержит y (все точки y содержатся в x И внутренняя область y имеет общие точки с внутренней областью x) st_contains_properly(x, y) x содержит y полностью (все точки y содержатся в x И граница x не имеет общих точек с границей y) st_overlaps(x, y) x перекрывает y (внутренняя область x имеет как общие, так и не общие точки с внутренней областью y) st_equals(x, y) x совпадает y (множества точек x и y совпадают) st_covers(x, y) x покрывает y (все точки y содержатся в x) st_covered_by(x, y) x покрыт y (все точки x содержатся в y) st_equals_exact(x, y) x совпадает y точно (упорядоченные множества точек x и y совпадают) Между covered_by и within, а также covers и contains нет разницы в случае, когда оба объекта являются площадными. Эта разница будет сказываться если хотя бы один из объектов является линией либо точкой. В этом случае within, contains и contains_properly будут давать ложный результат (FALSE), поскольку ни у линий, ни у точек нет внутренней области. Проверка топологических отношений используется для выполнения выборки объектов по местоположению — пространственной выборки. Наиболее простой способ выбрать объекты по пространственному местоположению — это использовать один слой в качестве фильтра для другого слоя. В этом случае будет по умолчанию использовано отношение st_intersects() (пересекает). Никаких отличий от работы с обычными таблицами нет. Например, вот так можно выбрать точки, находящиеся внутри ранее отобранных стран с максимальным ВВП: cities = st_read(&#39;data/ne/cities.gpkg&#39;) ## Reading layer `populated_places&#39; from data source `/Users/tsamsonov/GitHub/r-geo-course/data/ne/cities.gpkg&#39; using driver `GPKG&#39; ## Simple feature collection with 243 features and 103 fields ## geometry type: POINT ## dimension: XY ## bbox: xmin: -175.2206 ymin: -41.29999 xmax: 179.2166 ymax: 64.15002 ## epsg (SRID): 4326 ## proj4string: +proj=longlat +datum=WGS84 +no_defs city.pts = st_geometry(cities) # Наносим исходную конфигурацию plot(outlines, lwd = 0.5) plot(cities, col = &#39;black&#39;, pch = 20, cex = 0.5, add = TRUE) # Отбираем точки внутри стран с максимальным ВВП sel = cities[largest, ] # Смотрим что получилось plot(outlines, lwd = 0.5) plot(largest, col = &#39;gray&#39;, add = TRUE) plot(sel, pch = 20, col = &#39;black&#39;, add = TRUE) Разумеется, при выполнении пространственных запросов могут возникать и другие пространственные отношения. Например, мы можем выбрать все страны, имеющие общую границу с Чехией. Для этого можно использовать топологическое отношение st_touches вместо st_intersects — это будет гарантировать, что сама Чехия в результате не выберется (касающиеся объекты не могут перекрываться). Тип отношения необходимо поставить в параметр op = при выполнении фильтрации фрейма данных: cz = countries %&gt;% filter(sovereignt == &#39;Czechia&#39;) neighbors = countries[cz, op = st_touches] plot(st_geometry(neighbors), col = &#39;lightgray&#39;, lwd = 0.5) plot(cz, col = &#39;darkgray&#39;, add = TRUE) 9.4.8 Создание пространственных объектов Пространственные объекты в R можно собирать “вручную”, если есть такая необходимость. Например, вам известны координаты границ участков полевого обследования, полученные посредством GPS, а вам необходимо превратить их в полигоны, чтобы выполнить анализ и картографирование. Придется из координат собрать полигоны программным путем. Процесс создания пространственных объектов осуществляется в последовательности их иерархического соподчинения: sfg &gt; sfc &gt; sf. 9.4.8.1 Геометрические объекты (sfg) Для создания геометрических объектов в пакете sf существует ряд функций с говорящими названиями: Функция Тип пространственного объекта st_point() POINT st_linestring() LINESTRING st_polygon() POLYGON st_multipoint() MULTIPOINT st_multilinestring() MULTILINESTRING st_multipolygon() MULTIPOLYGON st_geometrycollection() GEOMETRYCOLLECTION В зависимости от типа создаваемого объекта, данные функции принимают координаты, организованные в виде одной из трех структур данных: Вектор координат (POINT) Матрица координат (MULTIPOINT или LINESTRING), в которой строки соответствуют точкам, столбцы — координатам Список (для всех остальных типов) Проще всего создаются отдельные точки (POINT): st_point(c(0, 2)) # XY POINT st_point(c(0, 2, -1)) # XYZ POINT st_point(c(0, 2, 5), dim = &#39;XYM&#39;) # XYM POINT st_point(c(0, 2, -1, 5)) # XYZM POINT Дополнительный параметр dim= служит для уточнения типа геометрии точек и по сути нужен только тогда, когда необходимо создать редко используемые точки типа XYM. во всех остальных случаях (XY, XYZ, XYZM) размерность геометрии распознается по умолчанию. При создании мультиточек (MULTIPOINT) и линий (LINESTRING) необходимо подавать на вход функции уже матрицу координат: coords = matrix(c( 0, 2, 1, 3, 3, 1, 5, 0 ), ncol = 2, byrow = TRUE) mp = st_multipoint(coords) # XY MULTIPOINT print(mp) ls = st_linestring(coords) # XY LINESTRING print(ls) В первом случае геометрия состоит из отдельных точек. Во втором случае те же самые точки соединены линией: plot(ls) plot(mp, col = &#39;red&#39;, pch = 19, add = TRUE) Создание трех-(XYZ, XYM) и четырехмерных (ZYXM) мультиточек и линий выполняется аналогично, но матрица должна содержать не 2, а, соответственно 3 или 4 столбца, и при необходимости параметр dim = 'XYM'. Создание полигонов (POLYGON), мультиполигонов (MULTIPOLYGON) и мультилиний (MULTILINESTRING) требует уже создания списков из матриц. Почему нельзя представить обычный (не мульти) полигон просто матрицей координат? Потому что полигон может содержать дырки. Например, контур леса может содержать дырку в том месте, где находится озеро. Или озеро может содержать дырку в том месте, где находится остров. Природа предлагает нам бесконечное число таких примеров. В целях универсализации приходится закладываться на возможность наличия дырок в полигонах, поэтому даже полигоны без дырок представляются в виде списков. При этом действу.т следующее правила: Первая матрица координат в списке отвечает за контур полигона Все остальные матрицы координат отвечают за дыры в полигоне Координаты первой и последней точки в каждой матрице должны совпадать Если дыр в полигоне нет, его список будет содержать только одну матрицу. Рассмотрим оба примера построения полигонов: coords = matrix(c( # Координаты главного полигона 1, 0, 0, 2, 2, 3, 4, 2, 3, 0.5, 1, 0 ), ncol = 2, byrow = TRUE) pol = st_polygon(list(coords)) # Простой полигон print(pol) plot(pol, col = &#39;lightblue&#39;) hole = matrix(c( # Координаты дыры 2, 1, 3, 1.5, 3, 2, 2, 2, 1.5, 1.5, 2, 1 ), ncol = 2, byrow = TRUE) pol2 = st_polygon(list(coords, hole)) # Полигон с дырой print(pol2) plot(pol2, col = &#39;lightblue&#39;) Мультиполигоны (MULTIPOLYGON) и мультилинии (MULTILINESTRING) требуются тогда, когда один и тот же географический объект состоит из нескольких геометрических объектов. Простейший пример — островные государства. Чтобы представить страну, занимающую архипелаг (Багамские острова, Индонезия, Япония и т.д.) как один пространственный объект, необходимо создать мультиполигон. Все компоненты мультиполигона будут иметь общий набор атрибутов (непространственных характеристик). Мультилинии используются реже мультиполигонов и необходимы для представления линейных объектов, разорванных в пространстве. Примером такого объекта может быть любая река или канал, которые разорваны в тех местах, где они протекают через озеро или водохранилище, представленное полигональным объектом. В мультиполигонах добавляется еще один уровень списка, то есть искомые матрицы координат будут располагаться как минимум на втором уровне вложенности: coords1 = matrix(c( 0.5, 0, 0, 1, 1, 1.5, 2, 1, 1.5, 0.25, 0.5, 0 ), ncol = 2, byrow = TRUE) coords2 = matrix(c( 3, 1, 2.5, 2, 3.5, 2.5, 4, 2, 4, 1.25, 3, 1 ), ncol = 2, byrow = TRUE) mpol = st_multipolygon(list(list(coords1), list(coords2))) print(mpol) plot(pol, col = &#39;grey&#39;) # Обычный полигон (серый) plot(mpol, col = &#39;pink&#39;, add = TRUE) # Мультиполигон (розовый) Как насчет острова на озере? Если остров и суша, окружающая озеро, составляют единое целое (например, подлежат учету как единый массив леса), их можно собрать как мультиполигон. В этом случае первая компонента мультиполигона будет представлять собой полигон с дыркой, а вторая компонента — остров. Порядок компонент в данном случае роли не играет: coords4 = matrix(c( 2.2, 1.2, 2.8, 1.5, 2.8, 1.8, 2.2, 1.8, 2.0, 1.6, 2.2, 1.2 ), ncol = 2, byrow = TRUE) island = st_polygon(list(coords4)) mpol2 = st_multipolygon(list(pol2, island)) print(mpol2) plot(mpol2, col = &#39;darkolivegreen4&#39;) Из данного примера также видно, что при сборе мультиполигона на самом нижнем уровне вложенности можно подавать не списки матриц координат, а готовые полигоны. Мультилиния, в отличие от мультиполигона, не требует дополнительного списка верхнего уровня, поскольку линии не могут содержать дыр. Например, можно собрать мультилинию из двух частей, соответствующих участкам реки до и после озера: coords1 = matrix(c( -3, 0, -1, 2, 0, 2 ), ncol = 2, byrow = TRUE) coords2 = matrix(c( 4, 2, 5, 3, 6, 5 ), ncol = 2, byrow = TRUE) mline = st_multilinestring(list(coords1, coords2)) print(mline) plot(mline, lwd = 3, col = &#39;blue&#39;) plot(pol2, col = &#39;lightblue&#39;, add = TRUE) Наконец, еще один вид геометрии — это геометрическая коллекция (GEOMETRYCOLLECTION), который позволяет хранить вместе любые виды геометрий. Эта возможность используется достаточно редко, тем не менее, рассмотреть ее нужно. Геометрическая коллекция собирается из списка объектов с простыми типами геометрии (мы создали их ранее): col = st_geometrycollection(list(ls, mp, mline, pol2)) print(col) plot(col) 9.4.8.2 Списки геометрических объектов (sfc) Списки геометрических объектов (класс sfc) используются в таблицах пространственных объектов в качестве столбца, который хранит геометрию объектов. Создание таких списков осуществляется функцией st_sfc(), которой достаточно передать в качестве перечня параметров объекты типа sfg. Рассмотрим создание списка геометрий на примере точечных объектов (для остальных типов объектов порядок действий не меняется): moscow.sfg = st_point(c(37.615, 55.752)) irkutsk.sfg = st_point(c(104.296, 52.298)) petro.sfg = st_point(c(158.651, 53.044)) cities.sfc = st_sfc(moscow.sfg, irkutsk.sfg, petro.sfg) print(cities.sfc) ## Geometry set for 3 features ## geometry type: POINT ## dimension: XY ## bbox: xmin: 37.615 ymin: 52.298 xmax: 158.651 ymax: 55.752 ## epsg (SRID): NA ## proj4string: NA При создании списка геометрий для него может быть определена система координат (это можно сделать и позднее при создании таблицы пространственных объектов). Для этого используем уже знакомую нам функцию st_crs(): st_crs(cities.sfc) = st_crs(4326) # WGS84 print(cities.sfc) ## Geometry set for 3 features ## geometry type: POINT ## dimension: XY ## bbox: xmin: 37.615 ymin: 52.298 xmax: 158.651 ymax: 55.752 ## epsg (SRID): 4326 ## proj4string: +proj=longlat +datum=WGS84 +no_defs Для списка геометрий может быть определена только одна система координат Можно посмотреть, куда легли наши точки: plot(cities.sfc, pch = 19) countries %&gt;% filter(sovereignt == &#39;Russia&#39;) %&gt;% st_geometry() %&gt;% plot(add = TRUE) 9.4.8.3 Пространственные объекты (sf) Пространственные объекты (класс sf) организуются в виде фрейма данных, один из столбцов которого имеет класс sfc. Для этого следует сначала создать обычный фрейм данных с атрибутами, а затем соединить его со списком геометрий посредством функции st_sf: city.attr = data.frame( name = c(&#39;Москва&#39;, &#39;Иркутск&#39;, &#39;Петропавловск-Камчатский&#39;), established = c(1147, 1661, 1740), population = c(12500, 620, 180) ) cites.sf = st_sf(city.attr, geometry = cities.sfc) print(cites.sf) ## Simple feature collection with 3 features and 3 fields ## geometry type: POINT ## dimension: XY ## bbox: xmin: 37.615 ymin: 52.298 xmax: 158.651 ymax: 55.752 ## epsg (SRID): 4326 ## proj4string: +proj=longlat +datum=WGS84 +no_defs ## name established population geometry ## 1 Москва 1147 12500 POINT (37.615 55.752) ## 2 Иркутск 1661 620 POINT (104.296 52.298) ## 3 Петропавловск-Камчатский 1740 180 POINT (158.651 53.044) 9.4.8.4 Точки по координатам Достаточно распространенной является следующая задача: имеются координаты точек в табличной форме, необходимо создать на их основе набор пространственных объектов. Для решения этой задачи можно воспользоваться функцией st_as_sf(). Рассмотрим задачу на примере файла координат станций из базы метеорологических данных ВНИИГМИ-МЦД: (stations = read_fwf(&#39;data/vniigmi/stations.txt&#39;, col_positions = fwf_widths(diff(c(1, 7, 42, 47, 53, 59, 67, 71)), col_names = c(&#39;id&#39;, &#39;name&#39;, &#39;lat&#39;, &#39;t1&#39;, &#39;lon&#39;, &#39;t2&#39;, &#39;z&#39;)), locale = locale(encoding = &#39;CP1251&#39;))) ## # A tibble: 1,124 x 7 ## id name lat t1 lon t2 z ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 20046 Им.Э.Т.Кренкеля,ГМО 80.6 с.ш. 58 в.д. 21 ## 2 20069 Остров_Визе 79.5 с.ш. 77.0 в.д. 10 ## 3 20087 Голомянный 79.6 с.ш. 90.6 в.д. 7 ## 4 20107 Баренцбург 78.1 с.ш. 14.2 в.д. 73 ## 5 20289 Русский 77.2 с.ш. 96.4 в.д. 9 ## 6 20292 Им.Е.К.Федорова,ГМО 77.7 с.ш. 104. в.д. 12 ## 7 20353 мыс_Желания 77.0 с.ш. 68.6 в.д. 9 ## 8 20476 Стерлегова 75.4 с.ш. 88.9 в.д. 10 ## 9 20667 Им.М.В.Попова 73.3 с.ш. 70.0 в.д. 4 ## 10 20674 Остров_Диксон 73.5 с.ш. 80.4 в.д. 42 ## # … with 1,114 more rows Теперь создадим пространственные точки на основе этой таблицы, взяв координаты из столбцов lat и lon соответственно и указав код системы координат: sf_stations = st_as_sf(stations, coords = c(&quot;lon&quot;, &quot;lat&quot;), crs = 4326) plot(st_geometry(sf_stations), pch = 19, col = &#39;red&#39;, cex = 0.25) plot(st_geometry(countries), border = &#39;grey&#39;, add = TRUE) box() 9.4.8.5 Преобразование типов геометрии Для преобразования типов геометрии существует функция st_cast(). Функция принимает объекты классов sfg, sfc или sf, а также название типа геометрии, к которому необходимо привести входные объекты. Довольно часто возникает задача конвертации площадного объекта в линейный и обратно, а также задача получения координат вершин линейного или площадного объекта в виде точек. Примеры преобразований: italy.borders = st_cast(italy, &#39;MULTILINESTRING&#39;) class(st_geometry(italy.borders)) ## [1] &quot;sfc_MULTILINESTRING&quot; &quot;sfc&quot; italy.regions = st_cast(italy.borders, &#39;MULTIPOLYGON&#39;) class(st_geometry(italy.regions)) ## [1] &quot;sfc_MULTIPOLYGON&quot; &quot;sfc&quot; italy.points = st_cast(italy.borders, &#39;POINT&#39;) class(st_geometry(italy.points)) ## [1] &quot;sfc_POINT&quot; &quot;sfc&quot; plot(st_geometry(italy.regions), lwd = 0.5) plot(italy.points, pch = 20, add = TRUE) 9.4.8.6 Полигонизация и разбиение линий Полигонизация — это процесс преобразования линии или мультилинии в полигон(ы). Полигон может быть образован последовательностью из одной и более линий, для которых выполняются следующие условия: Каждая линия является простой (не имеет самопересечений) Линии касаются только своими начальными и конечными точками Линии образуют замкнутую последовательность (т.е. выйдя из любой конечной точки и двигаясь вдоль множества линий, можно вернуться в ту же точку.) Полигонизация может применяться только к одному геометрическому объекту (simple feature geometry). Соответственно, это должна быть либо просто замкнутая линия, либо мультилиния, компоненты которой образуют замкнутую последовательность. Рассмотрим операции полигонизации и добавления узлов на простом примере трех пересекающихся отрезков: # Создадим три линии coords1 = rbind(c(0, 0), c(0, 6)) line1 = st_linestring(coords1) coords2 = rbind(c(-1,1), c(5,1)) line2 = st_linestring(coords2) coords3 = rbind(c(-1,5), c(4,0)) line3 = st_linestring(coords3) # Создадим мультилинию mls = st_multilinestring(list(line1, line2, line3)) plot(mls) # Посмотрим на ее точки points = st_cast(mls, &#39;MULTIPOINT&#39;) plot(points, pch = 20, add = TRUE) Из рисунка видно, что линии образуют треугольную замкнутую область. Также рисунок показывает, что у компонент мультилинии нет вершин в точках пересечения. Мы можем попытаться найти замкнутые области и превратить их в полигоны, используя st_polygonize(): st_polygonize(mls) Операция завершилась возвратом пустой геометрической коллекции, то есть программа не смогла выделить замкнутые области. Это произошло по причине того, что линии не разбиты в точках пересечения. Разбить их на компоненты можно, используя функцию st_node(): mls2 = st_node(mls) poly2 = st_polygonize(mls2) points2 = st_cast(mls2, &#39;MULTIPOINT&#39;) plot(mls2) plot(poly2, col = &#39;grey&#39;, add = TRUE) plot(points2, pch = 20, add = TRUE) Таким образом, после разбиения линий на куски в точках пересечения стала возможной операция полигонизации. 9.4.9 Геометрические атрибуты К описательным характеристикам геометрии относятся ограничивающий прямоугольник, периметр (для линий и полигонов), площадь (для полигонов), центроид и список координат, которые можно получить с помощью функций st_bbox(), st_length(), st_area(), st_centroid() и st_coordinates() соответственно. Функции корректно работают для простых объектов, мультиобъектов, списков геометрий и пространственных объектов. Применительно к полигону Италии эти параметры будут учитывать части геометрии, занимаемые островами: st_bbox(italy) # Координаты органичивающего прямоугольника ## xmin ymin xmax ymax ## 6.749955 36.619987 18.480247 47.115393 st_area(italy) # Площадь ## 315104851198 [m^2] st_length(italy) # Периметр ## 5323111 [m] st_centroid(italy) %&gt;% st_geometry() # Центроид (может быть не внутри для невыпуклых фигур) ## Geometry set for 1 feature ## geometry type: POINT ## dimension: XY ## bbox: xmin: 12.14079 ymin: 42.75118 xmax: 12.14079 ymax: 42.75118 ## epsg (SRID): 4326 ## proj4string: +proj=longlat +datum=WGS84 +no_defs st_point_on_surface(italy) %&gt;% st_geometry() # Точка гарантированно внутри, но не обязательно в центре ## Geometry set for 1 feature ## geometry type: POINT ## dimension: XY ## bbox: xmin: 12.63118 ymin: 42.55822 xmax: 12.63118 ymax: 42.55822 ## epsg (SRID): 4326 ## proj4string: +proj=longlat +datum=WGS84 +no_defs st_coordinates(italy) %&gt;% head() # Список координат ## X Y L1 L2 L3 ## [1,] 10.44270 46.89355 1 1 1 ## [2,] 11.04856 46.75136 1 1 1 ## [3,] 11.16483 46.94158 1 1 1 ## [4,] 12.15309 47.11539 1 1 1 ## [5,] 12.37649 46.76756 1 1 1 ## [6,] 13.80648 46.50931 1 1 1 Обратите внимание на то, что площадь и периметр выводятся с указанием единиц измерений! Это возможно благодаря тому, что объекты типа sf поддерживают единицы измерений на основе пакета units. Если данные находятся в плоской прямоугольной системе координат, то единицы измерения как правило указываются в параметрах проекции — следовательно, они могут быть использованы при вычислении геометрических параметров объектов. Если же данные хранятся в широтах и долготах, то вычисление геометрических параметров осуществляется пакетом sf по формулам сферической тригонометрии через пакет geosphere. Это позволяет выводить результат в плоских единицах измерения. Ограничивающий прямоугольник можно быстро преобразовать в полигон и нанести на карту, применив функцию st_as_sfc(): box = st_as_sfc(st_bbox(italy)) # Ограничивающий прямоугольник plot(italy %&gt;% st_geometry(), col = &#39;lightgrey&#39;) plot(box, border = &#39;orangered&#39;, add = TRUE) plot(st_centroid(italy), col = &#39;darkgreen&#39;, pch = 19, add = TRUE) plot(st_point_on_surface(italy), col = &#39;steelblue4&#39;, pch = 19, add = TRUE) Как видно, в данном случае центроид и характерная точка расположились относительно рядом. Однако так бывает далеко не всегда. Выполним аналогичные вычисления для Индонезии: indonesia = countries %&gt;% filter(sovereignt == &#39;Indonesia&#39;) box = st_as_sfc(st_bbox(indonesia)) plot(indonesia %&gt;% st_geometry(), col = &#39;lightgrey&#39;) plot(box, border = &#39;red&#39;, add = TRUE) plot(st_centroid(indonesia), col = &#39;darkgreen&#39;, pch = 19, add = TRUE) plot(st_point_on_surface(indonesia), col = &#39;steelblue4&#39;, pch = 19, add = TRUE) Как видно, в данном случае центроид мультиполигона оказался за пределами какой-либо из его полигональных компонент, в то время как характерная точка находится внутри одного из полигонов. Таким образом, если необходимо получить точку, находящуюся гарантированно в пределах исходного множества, следует использовать st_point_on_surface(). При этом следует помнить, что характерная точка, в отличие от центроида, может не располагаться в визуальном центре тяжести множества объектов, и выбор между этими способами описания геометрии остается за разработчиком. 9.4.10 Экспорт Для экспорта векторных пространственных данных можно воспользоваться функцией st_write(), которая определит формат выходного файла по указанному вами расширению: st_write(cites.sf, &#39;data/mycities.shp&#39;) # Шейп-файл 9.5 Растровые данные Работа с растровыми данными в целом гораздо проще, чем работа с векторными объектами. Это обусловлено в том числе жесткой сеточной структурой данных, которая предоставляет не так много свободы в различных сценариях обработки данных. В то же время, эта жесткая структура позволяет сделать растровые алгоритмы универсальными и робастными, многие задачи решаются в растровом виде быстрее и проще, чем в векторном. В настоящее время для работы с растровыми данными в R используется мощный и достаточно универсальный пакет raster8. 9.5.1 Чтение Для чтения одноканальных растров (например, цифровых моделей рельефа или полей распределения метеорологических величин) используется функция raster(), она создает растровый слой (Raster Layer). Многоканальные растры (например, космические снимки или файлы NetCDF) читаются с помощью функции stack(), она создает растровый стек (Raster Stack): library(raster) dem = raster(&#39;data/world/gebco.tif&#39;) # Цифровая модель рельефа class(dem) ## [1] &quot;RasterLayer&quot; ## attr(,&quot;package&quot;) ## [1] &quot;raster&quot; img = stack(&#39;data/world/BlueMarbleJuly.tif&#39;) # Цветной космический снимок (RGB) class(img) ## [1] &quot;RasterStack&quot; ## attr(,&quot;package&quot;) ## [1] &quot;raster&quot; class(img[[1]]) ## [1] &quot;RasterLayer&quot; ## attr(,&quot;package&quot;) ## [1] &quot;raster&quot; Вы также можете прочитать каналы многоканального растра по отдельности. Для этого необходимо использовать функцию raster(), указав ей в качестве второго параметра номер канала, который вы хотите прочитать. Если потом потребуется собрать поканальные растры в один стек, для этого можно снова использовать функцию stack(): ch1 = raster(&#39;data/world/BlueMarbleJuly.tif&#39;, 1) ch2 = raster(&#39;data/world/BlueMarbleJuly.tif&#39;, 2) ch3 = raster(&#39;data/world/BlueMarbleJuly.tif&#39;, 3) img = stack(ch1, ch2, ch3) 9.5.2 Визуализация 9.5.2.1 Одноканальные растры Для визуализации одноканальных растров используется функция plot(). В простейшем виде ей достаточно просто передать визуализруемый растр: par(mfrow = c(1,1)) plot(dem) Поскольку растры часто используют в классифицированном виде, вы можете сформировать вектор граничных значений классов, вектор цветов классов, и передать их в параметры breaks и col функции plot() соответственно. Если параметр breaks не определять, то весь диапазон значений растра будет разбит на равные интервалы соответственно количеству цветов. Если не определять параметр col, то будет применена стандартная палитра terrain.colors. Вы также можете использовать одну из готовых палитр цветов или создать ее вручную (см. посвященную графической подсистеме R): brks = c(-12000, 0, 200, 500, 1000, 2000, 4000, 8000) clrs = c( &quot;steelblue4&quot;, &quot;darkseagreen&quot;, &quot;lightgoldenrod1&quot;, &quot;darkgoldenrod1&quot;, &quot;darkorange&quot;, &quot;coral2&quot;, &quot;firebrick3&quot;) plot(dem, breaks = brks, col = clrs) plot(ch1, col = colorRampPalette(c(&quot;black&quot;, &quot;white&quot;))(255)) plot(ch1, col = rainbow(10)) 9.5.2.2 Многоканальные растры Для визуализации растрового стека (многоканального растра) следует использовать функцию plotRBG(): plotRGB(img) Поскольку при визуализации космических снимков часто используют различные варианты синтеза каналов (чтобы лучше дешифрировать те или иные категории объектов), функция plotRGB() предоставляет такую возможность. Достаточно перечислить последовательность каналов растрового стека (по умолчанию эти каналы будут подставлены в каналы R, G и B соответственно): par(mfrow = c(3,2)) plotRGB(img, 1, 2, 3) plotRGB(img, 1, 3, 2) plotRGB(img, 2, 1, 3) plotRGB(img, 2, 3, 1) plotRGB(img, 3, 1, 2) plotRGB(img, 3, 2, 1) par(mfrow = c(1,1)) 9.5.2.3 Совмещение слоев Вы можете совмещать на картах несколько растровых и векторных слоев точно так же как и при совмещении векторных данных (указав параметр add = TRUE при вызове функции plot()): plotRGB(img) plot(outlines, border = &quot;white&quot;, lwd = 0.5, add = TRUE) 9.5.3 Системы координат и проекции Как и в случае с векторными данными, работа с проекцией растровых данных предполагает четыре возможных процедуры: чтение, создание, замена и проецирование. Для чтения и замены информации о системе координат растра используется функция crs(). Она возвращает и принимает строку в формате PROJ.4. Для создания информации о системе координат можно использовать уже знакомую нам функцию st_crs() из пакета sf. Данная функция возвращает список, вторая компонента которого и есть искомая строка: crs(dem) # читаем систему координат ## CRS arguments: ## +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 crs(dem) = NA # очищаем систему координат crs(dem) ## CRS arguments: NA crs(dem) = st_crs(4326)[[2]] # создаем систему координат crs(dem) ## CRS arguments: ## +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 Для проецирования растра в новую систему координат необходимо использовать функцию projectRaster(). В эту функцию необходимо передать как минимум два параметра: from= отвечает за входной растр и crs= отвечает за выходную систему координат в формате PROJ.4. Дополнительно можно указать разрешение растра (res=), метод передискретизации (method=) и растр-шаблон (to= — можно создать растр в выходной системе координат заранее и как бы “перенести” значения пикселей входного растра на пиксели шаблона). Есть и другие параметры, с которыми можно ознакомиться в справке функции projectRaster(). Приведем несколько примеров проецирования: # Проекция Меркатора: img.merc = projectRaster(img, crs = st_crs(3857)[[2]]) plotRGB(img.merc) plot(st_geometry(countries.merc), border = rgb(1,1,1,0.2), lwd = 0.5, add = TRUE) # Проекция Робинсона: img.merc = projectRaster(img, crs = st_crs(54030)[[2]]) plotRGB(img.merc) plot(st_geometry(countries.rob), border = rgb(1,1,1,0.2), lwd = 0.5, add = TRUE) 9.5.4 Операции со значениями Операции со значениями растров чрезвычайно разнообразны, поэтому подробно они разбираются в одной из последующих глав. Здесь же мы кратко познакомимся с локальными операциями над растром, такими как фильтрация и арифметические преобразования. В локальных операциях каждый пиксел растра анализируется отдельно, независимо от остальных пикселов. Поэтому локальные операции наиболее просты в применении. Но это не означает, что они менее важны, чем более сложные операции. Как раз наоборот: фильтрация и арифметика представляют собой важнейшие операции растровой алгебры. Особенность растровой алгебры заключается в том, что растры используются в выражениях как обычные переменные — это делает преобразования растров простыми и наглядными. Чтобы произвести фильрацию (выбор) ячеек по значениям, необходимо соорудить логическое выражение с участием растра. Все пикселы, удовлетворяющие критерию, получат в результирующем растре значение 1, а все остальные — 0. Несколько примеров: below.zero = dem &lt; 0 plot(below.zero) highlands = dem &gt; 100 &amp; dem &lt; 500 plot(highlands) mountains = dem &gt; 1000 plot(mountains) С помощью локальных операций растровой алгебры можно складывать, вычитать, перемножать и делить растры (а также брать из них квадратные корни, логарифмы, тригонометрические функции), точно так же как это происходит с обычными числами. Соответственно, бывают бинарные (два растра) и унарные (один растр) операции. Чтобы получать предсказуемые результаты бинарных операций растровой алгебры, необходимо, чтобы геометрия растров совпадала. Покажем возможности растровой алгебры на примере определения толщины покровного оледенения. Глобальная цифровая модель рельефа ETOPO1 поставляется в двух вариантах: Ice Surface (поверхность с учетом покровного оледенения) и Bedrock (подстилающая поверхность). Если вычесть из первой вторую, можно узнать толщину льда в Гренландии и на Антарктиде: bed = raster(&#39;data/world/etopo1_bed.tif&#39;) ice = raster(&#39;data/world/etopo1_ice.tif&#39;) ice.depth = ice - bed plot(ice.depth, col = cm.colors(255)) plot(outlines, border = &#39;black&#39;, lwd = 0.5, add = TRUE) Чтобы маскировать значения растра, необходимо воспользоваться функцией values(), которая обнажает список значений растра. Например, можно превратить в NA все пикселы, в которых толщина льда меньше или равна нулю: ice.depth[ice.depth &lt;= 0] = NA plot(ice.depth, col = cm.colors(255)) plot(outlines, border = &#39;black&#39;, lwd = 0.5, add = TRUE) 9.5.5 Экспорт Чтобы экспортировать (сохранить в файл) любой растр, можно воспользоваться функцией writeRaster(), указав имя выходного файла: writeRaster(ice.depth, &#39;data/world/ice_depth.tif&#39;) 9.6 Визуализация средствами ggplot2 Пространственные данные поддерживаются в графической подсистеме ggplot2. Для этого существует несколько специализированных функций: geom_sf() вызывает stat_sf() и coord_sf() того чтобы отобразить пространственные данные в нужной системе координат; coord_sf() обеспечивает поддержку картографических проекций и позволяет отображать данные в нужной системе координат на лету; stat_sf() отвечает за отображение переменных данных на графические переменные для пространственных данных; geom_sf_label() позволяет отображать подписи объектов на плашке; geom_sf_text() позволяет размещзать подписи объектов без плашки. Отобразим для примера границы России в конической проекции: russia = dplyr::filter(countries, adm0_a3 == &#39;RUS&#39;) ggplot(russia) + geom_sf() + geom_sf_label(aes(label = name)) + coord_sf(crs = &#39;+proj=eqdc +lon_0=100 +lat_1=42 +lat_2=60 +datum=WGS84 +units=m&#39;) + scale_x_continuous(breaks = seq(-30, 180, by = 30)) Так же как ив случае стандартной подсистемы, можно указать атрибутивное поле, по которому будет строиться тематическая карта. Покажем это на примере выгруженных ранее Европейских стран: brks = seq(0, 100, 10) nbrks = length(brks) ggplot(europe.conic) + geom_sf(aes(fill = 1000 * gdp_md_est/pop_est)) + scale_fill_gradientn( colours = RColorBrewer::brewer.pal(10, &#39;RdYlGn&#39;), breaks = brks, labels = paste(c(0, brks[-nbrks]), &#39;-&#39;, brks), guide = guide_legend(keyheight = unit(0.5, &quot;cm&quot;), reverse = TRUE) ) + labs(title = &#39;Валовый внутренний продукт&#39;, fill = &#39;\\n$ тыс/чел.&#39; ) 9.7 Интерактивные карты R предоставляет возможности для интерактивного просмотра пространственных данных средствами библиотек веб-картографирования. В данном разделе мы кратко познакомимся с возможностями пакета mapview, который использует возможности библиотеки Leaflet. Функции данного пакета не предназначены для создания тематических карт высокого качества и рассчитаны на выполнение исследовательского анализа данных. Чтобы отобразить векторный или растровый слой средствами mapview, достаточно вызвать одноименную функцию данного пакета: mapview(sf_stations) Чтобы скомбинировать несколько слоев, необходимо сложить несколько вызовов mapview(): mapview(countries, col.regions = &#39;white&#39;) + mapview(sf_stations, col.regions = &#39;red&#39;) 9.8 Контрольные вопросы и упражнения 9.8.1 Вопросы Что такое пространственные данные и какие модели пространственных данных существуют? Назовите номер стандарта ISO, в котором описана модель Simple Features. Перечислите основные принципы представления объектов в рамках стандарта Simple Features. Какие размерности координат допустимы в объектах Simple Features? Перечислите основные 7 типов геометрий. Сколько всего их описано в стандарте Simple Features? Как называются основные два формата представления объектов Simple Features? Перечислите основные компоненты пространственной привязки. Перечислите основные форматы описания пространственной привязки. Дайте расшифровку основных параметров строки PROJ.4. Какой номер EPSG имеет географическая система координат WGS84? В чем отличие трансформирования координат и проецирования? Какие три программных библиотеки составляют основу функциональности пакета sf? Каково их назначение? В чем отличие объектов типа sp от sf? Что означает префикс st_, используемый в названиях функций пакета sf? Какая функция используется для чтения данных средствами пакета sf? Перечислите три класса, слагающих иерархию представления пространственных объектов, реализуемую пакетом sf. Какой тип данных имеет колонка с геометрией объекта sf? Какая функция позволяет извлечь геометрическую колонку из объекта sf? С помощью какой структуры данных фактически реализован класс объектов sfg? Сколько карт будет построено функцией plot() применительно к объекту sf? Как с помощью функции plot() нарисовать только геометрию объектов, не отображая атрибутивные характеристики? Какой параметр функции plot() отвечает за отображение/не отображение градусной сетки координат? Каким способом можно узнать и задать систему координат объекта sf? Какая функция позволяет осуществить проецирование данных? Можно ли применять к объектам типа sf стандартные манипуляции dplyr? Что произойдет с геометрией пространственных объектов при выполнении агрегирования данных по группам значений заданных атрибутов? Перечислите 8 вариантов топологических отношений и названий функций sf, которые им соответствуют. Опишите способ, с помощью которого можно выбрать пространственные объекты, пересекающиеся с заданным множеством пространственных объектов. Каким образом можно заменить тип топологического отношения с пересечения на любой другой при выполнении пространственной выборки? Перечислите функции, с помощью которых создаются объекты типа sfg, и структуры данных с координатами, которые должны быть поданы на вход этих функций. Назовите три правила, которым подчиняется формат представления координат вершин полигональных объектов. Может ли обычный полигон sf содержать дырку, или же для этого требуется создание мультиполигона? Как можно быстро собрать слой точечных объектов по их координатам, не собирая объекты вручную? Какая функция позволяет осуществлять преобразование типа геометрии sf? Перечислите требования, которым должно удовлетворять множество линейных объектов для того, чтобы к нему была применима операция полигонизации? Назовите функции sf, реализующие операцию добавления вершин в точках пересечения линий и операцию полигонизации линий. Перечислите названия функций sf, позволяющих получать ограничивающий прямоугольник, периметр, площадь, центроид, характерную точку и координаты объекта. С помощью какой функции осуществляется запись (экспорт) sf в файлы пространственных данных? Назовите основные параметры, определяющие геометрию растра. Какой пакет отвечает за поддержку растровых данных в R? Как можно прочитать одноканальный и многоканальный растры в R? В чем отличие этих случаев? Какие функции можно использовать для визуализации одноканальных и многоканальных растров? Можно ли совмещать растровые и векторные слои на одном изображении? Если да, то как эта возможность реализуется? Каким образом можно узнать и задать пространственную привязку растрового набора данных? Какая функция отвечает за проецирование растровых данных? Перечислите ее параметры и их назначение. Опишите способ, с помощью которого можно осуществить фильтрацию растра (превратить его в растр TRUE/FALSE) и маскирование растра (заменить ненужные ячейки на NA). С помощью какой функции пакета raster можно осуществить экспорт растра в файл? Назовите пакет (и одноименную функцию), с помощью которых можно быстро осуществлять интерактивный просмотр пространственных данных. 9.8.2 Упражнения Преобразуйте точки землетрясений из набора данных quakes в пространственные объекты и отобразите и на интерактивной карте средствами пакета mapview. Передайте магнитуду землетрясения в параметр zcol функции mapview(), чтобы дифференцировать точки цветом по этому параметру. Таблица storms из пакета dplyr содержит данные трекинга тропических циклонов c 1975 по 2015 год. Выберите любой циклон и постройте для него линию трека прохождения и точки прохождения. Отобразите эти данные на интерактивной карте средствами mapview. Напишите программу таким образом, чтобы можно было выбирать имя циклона и программа отображала его трек на интерактивной карте. Самсонов Т.Е. Визуализация и анализ географических данных на языке R. М.: Географический факультет МГУ, lubridate::year(Sys.Date()). DOI: 10.5281/zenodo.901911 ГОСТ Р 52438-2005 &lt;&lt;Географические информационные системы. Термины и определения&gt;&gt;. В стандарте поясняется, что объектом может быть неподвижный или движущийся простой или сложный объект, явление, событие, процесс и ситуация. Моделируемый объект может относиться к территории, акватории, недрам и воздушному пространству Земли, околоземному космическому пространству, другим космическим телам и небесной сфере. В широком смысле под пространственным объектом в геоинформатике понимается как сам объект, так и адекватная ему цифровая модель↩︎ Названия перечисленных компонент геометрии растра укоренились благодаря распространенности стандарта Esri ASCII Grid↩︎ Например, в широко распространенном формате Esri Shapefile атрибутивная таблица хранится в файле *.dbf формата DBASE, геометрия хранится в отдельном файле *.shp, а связь между ними осуществляется через файл *.shx. Разбиение формата хранения на несколько файлов — это одна из уязвимостей шейп-файлов: при отсутствии хотя бы одного из этих файлов данные прочесть стандартными средствами (без дополнительного хакинга) будет нельзя.↩︎ В настоящий момент ведется разработка нового пакета ____, который рассматривается как замена пакету raster и будет поддерживать большие массивы многовременных растровых данных, однако пока что пакет не доступен для использования.↩︎ "],
["thematic-mapping-new.html", "Глава 10 Тематические карты Предварительные условия 10.1 Введение 10.2 Способы изображения 10.3 Цветовые шкалы 10.4 Классификация 10.5 Компоновка 10.6 Фасеты и серии карт 10.7 Картографические анимации 10.8 Интерактивные карты 10.9 Контрольные вопросы и упражнения", " Глава 10 Тематические карты Предварительные условия Для выполнения кода данной лекции вам понадобятся следующие пакеты: library(sf) library(tmap) library(readxl) library(raster) library(mapview) library(classInt) library(gapminder) library(tidyverse) library(googlesheets) library(rnaturalearth) 10.1 Введение Тематические карты представляют собой важный инструмент географических исследований. Таблицы и графики не дают полного представления о пространственном распределении изучаемого явления. Это знание способна дать исследователю карта. Разнообразие типов и видов карт достаточно велико. Комплексные картографические произведения, содержащие многослойный набор объектов, создаются, как правило, средствами геоинформационных пакетов. Такие карты требуют тщательной и кропотливой работы с легендой, устранения графических конфликтов между знаками, многократного редактирования входных данных, условий, фильтров и способов изображения в попытке достичь эстетичного и вместе с тем информативного результата. В то же время, гораздо большее количество создаваемых в повседневной практике карт носят простой аналитический характер. Такие карты показывают одно, максимум два явления, и могут иллюстрировать входные данные, результаты промежуточных или итоговых расчетов. Создание именно таких карт целесообразно автоматизировать средствами программирования. В этом разделе мы познакомимся с созданием тематических карт средствами пакета tmap. В качестве источника открытых данных мы будем использовать Natural Earth и WorldClim. 10.1.1 Данные Natural Earth Natural Earth — это открытые мелкомасштабные картографические данные высокого качества. Данные доступны для трех масштабов: 1:10М, 1:50М и 1:110М. Для доступа к этим данным из среды R без загрузки исходных файлов можно использовать пакет rnaturalearth. Пакет позволяет выгружать данные из внешнего репозитория, а также содержит три предзакачанных слоя: ne_countries() границы стран ne_states() границы единиц АТД 1 порядка ne_coastline() береговая линия Для загрузки других слоев необходимо использовать функцию ne_download(), передав ей масштаб, название слоя и его категорию: countries = ne_countries() %&gt;% st_as_sf() coast = ne_coastline() %&gt;% st_as_sf() ocean = ne_download(scale = 110, type = &#39;ocean&#39;, category = &#39;physical&#39;) %&gt;% st_as_sf() ## OGR data source with driver: ESRI Shapefile ## Source: &quot;/private/var/folders/5s/rkxr4m8j24569d_p6nj9ld200000gn/T/Rtmpogv0WH&quot;, layer: &quot;ne_110m_ocean&quot; ## with 2 features ## It has 3 fields cities = ne_download(scale = 110, type = &#39;populated_places&#39;, category = &#39;cultural&#39;) %&gt;% st_as_sf() ## OGR data source with driver: ESRI Shapefile ## Source: &quot;/private/var/folders/5s/rkxr4m8j24569d_p6nj9ld200000gn/T/Rtmpogv0WH&quot;, layer: &quot;ne_110m_populated_places&quot; ## with 243 features ## It has 119 fields ## Integer64 fields read as strings: wof_id ne_id rivers = ne_download(scale = 110, type = &#39;rivers_lake_centerlines&#39;, category = &#39;physical&#39;) %&gt;% st_as_sf() ## OGR data source with driver: ESRI Shapefile ## Source: &quot;/private/var/folders/5s/rkxr4m8j24569d_p6nj9ld200000gn/T/Rtmpogv0WH&quot;, layer: &quot;ne_110m_rivers_lake_centerlines&quot; ## with 13 features ## It has 31 fields ## Integer64 fields read as strings: scalerank ne_id Познакомимся с загруженными данными: plot(ocean %&gt;% st_geometry(), col = &#39;lightblue&#39;) plot(countries, col = &#39;white&#39;, border = &#39;grey&#39;, add = TRUE) plot(coast, add = TRUE, col = &#39;steelblue&#39;) plot(rivers, add = TRUE, col = &#39;steelblue&#39;) plot(cities, add = TRUE, col = &#39;black&#39;, pch = 19, cex = 0.2) Перед построением карт мира данные целесообразно спроецировать. Чтобы не трансформировать каждый слой отдельно, можно объединить слои в список и воспользоваться функционалом lapply для множественного трансформирования. Для создания списка воспользуемся функцией lst() из пакета tibble, которая присваивает компонентам списка имена, соответствующие названиям входных переменных (чтобы не писать ocean = ocean): lyr = tibble::lst(ocean, coast, countries, rivers, cities) lyrp = lapply(lyr, st_transform, crs = &quot;+proj=eck3&quot;) # Псевдоцилиндрическая проекция Эккерта plot(lyrp$countries %&gt;% st_geometry(), col = &#39;white&#39;, border = &#39;grey&#39;, lwd = 0.5) plot(lyrp$ocean , col = &#39;lightblue&#39;, lwd = 0.5, border = &#39;steelblue&#39;, add = TRUE) plot(lyrp$rivers, add = TRUE, lwd = 0.5, col = &#39;steelblue&#39;) plot(lyrp$cities, add = TRUE, col = &#39;black&#39;, pch = 19, cex = 0.1) 10.1.2 Данные WorldClim WorldClim — это открытые сеточные наборы климатических характеристик с пространственным разрешением от \\(30&#39;&#39;\\) (около 1 км) до \\(10&#39;\\) (около 20 км). Данные можно выгрузить в виде файлов GeoTiff, однако эту операцию можно сделать и программным путем через пакет raster — используя функцию getData(). Выполним загрузку 10-минутного растра с суммарным количеством осадков за год: prec = raster::getData(&quot;worldclim&quot;, var = &quot;prec&quot;, res = 10) plot(prec, nc = 2) # это 12-канальный растр Использовать программную загрузку целесообразно для небольших наборов данных. Если счет пошел на десятки мегабайт и выше, следует все-таки выкачать данные в виде файла и работать с ним. Выполним трансформирование данных в проекцию Миллера. Для того чтобы карта не обрезалась по охвату растра (он не включает данные на Антарктиду), необходимо расширить его охват на весь земной шар. Для этого используем функцию extend() из пакета raster: precm = prec %&gt;% extend(extent(-180, 180, -90, 90)) %&gt;% projectRaster(crs = &quot;+proj=mill&quot;) lyrm = lapply(lyr, st_transform, crs = &quot;+proj=mill&quot;) # Цилиндрическая проекция Миллера Визуализируем полученные данные на карте: ramp = colorRampPalette(c(&quot;white&quot;, &quot;violetred&quot;)) # Визуализируем данные на январь: plot(precm, 1, col = ramp(10), colNA = &#39;grey&#39;, main = &#39;Количество осадков в январе, мм&#39;, box = FALSE, axes = FALSE) plot(lyrm$ocean, border = &#39;steelblue&#39;, col = &#39;lightblue&#39;, add = TRUE) 10.2 Способы изображения В этом разделе изложение сосредоточено на параметрах способов изображения. Приведение легенд и компоновки карты в аккуратный вид рассматривается далее в разделе Компоновка. Пакет tmap предоставляет простой в использовании и достаточно мощный механизм формирования тематических карт. Шаблон построения карты в этом пакете напоминает ggplot и выглядит следующим образом: tm_shape(&lt;DATA&gt;) + tm_&lt;METHOD&gt;(&lt;PARAMETERS&gt;) где: DATA - объект пространственного типа (sf, sp, stars или raster) METHOD - метод визуализации этого объекта (способ изображения) PARAMETERS - параметры метода 10.2.1 Векторные данные Для реализации качественного и количественного фона, а также картограмм используется метод tm_polygons(). Он автоматически определяет тип переменной и строит соответствующую шкалу: tm_shape(lyrp$countries) + tm_polygons(&#39;economy&#39;) + # качественная переменная tm_shape(lyrp$ocean)+ tm_fill(col = &#39;azure&#39;) + tm_borders(col = &#39;steelblue&#39;) Количественный фон или картограммы получаются при картографировании числового показателя применением той же функции tm_polygons(): (&#39;1H3nzTwbn8z4lJ5gJ_WfDgCeGEXK3PVGcNjQ_U5og8eo&#39; %&gt;% # продолжительность жизни gs_key(lookup = FALSE) %&gt;% # не используем авторизацию gs_read(ws = 1) %&gt;% rename(name = 1) %&gt;% gather(year, lifexp, -name) %&gt;% filter(year == 2016) %&gt;% left_join(read_excel(&#39;data/gapminder.xlsx&#39;, 2)) %&gt;% mutate(geo = stringr::str_to_upper(geo)) -&gt; lifedf) # выгружаем данные по продолжительности и сохраняем в переменную lifedf ## # A tibble: 260 x 13 ## name year lifexp geo four_regions eight_regions six_regions ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Abkh… 2016 NA &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 2 Afgh… 2016 52.7 AFG asia asia_west south_asia ## 3 Akro… 2016 NA &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 4 Alba… 2016 78.1 ALB europe europe_east europe_cen… ## 5 Alge… 2016 76.5 DZA africa africa_north middle_eas… ## 6 Amer… 2016 73 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 7 Ando… 2016 84.8 AND europe europe_west europe_cen… ## 8 Ango… 2016 60 AGO africa africa_sub_s… sub_sahara… ## 9 Angu… 2016 NA &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 10 Anti… 2016 76.5 ATG americas america_north america ## # … with 250 more rows, and 6 more variables: members_oecd_g77 &lt;chr&gt;, ## # Latitude &lt;dbl&gt;, Longitude &lt;dbl&gt;, `UN member since` &lt;dttm&gt;, `World bank ## # region` &lt;chr&gt;, `World bank income group 2017` &lt;chr&gt; coun = lyrp$countries %&gt;% left_join(lifedf, by = c(&#39;adm0_a3&#39; = &#39;geo&#39;)) tm_shape(coun) + tm_polygons(&#39;lifexp&#39;, border.col = &#39;gray20&#39;) + # количественная переменная tm_shape(lyrp$ocean) + tm_fill(col = &#39;azure&#39;) + tm_borders(col = &#39;steelblue4&#39;) Для реализации способа картодиаграмм используется геометрия tm_bubbles(). Чтобы оставить отображение границ полигонов, нам необходимо к одной геометрии применить несколько способов изображения: tm_shape(coun) + tm_fill(col = &#39;white&#39;) + tm_borders(col = &#39;grey&#39;) + tm_bubbles(&#39;gdp_md_est&#39;, scale = 3, col = &#39;red&#39;, alpha = 0.5) + # количественная переменная tm_shape(lyrp$ocean) + tm_fill(col = &#39;lightblue&#39;) + tm_borders(col = &#39;steelblue&#39;) Аналогичным образом реализуется значковый способ применительно к объектам, локализованным по точкам. Картографируем численность населения по крупнейшим городам: tm_shape(lyrp$countries) + tm_fill(col = &#39;white&#39;) + tm_borders(col = &#39;grey&#39;) + tm_shape(lyrp$ocean) + tm_fill(col = &#39;lightblue&#39;) + tm_borders(col = &#39;steelblue&#39;) + tm_shape(lyrp$cities) + tm_bubbles(&#39;POP2015&#39;, col = &#39;olivedrab&#39;, alpha = 0.8) Надписи объектов на карте размещаются с помощью функции tm_text. Данная функция содержит весьма полезные параметры remove.overlap и auto.placement, которые позволяют убрать перекрывающиеся подписи и автоматически разместить из вокруг точек так, чтобы уменьшить перекрытия с самими знаками и другими подписями. Дополним предыдущую карту названиями городов: tm_shape(lyrp$countries) + tm_fill(col = &#39;white&#39;) + tm_borders(col = &#39;grey&#39;) + tm_shape(lyrp$ocean) + tm_fill(col = &#39;lightblue&#39;) + tm_borders(col = &#39;steelblue&#39;) + tm_shape(lyrp$cities) + tm_bubbles(&#39;POP2015&#39;, col = &#39;olivedrab&#39;, alpha = 0.8) + tm_text(&#39;name_ru&#39;, size = 0.5, remove.overlap = TRUE, auto.placement = TRUE) 10.2.2 Растровые данные При отображении растровых данных используется способ отображения tm_raster(). В случае отображения количественных растров Параметр breaks определяет границы интервалов, для которых будут использованы цвета, взятые из параметра palette: tm_shape(precm) + tm_raster(&#39;prec1&#39;, breaks = c(10, 50, 100, 200, 500, 1000), palette = ramp(5)) + tm_shape(lyrm$ocean) + tm_fill(col = &#39;lightblue&#39;) + tm_borders(col = &#39;steelblue&#39;) Растровые данные могут хранить и качественную информацию: например, тип почв или вид землепользования. В качестве примера визуализируем типы земельного покрова (land cover) из растрового стека land, который есть в пакете tmap. Цвета здесь выбираются автоматически, их настройка рассматривается в следующем параграфе: data(land, package = &#39;tmap&#39;) tm_shape(land) + tm_raster(&#39;cover&#39;) 10.3 Цветовые шкалы Для изменения цветовой шкалы при определении способа изображения вы можете определить параметр palette. Пакет tmap позволяет работать с цветовыми палитрами Color Brewer или задавать цвета вручную. Очень удобным инструментом подбора шкалы является функция palette_explorer() из пакета tmaptools. При вызове функции открывается интерактивное приложение, позволяющее менять настройки цветовых палитр: tmaptools::palette_explorer() Приложение Palette Explorer из пакета tmaptools Данных палитр хватит для решения большинства задач по картографической визуализации. Применим категориальную палитру Dark2: tm_shape(lyrp$countries) + tm_polygons(&#39;economy&#39;, palette = &#39;Dark2&#39;) + # качественная переменная tm_shape(lyrp$ocean)+ tm_fill(col = &#39;azure&#39;) + tm_borders(col = &#39;steelblue&#39;) Для количественного показателя (количество осадков) применим палитру PuBuGn: tm_shape(precm) + tm_raster(&#39;prec1&#39;, breaks = c(10, 50, 100, 200, 500, 1000), palette = &#39;PuBuGn&#39;) + tm_shape(lyrm$ocean) + tm_fill(col = &#39;lightblue&#39;) + tm_borders(col = &#39;steelblue&#39;) Вы всегда можете, конечно, определить цвета вручную. В этом случае их количество должно совпадать с количеством интервалов классификации: tm_shape(precm) + tm_raster(&#39;prec1&#39;, breaks = c(10, 50, 100, 200, 500, 1000), palette = c(&#39;white&#39;, &#39;gray80&#39;, &#39;gray60&#39;, &#39;gray40&#39;, &#39;gray20&#39;)) + tm_shape(lyrm$ocean) + tm_fill(col = &#39;lightblue&#39;) + tm_borders(col = &#39;steelblue&#39;) Для категориальных данных необходимо тщательно подбирать цвета, стандартные шкалы тут могут не подойти (более подробно о шкалах — далее). Для вышеприведенного примера с растром типов земельного покрова можно подобрать следующие цвета: pal = c(&quot;#003200&quot;, &quot;#3C9600&quot;, &quot;#006E00&quot;, &quot;#556E19&quot;, &quot;#00C800&quot;, &quot;#8CBE8C&quot;, &quot;#467864&quot;, &quot;#B4E664&quot;, &quot;#9BC832&quot;, &quot;#EBFF64&quot;, &quot;#F06432&quot;, &quot;#9132E6&quot;, &quot;#E664E6&quot;, &quot;#9B82E6&quot;, &quot;#B4FEF0&quot;, &quot;#646464&quot;, &quot;#C8C8C8&quot;, &quot;#FF0000&quot;, &quot;#FFFFFF&quot;, &quot;#5ADCDC&quot;) tm_shape(land) + tm_raster(&#39;cover&#39;, palette = pal) 10.4 Классификация 10.4.1 Методы классификации Классификация данных — важнейший этап картографирования, который во многом определяет, как данные будут представлены на карте и какие географические выводы читатель сделает на ее основе. Существует множество методов классификации числовых рядов. Классифицировать данные автоматически можно с помощью функции classIntervals() из пакета classInt. Наберите в консоли ?classInt чтобы прочитать справку о методах классификации. Посмотрим несколько методов классификации. Первый параметр функции classInt — это числовой ряд. Число классов следует передать в параметр n =, метод классификации указывается в параметре style =. Для начала попробуем метод равных интервалов, который просто делит размах вариации (диапазон от минимума до максимум) на \\(n\\) равных интервалов. Функция plot() применительно к созданной классификации рисует замечательный график, на котором показаны границы классов и эмпирическая функция распределения показателя. В параметр pal можно передать цветовую палитру: # Запишем число классов в переменную nclasses = 5 intervals = classIntervals(coun$lifexp, n = nclasses, style = &quot;equal&quot;) # извлечь полученные границы можно через $brks intervals$brks ## [1] 48.860 55.748 62.636 69.524 76.412 83.300 plot(intervals, pal = ramp(nclasses), cex=0.5, main = &quot;Равные интервалы MIN/MAX&quot;) Созданные интервалы хоть и равны, но не аккуратны. Зато метод классификации \"pretty\" создает также равные интервалы, но может слегка расширить диапазон или добавить 1 класс, чтобы получить границы интервалов, округленные до целых чисел: intervals = classIntervals(coun$lifexp, n = nclasses, style = &quot;pretty&quot;) intervals$brks ## [1] 45 50 55 60 65 70 75 80 85 plot(intervals, pal = ramp(nclasses), cex=0.5, main = &quot;Округленные равные интервалы&quot;) Квантили — равноколичественные интервалы. В каждом классе содержится одинаковое число объектов: intervals = classIntervals(coun$lifexp, n = nclasses, style = &quot;quantile&quot;) intervals$brks ## [1] 48.860 64.488 71.300 75.440 79.360 83.300 plot(intervals, pal = ramp(nclasses), cex=0.5, main = &quot;Квантили (равноколичественные)&quot;) Метод “естественных интервалов”, или метод Фишера-Дженкса позволяет найти классы, максимально однородные внутри и при этом максимально отличающиеся друг от друга: intervals = classIntervals(coun$lifexp, n = nclasses, style = &quot;jenks&quot;) intervals$brks ## [1] 48.86 55.90 63.70 70.40 77.10 83.30 plot(intervals, pal = ramp(nclasses), cex=0.5, main = &quot;Естественные интервалы&quot;) 10.4.2 Применение на картах Чтобы использовать заранее вычисленные интервалы классификации, их необходимо подать в параметр breaks при построении карты: brks = classIntervals(coun$lifexp, n = 4, style = &quot;pretty&quot;)$brks tm_shape(coun) + tm_polygons(&#39;lifexp&#39;, border.col = &#39;gray20&#39;, palette = &#39;YlGn&#39;, breaks = brks) + # количественная переменная tm_shape(lyrp$ocean) + tm_fill(col = &#39;azure&#39;) + tm_borders(col = &#39;steelblue4&#39;) Аналогичным путем работают шкалы для растровых данных: tm_shape(precm) + tm_raster(&#39;prec1&#39;, breaks = classIntervals(values(precm), n = 5, style = &quot;quantile&quot;)$brks, palette = &#39;PuBuGn&#39;) + tm_shape(lyrm$ocean) + tm_fill(col = &#39;lightblue&#39;) + tm_borders(col = &#39;steelblue&#39;) Учтите, что метод естественных интервалов — ресурсоемкий в вычислительном плане. Поэтому если вы хотите с его помощью классифицировать растровые данные, целесообразно сделать выборку не более чем из нескольких тысяч пикселов. Иначе придется долго ждать. Для классификации естественными интервалами сделаем выборку в 2 000 значений с растра c помощью функции sampleRandom() из пакета raster: smpl = sampleRandom(precm$prec1, size = 2000) tm_shape(precm) + tm_raster(&#39;prec1&#39;, breaks = classIntervals(smpl, n = 5, style = &quot;jenks&quot;)$brks, palette = &#39;PuBuGn&#39;) + tm_shape(lyrm$ocean) + tm_fill(col = &#39;lightblue&#39;) + tm_borders(col = &#39;steelblue&#39;) 10.4.3 Классификация при отображении Пакет tmap позволяет выполнять классификацию данных непосредственно при отображении. Это бывает удобно, когда одну и ту же классификацию не надо использовать несколько раз, и когда нет необходимости делать выборку значений (как в случае метода естественных интервалов). Для этого функции способов изображения предлагают несколько параметров: n — количество классов style — метод классификации (так же как и в classIntervals()) breaks — значения границ интервалов (необходимы, если style == fixed) interval.closure — замыкание интервала (по умолчанию стоит left, что означает, что в интервал включается нижняя граница, за исключением последнего интервала, включающего и нижнюю и верхнюю границу) midpoint — нейтральное значение, которое используется для сопоставления с центральным цветом в расходящихся цветовых палитрах Построим карту продолжительности жизни, используя классификацию при отображении: tm_shape(coun) + tm_polygons(&#39;lifexp&#39;, palette = &#39;YlGn&#39;, n = 5, style = &#39;fisher&#39;, border.col = &#39;gray20&#39;) + # количественная переменная tm_shape(lyrp$ocean) + tm_fill(col = &#39;azure&#39;) + tm_borders(col = &#39;steelblue4&#39;) Установка средней точки при классификации оказывается очень полезной в тех случаях, когда данные являются биполярными. Покажем это на примере данных WorldClim по температуре: temp = raster::getData(&quot;worldclim&quot;, var = &quot;tmean&quot;, res = 10) %&gt;% extend(extent(-180, 180, -90, 90)) %&gt;% projectRaster(crs = &quot;+proj=mill&quot;) / 10 # не забываем поделить результат на 10, # так как данные хранятся в виде целых чисел! Визуализируем данные по температуре, используя классическую красно-бело-синюю палитру RdBu и нейтральную точку 0 градусов по Цельсию. По умолчанию в данной палитре красный цвет соответствует малым значениям. пакет tmap позволяет инвертировать цвета палитры, добавив знак минус перед ее названием. Помимо этого, для размещения положительных значений наверху выполним обратную сортировку элементов легенды, используя параметр legend.reverse = TRUE: tm_shape(temp) + tm_raster(&#39;tmean1&#39;, n = 11, midpoint = 0, style = &#39;pretty&#39;, legend.reverse = TRUE, palette = &#39;-RdBu&#39;) + tm_shape(lyrm$ocean) + tm_fill(col = &#39;azure&#39;) + tm_borders(col = &#39;steelblue&#39;) 10.4.4 Пропущенные данные Весьма важно отметить на карте области, для которых данные отсутствуют. Вы могли обратить внимание, что для способов изображения, применимых к векторным данным, tmap автоматически добавляет класс легенды, который отвечает за пропуски. Для растров, однако, он это не делает. Чтобы принудительно вывести в легенду и на карту символ, отвечающий за пропущенные значения, необходимо определить параметр colorNA. Обычно, в зависимости от цветовой палитры легенды, для этого используют серый или белый цвет: tm_shape(temp) + tm_raster(&#39;tmean1&#39;, colorNA = &#39;grey&#39;, # определяем цвет для пропущенных значений n = 11, midpoint = 0, style = &#39;pretty&#39;, legend.reverse = TRUE, palette = &#39;-RdBu&#39;) + tm_shape(lyrm$ocean) + tm_fill(col = &#39;azure&#39;) + tm_borders(col = &#39;steelblue&#39;) 10.5 Компоновка Пакет tmap предоставляет широкий набор настроек компоновки картографического изображения, который включает настройку легенды, заголовка карты и ряда других важных параметров. Большинство настроек компоновки осуществляется через функцию tm_layout(), однако часть из них, специфичная для конкретного слоя, определяется непосредственно при настройке способа изображения. В примере ниже показано, как: добавить заголовок карты (main.title), разместить легенду в нижнем левом углу (legend.position = c('left', 'bottom')) поместить ее легенду в полупрозрачный прямоугольник (параметры legend&lt;...&gt;), убрать заголовок легенды (title), заменить стандартный шрифт на Open Sans (fontfamily): tm_shape(lyrp$countries) + tm_polygons(&#39;economy&#39;, title = &#39;&#39;) + # убираем заголовок легенды tm_shape(lyrp$ocean)+ tm_fill(col = &#39;azure&#39;) + tm_borders(col = &#39;steelblue&#39;) + tm_layout(legend.position = c(&#39;left&#39;, &#39;bottom&#39;), fontfamily = &#39;Open Sans&#39;, # шрифт main.title.size = 1.2, # масштаб шрифта в заголовке main.title = &#39;Тип экономики&#39;, # заголовок legend.frame = TRUE, # рамка вокруг легенды legend.frame.lwd = 0.2, # толщина рамки вокруг легенды legend.bg.alpha = 0.8, # прозрачность фона в легенде legend.bg.color = &#39;white&#39;) # цвет фона легенды Для того чтобы определить заголовок легенды размера значка или диаграммы, необходимо задать параметр title.size. Помимо этого, легенду можно пристыковать непосредственно к рамке карты, если задать значения параметра legend.position в верхнем регистре: tm_shape(coun) + tm_fill(col = &#39;white&#39;) + tm_borders(col = &#39;grey&#39;) + tm_bubbles(&#39;gdp_md_est&#39;, scale = 2.5, col = &#39;red&#39;, alpha = 0.5, title.size = &#39;$ млн&#39;) + # количественная переменная tm_shape(lyrp$ocean) + tm_fill(col = &#39;lightblue&#39;) + tm_borders(col = &#39;steelblue&#39;) + tm_layout(legend.position = c(&#39;LEFT&#39;, &#39;BOTTOM&#39;), # верхний регистр — легенда встык fontfamily = &#39;Open Sans&#39;, # шрифт main.title.size = 1.2, # масштаб шрифта в заголовке main.title = &#39;Валовый внутренний продукт стран мира&#39;, # заголовок frame.lwd = 2, legend.frame = TRUE, # рамка вокруг легенды legend.frame.lwd = 0.5, # толщина рамки вокруг легенды legend.bg.color = &#39;white&#39;) # цвет фона легенды По умолчанию tmap размещает легенду внутри фрейма картографического изображения. Однако ее можно вынести и наружу, используя параметр legend.outside функции tm_layout(). В примере ниже показано также, как можно задать текст легенды для отсутствующих данных (textNA), отформатировать разделитель в легенде с интервалами значений (legend.format), убрать рамку карты (frame), сдвинуть заголовок вдоль строки, выровняв его с центром карты (main.title.position): tm_shape(coun) + tm_polygons(&#39;lifexp&#39;, border.col = &#39;gray20&#39;, palette = &#39;YlGn&#39;, n = 4, style = &#39;jenks&#39;, title = &#39;Лет&#39;, colorNA = &#39;lightgray&#39;, textNA = &#39;Нет данных&#39;, legend.format = list(text.separator = &#39;—&#39;)) + # количественная переменная tm_shape(lyrp$ocean) + tm_fill(col = &#39;azure&#39;) + tm_borders(col = &#39;steelblue4&#39;) + tm_layout(frame = FALSE, main.title.position = 0.15, legend.outside = TRUE, legend.outside.position = &#39;right&#39;, fontfamily = &#39;Open Sans&#39;, main.title.size = 1.2, main.title = &#39;Продолжительность жизни&#39;, legend.bg.color = &#39;white&#39;) Для отображения координатной сетки вы можете использовать функцию tm_grid(). По умолчанию она строит координатную сетку в единицах измерения проекции. Однако если требуется градусная сетка, то ее можно определить, используя параметр projection = \"longlat\": tm_shape(temp) + tm_raster(&#39;tmean1&#39;, title = &#39;°C&#39;, colorNA = &#39;grey&#39;, # определяем цвет для пропущенных значений textNA = &#39;Нет данных&#39;, legend.format = list(text.separator = &#39;—&#39;), n = 11, midpoint = 0, style = &#39;pretty&#39;, legend.reverse = TRUE, palette = &#39;-RdBu&#39;) + tm_shape(lyrm$ocean) + tm_fill(col = &#39;azure&#39;) + tm_borders(col = &#39;steelblue&#39;) + tm_layout(legend.position = c(&#39;left&#39;, &#39;bottom&#39;), fontfamily = &#39;Open Sans&#39;, main.title.size = 1.2, main.title = &#39;Средняя температура января&#39;, legend.frame = TRUE, legend.frame.lwd = 0.2, legend.bg.alpha = 0.5, legend.bg.color = &#39;white&#39;) + tm_grid(x = seq(-180, 180, by = 30), y = seq(-90, 90, by = 30), lwd = 0.2, col = &quot;black&quot;, projection = &quot;longlat&quot;, labels.inside.frame = FALSE) Если вам необходимо обеспечить значки градуса, вы можете сделать это, используя параметр labels.format, определив в нем анонимную функцию, добавляющую значок градуса в переданный ей вектор подписей. Помимо этого, вам может понадобиться увеличить поля вокруг карты, чтобы освободить пространство для размещения меток (на предыдущей карте они не влезли). Это делается через параметр outer.margins, который ожидает получить вектор из четырех значений (по умолчанию все они равны 0.02, т.е. 2% от размера окна). tm_shape(temp) + tm_raster(&#39;tmean1&#39;, title = &#39;°C&#39;, colorNA = &#39;grey&#39;, # определяем цвет для пропущенных значений textNA = &#39;Нет данных&#39;, legend.format = list(text.separator = &#39;—&#39;), n = 11, midpoint = 0, style = &#39;pretty&#39;, legend.reverse = TRUE, palette = &#39;-RdBu&#39;) + tm_shape(lyrm$ocean) + tm_fill(col = &#39;azure&#39;) + tm_borders(col = &#39;steelblue&#39;) + tm_layout(legend.position = c(&#39;LEFT&#39;, &#39;BOTTOM&#39;), fontfamily = &#39;Open Sans&#39;, main.title.size = 1.2, main.title = &#39;Средняя температура января&#39;, legend.frame = TRUE, legend.frame.lwd = 0.2, legend.bg.alpha = 0.8, legend.bg.color = &#39;white&#39;, outer.margins = c(0.05, 0.02, 0.02, 0.02), inner.margins = c(0, 0, 0, 0)) + tm_grid(x = seq(-180, 180, by = 30), y = seq(-90, 90, by = 30), lwd = 0.2, col = &quot;black&quot;, projection = &quot;longlat&quot;, labels.inside.frame = FALSE, labels.format = list(fun = function(X) paste0(X, &#39;°&#39;))) Подписи сетки координат можно добавить и для более сложных проекций, однако располагаться они будут по-прежнему вдоль осей X и Y. В примере ниже также показано как можно увеличить расстояние между заголовком и картой, определив более крупный отступ от верхней стороны в параметре inner.margins: tm_shape(coun) + tm_polygons(&#39;lifexp&#39;, palette = &#39;YlGn&#39;, n = 4, style = &#39;jenks&#39;, border.col = &#39;gray20&#39;, title = &#39;Лет&#39;, colorNA = &#39;lightgray&#39;, textNA = &#39;Нет данных&#39;, legend.reverse = TRUE, legend.format = list(text.separator = &#39;—&#39;)) + # количественная переменная tm_shape(lyrp$ocean) + tm_fill(col = &#39;azure&#39;) + tm_borders(col = &#39;steelblue4&#39;) + tm_layout(frame = FALSE, main.title.position = 0.22, legend.outside = TRUE, legend.outside.position = &#39;right&#39;, fontfamily = &#39;Open Sans&#39;, main.title.size = 1.2, main.title = &#39;Продолжительность жизни&#39;, legend.bg.color = &#39;white&#39;, outer.margins = c(0.02, 0.05, 0.02, 0.02), inner.margins = c(0.02, 0.02, 0.07, 0.02)) + tm_grid(x = seq(-180, 180, by = 60), y = seq(-90, 90, by = 30), lwd = 0.2, col = &quot;black&quot;, projection = &quot;longlat&quot;, labels.inside.frame = FALSE, labels.format = list(fun = function(X) paste0(X, &#39;°&#39;))) 10.6 Фасеты и серии карт Фасетная компоновка предполагает, упорядочение элементов в матричной форме на одной странице. Как правило, картографические фасеты идентичны по содержанию, но показывают одно и то же явление при различных заданных условиях: за разные года, по разным странам и т.д. Создание фасет с помощью tmap осуществляется с помощью специальной функции tm_facets(), которой необходимо передать название переменной, отвечающей за разделение. В свою очередь, это означает, что данные должны быть приведены к «длинной» форме (если информация за разные года содержится в разных столбцах, то нужно год записать в отдельную переменную). Здесь вам пригодится знание пакета tidyr. Рассмотрим создание фасет на примере данных Gapminder по средней продолжительности жизни c 1960 по 2010 г: (&#39;1H3nzTwbn8z4lJ5gJ_WfDgCeGEXK3PVGcNjQ_U5og8eo&#39; %&gt;% # продолжительность жизни gs_key(lookup = FALSE) %&gt;% # не используем авторизацию gs_read(ws = 1) %&gt;% rename(name = 1) %&gt;% gather(year, lifexp, -name) %&gt;% filter(year %in% c(1960, 1970, 1980, 1990, 2000, 2010)) %&gt;% left_join(read_excel(&#39;data/gapminder.xlsx&#39;, 2)) %&gt;% mutate(geo = stringr::str_to_upper(geo)) -&gt; lifedf2) # выгружаем данные по ВВП на душу населения и сохраняем в переменную lifedf ## # A tibble: 1,560 x 13 ## name year lifexp geo four_regions eight_regions six_regions ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Abkh… 1960 NA &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 2 Afgh… 1960 31.9 AFG asia asia_west south_asia ## 3 Akro… 1960 NA &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 4 Alba… 1960 62.9 ALB europe europe_east europe_cen… ## 5 Alge… 1960 47.5 DZA africa africa_north middle_eas… ## 6 Amer… 1960 NA &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 7 Ando… 1960 NA AND europe europe_west europe_cen… ## 8 Ango… 1960 36.0 AGO africa africa_sub_s… sub_sahara… ## 9 Angu… 1960 NA &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 10 Anti… 1960 63.0 ATG americas america_north america ## # … with 1,550 more rows, and 6 more variables: members_oecd_g77 &lt;chr&gt;, ## # Latitude &lt;dbl&gt;, Longitude &lt;dbl&gt;, `UN member since` &lt;dttm&gt;, `World bank ## # region` &lt;chr&gt;, `World bank income group 2017` &lt;chr&gt; coun2 = lyrp$countries %&gt;% left_join(lifedf2, by = c(&#39;adm0_a3&#39; = &#39;geo&#39;)) Создадим серию карт за разные года: tm_shape(coun2) + tm_polygons(&#39;lifexp&#39;, palette = &#39;YlGnBu&#39;, n = 3, style = &#39;pretty&#39;, border.col = &#39;gray20&#39;, title = &#39;Лет&#39;, colorNA = &#39;lightgray&#39;, textNA = &#39;Нет данных&#39;, legend.reverse = TRUE, legend.format = list(text.separator = &#39;—&#39;)) + # количественная переменная tm_facets(by = &#39;year&#39;, free.coords = FALSE, drop.units = TRUE, drop.NA.facets = TRUE, ncol = 2) + tm_shape(lyrp$ocean) + tm_fill(col = &#39;azure&#39;) + tm_borders(col = &#39;steelblue4&#39;) + tm_layout(frame = FALSE, legend.outside = TRUE, legend.outside.position = &#39;bottom&#39;, fontfamily = &#39;Open Sans&#39;, main.title.size = 1.2, main.title = &#39;Средняя продолжительность жизни&#39;, legend.bg.color = &#39;white&#39;, outer.margins = c(0.02, 0.1, 0.02, 0.02), inner.margins = c(0.02, 0.02, 0.07, 0.02)) Фасетные карты по растровым данным в настоящий момент не поддерживаются в пакете tmap, но вы можете создать их, используя функцию tmap_arrange(), которая принимает на вход список из карт tmap и упорядочивает их в фасетной компоновке. В примере ниже показано, как: вычислить равноступенную шкалу, единую для всех карт — используя максимум и минимум по всем растрам из стека, а также функцию fullseq() из пакета scales, заведомо накрывающую указанный диапазон значений интервалами заданного размера. применить функционал map2()из пакета purrr (входит в tidyverse) для одновременной итерации по двум спискам: названий растров в стеке (X) и названий месяцев (Y), которые нужны для формирования заголовков упорядочить карты по регулярной сетке с двумя столбцами и полями отступа каждой фасеты (параметр outer.margins), используя tmap_arrange() minval = min(cellStats(temp, &#39;min&#39;)) maxval = max(cellStats(temp, &#39;max&#39;)) brks = scales::fullseq(c(minval, maxval), 10) months = c(&#39;Январь&#39;, &#39;Февраль&#39;, &#39;Март&#39;, &#39;Апрель&#39;, &#39;Март&#39;, &#39;Июнь&#39;, &#39;Июль&#39;, &#39;Август&#39;, &#39;Сентябрь&#39;, &#39;Октябрь&#39;, &#39;Ноябрь&#39;, &#39;Декабрь&#39;) maps = purrr::map2(names(temp), months, function(X, Y) { tm_shape(temp) + tm_raster(X, title = &#39;°C&#39;, colorNA = &#39;grey&#39;, # определяем цвет для пропущенных значений textNA = &#39;Нет данных&#39;, legend.format = list(text.separator = &#39;—&#39;), breaks = brks, midpoint = 0, style = &#39;fixed&#39;, legend.reverse = TRUE, palette = &#39;-RdBu&#39;) + tm_shape(lyrm$ocean) + tm_fill(col = &#39;azure&#39;) + tm_borders(col = &#39;steelblue&#39;) + tm_layout(legend.position = c(&#39;LEFT&#39;, &#39;BOTTOM&#39;), fontfamily = &#39;Open Sans&#39;, main.title.size = 1.2, main.title = Y, legend.frame = TRUE, legend.frame.lwd = 0.2, legend.bg.alpha = 0.8, legend.bg.color = &#39;white&#39;, inner.margins = c(0, 0, 0, 0)) + tm_grid(x = seq(-180, 180, by = 30), y = seq(-90, 90, by = 30), lwd = 0.2, col = &quot;black&quot;, projection = &quot;longlat&quot;, labels.inside.frame = FALSE, labels.format = list(fun = function(Z) paste0(Z, &#39;°&#39;))) }) tmap_arrange(maps, asp = NA, ncol = 2, outer.margins = 0.05) 10.7 Картографические анимации Картографические анимации вы пакете tmap создаются путем следующей последовательности действий: Добавить в построение карты функцию tm_facets(along = \"name\"), где name — название атрибута, значения которого отвечают за каждый кадр анимации. Записать созданную карту в переменную (условно назовем ее map). Вызвать для созданной переменной функцию tmap_animation(map, filename = \"filename.gif\", delay = 25), определив имя файла и задержку в миллисекундах между кадрами. Внимание: для того чтобы работало построение анимаций средствами tmap, на вашем компьютере должна быть установлена библиотека ImageMagick. Для примера построим анимацию по данным изменения средней продолжительности жизни: map = tm_shape(coun2) + tm_polygons(&#39;lifexp&#39;, palette = &#39;YlGnBu&#39;, n = 3, style = &#39;pretty&#39;, border.col = &#39;gray20&#39;, title = &#39;Лет&#39;, colorNA = &#39;lightgray&#39;, textNA = &#39;Нет данных&#39;, legend.reverse = TRUE, legend.format = list(text.separator = &#39;—&#39;)) + # количественная переменная tm_facets(along = &#39;year&#39;, free.coords = FALSE, drop.units = TRUE) + tm_shape(lyrp$ocean) + tm_fill(col = &#39;azure&#39;) + tm_borders(col = &#39;steelblue4&#39;) tmap_animation(map, &#39;images/lifexp.gif&#39;, delay = 100) 10.8 Интерактивные карты Любую карту tmap можно перевести в интерактивный режим с помощью функции tmap_mode() с параметром 'view'. Управлять дополнительными параметрами, специфичными для интерактивного режима, можно используя функцию tm_view(). В частности, можно установить координаты центра карты и масштабный уровень в параметре set.view и ограничить диапазон масштабных уровней в параметре set.zoom.limits. Состав полей, значения которых отображаются во всплывающем окне при щелчке на символе, определяются параметром popup.vars: tmap_mode(&#39;view&#39;) tm_shape(coun) + tm_polygons(&#39;lifexp&#39;, border.col = &#39;gray20&#39;, palette = &#39;YlGn&#39;, n = 4, style = &#39;jenks&#39;, title = &#39;Лет&#39;, colorNA = &#39;lightgray&#39;, textNA = &#39;Нет данных&#39;, legend.format = list(text.separator = &#39;—&#39;), popup.vars = c(&#39;sovereignt&#39;, &#39;lifexp&#39;)) + # поля для всплывающего окна tm_view(set.view = c(20, 45, 2), # центр карты и масштабный уровень set.zoom.limits = c(1, 4)) Чтобы добавить карту-подложку, необходимо предварительно вызвать функцию tm_basemap(), передав ей название картографического сервиса. В примере ниже также показано, как можно сделать размер кружка постоянным во всех масштабах (параметр symbol.size.fixed): tmap_mode(&#39;view&#39;) coun = coun %&gt;% mutate(gdp_scaled = round(0.001 * gdp_md_est)) tm_basemap(&quot;OpenStreetMap&quot;) + tm_shape(coun) + tm_borders(col = &#39;black&#39;, alpha = 0.5, lwd = 0.3) + tm_shape(st_point_on_surface(coun)) + # делаем точки, чтобы диаграммы были точно внутри tm_bubbles(&#39;gdp_scaled&#39;, scale = 3, col = &#39;violetred&#39;, alpha = 0.5, popup.vars = c(&#39;sovereignt&#39;, &#39;gdp_scaled&#39;)) + tm_text(&#39;gdp_scaled&#39;, size = &#39;gdp_scaled&#39;, remove.overlap = TRUE, size.lowerbound = 0.2, scale = 2) + tm_view(set.view = c(20, 45, 3), set.zoom.limits = c(2, 4), symbol.size.fixed = TRUE, text.size.variable = TRUE) 10.9 Контрольные вопросы и упражнения 10.9.1 Вопросы Опишите шаблон построения тематической карты средствами tmap. Что из себя представляют его три основные компоненты? Могут ли на одной тематической карте комбинироваться пространственные данные в разных проекциях? Перечислите названия функций, отвечающих за отображение полигонов, линий и окружностей средствами tmap. Чему должно быть равно значение параметра col при отображении одноканального растра в случае если классификация и цвета определяются посредством параметров breaks и palette? Опишите порядок использования функции classIntervals() и ее основные параметры. Перечислите методы классификации, доступные в classIntervals(), а также принципы и работы. Какой из методов наиболее трудоемок в вычислительном плане? В каком соотношении должно быть количество граничных классов и количество цветов при классификации? График какой функции отображается при вызове функции plot() применительно к результату выполнения classIntervals()? Какие возможности существуют для применения классификации при построении карт средствами tmap? Обязательно ли заранее определять количество классов? В каком случае это может быть полезно. Как можно изменить порядок размещения элементов легенды в tmap? Опишите возможности управления расположением и внутренним форматированием легенды средствами tmap. С помощью какой функции можно построить координатную сетку на карте tmap? Как добавить значки градусов в подписи выходов сетки координат на карте tmap? Какие параметры позволяют управлять внешними и внутренними полями карты tmap? Опишите последовательность действий, которую необходимо реализовать для построения фасетной карты средствами tmap. Как можно реализовать построение таких карт на основе растровых данных? Опишите последовательность действий, которую необходимо реализовать для построения картографических анимаций средствами tmap. Какая библиотека должна быть установлена для этого на компьютере пользователя? Каким образом можно перевести отображение карт tmap в интерактивный режим? А обратно в статичный? Расскажите, что вы знаете о данных Natural Earth. На каком сайте они размещены? Сколько существует масштабных уровней? В каких форматах доступны данные? Как получить доступ к ним программным путем непосредственно из среды R? 10.9.2 Упражнения Используя возможности пакетов rnaturalearth и tmap, создайте карту мира, в которой страны раскрашены в соответствии с континентом (переменная continent). Визуализируйте ее в статичном и интерактивном режиме. Выполните выборку стран на Европейский континент. Трансформируйте данные о странах в коническую равнопромежуточную проекцию. Визуализируйте численность населения по странам (переменная pop_est) способом картодиаграмм. Добавьте на карту реки, озера и города, используя возможности ne_download(). Самсонов Т.Е. Визуализация и анализ географических данных на языке R. М.: Географический факультет МГУ, lubridate::year(Sys.Date()). DOI: 10.5281/zenodo.901911 "],
["vector-analysis.html", "Глава 11 Векторный и сетевой анализ 11.1 Пространственные запросы 11.2 Постановка задач и изучение данных 11.3 Анализ расстояний 11.4 Анализ взаимного положения (топологический) 11.5 Анализ абсолютных зон окружения 11.6 Анализ конкурентных зон окружения 11.7 Анализ зон транспортной доступности 11.8 Построение маршрутов и матриц времени движения 11.9 Контрольные вопросы и упражнения", " Глава 11 Векторный и сетевой анализ Данный модуль посвящен пространственному анализу в R. Несмотря на то, что пространственный анализ — чрезвычайно широкая и многогранная область геоинформатики, все методы, которые объединяются под этим заголовком, базируются на ограниченном числе базовых операций, таких как вычисление расстояний, оценка плотности распределения, построение буферных зон и выполнение пространственных запросов. В настоящем модуле мы рассмотрим, как одно и то же множество пространственных объектов можно анализировать в различных контекстах, используя базовые методы пространственного анализа Пространственный анализ связан с оценкой размещения объектов и распределения величин в географическом пространстве. В геоинформатике для этих целей используется два подхода: геометрический и статистический. Эти подходы образуют две ступени пространственного анализа: как правило, данные геометрического анализа представляют собой входную информацию для анализа статистического. Геометрический подход связан с вычислением расстояний между географическими локациями, а также агрегированием объектов/интегрированием показателей в пределах заданных областей, вдоль линий или в окрестности точек. Поиск входной информации для агрегирования решается путем выполнения пространственных запросов. 11.1 Пространственные запросы Пространственные запросы связаны с поиском объектов (географических локаций), удовлетворяющих условию, заданному на множестве пространственных отношений. В свою очередь, пространственные отношения бывают трех типов: дирекционные (направления), метрические (расстояния) и топологические (взаимное размещение). Примеры пространственных запросов знакомы любому географу: Найти все объекты внутри административного района (топологические отношения) Найти все объекты не далее 100 метров от дороги (метрические отношения) Найти все объекты, расположенные к северу от точки (дирекционные отношения) Пространственные запросы могут объединять несколько условий. Можно найти объекты, удовлетворяющие одновременно всем (логическое И) вышеперечисленным условиям: внутри района, не далее 100 м от дороги и к северу от выбранной точки; или хотя бы одному (логическое ИЛИ) из вышеперечисленных условий. Результат выполнения такого комплексного запроса будет являться, соответственно, пересечением множеств объектов, полученных каждым из запросов, или их объединением. Наконец, пространственные запросы можно объединять с атрибутивными и временными. Атрибутивные запросы связаны с поиском объектов (географических локаций), удовлетворяющих условию, заданному на множестве характеристик объектов. Временные запросы определены на множестве шкалы времени. Например, можно найти все населенные пункты населением свыше 10 000 человек (атрибутивный запрос), находящиеся в пределах выбранного административного района (пространственный запрос, основанный на топологических отношениях), время движения от которых до районного центра не превышает 90 минут (временной запрос). 11.1.1 Контекстные и целевые объекты При выполнении пространственного анализа, в общем случае, имеются множества объектов двух типов: контекстные — объекты, относительно которых будет оцениваться размещение других объектов, то есть, определяющие контекст анализа целевые — объекты, размещение которых анализируется по отношению к контекстным объектам, что является целью анализа Эти множества, разумеется, могут совпадать. Скажем, мы можем проанализировать размещение магазинов относительно других магазинов. 11.1.2 Зоны окружения объектов Весьма часто в качестве контекстного множества используются не реальные пространственные объекты, а набор абстрактных геометрических объектов, каждый из которых является производным от оригинального пространственного объекта. Как правило, такие геометрии представляют из себя зоны окружения объектов, построенные по некоторому формальному признаку. Методы построения зон окружения можно разделить по двум критериям: учету взаимного размещения объектов (абсолютные и конкурентные зоны) и пространству признаков, в котором эти зоны строятся. Если зоны окружения строятся без учета взаимного размещения объектов, то есть, независимо для каждого объекта, то мы будем называть их абсолютными. Абсолютные зоны окружения строятся путем фиксации порогового расстояния либо времени движения относительно исходного объекта. Такие зоны носят название буферных зон (по расстоянию) или зон доступности (по времени). Границей абсолютной зоны окружения является изолиния, построенная по соответствующему показателю. В случае времени это будет изохрона. Примеры абсолютных зон окружения: Водоохранная зона реки 200 метров (буферная зона) Площадь городской территории, в любую точку которой вы можете доехать из дома на машине в течение 30 минут (зона доступности) Если же при построении зон окружения учитывается взаимное размещение объектов, то в данном случае зоны доступности строятся не исходя из порогового значения показателя (хотя оно может использоваться дополнительно), а исходя из того, какой объект является ближайшим. Конкурентные зоны окружения представляют собой разбиение пространства на неперекрывающиеся участки без дыр, каждый из которых является зоной окружения соответствующего пространственного объекта. При этом любая точка внутри зоны окружения объекта ближе к этому объекту по выбранному признаку (времени или расстоянию), нежели к любому другому объекту. Конкурентные зоны окружения, построенные по расстоянию, можно реализовать средствами диаграммы Вороного. 11.2 Постановка задач и изучение данных В настоящем модуле мы рассмотрим вышеперечисленные методы на примере анализа размещения пунктов общественного питания — кафе, ресторанов и т.д. Используя методы пространственного анализа в среде R, мы ответим на следующие вопросы: Какие улицы являются местами наибольшей концентрации заведений общественного питания? Как распределены заведения общественного питания по районам центра Москвы? Какие заведения общественного питания находятся вблизи метро и на берегу реки? В какие заведения общественного питания можно доехать от выбранной точки в течение 5 минут? Каков оптимальный маршрут между вашим местоположением и заведением, в котором вы хотите пообедать? В качестве источника данных используем OpenStreetMap — краудсорсинговый интернет-проект по созданию бесплатных и открытых пространственных данных глобального охвата. Данные OpenStreetMap в удобном для использования в ГИС виде доступны на портале GIS-Lab. Для решения задач настоящего модуля нам понадобятся следующие дополнительные пакеты, которые мы не использовали ранее: osrm — построение зон доступности, маршрутов и матриц корреспонденции онлайн на основе данных OpenStreetMap и OSRM API. cartography — пакет, облегчающий построение тематических карт и легенд средствами стандартной функции plot(). Начнем наше исследование с визуального анализа исходных данных library(sf) library(tidyverse) library(classInt) library(osrm) # Использование онлайн-сервиса маршрутизации OSRM library(cartography) # Удобное построение тематических карт средствами plot() # Чтение данных roads = st_read(&quot;data/roads.gpkg&quot;) # Дороги poi = st_read(&quot;data/poi_point.gpkg&quot;) # Точки интереса rayons = st_read(&quot;data/boundary_polygon.gpkg&quot;) # Границы районов stations = st_read(&quot;data/metro_stations.gpkg&quot;) # Станции метро water = st_read(&quot;data/water_polygon.gpkg&quot;) # Водные объекты # Прочитаем текущие параметры компоновки def = par(no.readonly = TRUE) # Уберем поля, чтобы карта занимала весь экран par(mar = c(0,0,0,0)) # Получим ограничивающий прямоугольник слоя дорог в качестве общего охвата карты frame = roads %&gt;% st_bbox() %&gt;% st_as_sfc() %&gt;% st_geometry() ## ОБЗОР ИСХОДНЫХ ДАННЫХ ------------------------------------- # Визуализируем входные данные plot(frame) plot(water %&gt;% st_geometry(), col = &quot;lightskyblue1&quot;, border = &quot;lightskyblue3&quot;, add = TRUE) plot(roads %&gt;% st_geometry(), col = &quot;gray70&quot;, add = TRUE) plot(poi %&gt;% st_geometry(), col = &quot;deepskyblue4&quot;, pch = 20, cex = 0.2, add = TRUE) Теперь приступим к изучению данных, хранящихся в слое poi (от англ. POI — Point Of Interest). Данный слой содержит все точечные маркеры OSM, которыми были отмечены на карте объекты, представляющие (по мнению создателей данных) интерес для пользователей. В POI включаются самые разнообразные объекты, такие как: объекты сферы услуг (amenity), места для отдыха (leisure), офисные здания (office), магазины и торговые центры (shop), туристические достопримечательности (tourism), спортивные объекты (sport), примечательные инженерные сооружения (man_made). В наших данных информация разнесена по соответствующим полям, каждый объект снабжен уникальным идентификатором: ## Simple feature collection with 6623 features and 9 fields ## geometry type: POINT ## dimension: XY ## bbox: xmin: 410947.3 ymin: 6176678 xmax: 415889.9 ymax: 6181909 ## epsg (SRID): 32637 ## proj4string: +proj=utm +zone=37 +datum=WGS84 +units=m +no_defs ## First 10 features: ## OSM_ID NAME MAN_MADE LEISURE AMENITY OFFICE ## 1 2932331614 Арт-квартал &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 2 3639408399 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; pharmacy &lt;NA&gt; ## 3 3707882299 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; parking_entrance &lt;NA&gt; ## 4 3639408396 Стиль золото &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 5 3639408397 Цветочная база №1 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 6 1413216563 Азбука Вкуса &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 7 3641139540 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; waste_disposal &lt;NA&gt; ## 8 3636920934 Аршин &lt;NA&gt; &lt;NA&gt; restaurant &lt;NA&gt; ## 9 3644422074 Адамас &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 10 3424516009 Андерсон &lt;NA&gt; &lt;NA&gt; restaurant &lt;NA&gt; ## SHOP TOURISM SPORT geometry ## 1 doityourself &lt;NA&gt; &lt;NA&gt; POINT (410947.3 6181185) ## 2 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; POINT (410961.8 6181858) ## 3 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; POINT (410953.8 6181302) ## 4 jewelry &lt;NA&gt; &lt;NA&gt; POINT (410966.7 6181864) ## 5 florist &lt;NA&gt; &lt;NA&gt; POINT (410973 6181862) ## 6 supermarket &lt;NA&gt; &lt;NA&gt; POINT (410963.7 6181250) ## 7 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; POINT (410973.9 6181676) ## 8 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; POINT (410975.2 6181661) ## 9 jewelry &lt;NA&gt; &lt;NA&gt; POINT (410982.5 6181905) ## 10 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; POINT (410954.9 6180118) Заведения общественного питания по классификатору OSM относятся к классу amenity. Поскольку данный классификатор представляет собой множество номинальных (категориальных) данных, можно начать изучение состава данных с помощью таблицы частот, которая строится средствами функции table(): data.frame(table(poi$AMENITY)) ## Var1 Freq ## 1 arts_centre 17 ## 2 atm 153 ## 3 bank 407 ## 4 bar 161 ## 5 bench 210 ## 6 bicycle_parking 81 ## 7 bicycle_rental 116 ## 8 biergarten 1 ## 9 brothel 1 ## 10 bureau_de_change 21 ## 11 bus_station 1 ## 12 cafe 490 ## 13 car_rental 1 ## 14 car_wash 12 ## 15 charging_station 1 ## 16 child_care 1 ## 17 cinema 16 ## 18 clinic 51 ## 19 clock 10 ## 20 college 5 ## 21 commercial 1 ## 22 community_centre 4 ## 23 courthouse 3 ## 24 dancing_school 1 ## 25 dentist 58 ## 26 doctors 22 ## 27 drinking_water 3 ## 28 driving_school 2 ## 29 embassy 31 ## 30 emergency_phone 5 ## 31 fast_food 169 ## 32 ferry_terminal 5 ## 33 food_court 3 ## 34 fountain 32 ## 35 fuel 8 ## 36 gym 1 ## 37 hospital 2 ## 38 hotel 1 ## 39 ice_cream 3 ## 40 kindergarten 13 ## 41 library 17 ## 42 musical_school 1 ## 43 nightclub 19 ## 44 official 1 ## 45 parking 92 ## 46 parking_entrance 72 ## 47 parking_space 1 ## 48 payment_terminal 6 ## 49 pharmacy 166 ## 50 photolab 1 ## 51 place_of_worship 23 ## 52 police 21 ## 53 post_box 4 ## 54 post_office 37 ## 55 pub 96 ## 56 public_bookcase 2 ## 57 public_building 8 ## 58 recycling 6 ## 59 register_office 2 ## 60 restaurant 844 ## 61 school 10 ## 62 shelter 2 ## 63 shop 4 ## 64 social_facility 3 ## 65 stripclub 4 ## 66 taxi 1 ## 67 telephone 58 ## 68 theatre 48 ## 69 toilets 82 ## 70 training 15 ## 71 university 15 ## 72 vehicle_inspection 1 ## 73 vending_machine 98 ## 74 waste_basket 52 ## 75 waste_disposal 102 Для дальнейшего анализа отберем из всего множества объектов сферы услуг заведения, где можно поесть: рестораны, кафе, бары, пабы и заведения быстрого питания (фастфуд). В классификаторе OSM эти заведения имеют тип restaurant, bar, cafe, pub и fast_food. Для отбора нужных строк и столбцов используем dplyr: poi.food = poi %&gt;% dplyr::select(NAME, AMENITY) %&gt;% filter(AMENITY %in% c(&quot;restaurant&quot;, &quot;bar&quot;, &quot;cafe&quot;, &quot;pub&quot;, &quot;fast_food&quot;)) head(poi.food) ## Simple feature collection with 6 features and 2 fields ## geometry type: POINT ## dimension: XY ## bbox: xmin: 410954.9 ymin: 6178842 xmax: 411023.8 ymax: 6181896 ## epsg (SRID): 32637 ## proj4string: +proj=utm +zone=37 +datum=WGS84 +units=m +no_defs ## NAME AMENITY geometry ## 1 Аршин restaurant POINT (410975.2 6181661) ## 2 Андерсон restaurant POINT (410954.9 6180118) ## 3 Holynoot fast_food POINT (410958.8 6179938) ## 4 Gayane&#39;s restaurant POINT (410958.4 6178842) ## 5 Molon Lave restaurant POINT (411013.7 6181448) ## 6 Шоколадница cafe POINT (411023.8 6181896) 11.3 Анализ расстояний Метрические отношения связывают объекты в терминах расстояний между ними. Предположим, что мы хотим определить улицы, являющиеся сосредоточением заведений питания. Один из вариантов решения состоит в том, чтобы для каждого пункта обслуживания определить ближайшую к нему улицу и далее для каждой улицы просуммировать количество раз, которое улиц оказалось ближайшей. Подробнее алгоритм решения выглядит следующим образом: Вычислить матрицу расстояний между пунктами обслуживания и улицами. Размер матрицы \\(M \\times N\\), где \\(M\\) — количество улиц (строк), \\(N\\) — количество пунктов (столбцов) Найти в каждом столбце минимальное расстояние. Получить идентификатор улицы (номер строки), соответствующий данному расстоянию. Записать идентификатор в выходной вектор. Таким образом, мы получим вектор из идентификаторов улиц, при этом каждый идентификатор будет встречаться в этом векторе столько раз, сколько раз данная улица оказалась ближайшей к какому-то объекту. Вычислим матрицу расстояний с помощью функции st_distance() из пакета sf: ## АНАЛИЗ РАССТОЯНИЙ ------------------------------------- dist.matrix = st_distance(roads, poi.food) # посмотрим, как выглядит результат на примере первых пяти объектов print(dist.matrix[1:5,1:5]) ## Units: [m] ## [,1] [,2] [,3] [,4] [,5] ## [1,] 4962.292 3420.6849 3240.2066 2145.2044 4748.686 ## [2,] 2247.737 705.2923 524.9411 570.3986 2035.341 ## [3,] 2213.236 670.7904 490.4167 605.1606 2000.759 ## [4,] 2197.874 655.4285 475.0629 620.4411 1985.242 ## [5,] 3910.957 2368.5560 2188.1348 1092.5472 3698.246 Далее необходимо в каждом столбце матрицы найти номер строки с минимальным расстоянием. Для этого необходимо получить порядок сортировки элементов по возрастанию значений данного столбца и взять номер первого элемента. Операцию можно применить с помощью apply ко всем столбцам: ids = apply(dist.matrix, 2, function(X) order(X)[1]) Теперь применим уже знакомую нам функцию table(), чтобы подсчитать, сколько раз каждая улица оказалась наиболее близкой. Далее присоединим статистику к исходным улицам, однако для этого нам потребуется вынести названия строк (номеров) улиц в отдельный столбец. count.stats = as.data.frame(table(ids)) roads = roads %&gt;% mutate(id = row.names(.)) roads.poi = merge(roads, count.stats, by.x = &#39;id&#39;, by.y = &#39;ids&#39;, all.x = T) Посмотрим первые 10 улиц по количеству общепита: # Статистика по улицам в табличном представлении (первые 10) roads.poi %&gt;% dplyr::select(NAME, Freq) %&gt;% arrange(desc(Freq)) %&gt;% head(10) ## Simple feature collection with 10 features and 2 fields ## geometry type: MULTILINESTRING ## dimension: XY ## bbox: xmin: 411105.1 ymin: 6178083 xmax: 414504.1 ymax: 6181734 ## epsg (SRID): 32637 ## proj4string: +proj=utm +zone=37 +datum=WGS84 +units=m +no_defs ## NAME Freq geometry ## 1 улица Арбат 43 MULTILINESTRING ((412157.9 ... ## 2 улица Новый Арбат 24 MULTILINESTRING ((411105.1 ... ## 3 Цветной бульвар 22 MULTILINESTRING ((413491.7 ... ## 4 Мясницкая улица 20 MULTILINESTRING ((414504.1 ... ## 5 Никольская улица 17 MULTILINESTRING ((413704.5 ... ## 6 Пятницкая улица 17 MULTILINESTRING ((413895.8 ... ## 7 Неглинная улица 14 MULTILINESTRING ((413498.2 ... ## 8 улица Рождественка 14 MULTILINESTRING ((413628.1 ... ## 9 Козицкий переулок 14 MULTILINESTRING ((412831.7 ... ## 10 улица Большая Дмитровка 14 MULTILINESTRING ((413262.7 ... Для завершения анализа осталось визуализировать результаты. Чтобы усилить наглядность визуализации, мы не будем каждую улицу утолщать пропорционально количеству привязанных объектов, а разделим это количество на 4 класса. Каждый класс покажем линией соответствующей толщины и интенсивности цвета (чем больше объектов привязано к улице, тем толще линия, темнее и насыщеннее ее цвет). Для классификации используем функцию cut(), позволяющую перекодировать интервальные данные в номинальные, то есть сопоставить каждому элементу вектора некий класс, которому он принадлежит. На выходе будем иметь вектор, который состоит из такого же количества элементов, что и исходный, но вместо исходных значений будут стоять названия классов. # Получим границы классов nclasses = 4 class.breaks = classIntervals(roads.poi$Freq, n = nclasses, style = &quot;jenks&quot;) # Извлечем граничные интервалы borders = class.breaks$brks # Названия классов — они же толщины линия от 1 до 4 line.widths = 1:nclasses # Перекодируем столбец количества присоединенных пунктов в классы sizes = cut(roads.poi$Freq, breaks = borders, labels = line.widths) Теперь присвоим каждому объекту свой цвет в соответствии с классом, который ему присвоен. Удобная функция findColours() позволяет найти цвет для каждого объекта в соответствии с полученной классификацией: base.colors = c(&quot;mistyrose&quot;, &quot;red&quot;) ramp = colorRampPalette(base.colors) colors = findColours(class.breaks, base.colors) plot(frame) plot(water %&gt;% st_geometry(), col = &quot;lightskyblue1&quot;, border = &quot;lightskyblue3&quot;, add = TRUE) plot(roads %&gt;% st_geometry(), col = &quot;gray70&quot;, add = TRUE) plot(roads.poi %&gt;% st_geometry(), lwd = sizes, col = colors, add = TRUE) plot(poi.food %&gt;% st_geometry(), col = &quot;deepskyblue4&quot;, pch = 20, cex = 0.2, add = TRUE) # Функция legendGradLines из пакета cartography позволяет строить # легенду для карт линий градуированных размеров: legendGradLines(title.txt = &quot;Пункты питания&quot;, pos = &quot;left&quot;, title.cex = 0.8, values.cex = 0.6, breaks = borders, lwd = line.widths, col = &quot;red&quot;) 11.4 Анализ взаимного положения (топологический) Пространственные запросы, основанные на топологических отношениях, позволяют находить объекты, находящиеся внутри других объектов, соприкасающиеся с другими объектами, пересекающиеся с ними и так далее. Топологические отношения сохраняются при взаимно-однозначных и непрерывных преобразованиях плоскости. Отличия от метрических отношений легко пояснить на примере преобразования проекции. Представьте, что карту России в конической проекции с концентрическими параллелями (известную по учебникам и атласам) вы трансформировали в карту России в проекции Меркатора (такую же как на Google Maps). Изогнутые параллели превратились в прямые линии; форма регионов, площади и расстояния между населенными пунктами значительно изменились. Однако Красноярск по-прежнему находится в Красноярском крае, Ярославль — на реке Волге, Нижний Новгород — на правом берегу Волги, озеро Белое — внутри Вологодской области, а Московская область как не граничила с Тамбовской, так и не граничит после трансформации проекции. Это и есть топологические отношения. Формально топологические отношения в ГИС описываются с помощью модели девяти пересечений DE-9IM, которая была рассмотрена в предыдущей лекции. ## АНАЛИЗ ВЗАИМНОГО ПОЛОЖЕНИЯ ------------------------------------- poi.food = poi.food %&gt;% mutate(count = 1) rayons.poi = aggregate(poi.food[&#39;count&#39;], rayons, sum) # Преобразуем результат в относительный показатель # (единиц на кв.км. площади) и запишем в таблицу районов: rayons.poi$density = 1000000 * rayons.poi$count / st_area(rayons.poi) Масштабный множитель 1000000 в коде понадобился чтобы перевести площадь, хранящуюся в поле Shape_Area из квадратных метров в квадратные километры. Обратите внимание на то, что в данном случае мы не стали ограничивать фигурными скобками тело анонимной функции (table(X)[2]) внутри apply(), поскольку выполняемая операция достаточно компактна. Подготовим параметры отображения: # Настроим параметры отображения choro.pal = colorRampPalette(c(&quot;lightgoldenrodyellow&quot;, &quot;orangered&quot;)) intervals = classIntervals(rayons.poi$density, n = 5, style = &quot;quantile&quot;) Далее используем функции choroLayer() и legendChoro() из пакета cartography для построения картограмм плотности пунктов питания и соответствующей им легенды средствами обычной функции plot(): choroLayer(rayons.poi, # Исходный слой типа SpatialPolygonsDataFrame var = &quot;density&quot;, # Картографируемая переменная (столбец) breaks = intervals$brks, # Границы интервалов col = choro.pal(5), # Цвета для соответствующих интервалов legend.pos = &quot;n&quot;) # Легенду мы нарисуем позднее, поверх всех слоев plot(water %&gt;% st_geometry(), col = &quot;lightskyblue1&quot;, border = &quot;lightskyblue3&quot;, add = TRUE) plot(roads %&gt;% st_geometry(), col = &quot;gray50&quot;, add = TRUE) plot(poi.food %&gt;% st_geometry(), col = &quot;deepskyblue4&quot;, pch = 20, cex = 0.5, add = TRUE) plot(rayons %&gt;% st_geometry(), border = &quot;black&quot;, lwd = 3, add = TRUE) text(rayons %&gt;% st_centroid() %&gt;% st_coordinates(), labels = gsub(&#39; &#39;, &#39;\\n&#39;, rayons$NAME), font = 2, cex = 0.6) # Рисуем легенду legendChoro(breaks = intervals$brks, col = choro.pal(5), pos = &quot;topleft&quot;, frame = FALSE, title.txt = &quot;Заведений\\nна 1 кв.км&quot;) Итак, используя топологический пространственный запрос “Содержит”, мы смогли агрегировать точечные объекты внутри площадных и построить картограммы плотности распределения пунктов питания по районам центра Москвы. 11.5 Анализ абсолютных зон окружения Задача данного раздела модуля звучит следующим образом: определить, какие пункты питания находятся в радиусе 300 метров от метро “Кропоткинская”. Контекстом анализа в данном случае служит 300-метровая зона окружения станции метро. Поставленную задачу можно решить двумя способами: Рассчитать расстояния от каждого пункта питания до станции метро “Кропоткинская” и выбрать точки, для которых это расстояние меньше или равно 300 метрам. Построить буферную зону радиусом 300 метров и выбрать ею точки, используя топологическое отношение пересечения Мы будем использовать второй вариант решения. Алгоритм выглядит следующим образом: Построить буферную зону, используя функцию st_buffer() из пакета sf. Выбрать полученной зоной точки пунктов питания, используя стандартный оператор []. Визуализировать на карте полученные точки и буферную зону. Определим функцию plotBasemap(), которая будет рисовать объекты картографической основы, ее мы будем использовать далее неоднократно. ## АНАЛИЗ АБСОЛЮТНЫХ ЗОН ОКРУЖЕНИЯ ------------------------------------- # Функция отвечает за рисование базовой карты plotBasemap = function(add = FALSE){ plot(frame, add = add) plot(water %&gt;% st_geometry(), col = &quot;lightskyblue1&quot;, border = &quot;lightskyblue3&quot;, add = TRUE) plot(roads %&gt;% st_geometry(), col = &quot;gray70&quot;, add = TRUE) plot(poi.food %&gt;% st_geometry(), col = &quot;deepskyblue4&quot;, pch = 20, cex = 0.3, add = TRUE) plot(stations %&gt;% st_geometry(), col = &quot;slategray4&quot;, pch = 20, cex = 2, add = TRUE) text(stations %&gt;% st_centroid() %&gt;% st_coordinates(), labels = &quot;M&quot;, col = &quot;white&quot;, cex = 0.4) } Определив вспомогательные функции, можем приступать к выполнению анализа: # Выберем станцию метро и построим буферную зону krop = stations %&gt;% filter(NAME == &quot;Кропоткинская&quot;) zone = st_buffer(krop, dist = 300) # Применим разработанную функцию для отбора точек selected.poi = poi.food[zone, ] # Применим разработанную функцию для рисования картографической основы plotBasemap() # Визуализируем результаты анализа plot(krop %&gt;% st_geometry(), col = &quot;red&quot;, pch = 20, cex = 4, add = TRUE) text(krop %&gt;% st_coordinates(), labels = &quot;M&quot;, col = &quot;white&quot;, cex = 0.7, add = TRUE) plot(zone %&gt;% st_geometry(), col = adjustcolor(&quot;sienna3&quot;, alpha.f = 0.5), border = &quot;sienna3&quot;, add = TRUE) plot(selected.poi %&gt;% st_geometry(), col = &quot;sienna4&quot;, pch = 20, cex = 0.5, add = TRUE) ## Simple feature collection with 23 features and 3 fields ## geometry type: POINT ## dimension: XY ## bbox: xmin: 412142.7 ymin: 6178370 xmax: 412593.7 ymax: 6178811 ## epsg (SRID): 32637 ## proj4string: +proj=utm +zone=37 +datum=WGS84 +units=m +no_defs ## First 10 features: ## NAME AMENITY geometry count ## 440 Азия Кафе restaurant POINT (412142.7 6178592) 1 ## 444 Баба Марта restaurant POINT (412154.8 6178720) 1 ## 447 Теремок fast_food POINT (412153 6178584) 1 ## 456 Воронеж cafe POINT (412177.7 6178535) 1 ## 457 Пафф Пойнт fast_food POINT (412180.6 6178620) 1 ## 458 What&#39;s Up Dog! fast_food POINT (412181.4 6178606) 1 ## 461 Воронеж restaurant POINT (412183.4 6178538) 1 ## 463 GlowSubs fast_food POINT (412190.1 6178599) 1 ## 464 Mr. Pit fast_food POINT (412193.2 6178610) 1 ## 469 Шоколадница cafe POINT (412204.3 6178570) 1 В качестве примера аналогичного анализа отберем все пункты питания, находящиеся в пределах 100 метров от реки Москвы: river = water %&gt;% filter(NAME == &quot;Москва&quot;) zone = st_buffer(river, dist = 100) selected.poi = poi.food[zone, ] plotBasemap() plot(zone %&gt;% st_geometry(), col = adjustcolor(&quot;orange&quot;, alpha.f = 0.5), border = &quot;orange&quot;, add = TRUE) plot(river %&gt;% st_geometry(), col = adjustcolor(&quot;deepskyblue&quot;, alpha.f = 0.5), border = F, add = TRUE) plot(selected.poi %&gt;% st_geometry(), col = &quot;firebrick1&quot;, pch = 20, cex = 0.5, add = TRUE) ## Simple feature collection with 39 features and 3 fields ## geometry type: POINT ## dimension: XY ## bbox: xmin: 411661.2 ymin: 6176685 xmax: 415287.1 ymax: 6178953 ## epsg (SRID): 32637 ## proj4string: +proj=utm +zone=37 +datum=WGS84 +units=m +no_defs ## First 10 features: ## NAME AMENITY geometry count ## 244 Белый журавль restaurant POINT (411661.2 6177029) 1 ## 332 What&#39;s Up Dog! fast_food POINT (411871.8 6176685) 1 ## 360 Coffee@Парк Горького cafe POINT (411917.7 6176775) 1 ## 386 Sekta restaurant POINT (411975 6176908) 1 ## 424 GlowSubs fast_food POINT (412060.5 6177161) 1 ## 473 Чай &amp; кофе cafe POINT (412197.5 6177284) 1 ## 479 Академия restaurant POINT (412222.4 6177790) 1 ## 509 Kaffebrod cafe POINT (412280.3 6177452) 1 ## 512 Les cafe POINT (412299.1 6177468) 1 ## 522 Beefbar restaurant POINT (412344.9 6177823) 1 11.6 Анализ конкурентных зон окружения В данном разделе мы решим следующую задачу: разбить всю изучаемую территорию на зоны окружения станций метро и подсчитать количество пунктов питания, попадающих в каждую зону. Полученные зоны должны быть конкурентными: любая точка, находящаяся в зоне окружения конкретной станции метро, должна быть ближе к этой станции, чем к любой другой станции. Ранее мы говорили о том, что конкурентные зоны окружения по расстоянию можно реализовать с помощью диаграммы Вороного. Применим функцию voronoi() из пакета dismo, чтобы посмотреть, как выглядит диаграмма Вороного для точек станций метро. Нам потребуется для этого конвертировать объекты в тип Spatial, а результат преобразовать вернуть обратно в sf: ## АНАЛИЗ КОНКУРЕНТНЫХ ЗОН ОКРУЖЕНИЯ ------------------------------------- zones = stations %&gt;% as(&#39;Spatial&#39;) %&gt;% dismo::voronoi() %&gt;% st_as_sf() %&gt;% st_crop(frame) plot(zones %&gt;% st_geometry()) plot(stations, add = TRUE, pch = 19, col = &#39;black&#39;) Для визуализации результатов мы будем использовать метод картодиаграмм (пропорциональных символов), реализованный в функции propSymbolsLayer() пакета cartography. Размером кружка покажем количество пунктов питания, оказавшихся в каждой зоне окружения: # Агрегруем данные по каждой зоне zones.poi = aggregate(poi.food[&#39;count&#39;], zones, sum) # Визуализируем результат plotBasemap() plot(zones %&gt;% st_geometry(), col = adjustcolor(&quot;white&quot;, alpha.f = 0.5), add = TRUE) propSymbolsLayer(zones.poi, var = &quot;count&quot;, symbols = &quot;circle&quot;, col = adjustcolor(&quot;turquoise3&quot;, alpha.f = 0.5), border = F, legend.title.txt = &quot;Заведений\\nпитания&quot;) text(zones %&gt;% st_centroid() %&gt;% st_coordinates(), labels = zones.poi$count, col = &quot;turquoise4&quot;, cex = log(zones.poi$count)/4) 11.7 Анализ зон транспортной доступности Зоны транспортной доступности представляют из себя зоны окружения объектов, построенные не по евклидову расстоянию, а по расстоянию или времени движения по дорожной сети. В задачах логистики и геомаркетинга зоны транспортной доступности часто называют зонами обслуживания (service area), поскольку используются для определения территории, которую может покрыть объект, предоставляющий некоторые услуги. Например, для пожарного депо зона 10-минутной доступности показывает территорию города, в любую точку которой пожарная машина может доехать из данного депо в течение 10 минут. И наоборот, для торгового центра зона 10-минутной доступности показывает территорию города, из любой точки которой можно добраться до ТЦ в течение 10 минут. Очевидно, что продолжительность прямого и обратного маршрута неодинакова, на нее может оказывать влияние схема движения, приоритет дорог и так далее. Задача, которую мы решим в данном разделе, звучит так: определить все заведения питания, находящиеся в 7 минутах езды от Центрального детского магазина. Для построения зоны доступности мы будем использовать пакет osrm, предоставляющий интерфейс R к онлайн-библиотеке маршрутизации OSRM, работающей на основе данных OSM. Для построения зоны доступности (изохроны) нам понадобится функция osrmIsochrone() из данного пакета. Внимание: для выполнения этого раздела модуля необходимо подключение к Интернету Поскольку данные, используемые в настоящем модуле, предварительно были конвертированы в проекцию UTM и хранятся в метрах, а OSRM решает все задачи в географических координатах (широте и долготе относительно эллипсоида WGS84), нам необходимо научиться работать с проекциями данных и преобразовывать системы координат между собой. ## АНАЛИЗ ЗОН ТРАНСПОРТНОЙ ДОСТУПНОСТИ ------------------------------------- # Инициализируем систему координат WGS84, используемую в OSRM WGS84 = st_crs(4326) # Извлечем информацию о системе координат исходных точек UTM = st_crs(poi) # Выберем целевой объект psel = poi %&gt;% filter(NAME == &quot;Центральный детский магазин&quot; &amp; SHOP == &quot;toys&quot;) # Преобразуем координаты точки в WGS84 psel.wgs = st_transform(psel, WGS84) # Получаем 5-минутную зону транспортной доступности # с помощью пакета osrm service_area = osrmIsochrone(loc = as(psel.wgs, &#39;Spatial&#39;), breaks = 7) # Преобразуем зону обратно в UTM для дальнейших операций service_area_utm = st_transform(st_as_sf(service_area), UTM) # Отбираем точки selected_poi = poi.food[service_area_utm, ] # Визуализируем результат plotBasemap() plot(service_area_utm %&gt;% st_geometry(), col = adjustcolor(&quot;violetred3&quot;, alpha.f = 0.2), border = &quot;violetred3&quot;, add = TRUE) plot(selected_poi %&gt;% st_geometry(), col = &quot;violetred3&quot;, pch = 20, cex = 0.5, add = TRUE) plot(psel %&gt;% st_geometry(), col = &quot;violetred4&quot;, pch = 20, cex = 4, add = TRUE) Итак, в данном разделе мы научились строить зоны транспортной доступности в виде полигонов, ограниченных изохроной времени движения. 11.8 Построение маршрутов и матриц времени движения В этом разделе модуля пространственного анализа мы посмотрим, каким образом можно построить оптимальный маршрут между двумя точками, а также получить матрицу времени движения между точками (на примере станций метро). Для решения этих задач используем следующие функции пакета osrm: osrmRoute(src, dest) — строит оптимальный маршрут между точками src и dest osrmTable(loc) — строит матрицу времени движения между всеми парами точек в loc Так же, как и в предыдущем разделе, нам понадобятся преобразования координат. Построим оптимальный маршрут между книжным магазином “Молодая Гвардия” на Полянке и чебуречной “Дружба” на метро Сухаревская: ## ПОСТРОЕНИЕ МАРШРУТОВ ------------------------------------- # Выбираем и проецируем начальную точку origin = poi %&gt;% filter(NAME == &#39;Молодая Гвардия&#39;) origin_wgs = st_transform(origin, WGS84) # Выбираем и проецируем конечную точку destination = poi %&gt;% filter(NAME == &#39;Чебуречная &quot;Дружба&quot;&#39;) destination_wgs = st_transform(destination, WGS84) # Строим маршрут route = osrmRoute(as(origin_wgs, &#39;Spatial&#39;), as(destination_wgs, &#39;Spatial&#39;), overview = &quot;full&quot;, # запретить генерализацию линий sp = TRUE) # вернуть результат в виде объекта класса Spatial # Преобразуем результат обратно в UTM route.utm = st_transform(route %&gt;% st_as_sf(), UTM) # Визуализируем результат: plotBasemap() plot(route.utm %&gt;% st_geometry(), lwd = 3, col = &quot;orange&quot;, add = TRUE) plot(origin %&gt;% st_geometry(), col = &quot;tomato3&quot;, pch = 20, cex = 3, add = TRUE) text(origin %&gt;% st_coordinates(), labels = &quot;O&quot;, col = &quot;tomato4&quot;, cex = 0.5) plot(destination %&gt;% st_geometry(), col = &quot;tomato&quot;, pch = 20, cex = 4, add = TRUE) text(destination %&gt;% st_coordinates(), labels = &quot;D&quot;, col = &quot;tomato4&quot;, cex = 0.7) 11.9 Контрольные вопросы и упражнения 11.9.1 Вопросы Перечислите три основных вида пространственных отношений, приведите их примеры. Чем отличаются контекстные и целевые объекты? В чем заключается отличие абсолютных и конкурентных зон окружения? Какая функция пакета sf позволяет вычислять расстояния между объектами? Как с помощью полученного результата определить для каждого объекта из множества \\(A\\) определить ближайший к нему объект из множества \\(B\\)? Опишите последовательность действий, которую необходимо выполнить для подсчета количества точечных объектов по заданной сетке полигонов. С помощью какой функции можно построить буферную зону вокруг пространственного объекта? Есть ли ограничения на размерность буферизуемого пространственного объекта (точка, линия, полигон)? Можно ли построить буфер вокруг поверхности? Какая геометрическая структура используется для построения конкурентных зон окружения? Что такое OSRM? Какими средствами можно построить зоны транспортной доступности и маршруты в среде R? В какой системе координат должны быть точки, участвующие в сетевом анализе? Опишите возможности и основные функции пакета cartography, с помощью которых можно строить тематические карты способами картограмм, картодиаграмм и линейных знаков, а также легенды к ним. 11.9.2 Упражнения Самсонов Т.Е. Визуализация и анализ географических данных на языке R. М.: Географический факультет МГУ, 2020. DOI: 10.5281/zenodo.901911 "],
["raster-analysis.html", "Глава 12 Растровый анализ Предварительные условия 12.1 Введение 12.2 Растровая алгебра 12.3 Извлечение данных 12.4 Контрольные вопросы и упражнения", " Глава 12 Растровый анализ Предварительные условия Для выполнения кода данной лекции вам понадобятся следующие пакеты: library(sf) library(sp) library(tmap) library(stars) library(raster) library(mapview) library(mapedit) library(lattice) library(classInt) library(geosphere) library(tidyverse) 12.1 Введение Растровая модель данных представляет собой мощный инструмент абстракции пространственных распределений и выполнения пространственного анализа. На первый взгляд, растр обладает целым рядом ограничений по сравнению с векторной моделью: не позволяет оперировать отдельными объектами, их границами и так далее. Растровые карты и снимки мы часто оцифровываем, выделяя объекты, чтобы на основе них можно было что-то посчитать. Самые первые ГИС были исключительно растровыми, что сейчас воспринимается как архаизм. Однако за ширмой ограниченности растровой модели кроются огромные аналитические возможности. Растровая модель обладает внутренней топологией: ее ячейки соприкасаются друг с другом, что позволяет моделировать непрерывные в пространстве и динамические явления (при которых происходит перемещение вещества, энергии или информации в пространстве). Поскольку ячейки растра имеют одинаковый размер, к ним можно применять однотипные операции, которые будут давать предсказуемый результат вне зависимости от конкретной локации в пределах растра. Это также позволяет сделать обработку растра очень быстро. 12.2 Растровая алгебра Существует классификация операций растрового анализа, введенная американским профессором Даной Томлином, которая объединяет их под общим названием “алгебра карт” или “растровая алгебра” (Tomlin 2012). Предполагая, что обработке подвергается каждая ячейка растра, данная классификация разделяет все операции по охвату относительно текущей ячейки Локальные — анализируется одна ячейка растра или совпадающие в пространстве ячейки нескольких растров Фокальные — анализируются все ячейки в окрестности. Окрестность может быть как фиксированной, так и расширенной (expanded), когда ее размер управляется внешними факторами, например множеством объектов, до которых требуется вычислить расстояние. Информация по соседним ячейкам может быть как из исходного растра, так и из внешнего. Фокальные методы алгебры карт также называются методами анализа соседства. Зональные — анализируются все ячейки в пределах зон, определяемых извне (например, вторым растровым слоем). Глобальные — анализируются все ячейки растра. 12.2.1 Локальные операции Локальные операции связаны с алгебраическими преобразованиями значений в ячейках. Например, цифровую модель высот в футах можно перевести в цифровую модель высот в метрах. Для этого нужно значение в каждой ячейке умножить на \\(0.3048\\). В локальных операциях могут участвовать несколько растров. Например, если у нас есть растровые поверхности плотности населения за разные года, мы можем вычесть одну поверхность из другой, чтобы получить поверхность изменений плотности, выяснить где она увеличилась, уменьшилась или осталось прежней. К локальным операциям относится также оверлей растров, при котором получается взвешенная сумма значений по нескольким растрам. И в том и в другом случае анализируются ячейки с нескольких растров, которые совпадают в пространстве. В качестве примера определим мощность покровного оледенения в Антарктике и Гренландии, путем вычитание двух моделей ETOPO1, одна из которых показывает рельеф коренных пород (bedrock), а вторая — видимый рельеф поверхности (ice surface): # ЛОКАЛЬНЫЕ ОПЕРАЦИИ # Вычисление толщины покровного оледенения # Чтение данных bed = raster(&#39;data/etopo1_bed.tif&#39;) ice = raster(&#39;data/etopo1_ice.tif&#39;) countries = st_read(&#39;data/countries.gpkg&#39;) ## Reading layer `admin_0_map_units&#39; from data source `/Users/tsamsonov/GitHub/r-geo-course/data/countries.gpkg&#39; using driver `GPKG&#39; ## Simple feature collection with 183 features and 72 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: -180 ymin: -90 xmax: 180 ymax: 83.64513 ## epsg (SRID): 4326 ## proj4string: +proj=longlat +datum=WGS84 +no_defs borders = countries %&gt;% st_geometry() # отображение данных classes = classIntervals(values(bed), 20) brks = classes$brks nclass = length(brks) - 1 plot(bed, breaks = brks, col = gray.colors(nclass), main = &#39;ETOPO Bedrock&#39;, legend = F) plot(ice, breaks = brks, col = gray.colors(nclass), main = &#39;ETOPO Ice surface&#39;, legend = F) # вычисление разности ice.depth = ice - bed plot(ice.depth, col = cm.colors(255), main = &#39;Мощность покровного оледенения&#39;) plot(borders, border = &#39;black&#39;, lwd = 0.5, add = TRUE) # сделаем пустыми все ячейки, в которых толщина льда равна нулю ice.depth[ice.depth == 0] = NA plot(ice.depth, col = cm.colors(255), main = &#39;Мощность покровного оледенения&#39;) plot(borders, border = &#39;black&#39;, lwd = 0.5, add = TRUE) 12.2.2 Фокальные операции В фокальных операциях участвует не только сама ячейка или совпадающие с ней ячейки других растров, но также ячейки, находящиеся в некоторой окрестности (опять же, в одном или нескольких растрах одновременно). Данный вид анализа подразделяется на две категории: фокальный анализ с фиксированной окрестностью и с расширенной окрестностью. 12.2.2.1 Фиксированная окрестность В общем случае фиксированная окрестность может иметь различную форму, однако наиболее часто используется квадратная окрестность размером \\(3\\times3\\): Виды растровых окрестностей. Темной точкой выделена анализируемая ячейка Фокальные операции с фиксированной окрестностью — привычное дело в обработке изображений. Они работают по принципу “плавающего окна”. Выбранная окрестность (квадратная, круглая и т.д.) представляется в виде матрицы коэффициентов — так называемого ядра свёртки (convolution kernel). Далее эта матрица перемещается, позиционируясь последовательно над каждой ячейкой растра, и значение в этой ячейке заменяется на взвешенную сумму значений ячеек в окрестности, умноженных на соответствующие коэффициенты ядра свертки. Например, если ядро состоит из единиц, то будет посчитана обычная сумма. С помощью фокального анализа можно выполнить сглаживание изображения, которое убирает из него мелкие детали (высокочастотные составляющие яркостного сигнала). В качестве такого изображения может быть цифровая модель рельефа или космический снимок. Чтобы выполнить сглаживание, коэффициенты должны быть такими, чтобы получаемая взвешенная сумма осредняла значения в соседних ячейках. Самый простой вариант — это рассчитать среднее арифметическое. В этом случае коэффициенты ядра свертки будут равны \\(1/k\\), где \\(k\\) — количество ячеек в окрестности. Для матрицы \\(3\\times3\\) они будут равны, соответственно \\(1/9\\): # ФОКАЛЬНЫЕ ОПЕРАЦИИ # Вырежем кусок из ЦМР dem = crop(ice, extent(-120, -75, 10, 40)) spplot(dem) # Среднее wgt = matrix(c(1, 1, 1, 1, 1, 1, 1, 1, 1) / 9, nrow = 3) # на самом деле проще написать так: # wgt = matrix(1/9, 3, 3), но полная форма записана для наглядности # выполним обработку ЦМР с помощью фокального фильтра filtered = focal(dem, w = wgt) spplot(stack(dem, filtered), names.attr=c(&#39;Исходный рельеф&#39;, &#39;Сглаживание средним&#39;)) Более мягким эффектом сглаживания, который к тому же не нарушает дифференцируемость поверхности, является гауссово сглаживание. Коэффициенты в матрице Гаусса убывают от центральной ячейки к краям матрицы по закону Гаусса-Лапласа, что позволяет придать центральной ячейке более высокий вес по сравнению с ячейками, располагающимися на краю анализируемой окрестности: # Гауссово (параметр 0.5 - это стандартное отклонение в единицах измерения растра) wgt = focalWeight(dem, 0.5, &quot;Gauss&quot;) filtered = focal(dem, wgt) spplot(stack(dem, filtered), names.attr=c(&#39;Исходный рельеф&#39;, &#39;Гауссово сглаживание&#39;)) Еще одна интересная область применения фильтрации — это обнаружение границ (change detection). Границы на изображении возникают в тех местах, где его яркость резко меняет свое значение (в одном или нескольких каналах). Например, на фотографии контур лица может быть распознан по перепаду яркости между его изображением и фоном (если он имеет существенно отличный цвет). Поскольку перепад яркости соответствует экстремальным значениям производной поверхности (отрицательным или положительным), его также можно определить путем фокального анализа, а затем отсечь ячейки растра, в которых значение этой производной по модулю превышает заданный порог (то есть, имеет необходимый контраст). Рассмотрим, как можно выделить уступы континентального склона океана путем применения фильтра Собеля для выделения границ: # Матрица Собеля: wgt = matrix(c(1, 2, 1, 0, 0, 0, -1,-2,-1) / 4, nrow=3) filtered = focal(dem, wgt) # Это поверхность производных: plot(filtered, col = gray.colors(128), main = &#39;Производная поверхности&#39;) # Отберем все ячейки, обладающие высокими значениями производных faults = (filtered &lt; -1500) | (filtered &gt; 1500) faults[faults == 0] = NA # Визуализируем результат plot(dem, col = rev(rainbow(20)), main = &#39;Уступы континентального склона&#39;, legend = FALSE) plot(faults, col = &#39;black&#39;, legend = FALSE, add = TRUE) Еще один распространенный случай использования фокальных операций — это морфометрический анализ поверхностей. Квадратная окрестность \\(3\\times3\\) вокруг каждой ячейки формирует локальную поверхность, производные которой дают представление об уклоне, экспозиции и прочих морфометрических параметрах. Их можно вычислить с помощью функции terrain() из пакета raster: # Морфометрия рельефа — фиксированное соседство dem = raster(&#39;data/dem_fergana.tif&#39;) spplot(dem) # углы наклона slope = terrain(dem, opt = &#39;slope&#39;, unit = &#39;degrees&#39;) spplot(slope, col.regions = heat.colors(20), names.attr=c(&#39;Углы наклона&#39;)) # экспозиция aspect = terrain(dem, opt = &#39;aspect&#39;, unit = &#39;degrees&#39;) spplot(aspect, col.regions = rainbow(20), names.attr=c(&#39;Экспозиции склона&#39;)) Вычисление производных поверхности позволяет не только исследовать рельеф, но также строить его изображения. Например, хорошо знакомую всем по картам аналитическую отмывку рельефа (hillshade). Яркость поверхности в этом способе изображения зависит от угла между направлением на источник освещения (откуда светит Солнце) и нормалью к поверхности. Нормаль можно вычислить как напрямую через производные поверхности, так и восстановить на основе значений угла наклона и экспозиции в точке, что и используется в пакете raster. Обратите внимание на то, что для того чтобы повысить наглядность (контрастность) изображения, мы умножаем высоты рельефа на 20. Это стандартная практика для мелкомасштабных карт: # отмывка slope2 = terrain(dem * 20, opt = &#39;slope&#39;) aspect2 = terrain(dem * 20, opt = &#39;aspect&#39;) # параметры angle и direction функции hillShade определяют азимут и высоту источника освещения: hill = hillShade(slope2, aspect2, angle = 45, direction = 315) plot(hill, col = gray.colors(128), main = &#39;Отмывка рельефа&#39;) 12.2.2.2 Расширенная окрестность Расширенность окрестности означает, что она определяется не фиксированным шаблоном, а условием, которое должно выполниться для того, чтобы анализ в ячейке считался выполненным. Типичный пример анализа на основе расширенной окрестности — это операции, основанные на вычислении расстояний на растровой матрице, такие как аллокация, определение кратчайшего пути на поверхности сопротивления, и собственно, само вычисление расстояние. В мелкомасштабных тематических атласах часто можно встретить карты доступности той или иной географической локации, которые в форме изолиний показывают время движения до ближайшего населенного пункта. Эти изолинии можно построить по растровой поверхности, в каждой ячейке которой зафиксировано расстояние до ближайшего населенного пункта. Рассмотрим построение аналогичной поверхности на примере доступности станций метро (по расстоянию). Для этого нам понадобится представить растр в виде матрицы точек, рассчитать для этих точек расстояния до ближайших станций метро и присвоить эти значения выходному растру: # Определение Евклидовых расстояний — расширенное соседство # Чтение данных roads = st_read(&quot;data/roads.gpkg&quot;) # Дороги ## Reading layer `roads&#39; from data source `/Users/tsamsonov/GitHub/r-geo-course/data/roads.gpkg&#39; using driver `GPKG&#39; ## Simple feature collection with 2213 features and 12 fields ## geometry type: MULTILINESTRING ## dimension: XY ## bbox: xmin: 410946.9 ymin: 6176676 xmax: 415890.8 ymax: 6181910 ## epsg (SRID): 32637 ## proj4string: +proj=utm +zone=37 +datum=WGS84 +units=m +no_defs poi = st_read(&quot;data/poi_point.gpkg&quot;) # Точки интереса ## Reading layer `poi_point&#39; from data source `/Users/tsamsonov/GitHub/r-geo-course/data/poi_point.gpkg&#39; using driver `GPKG&#39; ## Simple feature collection with 6623 features and 9 fields ## geometry type: POINT ## dimension: XY ## bbox: xmin: 410947.3 ymin: 6176678 xmax: 415889.9 ymax: 6181909 ## epsg (SRID): 32637 ## proj4string: +proj=utm +zone=37 +datum=WGS84 +units=m +no_defs rayons = st_read(&quot;data/boundary_polygon.gpkg&quot;) # Границы районов ## Reading layer `boundary_polygon&#39; from data source `/Users/tsamsonov/GitHub/r-geo-course/data/boundary_polygon.gpkg&#39; using driver `GPKG&#39; ## Simple feature collection with 11 features and 5 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: 410946.9 ymin: 6176676 xmax: 415890.8 ymax: 6181910 ## epsg (SRID): 32637 ## proj4string: +proj=utm +zone=37 +datum=WGS84 +units=m +no_defs stations = st_read(&quot;data/metro_stations.gpkg&quot;) # Станции метро ## Reading layer `metro_stations&#39; from data source `/Users/tsamsonov/GitHub/r-geo-course/data/metro_stations.gpkg&#39; using driver `GPKG&#39; ## Simple feature collection with 45 features and 3 fields ## geometry type: POINT ## dimension: XY ## bbox: xmin: 411007.5 ymin: 6176747 xmax: 415852.2 ymax: 6181892 ## epsg (SRID): 32637 ## proj4string: +proj=utm +zone=37 +datum=WGS84 +units=m +no_defs water = st_read(&quot;data/water_polygon.gpkg&quot;) # Водные объекты ## Reading layer `water_polygon&#39; from data source `/Users/tsamsonov/GitHub/r-geo-course/data/water_polygon.gpkg&#39; using driver `GPKG&#39; ## Simple feature collection with 8 features and 7 fields ## geometry type: POLYGON ## dimension: XY ## bbox: xmin: 411595.6 ymin: 6176676 xmax: 415890.8 ymax: 6180765 ## epsg (SRID): 32637 ## proj4string: +proj=utm +zone=37 +datum=WGS84 +units=m +no_defs # Создаем пустой растр с охватом, равным охвату станции dist_grid = stations %&gt;% st_bbox() %&gt;% st_as_stars(dx = 25, dy = 25) %&gt;% transmute(dist = st_as_sf(., as_points = TRUE, merge = FALSE) %&gt;% st_distance(stations, .) %&gt;% apply(2, min)) # Визуализируем результат ggplot() + geom_stars(data = dist_grid) + scale_fill_gradientn(colours = c(&#39;white&#39;, &#39;red&#39;, &#39;black&#39;)) + coord_sf(crs = st_crs(stations)) + geom_sf(data = water, size = 0.1) + geom_sf(data = roads, size = 0.1) + geom_sf(data = stations) + ggtitle(&#39;Расстояние до ближайшей станции метро&#39;) + theme_bw() 12.2.3 Зональные операции Зональные операции связаны с агрегированием растровых данных по площадным зонам. В пределах каждой зоны вычисляется одна или несколько характеристик значений анализируемого растра: среднее, максимум и т.д. Как правило, зоны задаются в виде вспомогательного растрового или векторного набора данных. В случае растра каждая ячейка должна содержать идентификатор (номер) зоны, к которой она относится. Совокупность ячеек, имеющих одинаковый идентификатор, определяет территорию, которую покрывает зона с этим идентификатором. Если зоны представлены векторным набором пространственных объектов, то каждый объект (полигон) также должен иметь собственный идентификатор. Теоретически в одном наборе данных может быть несколько пространственно не связанных объектов, относящихся к одной зоне (например, зона экваториального климата состоит из трех ареалов). В этом случае агрегирование данных будет произведено сразу по трем полигонам. Таким образом, количество получаемых в результате зональной статистики значений определяется количеством зон, но может не совпадать с общим количеством полигонов, которыми эти зоны представлены. В качестве примера рассмотрим вычисление среднеклиматических параметров WorldClim в пределах различных типов земельного покрова (Land Cover), которые доступны в пакете tmap: temp_stars = raster::getData(&quot;worldclim&quot;, var = &quot;tmean&quot;, res = 10) %&gt;% st_as_stars() / 10 plot(temp_stars) data(land, package = &#39;tmap&#39;) types = land@data@attributes land_stars = land %&gt;% st_as_stars() %&gt;% split(&#39;band&#39;) %&gt;% mutate(cover = factor(cover, levels = types[[1]]$ID, labels = types[[1]]$cover), cover_cls = factor(cover, levels = types[[2]]$ID, labels = types[[2]]$cover)) # таблица типов земельного покрова и их идентификаторов в растре pal = c(&quot;#003200&quot;, &quot;#3C9600&quot;, &quot;#006E00&quot;, &quot;#556E19&quot;, &quot;#00C800&quot;, &quot;#8CBE8C&quot;, &quot;#467864&quot;, &quot;#B4E664&quot;, &quot;#9BC832&quot;, &quot;#EBFF64&quot;, &quot;#F06432&quot;, &quot;#9132E6&quot;, &quot;#E664E6&quot;, &quot;#9B82E6&quot;, &quot;#B4FEF0&quot;, &quot;#646464&quot;, &quot;#C8C8C8&quot;, &quot;#FF0000&quot;, &quot;#FFFFFF&quot;, &quot;#5ADCDC&quot;) ggplot() + geom_stars(data = land_stars[&#39;cover&#39;]) + scale_fill_manual(values = pal, guide = guide_legend(ncol = 3), name = NULL) + coord_sf(crs = st_crs(land_stars)) + theme(legend.position = &#39;bottom&#39;) Оператор @ означает обращение к слоту объекта. Слоты представляют собой объекты, являющиеся внутри других объектов, являющихся экземплярами классов S4. Предварительно необходимо убедиться, что оба растра имеют совпадающий охват (экстент) и пространственное разрешение. Обратите внимание на то, что, поскольку растр земельного покрова категориальный, для его передискретизации необходимо использовать метод ближайшего соседа (Nearest Neighbor), который для каждого пиксела нового растра берет значение в ближайшем к нему пикселе исходного растра: temp_stars ## stars object with 3 dimensions and 1 attribute ## attribute(s), summary of first 100000 cells: ## tmean1 ## Min. :-42.10 ## 1st Qu.:-34.08 ## Median :-30.85 ## Mean :-31.99 ## 3rd Qu.:-29.50 ## Max. :-27.80 ## NA&#39;s :98298 ## dimension(s): ## from to offset delta refsys point ## x 1 2160 -180 0.166667 +proj=longlat +datum=WGS8... NA ## y 1 900 90 -0.166667 +proj=longlat +datum=WGS8... NA ## band 1 12 NA NA NA NA ## values ## x NULL [x] ## y NULL [y] ## band tmean1,...,tmean12 land_stars ## stars object with 2 dimensions and 4 attributes ## attribute(s): ## cover cover_cls ## Water bodies :393060 Forest : 0 ## Snow / Ice : 61986 Other natural vegetation : 0 ## Herbaceous : 21377 Cropland : 0 ## Tree Open : 16171 Wetland : 0 ## Sparse vegetation: 12247 Bare area/Sparse vegetation: 0 ## Cropland : 11658 (Other) : 0 ## (Other) : 66701 NA&#39;s :583200 ## trees elevation ## Min. : 0.0 Min. :-412 ## 1st Qu.: 0.0 1st Qu.: 218 ## Median : 0.0 Median : 608 ## Mean : 15.6 Mean :1140 ## 3rd Qu.: 19.0 3rd Qu.:1941 ## Max. :100.0 Max. :6410 ## NA&#39;s :393060 NA&#39;s :389580 ## dimension(s): ## from to offset delta refsys point values ## x 1 1080 -180 0.333333 +proj=longlat +datum=WGS8... NA NULL [x] ## y 1 540 90 -0.333333 +proj=longlat +datum=WGS8... NA NULL [y] (cover_stars = st_warp(land_stars[&#39;cover&#39;], temp_stars %&gt;% slice(band, 1), method = &#39;near&#39;)) ## stars object with 2 dimensions and 1 attribute ## attribute(s), summary of first 100000 cells: ## cover ## Water bodies :98596 ## Snow / Ice : 996 ## Sparse vegetation : 400 ## Bare area,consolidated (gravel,rock): 8 ## Broadleaf Evergreen Forest : 0 ## Broadleaf Deciduous Forest : 0 ## (Other) : 0 ## dimension(s): ## from to offset delta refsys point values ## x 1 2160 -180 0.166667 +proj=longlat +datum=WGS8... NA NULL [x] ## y 1 900 90 -0.166667 +proj=longlat +datum=WGS8... NA NULL [y] # используем &#39;near&#39;, поскольку растр категориальный Для вычисления средней температуры за каждый месяц в пределах каждой зоны земельного покрова выполним следующую последовательность действий: months = 1:12 cover_types = levels(cover_stars$cover) zonal_stats = lapply(cover_types, function(X) { sapply(months, function(Y) { temp_month = temp_stars %&gt;% slice(band, Y) %&gt;% pull(1) cover_stars %&gt;% transmute(masked = ifelse(cover == X, temp_month, NA)) %&gt;% pull(masked) %&gt;% mean(na.rm = TRUE) }) }) %&gt;% bind_cols() %&gt;% set_names(cover_types) %&gt;% mutate(month = months) %&gt;% pivot_longer(-month, names_to = &#39;cover&#39;, values_to = &#39;tmean&#39;) Визуализируем полученные результаты: ggplot(zonal_stats) + geom_line(aes(x = month, y = tmean, color = cover), size = 1) + scale_color_manual(values = pal) + scale_x_continuous(breaks = months) Перед вычислением целесообразно разделить растр землепользования на северное и южное полушарие (т.к. ход температур в них противоположный): cover_north = crop(cover, extent(-180, 180, 0, 90)) cover_south = crop(cover, extent(-180, 180, -60, 0)) temp_north = crop(temp, extent(-180, 180, 0, 90)) temp_south = crop(temp, extent(-180, 180, -60, 0)) mtemp_north_tidy = zonal(temp_north, cover_north, &#39;mean&#39;) %&gt;% as_tibble() %&gt;% left_join(tbl[[1]], by = c(&#39;zone&#39; = &#39;ID&#39;)) %&gt;% gather(month, tmean, tmean1:tmean12) %&gt;% separate(month, c(&#39;dummy&#39;, &#39;month&#39;), sep = 5) %&gt;% mutate(month = as.integer(month), hemisphere = &#39;north&#39;) %&gt;% dplyr::select(-COUNT, -dummy) mtemp_south_tidy = zonal(temp_south, cover_south, &#39;mean&#39;) %&gt;% as_tibble() %&gt;% left_join(tbl[[1]], by = c(&#39;zone&#39; = &#39;ID&#39;)) %&gt;% gather(month, tmean, tmean1:tmean12) %&gt;% separate(month, c(&#39;dummy&#39;, &#39;month&#39;), sep = 5) %&gt;% mutate(month = as.integer(month), hemisphere = &#39;south&#39;) %&gt;% dplyr::select(-COUNT, -dummy) mtemp_tidy2 = bind_rows(mtemp_north_tidy, mtemp_south_tidy) ggplot(mtemp_tidy2) + geom_line(aes(x = month, y = tmean, color = cover), size = 1) + scale_color_manual(values = pal) + scale_x_continuous(breaks = 1:12) + facet_wrap(~hemisphere, ncol = 1) 12.2.4 Глобальные операции Глобальные операции охватывают все ячейки растра. По сути, можно говорить, что это частный случай зональной операции, когда зона одна и покрывает растр целиком. В пакете raster для расчета глобальных статистик можно использовать функцию cellStats(), передав ей название растра и агрегирующей функции: cellStats(temp_north, max) cellStats(temp_south, min) 12.3 Извлечение данных Растровая модель данных обеспечивает сплошное покрытие территории (с дискретностью, определяемой размером ячейки). В то же время, достаточно часто требуется получить значения растра в заданных местоположениях. Местоположения могут быть как конкретными объектами (например, точками почвенных разрезов), так и абстрактными географическими локациями, для которых известны координаты. Для извлечения растровых данных можно воспользоваться функцией extract(). Получать данные можно как по координатам (записанным в фрейм данных), так и используя пространственные объекты класса Spatial. Например, узнаем мощность покровного оледенения в точке в центре Гренландии: coords = data.frame(x = -45, y = 70) z = raster::extract(ice.depth, coords) plot(bed, breaks = brks, col = gray.colors(nclass), legend = F) plot(ice.depth, col = cm.colors(255), add = TRUE) points(coords) text(coords, labels = z, pos = 4) Одна из наиболее распространенных задач по извлечению растровых данных — это построение профиля вдоль заданной линии. Воспользуемся интерактивным редактором для проведения линии профиля mp = mapview(temp$tmean6) profile = mapedit::drawFeatures(mp) temprof = raster::extract(temp$tmean6, as(profile, &#39;Spatial&#39;), along = TRUE, cellnumbers = TRUE) head(temprof[[1]]) Для построения линии профиля далее нам необходимо преобразовать идентификаторы ячеек растра в расстояние от начала профиля: tempdf = temprof[[1]] %&gt;% as_tibble() %&gt;% bind_cols(xyFromCell(temp, .$cell) %&gt;% as_tibble()) %&gt;% mutate(dist = 0.001 * c(0, dplyr::select(., x, y) %&gt;% geosphere::distGeo() %&gt;% cumsum() %&gt;% head(-1))) pts = profile %&gt;% st_cast(&#39;POINT&#39;) %&gt;% mutate(label = c(&#39;A&#39;, &#39;B&#39;)) tm_shape(temp) + tm_raster(&#39;tmean6&#39;, midpoint = 0, palette = &#39;-RdBu&#39;) + tm_shape(profile) + tm_lines() + tm_shape(pts) + tm_bubbles(size = 0.1) + tm_text(&#39;label&#39;, remove.overlap = TRUE, auto.placement = TRUE) + tm_layout(legend.position = c(&#39;left&#39;, &#39;bottom&#39;)) ggplot(tempdf, aes(x = dist, y = tmean6)) + geom_line() + geom_smooth(span = 0.1) + annotate(&#39;text&#39;, x = 0, y = 10, label = &#39;A&#39;) + annotate(&#39;text&#39;, x = max(tempdf$dist), y = 10, label = &#39;B&#39;) + ggtitle(&#39;Профиль среднемесячной температуры июня по линии A—B&#39;) 12.4 Контрольные вопросы и упражнения 12.4.1 Вопросы Дайте описание локальных, фокальных, зональных и глобальных операций растровой алгебры. Приведите примеры использования данных типов операций. Каким требованиям должна отвечать геометрия растров, участвующих в локальных и зональных операциях? В чем заключается отличие фокальных операций с фиксированной и расширенной окрестностью? Чем отличается геометрия растра до и после применения фокальной операции? Какая функция пакета raster реализует возможности фокальной обработки растров? Какой эффект оказывает сглаживающая фильтрация на значения растра? Какие виды производных морфометрических величин позволяет получать функция terrain() из пакета raster? Какие два растра необходимо рассчитать для построения аналитической отмывки средствами функции terrain()? Опишите последовательность действий, которую необходимо выполнить для построения растра Евклидовых расстояний от заданных объектов? Какой метод интерполяции необходимо использовать для передискретизации категориальных растров? В чем заключается принцип его действия? Какая функция пакета raster используется для выполнения зональных операций? Какой тип результата она возвращает? Опишите возможности функции extract() по извлечению информации из растровых данных. В какой формате можно задать анализируемые локации? Что будет результатом вызова этой функции в зависимости от формата входных данных? Опишите последовательность действий, которую необходимо выполнить для построения профиля растровой поверхности средствами R. Можно ли построить профиль по растру, имеющему привязку в географической системе координат (координаты выражены градусах)? Если да, то как добиться того, чтобы расстояния между точками профиля были посчитаны в метрических единицах? 12.4.2 Упражнения В пакете tmap содержится растровый каталог land, включающий в себя растр elevation. Используя пакет mapedit, оцифруйте произвольную линию и постройте средствами ggplot профиль рельефа вдоль этой линии. Индекс континентальности Хромова рассчитывается по формуле \\(K = (A - 5.4 \\sin \\phi)/A\\), где \\(A\\) — годовая амплитуда хода температуры, \\(\\phi\\) — широта точки. Используя данные WorldClim, рассчитайте растр индекса континентальности на территорию суши и нанесите его на карту средствами tmap. Подсказка: используйте функцию xyFromCell(), чтобы получить широты всех ячеек растра температур. Далее создайте новый растр и запишите в него широты в качестве значений. Растры минимальных и максимальных значений из стека растров можно получить, используя обычные статистические функции min() и max(). Постройте растр, который содержит расстояние до береговой линии. Используйте данные Natural Earth. Задайте грубое разрешение растра, чтобы расчеты не производились долго (100 x 50 ячеек будет достаточно). Где находится самая удаленная от берега точка на суше? А самая удаленная точка на океане? Постройте карту, которая отображает полученный растр и береговую линию. Рассчитайте морфометрические коэффициенты TPI, TRI и roughness для цифровой модели рельефа Ферганской долины, которая использовалась в текущей лекции. В чем их суть? Изучите справку к инструменту terrain(). Самсонов Т.Е. Визуализация и анализ географических данных на языке R. М.: Географический факультет МГУ, lubridate::year(Sys.Date()). DOI: 10.5281/zenodo.901911 References "],
["interpolation-deterministic.html", "Глава 13 Моделирование геополей 13.1 Введение 13.2 Построение сетки 13.3 Интерполяционные методы 13.4 Аппроксимационные методы 13.5 Интерполяция по ареалам 13.6 Краткий обзор 13.7 Контрольные вопросы и упражнения", " Глава 13 Моделирование геополей Программный код главы В лекции рассмотрены детерминистические методы восстановления непрерывных поверхностей по данным в точках. Детерминистические методы интерполяции производят интерполяцию значений на основе заданной аналитической зависимости между значением в точке и значениями в пунктах с исходными данными. Это отличает их от методов геостатистических, где эта зависимость находится статистическим путем. Геостатистические методы будут рассмотрены далее. 13.1 Введение Интерполяция в общем случае — это способ нахождения промежуточных значений величины по имеющемуся дискретному набору известных значений. В географии обычно имеют дело с двумерным случаем интерполяции — когда измерения проведены в некоторых географических локациях, и по ним нужно восстановить непрерывную картину поля распределения величины. В общем случае неизвестно, как ведет себя исследуемое явление между точками, поэтому существует бесчисленное множество вариантов интерполяции. Методы которые производят интерполяцию на основе заданной аналитической зависимости, называют детерминистическими. Параметры этой зависимости могут быть как априори заданы пользователем, так и определяться автоматически одним из методов оптимизации — в частности, по методу наименьших квадратов. Например, мы можем сказать, что между соседними точками показатель меняется линейным образом (здесь нужно еще указать, что мы понимаем под соседством). Такие методы достаточно просты в использовании и интерпретации. В то же время, они не учитывают статистических особенностей поведения величины между точками, которое определяется ее автокорреляционными свойствами. Методы интерполяции, которые учитывают пространственную автокорреляцию, называют геостатистическими. Они более сложны в использовании, но потенциально могут дать более достоверные результаты. В этом модуле мы познакомимся со следующими детерминистическими методами интерполяции. Метод ближайшего соседа (nearest neighbor) Метод интерполяции на основе триангуляции Метод обратно взвешенных расстояний (ОВР) Метод радиальных базисных функций (РБФ) Метод иерархических базисных сплайнов (ИБС) Интерполяцию будем рассматривать на примере данных по количеству осадков на метеостанциях в северной Италии (долина реки По и окружающие горы). Станции распределены в пространстве нерегулярно, что позволит визуально оценить чувствительность методов к этому фактору. Прежде чем исследовать распределение показателя, необходимо проанализировать географический контекст. В этой части модуля мы воспользуемся уже известными функциями чтобы создать карту с общегеографической основой и нанести на нее пункты метеонаблюдений. library(sf) library(stars) library(tmap) library(raster) library(plotly) library(mapview) library(tidyverse) library(ggrepel) library(dismo) # библиотека species distribution modelling library(akima) # библиотека для интерполяции на основе триангуляции library(gstat) # библиотека для геостатистической интерполяции, построения трендов и IDW library(deldir) # библиотека для построения триангуляции Делоне и диаграммы Вороного library(fields) # радиальные базисные функции (сплайны минимальной кривизны) library(MBA) # иерархические базисные сплайны # Убираем экспоненциальное представление больших чисел options(scipen=999) # Читаем слои картографической основы cities = st_read(&quot;data/Italy_Cities.gpkg&quot;) %&gt;% # Города bind_cols(st_coordinates(.) %&gt;% as_tibble()) ## Reading layer `Italy_Cities&#39; from data source `/Users/tsamsonov/GitHub/r-geo-course/data/Italy_Cities.gpkg&#39; using driver `GPKG&#39; ## Simple feature collection with 8 features and 37 fields ## geometry type: POINT ## dimension: XY ## bbox: xmin: 368910.4 ymin: 4930119 xmax: 686026 ymax: 5115936 ## epsg (SRID): 32632 ## proj4string: +proj=utm +zone=32 +datum=WGS84 +units=m +no_defs rivers = st_read(&quot;data/Italy_Rivers.gpkg&quot;) # Реки ## Reading layer `Italy_Rivers&#39; from data source `/Users/tsamsonov/GitHub/r-geo-course/data/Italy_Rivers.gpkg&#39; using driver `GPKG&#39; ## Simple feature collection with 23 features and 10 fields ## geometry type: MULTILINESTRING ## dimension: XY ## bbox: xmin: 332178.5 ymin: 4922880 xmax: 758033.3 ymax: 5121416 ## epsg (SRID): 32632 ## proj4string: +proj=utm +zone=32 +datum=WGS84 +units=m +no_defs lakes = st_read(&quot;data/Italy_Lakes.gpkg&quot;) # Озера ## Reading layer `Italy_Lakes&#39; from data source `/Users/tsamsonov/GitHub/r-geo-course/data/Italy_Lakes.gpkg&#39; using driver `GPKG&#39; ## Simple feature collection with 6 features and 13 fields ## geometry type: POLYGON ## dimension: XY ## bbox: xmin: 460686.2 ymin: 4938750 xmax: 757443.7 ymax: 5113557 ## epsg (SRID): 32632 ## proj4string: +proj=utm +zone=32 +datum=WGS84 +units=m +no_defs # Читаем ЦМР — цифровую модель рельефа на регулярной сетке dem = read_stars(&quot;data/gtopo.tif&quot;) # Читаем данные об осадках pts = read_table2(&quot;data/Rainfall.dat&quot;) %&gt;% st_as_sf(coords = c(&#39;x&#39;, &#39;y&#39;), crs = st_crs(cities), remove = FALSE) # Координаты пригодятся нам в дальнейшем coords = st_coordinates(pts) Построение карты # Цветовая шкала для рельефа dem_colors = colorRampPalette(c(&quot;darkolivegreen4&quot;, &quot;lightyellow&quot;, &quot;orange&quot;, &quot;firebrick&quot;)) # Шкала высот для рельефа dem_levels = c(0, 50, 100, 200, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 5000) dem_ncolors = length(dem_levels) - 1 dem_contours = st_contour(dem, breaks = dem_levels, contour_lines = TRUE) old = theme_set(theme_bw()) # Смотрим как выглядит результат ggplot() + geom_stars(data = cut(dem, breaks = dem_levels)) + coord_sf(crs = st_crs(dem)) + scale_fill_manual(name = &#39;м&#39;, values = dem_colors(dem_ncolors), labels = dem_levels, na.translate = FALSE, guide = guide_legend(label.vjust = -0.3, reverse = TRUE)) + geom_sf(data = dem_contours, color = &#39;black&#39;, size = 0.2) + geom_sf(data = rivers, color = &#39;midnightblue&#39;, size = 0.2) + geom_sf(data = lakes, color = &#39;midnightblue&#39;, fill = &#39;lightblue&#39;, size = 0.2) + geom_sf(data = pts, color = &#39;black&#39;, size = 0.5) + geom_sf(data = cities, shape = 21, fill = &#39;white&#39;) + geom_text_repel(data = cities, mapping = aes(x = X, y = Y, label = name), box.padding = 0.2) 13.2 Построение сетки Любопытным свойством пакетов R, отвечающих за интерполяцию данных, является их индифферентность относительно того, в каких точках эта интерполяция будет производиться. Это может быть как регулярная растровая сетка, так и множество точек в совершенно произвольных конфигурациях. Подобная гибкость делает процесс интерполяции данных чуть более сложным, чем в ГИС-пакетах, однако способствует полному и глубокому пониманию происходящего. Вы своими руками задаете пункты, в которых следует интерполировать значения. Для построения сетки воспользуемся функцией st_as_stars() из пакета stars, передав ей ограничивающий прямоугольник исходного множества точек и разрешение сетки: # ПОСТРОЕНИЕ СЕТКИ ДЛЯ ИНТЕРПОЛЯЦИИ # получим ограничивающий прямоугольник вокруг точек: box = st_bbox(pts) envelope = box[c(1,3,2,4)] px_grid = st_as_stars(box, dx = 10000, dy = 10000) ggplot() + geom_sf(data = pts, color = &#39;red&#39;) + geom_sf(data = st_as_sf(px_grid), size = 0.5, fill = NA) Получившееся представление можно назвать сеточной моделью. В пределах каждой ячейки величина будет считаться постоянной. Ее значение будет интерполировано в центре пиксела. Можно видеть, что интерполяционная сетка слегка выходит за пределы исходного охвата множества точек. Это связано с тем, что размеры прямоугольника, ограничивающего множество точек, не кратны выбранному разрешению растра (\\(10 000\\) м). Проблема, однако, не столько критична, если вы выбираете достаточно подробное (малое) разрешение растра, что мы и сделаем. Зададим его равным \\(1 000\\) м: # создадим детальную растровую сетку px_grid = st_as_stars(box, dx = 1000, dy = 1000) # извлечем координаты точек в соответствующие столбцы, они нам пригодятся: coords_grid = st_coordinates(px_grid) 13.3 Интерполяционные методы # Цветовая шкала для осадков rain_colors = colorRampPalette(c(&quot;white&quot;, &quot;dodgerblue&quot;, &quot;dodgerblue4&quot;)) # Шкала количества осадков и соответствющее число цветов rain_levels = seq(0, 80, by=10) rain_ncolors = length(rain_levels)-1 rain_legend = scale_fill_manual(name = &#39;мм&#39;, values = rain_colors(rain_ncolors), guide = guide_legend(label.vjust = -0.3, reverse = TRUE, title.position = &quot;bottom&quot;), labels = rain_levels, na.value = &#39;white&#39;, drop = FALSE) rain_mapping = aes(fill = cut(rain_24, breaks = rain_levels)) 13.3.1 Метод ближайшего соседа (nearest neighbour) Данный метод является простейшим по сути подходом к интерполяции. В его основе лежит построение диаграммы Вороного исходного множества точек. Считается, что в пределах каждой ячейки диаграммы значение показателя постоянно и равно значению в центре ячейки. Далее поверх диаграммы накладывается сетка интерполируемых точек и снимаются соответствующие значения: # МЕТОД БЛИЖАЙШЕГО СОСЕДА (NEAREST NEIGHBOR) # Диаграмма Вороного voronoi_sf = voronoi(coords, envelope) %&gt;% st_as_sf() %&gt;% st_set_crs(st_crs(pts)) %&gt;% st_join(pts) # Триангуляция Делоне edges = pts %&gt;% st_union() %&gt;% st_triangulate() # Визуализация ggplot() + geom_sf(data = voronoi_sf, mapping = rain_mapping, size = 0.2) + rain_legend + geom_sf(data = pts, color = &#39;red&#39;, size = 0.5) + geom_sf(data = edges, color = &#39;red&#39;, size = 0.1, fill = NA) Если есть задача конвертировать это в растр, то надо сформировать новый растр и “перенести” на него информацию с полигонов: # Создаем растр rnn = st_rasterize(voronoi_sf[&quot;rain_24&quot;], px_grid) # Визуализируем: ggplot() + geom_stars(data = cut(rnn, breaks = rain_levels)) + rain_legend + coord_sf(crs = st_crs(pts)) Видно, что полученная поверхность уже пиксельная. Для наглядности визуализируем ее в трехмерном виде. Для этого используем замечательный пакет plotly, предоставляющий интерфейс к одноименной библиотеке. Функция plot_ly(), отвечающая за построение графиков в этом пакете, требует для визуализации поверхности предоставить три компоненты: x - вектор координат ячеек по оси \\(Х\\) y - вектор координат ячеек по оси \\(Y\\) z - матрицу значений, имеющую размеры \\(length(x) \\times length(y)\\) Поверхность будет раскрашиваться в различные цвета в зависимости от значений z, для управления цветами можно определить параметр colors, который должен иметь тип colorRamp: rain_colors3d = colorRamp(c(&quot;white&quot;, &quot;dodgerblue&quot;, &quot;dodgerblue4&quot;)) x = coords_grid[,&#39;x&#39;] %&gt;% unique() # Получим координаты столбцов y = coords_grid[,&#39;y&#39;] %&gt;% unique() # Получим координаты строк p = plot_ly(x = x, y = y, z = rnn$rain_24, type = &quot;surface&quot;, colors = rain_colors3d) layout(p, scene = list(aspectratio = list(x = 1, y = 1, z = 0.3) )) Понятное дело, что такая ступенчатая форма поверхности вряд ли соответствует реальному распределению показателя, который меняется в пространстве непрерывным образом. Можно сказать, что это первое приближение пространственного распределения. 13.3.2 Интерполяция на основе триангуляции Интерполяция на основе триангуляции — метод интерполяции, результатом которого является уже не ступенчатая поверхность, а аппроксимированная треугольными гранями — наподобие того как объекты представлены в системах трехмерного моделирования и компьютерных играх. Триангуляция представляет собой поверхность, склеенную из треугольников, соединяющих исходные точки. Каждый треугольник является участком наклонной плоскости. Для выполнения интерполяции на первом этапе необходимо найти уравнение плоскости, которое содержит четыре неизвестных коэффициента: \\[ Ax + By + Cz + D = 0, \\] Коэффициенты \\(A\\), \\(B\\), \\(C\\) и \\(D\\) вычисляются заранее для каждого треугольника и хранятся вместе с триангуляцией. Для вычисления \\(z(x, y)\\) в произвольно заданной точке необходимо определить треугольник, в который попадает точка, и выразить значени искомой величины, используя коэффициенты уравнения плоскости для найденного треугольника: \\[ z(x, y) = -\\frac{1}{C}(Ax+By+D) \\] Также возможно применение бикубической интерполяции, или метода Акимы, который позволяет сгладить поверхность за счет применения полиномов 5-й степени: \\[ z(x, y) = \\sum_{j=0}^5 \\sum_{k=0}^{5-j} q_{jk} x^j y^k \\] # ИНТЕРПОЛЯЦИЯ НА ОСНОВЕ ТРИАНГУЛЯЦИИ (TRIANGULATION) # Интерполируем. Параметр linear говорит о том, что показатель будет меняться вдоль ребер триангуляции линейно: px_grid = px_grid %&gt;% mutate(z_linear = interpp(x = coords[,1], y = coords[,2], z = pts$rain_24, xo = coords_grid[,1], yo = coords_grid[,2], linear = TRUE)$z) cont_linear = st_contour(px_grid[&#39;z_linear&#39;], breaks = rain_levels, contour_lines = TRUE) # Смотрим как выглядит результат ggplot() + geom_stars(data = cut(px_grid[&#39;z_linear&#39;], breaks = rain_levels)) + rain_legend + coord_sf(crs = st_crs(pts)) + geom_sf(data = cont_linear, color = &#39;black&#39;, size = 0.2) + geom_sf(data = pts, color = &#39;red&#39;, size = 0.5) + geom_sf(data = edges, color = &#39;red&#39;, size = 0.1, fill = NA) Обратите внимание, что все изломы (повороты) изолиний происходят на ребрах триангуляции, а внутри треугольников изолинии проходят параллельно друг другу. Каждый треугольник представляет собой фрагмент наклонной плоскости. Такой метод интерполяции, по сути, является самым простым и “честным” подходом, который близок к тому как горизонтали интерполируются вручную. Рассмотрим поверхность в 3D: p = plot_ly(x = x, y = y, z = px_grid$z_linear, type = &quot;surface&quot;, colors = rain_colors3d) layout(p, scene = list(aspectratio = list(x = 1, y = 1, z = 0.3) )) Линейная интерполяция на треугольниках, как можно видеть, выглядит достаточно угловато, хотя и существенно более правдоподобна, нежели ступенчатая поверхность, полученная методом ближайшего соседа. Более гладкий результат можно получить, используя не линейный, а бикубический метод интерполяции на треугольниках. Для этого следует указать параметр linear = FALSE. Помимо этого, параметр extrap = TRUE говорит о том, что можно производить экстраполяцию за пределами выпуклой оболочки точек (такая возможность недоступна в линейном случае) px_grid = px_grid %&gt;% mutate(z_spline = interpp(x = coords[,1], y = coords[,2], z = pts$rain_24, xo = coords_grid[,1], yo = coords_grid[,2], linear = FALSE, extrap = TRUE)$z) cont_spline = st_contour(px_grid[&#39;z_spline&#39;], breaks = rain_levels, contour_lines = TRUE) # Смотрим как выглядит результат ggplot() + geom_stars(data = cut(px_grid[&#39;z_spline&#39;], breaks = rain_levels)) + rain_legend + coord_sf(crs = st_crs(pts)) + geom_sf(data = cont_spline, color = &#39;black&#39;, size = 0.2) + geom_sf(data = pts, color = &#39;red&#39;, size = 0.5) + geom_sf(data = edges, color = &#39;red&#39;, size = 0.1, fill = NA) Полученные изолинии отличаются более плавным и естественным рисунком. Тем не менее, использование триангуляции все еще заметно по фестончатым изгибам изолиний на ребрах. Смотрим наглядное представление поверхности в 3D: p = plot_ly(x = x, y = y, z = px_grid$z_spline, type = &quot;surface&quot;, colors = rain_colors3d) layout(p, scene = list(aspectratio = list(x = 1, y = 1, z = 0.3) )) Можно видеть, что в данном случае получена уже гладкая поверхность, плотно натянутая на ребра триангуляции. 13.3.3 Метод обратно взвешенных расстояний (IDW) В методе обратно взвешенных расстояний значение показателя в произвольной точке получается как средневзвешенная сумма значений в исходных точках. Веса определяются обратно пропорционально расстоянию: чем дальше исходная точка удалена, тем меньший вес она будет иметь в оценке. Формально значение функции в точке определяет согласно следующей формуле: \\[ z(\\mathbf{x}) = \\begin{cases} \\dfrac{\\sum_{i = 1}^{N}{ w_i(\\mathbf{x}) z_i } }{ \\sum_{i = 1}^{N}{ w_i(\\mathbf{x}) } }, &amp; \\text{если } d(\\mathbf{x},\\mathbf{x}_i) \\neq 0 \\text{ для всех } i, \\\\ z_i, &amp; \\text{если } d(\\mathbf{x},\\mathbf{x}_i) = 0 \\text{ хотя бы для одного } i, \\end{cases} \\] где \\(w_i(\\mathbf{x}) = | \\mathbf x - \\mathbf x_i | ^{-p}\\) — весовая функция. Метод реализуется в R с помощью функции idw() из пакета gstat. Основным параметром метода является степень idp =, которая указывает, насколько быстро в зависимости от расстояния будет убывать вес исходной точки. По умолчанию idp = 2. При больших значениях степени (3, 4, 5, …) поверхность становится более платообразной, при меньших — островершинной. Функция idw() принимает 4 параметра: Формула, указывающая название зависимой переменной и независимых переменных Исходные точки Результирующие точки Степень весовой функции idp Формулы полезны в тех случаях, когда известно (или делается предположение), что исследуемый показатель функционально связан с другой величиной. В этом случае запись Z ~ x означает, что сначала будет построена линейная регрессия \\(Z(x)\\) и на основе нее получена грубая оценка показателя в каждой результирующей точке. Интерполяции же будут подвергаться случайные остатки между исходными величинами в точках и теми, что получены по регрессии. Эти остатки добавляются в результирующих точках к оценке, полученной по регрессии. С этой техникой мы познакомимся подробнее в следующем модуле при рассмотрении универсального кригинга. А пока что мы воспользуемся стандартной записью вида Z ~ 1, которая означает, что интерполироваться будет непосредственно исходная величина. В качестве Z надо указать название столбца, содержащего значения показателя. Этот столбец должен находиться в слое с исходными точками, который передается в параметр locations =. Сетка новых точек передается в параметр newdata. Рассмотрим, как меняется вид поверхности при разных значениях idp. Оператор ‘@’ позволяет извлекать слоты из классов S4. К таким классам относятся объекты типа Spatial*, которые мы активно используем в настоящей лекции. Атрибуты в таких объектах хранятся в слоте @data, а координаты — в слоте @coords # МЕТОД ОБРАТНО ВЗЕШЕННЫХ РАССТОЯНИЙ (IDW --- INVERSE DISTANCE WEIGHTED) # Интерполируем количество осадков: px_grid = px_grid %&gt;% mutate(z_idw2 = gstat::idw(rain_24 ~ 1, locations = pts, newdata = px_grid, idp = 2.0)$var1.pred, z_idw3 = gstat::idw(rain_24 ~ 1, locations = pts, newdata = px_grid, idp = 3.0)$var1.pred, z_idw4 = gstat::idw(rain_24 ~ 1, locations = pts, newdata = px_grid, idp = 4.0)$var1.pred, z_idw5 = gstat::idw(rain_24 ~ 1, locations = pts, newdata = px_grid, idp = 5.0)$var1.pred) cont_idw2 = st_contour(px_grid[&#39;z_idw2&#39;], breaks = rain_levels, contour_lines = TRUE) cont_idw3 = st_contour(px_grid[&#39;z_idw3&#39;], breaks = rain_levels, contour_lines = TRUE) cont_idw4 = st_contour(px_grid[&#39;z_idw4&#39;], breaks = rain_levels, contour_lines = TRUE) cont_idw5 = st_contour(px_grid[&#39;z_idw5&#39;], breaks = rain_levels, contour_lines = TRUE) ggplot() + geom_stars(data = cut(px_grid[&#39;z_idw2&#39;], breaks = rain_levels)) + rain_legend + coord_sf(crs = st_crs(pts)) + geom_sf(data = cont_idw2, color = &#39;black&#39;, size = 0.2) + geom_sf(data = pts, color = &#39;red&#39;, size = 0.5) ggplot() + geom_stars(data = cut(px_grid[&#39;z_idw3&#39;], breaks = rain_levels)) + rain_legend + coord_sf(crs = st_crs(pts)) + geom_sf(data = cont_idw3, color = &#39;black&#39;, size = 0.2) + geom_sf(data = pts, color = &#39;red&#39;, size = 0.5) ggplot() + geom_stars(data = cut(px_grid[&#39;z_idw4&#39;], breaks = rain_levels)) + rain_legend + coord_sf(crs = st_crs(pts)) + geom_sf(data = cont_idw4, color = &#39;black&#39;, size = 0.2) + geom_sf(data = pts, color = &#39;red&#39;, size = 0.5) ggplot() + geom_stars(data = cut(px_grid[&#39;z_idw5&#39;], breaks = rain_levels)) + rain_legend + coord_sf(crs = st_crs(pts)) + geom_sf(data = cont_idw5, color = &#39;black&#39;, size = 0.2) + geom_sf(data = pts, color = &#39;red&#39;, size = 0.5) Видно, что метод ОВР формирует вокруг каждой исходной точки замкнутые изолинии, оконтуривающие вершины и впадины на поверхности. Этот эффект является основным недостатком метода и носит название эффекта “бычьих глаз”. Он вызван тем, что производная функции ОВР в каждой точке равняется нулю. При увеличении степени весовой функции происходит расширение зоны влияния каждой точки, поверхности вершин и впадин приобретают платообразный характер. Наглядное представление о характере поверхности, получаемой методом ОВР, дает трехмерная визуализация: p = plot_ly(x = x, y = y, z = px_grid$z_idw3, type = &quot;surface&quot;, colors = rain_colors3d) layout(p, scene = list(aspectratio = list(x = 1, y = 1, z = 0.3) )) Любопытным фактом является то, что при стремлении параметра idp к плюс-бесконечности получаемая поверхность становится все более похожей не результат интерполяции методом ближайшего соседа. А именно этот метод, как мы помним, дает ступенчатую платообразную поверхность. Это легко проверить на практике, задав достаточно большой параметр idp, например \\(30\\): px_grid = px_grid %&gt;% mutate(z_idw30 = gstat::idw(rain_24 ~ 1, locations = pts, newdata = px_grid, idp = 30.0)$var1.pred) ## [inverse distance weighted interpolation] cont_idw30 = st_contour(px_grid[&#39;z_idw30&#39;], breaks = rain_levels, contour_lines = TRUE) ggplot() + geom_stars(data = cut(px_grid[&#39;z_idw30&#39;], breaks = rain_levels)) + rain_legend + coord_sf(crs = st_crs(pts)) + geom_sf(data = cont_idw30, color = &#39;black&#39;, size = 0.2) + geom_sf(data = pts, color = &#39;red&#39;, size = 0.5) + geom_sf(data = voronoi_sf, color = &#39;violet&#39;, fill = NA, size = 0.2) Рассмотрим полученную поверхность в 3D: p = plot_ly(x = x, y = y, z = px_grid$z_idw30, type = &quot;surface&quot;, colors = rain_colors3d) layout(p, scene = list(aspectratio = list(x = 1, y = 1, z = 0.3) )) 13.3.4 Метод радиальных базисных функций (РБФ) В методе РБФ задается радиальная функция — некоторая монотонно возрастающая функция, в качестве аргумента которой выступает расстояние между точками. Для интерполируемой точки вычисляются расстояния от нее до каждой из исходных точек. На основе этих расстояний получают значения радиальной функции. Результат интерполяции получается как сумма значений радиальной функции с коэффициентами. Коэффициенты определяются исходя из условия прохождения поверхности через исходные точки путем решения системы линейных уравнений. Метод РБФ является одним из самых мощных и гибких широким возможностям выбора радиальной функции. Недостатком же его является то, что поверхность может выходить за пределы исходного диапазона значений. Существуют радиальные функции, обладающие особыми свойствами. В частности, в качестве радиальной функции можно использовать сплайны - функции, выполняющие некоторое дополнительное условие (условия) при одновременном выполнении условий интерполяции (прохождение через исходные точки). Одним из наиболее популярных сплайнов является сплайн минимальной кривизны (thin plate spline — TPS), который дает поверхность, обладающую максимально низкой кривизной между исходными точками. Это, кстати, не означает что поверхность плотно натянута на исходные точки (как в триангуляции). Скорее, в ней будут отсутствовать резкие скачки и понижения, что мы видели на поверхности, построенной методом ОВР. Задается такой сплайн с помощью радиальной функции \\(R(d) = d^2 * log(d^2)\\) На языке R сплайны минимальной кривизны реализованы в пакете fields. Сначала необходимо инициализировать процесс интерполяции с помощью функции Tps(), передав ей координаты исходных точек и значения показателя в них. Дополнительно при необходимости указывается параметр scale.type = 'unscaled', который означает, что не следует масштабировать координаты исходных точек так чтобы область определения стала квадратной: # РАДИАЛЬНЫЕ БАЗИСНЫЕ ФУНКЦИИ (RADIAL BASIS FUNCTIONS) pred = Tps(coords, pts$rain_24, scale.type = &#39;unscaled&#39;) # После этого можно интерполировать значения с помощью функции predict(): px_grid = px_grid %&gt;% mutate(z_tps = predict(pred, coords_grid)) # Придется расширить шкалу, так как сплайновая поверхность выходит за пределы исходных значений: tps_breaks = seq(-10,90,by=10) tps_ncolors = length(tps_breaks) - 1 cont_tps = st_contour(px_grid[&#39;z_tps&#39;], breaks = tps_breaks, contour_lines = TRUE) # Виузализируем результат: ggplot() + geom_stars(data = cut(px_grid[&#39;z_tps&#39;], breaks = tps_breaks)) + scale_fill_manual(name = &#39;мм&#39;, values = rain_colors(tps_ncolors), labels = paste(tps_breaks[-tps_ncolors-1], &#39;-&#39;, tps_breaks[-1])) + coord_sf(crs = st_crs(pts)) + geom_sf(data = cont_tps, color = &#39;black&#39;, size = 0.2) + geom_sf(data = pts, color = &#39;red&#39;, size = 0.5) Можно видеть, что по плавному характеру изолиний и отсутствию артефактов в виде “бычьих глаз” интерполяция методом РБФ существенно ближе к ожидаемому распределению показателя, а также удачно сглаживает неравномерность распределения исходных данных. Смотрим, как выглядит поверхность в 3D: p = plot_ly(x = x, y = y, z = px_grid$z_tps, type = &quot;surface&quot;, colors = rain_colors3d) layout(p, scene = list(aspectratio = list(x = 1, y = 1, z = 0.3) )) 13.3.5 Метод иерархических базисных сплайнов (B-сплайнов) Если говорить просто — в методе иерархических базисных сплайнов (ИБС) поверхность формируется как совокупность профилей по осям \\(X\\) и \\(Y\\). Участок профиля, соединяющий 4 последовательных узла, представляет из себя кубический полином — базисный сплайн. Сплайны стыкуются гладко, то есть в любом узле поверхности существуют и первая и вторая производная. Каждый участок поверхности размером \\(4 \\times 4\\) ячейки представляет собой уже бикубическую поверхность. Высоты в ячейках получаются исходя из условия прохождения поверхности через исходные точки, а также минимизации суммы квадратов высот (поскольку существует бесконечное число различных поверхностей на сетке \\(4 \\times 4\\), которые проходят через заданную точку). Если хотя бы в один участок \\(4 \\times 4\\) попадает более одной точки, поверхность будет аппроксимирующей, так как каждая точка дает свой оптимум, минимизирующий сумму квадратов значений в узлах. При иерархическом подходе поверхность строится в несколько итераций с последовательным переходом на более детальное разрешение сетки. При этом на каждой последующей итерации аппроксимации подвергаются остатки между исходными значениями в точках и теми, которые получаются по бикубической поверхности. Если результирующее разрешение таково, что в окрестности \\(4 \\times 4\\) исходной точки нет других исходных точек, метод будет интерполирующим. Достоинством метода иерархических базисных сплайнов является то, что поверхность получается сразу для всех узлов, нет необходимости решать систему линейных уравнений для каждого узла сетки. Метод является локальным: исходные точки, удаленные от текущего узла ЦМР далее чем на 2 узла, не оказывают на нее влияние. В результате этого метод ИБС получается чрезвычайно быстрым и эффективным в вычислительном плане. Помимо этого, мультимасштабность метода позволяет эффективно использовать его при интерполяции данных, распределенных кластерным образом — например, данных профилирования. Метод иерархических базисных сплайнов доступен в пакете MBA. Чтобы использовать его, сначала необходимо подготовить исходные данные. Они должны представлять из себя матрицу из трех столбцов: X, Y, Показатель: # ИЕРАРХИЧЕСКИЕ БАЗИСНЫЕ СПЛАЙНЫ (HIERARCHICAL BASIS SPLINES) mba_data = cbind(coords, pts$rain_24) Метод ИБС, так же как и РБФ, предполагает по умолчанию, что область определения должна быть квадратной. Если разброс координат по осям X и Y не одинаков, поверхность будет искусственно растянута или сжата. Чтобы этого не произошло, необходимо сначала рассчитать пропорции ЦМР. Ранее мы уже создали объект envelope, который хранит крайние координаты по X и Y: ratio = (envelope[2] - envelope[1])/(envelope[4] - envelope[3]) # После этих приготовлений можно осуществить интерполяцию px_grid = px_grid %&gt;% mutate(z_bspline = mba.points(mba_data, coords_grid, n = 1, m = ratio)$xyz.est[, &#39;z&#39;]) # Строим горизонтали cont_bspline = st_contour(px_grid[&#39;z_bspline&#39;], breaks = tps_breaks, contour_lines = TRUE) # Виузализируем результат: ggplot() + geom_stars(data = cut(px_grid[&#39;z_bspline&#39;], breaks = tps_breaks)) + scale_fill_manual(name = &#39;мм&#39;, values = rain_colors(tps_ncolors), labels = paste(tps_breaks[-tps_ncolors-1], &#39;-&#39;, tps_breaks[-1])) + coord_sf(crs = st_crs(pts)) + geom_sf(data = cont_bspline, color = &#39;black&#39;, size = 0.2) + geom_sf(data = pts, color = &#39;red&#39;, size = 0.5) Можно видеть, что метод иерархических базисных сплайнов обеспечивает некий оптимум представления поверхности. С одной стороны, он, как и метод РБФ, дает гладкую и достаточно генерализованную поверхность. С другой стороны, на участках с плотным размещением исходных данных метод ИБС раскрывает локальные нюансы поверхности, чего лишен метод РБФ, и что более типично для метода ОВР. Наконец, рассмотрим результат в трехмерном виде: p = plot_ly(x = x, y = y, z = px_grid$z_bspline, type = &quot;surface&quot;, colors = rain_colors3d) layout(p, scene = list(aspectratio = list(x = 1, y = 1, z = 0.3) )) Итак, в настоящем модуле мы рассмотрели несколько распространенных методов детерминистической интерполяции поверхностей по данным в нерегулярно расположенных точках. В следующем модуле мы рассмотрим методы аппроксимации, которые могут быть полезны для работы с данными, обладающими высоким уровнем шума, а также для оценки пространственных трендов изменения показателя. 13.4 Аппроксимационные методы Аппроксимационные методы используются для выявления пространственных трендов - глобальных или локальных. В зависимости от этого они и классифицируются. Полученная поверхность в каждом узле показывает средневзвешенное (типичное) значение в заданной окрестности. Таким образом, задача аппроксимации — убрать детали и выявить основные закономерности пространственного распределения. При проведении аппроксимации условие прохождения поверхности через исходные точки не применяется. В случае глобального тренда окрестность аппроксимации включает весь набор исходных точек. Локальные аппроксимации учитывают только ближайшие точки, причем общепринятым является подход, в котором окрестность определяется не расстоянием, а заданным количеством ближайших точек (или их долей от общего числа). В этом случае в области сгущения исходных данных локальная аппроксимация будет строиться по меньшей окрестности, что позволит отразить нюансы изменения показателя. И в локальных и в глобальных аппроксимациях используются обычно полиномиальные поверхности степени от \\(0\\) до \\(3\\). Коэффициенты полиномов подбираются методом наименьших квадратов для минимизации отклонения поверхности от исходных точек в заданной окрестности. В случае если степень равна \\(0\\), поверхность представляет из себя константу, или горизонтальную плоскость. Для степени \\(1\\) возможно построение наклонной плоскости. Степени \\(2\\) и \\(3\\) соответствуют квадратичным и кубическим поверхностям. Степени большего порядка для построения трендов, как правило, не используются. 13.4.1 Глобальный тренд Построение поверхности глобального тренда можно осуществить с помощью геостатистического пакета gstat, с которым мы познакомимся в следующем модуле. Для этого необходимо сначала создать объект gstat, используя формулу (см. метод ОВР), исходные точки и степень аппроксимации. После этого аппроксимация осуществляется с помощью функции predict(). Дальнейшие действия совпадают со стандартным алгоритмом, который мы использовали ранее. # ГЛОБАЛЬНАЯ АППРОКСИМАЦИЯ (GLOBAL APPROXIMATION) # Создаем объект gstat и интерполируем на его основе. Столбец, указываемый в параметре formula, должен содержаться # в наборе данных, который передается в параметр data: px_grid = px_grid %&gt;% mutate(z_trend1 = predict(gstat(formula = rain_24 ~ 1, data = pts, degree = 1), newdata = px_grid)$var1.pred, z_trend2 = predict(gstat(formula = rain_24 ~ 1, data = pts, degree = 2), newdata = px_grid)$var1.pred, z_trend3 = predict(gstat(formula = rain_24 ~ 1, data = pts, degree = 3), newdata = px_grid)$var1.pred) # Строим горизонтали cont_trend1 = st_contour(px_grid[&#39;z_trend1&#39;], breaks = rain_levels, contour_lines = TRUE) cont_trend2 = st_contour(px_grid[&#39;z_trend2&#39;], breaks = rain_levels, contour_lines = TRUE) cont_trend3 = st_contour(px_grid[&#39;z_trend3&#39;], breaks = rain_levels, contour_lines = TRUE) ggplot() + geom_stars(data = cut(px_grid[&#39;z_trend1&#39;], breaks = rain_levels)) + rain_legend + coord_sf(crs = st_crs(pts)) + geom_sf(data = cont_trend1, color = &#39;black&#39;, size = 0.2) + geom_sf(data = pts, color = &#39;red&#39;, size = 0.5) ggplot() + geom_stars(data = cut(px_grid[&#39;z_trend2&#39;], breaks = rain_levels)) + rain_legend + coord_sf(crs = st_crs(pts)) + geom_sf(data = cont_trend2, color = &#39;black&#39;, size = 0.2) + geom_sf(data = pts, color = &#39;red&#39;, size = 0.5) ggplot() + geom_stars(data = cut(px_grid[&#39;z_trend3&#39;], breaks = rain_levels)) + rain_legend + coord_sf(crs = st_crs(pts)) + geom_sf(data = cont_trend3, color = &#39;black&#39;, size = 0.2) + geom_sf(data = pts, color = &#39;red&#39;, size = 0.5) Наконец, рассмотрим полученные поверхности в трехмерном виде: p = plot_ly(x = x, y = y, z = px_grid$z_trend1, type = &quot;surface&quot;, colors = rain_colors3d) layout(p, scene = list(aspectratio = list(x = 1, y = 1, z = 0.3))) p = plot_ly(x = x, y = y, z = px_grid$z_trend2, type = &quot;surface&quot;, colors = rain_colors3d) layout(p, scene = list(aspectratio = list(x = 1, y = 1, z = 0.3))) p = plot_ly(x = x, y = y, z = px_grid$z_trend3, type = &quot;surface&quot;, colors = rain_colors3d) layout(p, scene = list(aspectratio = list(x = 1, y = 1, z = 0.3))) 13.4.2 Локальный тренд Метод построения локальной регрессии изначально был разработан для построения кривых регрессии в случае когда зависимость между переменными ведет себя сложным образом и не может быть описана в терминах традиционной линейной и нелинейной регрессии — глобальных методов. В этом случае область значений независимой переменной \\(X\\) можно покрыть конечным числом отрезков, для каждого из которых далее находят регрессию традиционным методом — как правило, линейную или квадратичную. В классической постановке метод реализуется следующим образом. Пусть дано \\(N\\) точек с координатами \\(X\\) (независимая переменная) и \\(Y\\) (зависимая). Задается число \\(\\alpha\\), которое обозначает долю от общего количества точек, которую необходимо выбрать в окрестности каждой из N точек для построения регрессии. То есть для каждой точки \\(p(x)\\) из исходных данных выбираются \\(\\alpha N\\) ближайших к ней. Близость определяется как разность координат \\(X\\). Выбранные точки определяют окрестность \\(p(x)\\), в которой будет строиться локальная регрессия. Далее происходит определение параметров линейной или квадратической регрессии взвешенным методом наименьших квадратов. При использовании этого метода более близкие к \\(p(x)\\) точки оказывают большее влияние на коэффициенты регрессии. Построенная регрессия дает в точке \\(x\\) сглаженную оценку \\(p&#39;(x)\\) вместо исходной \\(p(x)\\). Процедура повторяется для каждой из \\(N\\) точек. Результирующая кривая соединяет точки \\(p&#39;(x)\\). При этом чем больше значение \\(\\alpha\\), тем более сглаженный вид будет иметь кривая регрессии. Метод получил название LOWESS (Locally weighted scatterplot smoothing). В дальнейшем эта аббревиатура была редуцирована до LOESS. В методе LOESS используются степени регрессии 0, 1, 2. Кубические и более высокие степени полиномов не применяются. При степени равной 0 метод носит название сглаживающего среднего. Вместо координат исходных точек для построения регрессии можно использовать и произвольные координаты \\(X\\). В этом случае кривая будет соединять точки, полученные локальной регрессионной оценкой в заданных координатах \\(X\\). Именно этот принцип используется в двумерном (и многомерном) случае. Пусть даны измерения показателя в \\(N\\) исходных точках и задано число \\(\\alpha\\) — сглаживающий параметр. Тогда аппроксимация показателя в каждом узле интерполяции получается путем построения поверхности тренда (см. выше) по \\(\\alpha N\\) ближайшим исходным точкам. Как и в одномерном случае, близкие точки будут оказывать более сильное влияние на коэффициенты регрессии, чем удаленные. Метод LOESS предоставляет широкие возможности настройки благодаря вариативности параметра сглаживания и степени регрессионного полинома. Рассмотрим применение метода LOESS на примере данных по осадкам. Поскольку это один из базовых методов регрессионного анализа, он входит в состав базового пакета stats. Для его использования нужно вначале инициализировать параметры локальной регрессии с помощью функции loess(). Параметры задаются в следующей форме: Формула, содержащая названия зависимой и независимых (координаты) переменной Набор данных, в котором содержатся значения переменных Степень полинома (degree) Сглаживающий параметр (span) Необходимость нормализации координат (приведения к квадратной области определения) # ЛОКАЛЬНАЯ АППРОКСИМАЦИЯ (LOWESS) # 0-я степень ------------------------------------------------------------- px_grid = px_grid %&gt;% mutate(z_local0 = predict(loess(rain_24 ~ x + y, pts, degree = 0, span = 0.07, normalize = FALSE), coords_grid), z_local1 = predict(loess(rain_24 ~ x + y, pts, degree = 1, span = 0.07, normalize = FALSE), coords_grid), z_local2 = predict(loess(rain_24 ~ x + y, pts, degree = 2, span = 0.07, normalize = FALSE), coords_grid)) # Визуализируем cont_local0 = st_contour(px_grid[&#39;z_local0&#39;], breaks = rain_levels, contour_lines = TRUE) cont_local1 = st_contour(px_grid[&#39;z_local1&#39;], breaks = rain_levels, contour_lines = TRUE) cont_local2 = st_contour(px_grid[&#39;z_local2&#39;], breaks = rain_levels, contour_lines = TRUE) ggplot() + geom_stars(data = cut(px_grid[&#39;z_local0&#39;], breaks = rain_levels)) + rain_legend + coord_sf(crs = st_crs(pts)) + geom_sf(data = cont_local0, color = &#39;black&#39;, size = 0.2) + geom_sf(data = pts, color = &#39;red&#39;, size = 0.5) ggplot() + geom_stars(data = cut(px_grid[&#39;z_local1&#39;], breaks = rain_levels)) + rain_legend + coord_sf(crs = st_crs(pts)) + geom_sf(data = cont_local1, color = &#39;black&#39;, size = 0.2) + geom_sf(data = pts, color = &#39;red&#39;, size = 0.5) ggplot() + geom_stars(data = cut(px_grid[&#39;z_local2&#39;], breaks = rain_levels)) + rain_legend + coord_sf(crs = st_crs(pts)) + geom_sf(data = cont_local2, color = &#39;black&#39;, size = 0.2) + geom_sf(data = pts, color = &#39;red&#39;, size = 0.5) Рассмотрим результаты в 3D: p = plot_ly(x = x, y = y, z = px_grid$z_local0, type = &quot;surface&quot;, colors = rain_colors3d) layout(p, scene = list(aspectratio = list(x = 1, y = 1, z = 0.3))) p = plot_ly(x = x, y = y, z = px_grid$z_local1, type = &quot;surface&quot;, colors = rain_colors3d) layout(p, scene = list(aspectratio = list(x = 1, y = 1, z = 0.3))) p = plot_ly(x = x, y = y, z = px_grid$z_local2, type = &quot;surface&quot;, colors = rain_colors3d) layout(p, scene = list(aspectratio = list(x = 1, y = 1, z = 0.3))) Можно заметить, что с увеличением степени полинома поверхность все более точно аппроксимирует исходные данные — там, где достаточно большое количество исходных точек. В то же время, появляются нежелательные экстраполяции в приграничных областях, слабо обеспеченных измерениями, что можно наблюдать на последнем рисунке (степень = 2) в северо-западной части. Поэтому нельзя однозначно сказать, что более высокая степень обеспечивает лучшие результаты аппроксимации. Точность аппроксимации правильно регулировать не степенью полинома, а увеличением и уменьшением сглаживающего параметра альфа. Рассмотрим это на примере линейной аппроксимации при \\(\\alpha = 0.05, 0.1, 0.2\\): px_grid = px_grid %&gt;% mutate(z_local1_005 = predict(loess(rain_24 ~ x + y, pts, degree = 1, span = 0.05, normalize = FALSE), coords_grid), z_local1_01 = predict(loess(rain_24 ~ x + y, pts, degree = 1, span = 0.1, normalize = FALSE), coords_grid), z_local1_02 = predict(loess(rain_24 ~ x + y, pts, degree = 1, span = 0.2, normalize = FALSE), coords_grid)) # Визуализируем cont_local1_005 = st_contour(px_grid[&#39;z_local1_005&#39;], breaks = rain_levels, contour_lines = TRUE) cont_local1_01 = st_contour(px_grid[&#39;z_local1_01&#39;], breaks = rain_levels, contour_lines = TRUE) cont_local1_02 = st_contour(px_grid[&#39;z_local1_02&#39;], breaks = rain_levels, contour_lines = TRUE) ggplot() + geom_stars(data = cut(px_grid[&#39;z_local1_005&#39;], breaks = rain_levels)) + rain_legend + coord_sf(crs = st_crs(pts)) + geom_sf(data = cont_local1_005, color = &#39;black&#39;, size = 0.2) + geom_sf(data = pts, color = &#39;red&#39;, size = 0.5) ggplot() + geom_stars(data = cut(px_grid[&#39;z_local1_01&#39;], breaks = rain_levels)) + rain_legend + coord_sf(crs = st_crs(pts)) + geom_sf(data = cont_local1_01, color = &#39;black&#39;, size = 0.2) + geom_sf(data = pts, color = &#39;red&#39;, size = 0.5) ggplot() + geom_stars(data = cut(px_grid[&#39;z_local1_02&#39;], breaks = rain_levels)) + rain_legend + coord_sf(crs = st_crs(pts)) + geom_sf(data = cont_local1_02, color = &#39;black&#39;, size = 0.2) + geom_sf(data = pts, color = &#39;red&#39;, size = 0.5) Сравниваем результаты в трехмерном виде: p = plot_ly(x = x, y = y, z = px_grid$z_local1_005, type = &quot;surface&quot;, colors = rain_colors3d) layout(p, scene = list(aspectratio = list(x = 1, y = 1, z = 0.3))) p = plot_ly(x = x, y = y, z = px_grid$z_local1_01, type = &quot;surface&quot;, colors = rain_colors3d) layout(p, scene = list(aspectratio = list(x = 1, y = 1, z = 0.3))) p = plot_ly(x = x, y = y, z = px_grid$z_local1_02, type = &quot;surface&quot;, colors = rain_colors3d) layout(p, scene = list(aspectratio = list(x = 1, y = 1, z = 0.3))) 13.5 Интерполяция по ареалам В некоторых случаях необходимо осуществить так называемую интерполяцию по ареалам. Данный метод применяется в тех случаях, когда исходная информация привязана не к точечным, а к площадным объектам. Задача заключается в том, чтобы с одной площадной сетки перенести на другую (как правило, регулярную, обладающую большей дискретностью). Необходимость подобного преобразования может быть обусловлена следующими (но и не только) причинами: метод анализа (например, моделирование диффузии) предполагает, что данные распределены по регулярной сетке, в то время как исходная сетка нерегулярна. необходимо обеспечить сравнимость пространственных распределений показателя для разных территорий, в то время как дробность исходного территориального деления существенно меняется в пространстве. Метод интерполяции по ареалам реализуется средствами функции st_interpolate_aw() из пакета sf. Данной функции необходимо подать исходную и целевую полигональную сетку, а также указать тип параметра: интенсивный или экстенсивный: — экстенсивные параметры суммируются и делятся при агрегировании/агрегировании территориальных единиц. Например, площадь, покрытая лесом или численность населения — это экстенсивный параметр. - интенсивные параметры осредняются или остаются постоянными при агрегировании/дизагрегировании территориальных единиц. Например, густота древостоя и плотность населения — интенсивные параметры. Рассмотрим это метод интерполяции на примере данных по графствам Северной Каролины (показатель — количество новорожденных в 1974 году). Для расчета векторной регулярной сетки используем функцию st_make_grid() из пакета sf. # Данные по Северной Каролине nc = st_read(system.file(&quot;shape/nc.shp&quot;, package=&quot;sf&quot;)) ## Reading layer `nc&#39; from data source `/Library/Frameworks/R.framework/Versions/3.6/Resources/library/sf/shape/nc.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 100 features and 14 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965 ## epsg (SRID): 4267 ## proj4string: +proj=longlat +datum=NAD27 +no_defs cells = st_make_grid(nc, cellsize = 0.25) birth = st_interpolate_aw(nc[&quot;BIR74&quot;], cells, extensive = TRUE) # исходное распределение tm_shape(nc) + tm_polygons(&#39;BIR74&#39;, style = &#39;jenks&#39;, palette = &#39;viridis&#39;) + tm_shape(cells) + tm_borders(col = &#39;white&#39;) # пересчет на регулярную сетку tm_shape(birth) + tm_polygons(&#39;BIR74&#39;, style = &#39;jenks&#39;, palette = &#39;viridis&#39;) + tm_shape(nc) + tm_borders(col = &#39;white&#39;) 13.6 Краткий обзор Для просмотра презентации щелкните на ней один раз левой кнопкой мыши и листайте, используя кнопки на клавиатуре: Презентацию можно открыть в отдельном окне или вкладке браузере. Для этого щелкните по ней правой кнопкой мыши и выберите соответствующую команду. 13.7 Контрольные вопросы и упражнения 13.7.1 Вопросы Сформулируйте отличие интерполяционных и аппроксимационных методов восстановления поверхностей по данным в нерегулярно расположенных точках. Какой метод интерполяции подходит для работы с категориальными (качественными) данными? При каких условиях в методе интерполяции на основе триангуляции возможна оценка величины за пределами выпуклой оболочки исходного множества точек? Назовите основной недостаток метода обратно взвешенных расстояний. Каким требованиям должна удовлетворять радиальная базисная функция? Если дана функция, являющаяся радиальной базисной, можно ли в качестве таковой использовать обратную к ней? Как это реализуется математически? В каком методе интерполяции используются сплайны с натяжением? Сформулируйте основные принципы восстановления поверхности методом иерархических базисных сплайнов. Полиномы каких степеней обычно используются в задачах аппроксимации на практике? Каким образом реализуется метод локальной регрессии в приложении к пространственным данным? В чем заключается отличие экстенсивных и интенсивных пространственных переменных? Расскажите алгоритм, лежащий в основе пикнофилактического метода интерполяции по ареалам. Перечислите пакеты программной среды R, которые можно использовать для восстановления поверхностей по данным в нерегулярно расположенных точках. Какие функции R позволяют построить регулярную сетку? Как преобразовать эту сетку в растр? Изложите последовательность действий, необходимую для трехмерной визуализации поверхности средствами библиотеки plotly. 13.7.2 Упражнения Загрузите данные дрейфующих буев ARGO на акваторию Северной Атлантики за 30 января 2010 года. Постройте поля распределения солености и температуры методами радиальных базисных функций и обратно взвешенных расстояний с размером ячейки 50 км. Визуализируйте их средствами tmap и сравните результаты. Какой метод интерполяции дает, на ваш взгляд, более правдоподобный результат? Подсказка: перед построением сетки интерполяции странсформируйте данные в проекцию Меркатора. Чтобы полученное поле распределения покрывало только акваторию, маскируйте полученный растр с использованием слоя ocean из набора данных Natural Earth. Перед выполнением маскирования преобразуйте мультиполигон в обычные полигоны (в противном случае маскирование отработает некорректно). Используя пакет eurostat, загрузите с портала Евростата таблицу по объему производства коровьего молока, а также соответствующие ей единицы деления 2-го уровня (NUTS 2). Используя метод интерполяции по ареалам, пересчитайте эти данные на регулярную сетку с шагом 100 км и визуализируйте средствами tmap. Сравните результаты с оригинальным распределением. Подсказка: перед построением сетки интерполяции обрежьте данные на территорию континентальной Европы по координатам углов, используя функцию st_crop(). Далее трансформируйте данные в коническую равнопромежуточную проекцию с параметрами +proj=eqdc +lon_0=20 +lat_1=43 +lat_2=62. После этого присоедините статистику по полю geo (метки c помощью label_eurostat() можно не назначать) и произведите интерполяцию по ареалам. Самсонов Т.Е. Визуализация и анализ географических данных на языке R. М.: Географический факультет МГУ, 2020. DOI: 10.5281/zenodo.901911 "],
["kriging.html", "Глава 14 Геостатистика 14.1 Введение 14.2 Базовые понятия и элементы геостатистики 14.3 Стационарность и эргодичность 14.4 Геостатистическое оценивание 14.5 Краткий обзор 14.6 Контрольные вопросы и упражнения", " Глава 14 Геостатистика Программный код главы 14.1 Введение Геостатистика — раздел математической статистики, который связан с численным описанием переменных, распределенных в географическом пространстве и, опционально, времени. Наиболее часто инструменты геостатистики используются для решения задачи интерполяции — восстановления сплошного поля распределения случайной величины по ограниченному множеству данных в точках наблюдений. Однако, геостатистика как научная дисциплина существенно шире. Ее первоочередной задачей является статистическое описание пространственных распределений. В основе геостатистики лежит широко разработанный математический аппарат. Понимание основ этого аппарата является необходимым условием осмысленного примения геостатистических методов на практике. В настоящей главе мы постараемся сформировать у читателя данное понимание, и показать, как геостатистика работает на практике. Мир геостатистики базируется на фундаментальных понятиях случайной величины, случайной функции и случайного процесса. Рассмотрим эти понятия. 14.2 Базовые понятия и элементы геостатистики 14.2.1 Базовые понятия Отправной точкой геостатистического анализа является конечное множество точек (локаций), в каждой из которых зафиксировано значение некоторой пространственной переменной. Пространственную и атрибутивную составляющую традиционно разделяют на две компоненты, каждая из которых может быть случайной: Пространственные локации (точки) \\[\\{p_1, p_2, ..., p_n\\}\\] Данные в этих локациях \\[\\{Z(p_1), Z(p_2), ..., Z(p_n)\\}\\] Данные в локациях получаются путем измерений значений пространственно распределенной переменной, или вычисления её значения на основе других данных, которые прямо или косвенно (через другие данные) базируются на прямых или дистанционных наблюдениях. Результаты измерений, как и исходные для расчетов данные, как правило, привязаны ко времени и характеризуют состояние среды на определенный момент. Если описываемое явление является динамическим (изменчивым во времени), результаты наблюдений или расчетов для двух разных моментов времени в общем случае будут различны. Эти различия невозможно полностью описать в аналитическом виде, поскольку природные и социально-экономические процессы формируются неопределенно большим числом факторов. Аналогично этому, невозможно и достоверно предсказать значение пространственной переменной в заданный момент времени. Чтобы работать с такими данными, используются понятия случайной величины и случайного процесса. Случайной величиной \\(Z(w)\\) называется функция, которая в результате случайного события \\(w\\) принимает некоторое вещественнозначное значение. Например, при анализе температуры водоема в отдельно взятой точке в толще воды случайной величиной (функцией) является собственно температура, а событием — та совокупность физико-химических условий, которая сложилась в данной точке в данный момент измерений и обусловила наблюдаемое значение температуры. Отметим, что элемент случайности вносится именно событием, которое в природе может быть сформировано сложной и трудно предсказуемой комбинацией факторов, в то время как случайная величина уже связана с событием некоторой зависимостью, которую можно описать с помощью аналитических или эмпирических формул. Случайность можно наблюдать не только в точке, но и по пространству. Например, уровень шума, формируемый автотранспортом в открытой городской среде, меняется непрерывно, и его можно измерить в каждой точке. При этом пространственное распределение величины этого уровня будет в каждый момент времени зависеть от случайного события — размещения автомобилей и уровня шума, производимого каждым из них. Городская среда оказывается полностью заполнена шумовым эфиром, густота которого неодинакова в пространстве и времени. Перемещаясь из точки в точку или ожидая последующего момента времени, находясь в одной точке, мы будем наблюдать разный уровень шума. Состояние этого шумового эфира как единого целого является случайным процессом. Введем общее понятие случайного процесса: Случайный процесс это семейство случайных величин, индексированных некоторым параметром \\(t\\) Наиболее часто анализируются одномерные случайные процессы, в которых \\(t\\) — это время. Классическим примером такого процесса является количество покупателей, находящихся в магазине. Пространственная статистика изучает случайные процессы, в которых \\(t\\) — это координата точки (обычно на плоскости). Такие процессы характеризуются следующими особенностями: в каждой точке \\(p_i\\) существует некоторая случайная величина \\(Z(p_i)\\) — сечение случайного процесса при изменении точки \\(p_i\\) наблюдаемое значение случайного процесса меняется случайным образом, поскольку определяется оно не только местоположением, но и заранее неизвестным случайным событием. Для описания случайных процессов в пространстве необходимо сформировать базовую математическую модель, а также определить ее свойства. 14.2.2 Случайный процесс в пространстве и его моменты Пусть \\(p \\in \\mathbb{R}^k\\) — точка в \\(k\\)-мерном Евклидовом пространстве и \\(Z(p)\\) — случайная величина в точке \\(p\\). Тогда если \\(p\\) меняется в пределах области \\(D \\subset \\mathbb{R}^k\\) (эта область именуется индексным множеством), то формируется случайный процесс: \\[\\{Z(p) | p \\in D\\}\\] Вертикальная черта в соответствии с принятой в теории вероятности нотацией означает условие. То есть, переменная \\(p\\) ограничена областью \\(D\\). Результат наблюдения случайного процесса в точках области \\(D\\) является реализацией случайного процесса: \\[\\{z(p) | p \\in D\\}\\] В общем случае \\(D\\) и \\(Z\\) случайны и независимы Случайный процесс, как и случайную величину, можно описать с помощью статистических моментов, таких как математическое ожидание и дисперсия. Математическое ожидание есть наиболее вероятная реализация случайного процесса: \\[\\operatorname E[Z(p)]=m(p)\\] Поясним суть математического ожидания СП на следующем примере: Пусть дан географический регион, в пределах которого рассматривается поле температуры и его временная изменчивость. В каждый момент времени мы имеем непрерывное поле температуры — реализацию случайного процесса. Если рассмотреть поведение это поля во временном разрезе (по аналогии с колебаниями волн в пространстве), то получим некое “среднее” поле — математическое ожидаение случайного процесса. Если в приведенном примере температура наблюдается посредством сети метеостанций, то в каждый момент времени реализацию СП можно приблизительно восстановить путем выполнения интерполяции по их данным. Осреднив же данные по времени, и снова проинтерполировав их, получим выборочную среднюю поверхность — оценку мат. ожидания СП. Дисперсия есть мера разброса реализаций случайного процесса относительно его математического ожидания: \\[\\operatorname{Var}[Z(p)]= \\operatorname E[Z^2(p)]-m^2(p)\\] Аналогично математическому ожиданию, дисперсия двумерного СП представляет собой поле распределения. Величина этого поля каждой точке равна дисперсии сечения СП в этой точке, то есть дисперсии случайной величины. Так же как и в традиционной статистике, вместо дисперсии в расчетах часто используют среднеквадратическое отклонение, поскольку оно выражено в тех же единицах, что и сама случайная величина: \\[\\sigma(p)= \\sqrt{\\operatorname{Var}[Z(p)]}\\] В случае поля температуры можно представить себе объем, ограниченный двумя поверхностями \\(m(p) + \\sigma(p)\\) и \\(m(p) - \\sigma(p)\\). Расстояние между этими поверхностями в каждой точке \\(p\\) представляет собой среднеквадратическое отклонение случайного процесса. Ковариация — это мера линейной зависимости сечений случайного процесса в двух точках \\(p_1\\) и \\(p_2\\): \\[\\operatorname{Cov}(p_1,p_2) = \\operatorname{Cov}[Z(p_1), Z(p_2)] = \\operatorname{E}[Z(p_1)Z(p_2)]-m(p_1)m(p_2)\\] Для вычисления ковариации необходимость знать математическое ожидание СП. Это условие выполняется далеко не всегда, что связано с тем что как правило приходится иметь дело только с одной его реализацией. Следует обратить внимание на то, что моменты пространственных случайных процессов являются функциями, а не константами, в отличие от моментов случайных величин. Давать оценку пространственной структуре явления на основе вычисленных моментов с.п. можно при условии, что он удовлетворяет свойствам стационарности и эргодичности. 14.3 Стационарность и эргодичность 14.3.1 Стационарность Стационарность в строгом смысле означает что функция распределения множества случайных величин для любой комбинации точек \\({x_1, x_2,...,x_k}\\) и любого \\(k &lt; \\infty\\) остается неизменной при смещении этой комбинации на произвольный вектор \\(h\\): \\[P\\{Z(x_1)&lt;z_1,...,Z(x_k)&lt;z_k\\} = P\\{Z(x_1 + h)&lt;z_1,...,Z(x_k + h)&lt;z_k\\}\\] Стационарность по другому называют однородностью в пространстве, подразумевая что явление ведет себя одинаковым образом в любой точке пространства, как бы повторяет само себя. Если СФ стационарна, все ее моменты будут инвариантны относительно сдвигов (то есть будут постоянны), а это означает что для их оценки можно использовать ограниченную в пространстве область. В реальности подобного рода «идеальное» поведение встречается крайне редко, поэтому используют более слабое предположение о стационарности второго порядка. Случайная функция имеет имеет стационарность второго порядка, если для любых точек \\(x\\) и \\(x+h\\) в \\(R^k\\) \\[\\begin{cases} \\operatorname{E}[Z(x)] = m \\\\ \\operatorname{E}[(Z(x)-m)(Z(x+h)-m)] = \\operatorname{Cov}(h) \\end{cases}\\] Данные условия означают, что математическое ожидание СФ постоянно, а ковариация зависит только от вектора \\(h\\) между точками и не зависит от их абсолютного положения. Если ковариация также не зависит от направления, а только от расстояния между точками, то \\(h\\) вырождается в скаляр, а такая случайная функция является изотропной стационарной. 14.3.2 Эргодичность Стационарная случайная функция \\(Z(x,w)\\) называется эргодической, если ее среднее по области \\(V \\subset R^k\\) сходится к математическому ожиданию \\(m(w)\\) при стремлении \\(V\\) к бесконечности: \\[\\lim_{V \\rightarrow \\infty} \\frac{1}{|V|}\\int_{V} Z(x,w)dx = m(w),\\] где \\(|V|\\) обозначает меру области \\(V\\) (площадь, объем). Предполагается что сама область \\(V\\) растет во всех направлениях, и предел ее роста не зависит от ее формы. Следствием эргодичности является то, что среднее по всем возможным реализациям равно среднему отдельной безграничной в пространстве реализации. Смысл эргодичности можно пояснить на следующем примере. Пусть дан кувшин с песком, в котором необходимо определить долю объема, занятую содержимым. Проведем следующий эксперимент: Зафиксируем некоторую точку \\(x\\) в системе отсчета, привязанной к кувшину, и будем его встряхивать бесконечное число раз, каждый раз фиксируя, оказалась ли точка \\(x\\) внутри песчинки (записываем 1) или же попала в свободное между ними пространство (записываем 0) Из серии подобных экспериментов мы сможем оценить среднее значение индикаторной функции \\(I(x,w)\\), которое равно вероятности попадания зерна в точку \\(x\\), и которое не зависит от \\(x\\). Эта вероятность и будет равна доли объема кувшина, занятой песком. Аналогичный результат можно получить, если теперь зафиксировать кувшин, а точку \\(x\\) выбирать каждый раз случайным образом. Однако в первом случае берется среднее по реализациям, а во втором среднее по пространству. 14.4 Геостатистическое оценивание 14.4.1 Простой кригинг Для оценки в точке \\(Z_0 = Z(p_0)\\) по \\(N\\) измерениям \\(Z_1, ..., Z_N\\) ищутся коэффициенты \\(\\lambda\\) следующего выражения: \\[Z^* = \\sum_{i} \\lambda_i Z_i + \\lambda_0,\\] где константа \\(\\lambda_0 = \\lambda(p_0)\\) и веса \\(\\lambda_i\\) подобираются в точке \\(p_0\\) таким образом, что минимизируется среднеквадратическая ошибка: \\[\\operatorname{E}[Z^* - Z_0]^2,\\] то есть, математическое ожидание квадрата отклонения оценки от теоретического значения. Согласно традиции, принятой в литературе по геостатистике, оценка в точке \\(p_0\\) обозначается звездочкой (\\(Z^*\\)), а истинное (неизвестное) значение нулевым индексом (\\(Z_0\\)). В целях уменьшения количества скобок мы используем нотацию \\(\\operatorname{E}[Z^* - Z_0]^2 = \\operatorname{E}\\big[(Z^* - Z_0)^2\\big]\\) Теоретическое значение \\(Z_0\\), входящее в формулу ошибки, не известно. Однако, как будет показано далее, его знание и не требуется, поскольку ищется не сам квадрат отклонения, а его математическое ожидание. Используя соотношение \\(\\operatorname{Var}[X] = \\operatorname{E}[X^2] - (\\operatorname{E}[X])^2\\), выразим среднюю квадратическую ошибку как: \\[\\operatorname{E}[Z^* - Z_0]^2 = \\operatorname{Var}[Z^* - Z_0] + \\big(\\operatorname{E}[Z^* - Z_0]\\big)^2\\] Поскольку дисперсия нечувствительна к сдвигам, изменение константы \\(\\lambda_0\\) влияет только на компоненту \\(\\operatorname{E}[Z^* - Z_0]\\). Приравняем ее нулю: \\[\\operatorname{E}[Z^* - Z_0] = \\operatorname{E}\\Big[\\sum_{i} \\lambda_i Z_i + \\lambda_0 - Z_0\\Big] = 0\\] Используя свойства математического ожидания, выразим из этого выражения \\(\\lambda_0\\): \\[\\lambda_0 = - \\operatorname{E}\\Big[\\sum_{i} \\lambda_i Z_i - Z_0\\Big] = \\operatorname{E}[Z_0] - \\sum_{i} \\lambda_i \\operatorname{E}[Z_i] = m_0- \\sum_i \\lambda_i m_i,\\] где \\(m_i\\) — теоретически известные значения мат. ожидания случайной функции в точках исходных данных \\(p_i\\), \\(m_0\\) — теоретически известное мат. ожидание случайной функции в оцениваемой точке \\(p_0\\). Имея: \\[Z^* = \\sum_{i} \\lambda_i Z_i + \\lambda_0,\\\\ \\lambda_0 = m_0 - \\sum_i \\lambda_i m_i,\\] Получаем: \\[Z^* = \\sum_{i} \\lambda_i Z_i + m_0 - \\sum_i \\lambda_i m_i = m_0 + \\sum_{i} \\lambda_i (Z_i - m_i)\\] Поскольку математические ожидания \\(m_0\\) и \\(m_i\\) предполагаются известными, величину \\(Z(p)\\) можно заменить величиной \\(Y(p) = Z(p) - m(p)\\) в обеих частях уравнения (это эквивалентно вычитанию известного тренда из исходных измерений): \\[ Z^* = m_0 + \\sum_{i} \\lambda_i (Z_i - m_i),\\\\ \\underbrace{Z^* - m_0}_{Y^*} = \\sum_{i} \\lambda_i \\underbrace{(Z_i - m_i)}_{Y_i},\\\\ Y^* = \\sum_{i} \\lambda_i Y_i. \\] Это означает, что оценку \\(Z^*\\) можно заменить оценкой \\(Y^*\\) и прибавлением к ней среднего значения \\(m_0\\): \\[Z^* = m_0 + \\sum_{i} \\lambda_i Y_i,\\] Обратим внимание на то, что \\(\\operatorname{E}[Y^* - Y_0] = \\underbrace{\\operatorname{E}[Y^*]}_0 - \\underbrace{\\operatorname{E}[Y_0]}_0 = 0\\) по определению \\(Y(p)\\). В этом случае также \\(\\lambda_0 = \\underbrace{\\operatorname{E}[Y_0]}_0 - \\sum_{i} \\lambda_i \\underbrace{\\operatorname{E}[Y_i]}_0 = 0\\) . Чтобы не загромождать дальнейшее изложение формулами, примем, что \\(Z^* := Y^*\\), предполагая, что исходная величина уже центрирована относительно мат. ожидания, и к результату вычислений его надо прибавить. Поскольку \\(\\operatorname{E}[Z^* - Z_0] = 0\\), среднеквадратическую ошибка будет равна дисперсии: \\[\\operatorname{E}[Z^* - Z_0]^2 = \\operatorname{Var}[Z^* - Z_0]\\] Выразим дисперсию разностей в терминах статистических моментов исходной функции. Для этого воспользуемся следующими свойствами дисперсии и ковариации: \\(\\operatorname{Var}[X + Y] = \\operatorname{Var}[X] + \\operatorname{Var}[Y] + 2\\operatorname{Cov}[X, Y]\\); \\(\\operatorname{Var}[-X] = \\operatorname{Var}[X]\\); \\(\\operatorname{Cov}[X, -Y] = -\\operatorname{Cov}[X, Y]\\). Используя эти свойства, получаем: \\[\\operatorname{E}[Z^* - Z_0]^2 = \\operatorname{Var}[Z^* - Z_0] = \\operatorname{Var}[Z^*] + \\operatorname{Var}[Z_0] - 2\\operatorname{Cov}[Z^*, Z_0].\\] Чтобы минимизировать данное выражение, необходимо раскрыть содержание трёх его компонент. Для этого нам понадобится следующая теорема, позволяющая выразить ковариацию двух линейных комбинаций случайных величин через ковариацию самих исходных случайных величин: Теорема 14.1 Пусть \\(X_1,\\ldots, X_n\\) случайные величины, а \\(Y_1 = \\sum\\limits_{i=1}^n a_i X_i,\\; Y_2 = \\sum\\limits_{j=1}^m b_j X_j\\) — их две произвольные линейные комбинации. Тогда: \\[\\mathrm{cov}[Y_1,Y_2] = \\sum\\limits_{i=1}^n\\sum\\limits_{j=1}^m a_i b_j \\mathrm{cov}[X_i,X_j].\\] Используя результат этой теоремы, а также тот факт, что \\(\\operatorname{Var}[X] = \\operatorname{Cov}[X, X]\\), распишем каждую компоненту вышеприведенного выражения: \\(\\operatorname{Var}[Z^*] = \\operatorname{Cov}[Z^*, Z^*] = \\operatorname{Cov}\\Big[\\sum_{i} \\lambda_i Z_i, \\sum_{j} \\lambda_j Z_j\\Big] =\\\\\\sum_{i}\\sum_{j} \\lambda_i \\lambda_j \\operatorname{Cov}[Z_i, Z_j] = \\sum_{i}\\sum_{j} \\lambda_i \\lambda_j \\sigma_{ij},\\) \\(\\operatorname{Var}[Z_0] = \\operatorname{Cov}[Z_0, Z_0] = \\sigma_{00},\\) \\(\\operatorname{Cov}[Z^*, Z_0] = \\operatorname{Cov}\\Big[\\sum_{i} \\lambda_i Z_i, Z_0\\Big] = \\sum_{i} \\lambda_i \\operatorname{Cov}[Z_i, Z_0] = \\sum_{i} \\lambda_i \\sigma_{i0},\\) где \\(\\sigma_{ij}\\) — ковариация случайных величин в точках \\(p_i\\) и \\(p_j\\), \\(\\sigma_{i0}\\) — ковариация случайных величин в точках \\(p_i\\) и оцениваемой точке \\(p_0\\), \\(\\sigma_{00}\\) — дисперсия в точке \\(p_0\\). Используя полученные соотношения, выражение для ошибки \\[\\operatorname{E}[Z^* - Z_0]^2 = \\operatorname{Var}[Z^*] + \\operatorname{Var}[Z_0] - 2\\operatorname{Cov}[Z^*, Z_0]\\] можно представить следующим образом: \\[\\operatorname{E}[Z^* - Z_0]^2 = \\sum_{i}\\sum_{j} \\lambda_i \\lambda_j \\sigma_{ij} - 2 \\sum_{} \\lambda_i \\sigma_{i0} + \\sigma_{00}\\] Для нахождения минимума этой квадратичной функции необходимо приравнять нулю ее производные по основной переменной \\(\\lambda\\). Выберем в качестве «жертвы» коэффициенты с индексом \\(i\\): \\[\\frac{\\partial}{\\partial \\lambda_i} E[Z^* - Z_0]^2 = 2 \\sum_{j} \\lambda_j \\sigma_{ij} - 2 \\sigma_{i0} = 0\\] Таким образом, система уравнений простого кригинга для точки \\(Z_0\\) имеет вид: \\[\\color{red}{\\boxed{\\color{blue}{\\sum_{j} \\lambda_j \\sigma_{ij} = \\sigma_{i0}\\color{gray}{,~i = 1,...,N}}}}\\] Полученные уравнения простого кригинга носят чисто теоретический характер, поскольку предполагают знание ковариационной матрицы \\(\\Sigma = \\{\\sigma_{ij}\\}\\) случайного процесса. Тем не менее, на их основе удобно выводить уравнения обычного (ординарного) кригинга, в котором подобное знание уже не требуется. 14.4.2 Дисперсия простого кригинга Существует возможность оценить в каждой точке не только величину показателя, но также дисперсию оценки (в случае постоянного мат. ожидания — среднеквадратическую ошибку). Для этого необходимо коэффициенты \\(\\lambda_i\\), полученные из системы уравнения простого кригинга \\[\\sum_{j} \\lambda_j \\sigma_{ij} = \\sigma_{i0}\\] подставить в выражение среднеквадратической ошибки \\[\\operatorname{Var}[Z^* - Z_0] = \\sum_{i}\\sum_{j} \\lambda_i \\lambda_j \\sigma_{ij} - 2 \\sum_{} \\lambda_i \\sigma_{i0} + \\sigma_{00}\\] Умножим обе части каждого уравнения простого кригинга на \\(\\lambda_i\\) и просуммируем все уравнения по \\(i\\): \\[\\sum_{j} \\lambda_j \\sigma_{ij} = \\sigma_{i0}~\\Bigg|\\times \\lambda_i\\\\ \\color{red}{\\sum_{i}\\sum_{j} \\lambda_i \\lambda_j \\sigma_{ij}} = \\color{blue}{\\sum_{i}\\lambda_i\\sigma_{i0}}\\] Заметим, что левая часть уравнения присутствует в выражении среднеквадратической ошибки: \\[\\operatorname{Var}[Z^* - Z_0] = \\color{red}{\\sum_{i}\\sum_{j} \\lambda_i \\lambda_j \\sigma_{ij}} - 2 \\sum_{} \\lambda_i \\sigma_{i0} + \\sigma_{00}\\] Выполним соответствующую замену \\(\\sum_{i}\\sum_{j} \\lambda_i \\lambda_j \\sigma_{ij}\\) на \\(\\sum_{i}\\lambda_i\\sigma_{i0}\\): \\[\\operatorname{Var}[Z^* - Z_0] = \\color{blue}{\\sum_{i}\\lambda_i\\sigma_{i0}} - 2 \\sum_{} \\lambda_i \\sigma_{i0} + \\sigma_{00}\\] Отсюда получаем выражение для дисперсии (ошибки) простого кригинга: \\[\\color{red}{\\boxed{\\color{blue}{\\sigma_{SK} = \\operatorname{Var}[Z^* - Z_0] = \\sigma_{00} - \\sum_{i}\\lambda_i\\sigma_{i0}}}}\\] 14.4.3 Стационарность приращений Стационарность второго порядка требует знания математического ожидания для вычисления ковариации. В ряде случаев оценить математическое ожидание оказывается невозможно (оно может не существовать) или же оно действительно оказывается непостоянным. Тогда пользуются еще более мягкой формой стационарности стационарностью приращений, при которой стационарной предполагается не сама с.ф. \\(Z(x)\\), а производная от нее функция: \\[Y_h(x) = Z(x+h)-Z(x)\\] Функция \\(Z(x)\\), обладающая таким свойством, называется подчиняющейся внутренней гипотезе. У функции \\(Y_h(x) = Z(x+h)-Z(x)\\) должны существовать математическое ожидание и дисперсия приращений: \\[\\begin{cases} E[Z(x+h)-Z(x)] = \\langle a,h \\rangle \\\\ Var[Z(x+h)-Z(x)] = 2\\gamma(h) \\end{cases}\\] \\(\\langle a,h \\rangle\\) обозначает линейный тренд \\(a\\) при заданном векторе \\(h\\) (математическое ожидание разности значений), который варажется через скалярное произведение: \\(\\langle a,h \\rangle = \\sum_i a_i h_i\\) \\(\\gamma(h)\\) — дисперсия приращений, называемая вариограммой Если процесс подчиняется гипотезе стационарности второго рода \\(E[Z(x)] = m\\), то \\(E[Z(x+h)-Z(x)] = E[Y_h(x)] = 0\\) и вариограмму можно выразить следующим образом: \\[2\\gamma(h) = Var[Z(x+h)-Z(x)] = Var[Y_h(x)] \\\\=E\\big[Y_h(x)\\big]^2 - \\Big(E\\big[Y_h(x)\\big]\\Big)^2 \\\\=E\\big[Y_h(x)\\big]^2 = E\\big[Z(x+h)-Z(x)\\big]^2\\] Таким образом, наиболее распространенная в геостатистике гипотеза подчиняется следующим условиям: \\[\\begin{cases} E\\big[Z(x)\\big] = m\\\\ E\\big[Z(x+h)-Z(x)\\big] = 0 \\\\ E\\big[Z(x+h)-Z(x)\\big]^2 = 2\\gamma(h) \\end{cases}\\] Эти условия позволяют избавиться от необходимости знания среднего значения и дисперсии случайной функции и использовать для вычислений вариограмму. Чтобы модифицировать соответствующим образом уравнения простого кригинга, необходимо знать связь между ковариацией и вариограммой. 14.4.4 Положительная определенность Для того чтобы функция могла считаться ковариацией, необходимо, чтобы дисперсия, вычисленная на ее основе, была положительной: \\[Var \\Bigg[\\sum_{i=1}^N \\lambda_i Z(x_i)\\Bigg] = \\sum_{i=1}^N \\sum_{j=1}^N \\lambda_i \\lambda_j cov\\big[Z(x_i), Z(x_j)\\big] \\\\= \\sum_{i=1}^N \\sum_{j=1}^N \\lambda_i \\lambda_j C(x_j - x_i)\\] Функция \\(C(h)\\), для которой при любых значениях \\(N\\), \\(x_i\\) и \\(\\lambda_i\\) выражение \\(\\sum_{i=1}^N \\sum_{j=1}^N \\lambda_i \\lambda_j C(x_j - x_i)\\) принимает неотрицательные значения, называется положительно определенной. 14.4.5 Допустимые линейные комбинации Если функция отвечает внутренней гипотезе, нет гарантий, что ее ковариация существует и ограничена. В этом случае можно оценить дисперсию суммы случайных функций через дисперсию приращений, наложив дополнительное условие \\(\\sum_{i=1}^N \\lambda_i = 0\\). В этом случае, учитывая что \\(\\sum_{i=1}^N \\lambda_i Z(x_0) = 0\\), имеем: \\[\\sum_{i=1}^N \\lambda_i Z(x_i) = \\sum_{i=1}^N \\lambda_i \\big[Z(x_i) - Z(x_0)\\big]\\] &gt; Линейные комбинации, отвечающие условию \\(\\sum_{i=1}^N \\lambda_i = 0\\), называются допустимыми линейными комбинациями. 14.4.6 Условная положительная определенность Дисперсия допустимой линейной комбинации может быть выражена через вариограмму: \\[Var \\Bigg[\\sum_{i=1}^N \\lambda_i Z(x_i)\\Bigg] = - \\sum_{i=1}^N \\sum_{j=1}^N \\lambda_i \\lambda_j \\gamma(x_j - x_i)\\] Функция \\(G(h)\\), для которой при условии и \\(\\sum_{i=1}^N \\lambda_i = 0\\) выражение \\(\\sum_{i=1}^N \\sum_{j=1}^N \\lambda_i \\lambda_j G(x_j - x_i)\\) принимает неотрицательные значения, называется условно положительно определенной. \\(-\\gamma(h)\\) — условно положительно определенная ф. 14.4.7 Переход от ковариации к вариограмме Рассмотрим ковариацию двух линейных комбинаций с.ф.: \\[Cov \\Bigg[\\sum_{i=1}^N \\lambda_i Z(x_i), \\sum_{j=1}^M \\mu_j Z(x_j) \\Bigg] = \\sum_{i=1}^N \\sum_{j=1}^M \\lambda_i \\mu_j C(x_j - x_i)\\] Используя правило \\(Cov[X + \\alpha, Y + \\beta] = Cov[X, Y]\\), введем условное начало координат: \\[\\sum_{i=1}^N \\sum_{j=1}^M \\lambda_i \\mu_j C(x_j - x_i) =\\\\ =\\sum_{i=1}^N \\sum_{j=1}^M \\lambda_i \\mu_j Cov \\big[Z(x_i) - Z(x_0), Z(x_j) - Z(x_0)\\big]\\] Распишем ковариацию через математические ожидания, учитывая, что, согласно гипотезе, \\(E\\big[Z(x+h)-Z(x)\\big] = 0\\): \\[Cov \\big[Z(x_i) - Z(x_0), Z(x_j) - Z(x_0)\\big] =\\\\ = E\\big[Z_i - Z_0\\big]\\big[Z_j - Z_0\\big] - E\\big[Z_i - Z_0\\big] E\\big[Z_j - Z_0\\big] = \\\\ = E\\big[Z_i - Z_0\\big]\\big[Z_j - Z_0\\big]\\] Обратим внимание, что произведение приращений можно выразить через квадраты приращений: \\[\\color{blue}{(Z_j - Z_i)^2} = \\big[(Z_j - Z_0) - (Z_i - Z_0)\\big]^2 = \\\\ = \\color{blue}{(Z_i - Z_0)^2} - 2\\color{red}{(Z_i - Z_0)(Z_j - Z_0)} + \\color{blue}{(Z_j - Z_0)^2}\\] Имеем: \\[ (Z_i - Z_0)(Z_j - Z_0) = \\frac{1}{2} \\Big[(Z_i - Z_0)^2 + (Z_j - Z_0)^2 - (Z_j - Z_i)^2\\Big]\\] Учитывая, что \\(E\\big[Z(x+h)-Z(x)\\big]^2 = 2\\gamma(h)\\), подставим это выражение в формулу вычисления ковариации: \\[Cov \\big[Z(x_i) - Z(x_0), Z(x_j) - Z(x_0)\\big] = E\\big[Z_i - Z_0\\big]\\big[Z_j - Z_0\\big] = \\\\ = \\frac{1}{2} E \\Big[(Z_i - Z_0)^2 + (Z_j - Z_0)^2 - (Z_j - Z_i)^2\\Big] = \\\\ = \\gamma(x_i - x_0) + \\gamma(x_j - x_0) - \\gamma(x_j - x_i)\\] Подставим полученное выражение в двойную сумму: \\[\\sum_{i=1}^N \\sum_{j=1}^M \\lambda_i \\mu_j Cov \\big[Z(x_i) - Z(x_0), Z(x_j) - Z(x_0)\\big] = \\\\ = \\sum_{i=1}^N \\sum_{j=1}^M \\lambda_i \\mu_j \\big[\\gamma(x_i - x_0) + \\gamma(x_j - x_0) - \\gamma(x_j - x_i)\\big] = \\\\ = - \\sum_{i=1}^N \\sum_{j=1}^M \\lambda_i \\mu_j \\gamma(x_j - x_i),\\] \\(\\sum_{i=1}^N \\sum_{j=1}^M \\lambda_i \\mu_j \\gamma(x_i - x_0) = \\sum_{j=1}^M \\mu_j \\sum_{i=1}^N \\lambda_i \\gamma(x_i - x_0) = 0\\) \\(\\sum_{i=1}^N \\sum_{j=1}^M \\lambda_i \\mu_j \\gamma(x_j - x_0) = \\sum_{i=1}^N \\lambda_i \\sum_{j=1}^M \\mu_i \\gamma(x_j - x_0) = 0\\) Стационарный случай: \\[Cov \\Bigg[\\sum_{i=1}^N \\lambda_i Z(x_i), \\sum_{j=1}^M \\mu_j Z(x_j) \\Bigg] = \\sum_{i=1}^N \\sum_{j=1}^M \\lambda_i \\mu_j C(x_j - x_i)\\] Внутренняя гипотеза: \\[Cov \\Bigg[\\sum_{i=1}^N \\lambda_i Z(x_i), \\sum_{j=1}^M \\mu_j Z(x_j) \\Bigg] = - \\sum_{i=1}^N \\sum_{j=1}^M \\lambda_i \\mu_j \\gamma(x_j - x_i)\\] При соблюдении внутренней гипотезы в уравнениях кригинга можно принять \\(\\sigma_{ij} = -\\gamma_{ij}\\) 14.4.8 Обычный кригинг Пусть дано неизвестное среднее \\(m(x) = a_0\\). Необходимо произвести линейную оценку \\(Z^* = \\sum_{i} \\lambda_i Z_i + \\lambda_0\\). Выразим среднюю квадратическую ошибку: \\[E\\big[(Z^* - Z_0)^2\\big] = Var[Z^* - Z_0] + \\big(E[Z^* - Z_0]\\big)^2 =\\\\ = Var[Z^* - Z_0] + \\Bigg[\\lambda_0 + \\bigg(\\sum_i \\lambda_i - 1 \\bigg) a_0 \\Bigg]^2\\] Только компонента сдвига \\(E[Z^* - Z_0]\\) содержит \\(\\lambda_0\\), однако, в отличие от случая простого кригинга, мы не можем минимизировать ее, не зная \\(a_0\\). Единственный способ избавиться от \\(a_0\\) заключается в том, чтобы наложить дополнительное условие \\(\\sum \\lambda_i - 1 = 0\\) Минимизируем ранее введенную функцию ошибки: \\[Var[Z^* - Z_0] = \\sum_{i}\\sum_{j} \\lambda_i \\lambda_j \\sigma_{ij} - 2 \\sum_{} \\lambda_i \\sigma_{i0} + \\sigma_{00}\\] Для этого, с учетом дополнительного условия \\(\\sum \\lambda_i -1 = 0\\) применим метод множителей Лагранжа и построим вспомогательную функцию: \\[Q = Var[Z^* - Z_0] + 2\\mu \\bigg(\\sum_i \\lambda_i - 1 \\bigg),\\] где \\(\\mu\\) – неизвестный множитель Лагранжа. Для минимизации функции приравняем нулю ее частные производные: \\[\\begin{cases}\\frac{\\partial Q}{\\partial \\lambda_i} = 2 \\sum_j \\lambda_j \\sigma_{ij} - 2 \\sigma_{i0} + 2\\mu = 0,~i = 1,...,N,\\\\ \\frac{\\partial Q}{\\partial \\mu} = 2\\bigg(\\sum_i \\lambda_i - 1 \\bigg) = 0 \\end{cases}\\] Имеем \\(N + 1\\) уравнений с \\(N + 1\\) неизвестными: \\[\\begin{cases}\\sum_j \\lambda_j \\sigma_{ij} + \\mu = \\sigma_{i0},~i = 1,...,N,\\\\ \\sum_i \\lambda_i = 1 \\end{cases}\\] Заменяя ковариацию на вариограмму, получаем систему уравнений обычного кригинга: \\[\\color{red}{\\boxed{\\color{blue}{\\begin{cases}\\sum_j \\lambda_j \\gamma_{ij} - \\mu = \\gamma_{i0},\\color{gray}{~i = 1,...,N,}\\\\ \\sum_i \\lambda_i = 1 \\end{cases}}}}\\] Это наиболее часто используемый в геостатистике метод оценки 14.4.9 Дисперсия обычного кригинга Вывод формулы для оценки дисперсии обычного кригинга выполняется аналогично случаю простого кригинга. Умножим \\(N\\) первых уравнений на \\(\\lambda_i\\), просуммируем их по \\(i\\): \\[\\sum_j \\lambda_j \\gamma_{ij} - \\mu = \\gamma_{i0}~\\Bigg|\\times \\lambda_i\\] Учтя дополнительное условие \\(\\sum_i \\lambda_i = 1\\), получаем выражение для оценки дисперсии (ошибки) обычного кригинга: \\[\\color{red}{\\boxed{\\color{blue}{\\sigma_{OK} = Var[Z^* - Z_0] = \\sum_{i}\\lambda_i\\gamma_{i0} - \\mu}}}\\] 14.4.10 Универсальный кригинг В методе универсального кригинга осуществляется декомпозиция переменной \\(Z(x)\\) в виде следующей суммы: \\[Z(x) = m(x) + Y(x)\\] \\(m(x)\\) — дрифт (drift), гладкая детерминированная функция, описывающая систематическую составляющую пространственной изменчивости явления; \\(Y(x)\\) - остаток (residual), случайная функция с нулевым математическим ожиданием, описывающая случайную составляющую пространственной изменчивости явления; Декомпозиция любого явления на дрифт и остаток зависит от масштаба рассмотрения явления. Метод универсального кригинга используется, когда математическое ожидание случайного процесса непостоянно по пространству. Это позволяет интерполировать данные, в которых присутствует тренд. В предположении, что м.о. имеет функциональную зависимость от других процессов в точке \\(x\\), вводится следующая модель: \\[m(x) = \\sum_{k=0}^{K} a_k f^k(x),\\] где \\(f^k(x)\\) — известные базисные функции, а \\(a_k\\) — фиксированные для точки \\(x\\), но неизвестные коэффициенты. Обычно первая базисная функция при \\(k = 0\\) представляет собой константу, равную 1. Это позволяет включить в модель случай постоянного м.о. Если среднее зависит только от местоположения, то оставшиеся функции \\(f^k(x), k &gt; 0\\), как правило, представляют собой одночлены от координат (например, для двумерного случая \\(f^2(p) = x^2 + y^2\\)) Коэффициенты \\(a_k\\) могут меняться в зависимости от \\(x\\), но обязательно медленно, чтобы их можно было считать постоянными в окрестности \\(x\\). В качестве дрифта \\(m(x)\\) можно использовать не только функцию от местоположения, но также значения внешней переменной — ковариаты. Например, количество осадков можно связать с высотой точки \\(H(x)\\) следующей моделью: \\[Z(x) = a_0 + a_1 H(x) + Y(x)\\] С статистической точки зрения это линейная регрессия, в которой остатки коррелированы (автокоррелированы). В литературе данный метод называют также регрессионным кригингом (regression kriging), а оценка дрифта — пространственной регрессией (spatial regression). Для вывода уравнений рассмотрим среднеквадратическую ошибку: \\[E[Z^* - Z_0]^2 = Var[Z^* - Z_0] + \\big(E[Z^* - Z_0]\\big)^2\\] Используя введенную модель дрифта \\(m(x) = \\sum_{k=0}^{K} a^k f^k(x)\\) распишем выражение для мат.ожидания приращений: \\[E[Z^* - Z_0] = E[Z^*\\big] - E[Z_0] = \\\\ \\sum_i \\lambda_i \\sum_k a_k f_i^k - \\sum_k a_k f_0^k = \\sum_k a_k \\Bigg(\\sum_i \\lambda_i f_i^k - f_0^k\\Bigg)\\] Чтобы минимизировать \\(E[Z^* - Z_0]\\) независимо от коэффициентов \\(a_k\\), достаточно в вышеприведенной формуле приравнять нулю выражение в скобках. Отсюда имеем: \\[\\sum_i \\lambda_i f_i^k = f_0^k,~k = 0, 1, ..., K.\\] Эти условия называются условиями универсальности. Отсюда идет название метода — универсальный кригинг Условия универсальности гаранируют, что оценка \\(Z^*\\) является несмещенной для любых значений \\(a_k\\). Минимизируем ранее введенную функцию ошибки: \\[Var[Z^* - Z_0] = \\sum_{i}\\sum_{j} \\lambda_i \\lambda_j \\sigma_{ij} - 2 \\sum_{} \\lambda_i \\sigma_{i0} + \\sigma_{00}\\] Для этого, с учетом дополнительного условия \\(\\sum_i \\lambda_i f_i^k = f_0^k\\) применим метод множителей Лагранжа и построим вспомогательную функцию: \\[Q = Var[Z^* - Z_0] + 2 \\sum_{k=0}^K \\mu_k \\Bigg[ \\sum_i \\lambda_i f_i^k - f_0^k\\Bigg],\\] где \\(\\mu_k,~k = 0, 1, ..., K\\) представляют \\(K + 1\\) дополнительных неизвестных, множители Лагранжа. Для минимизации функции приравняем нулю ее частные производные: \\[\\begin{cases}\\frac{\\partial Q}{\\partial \\lambda_i} = 2 \\sum_j \\lambda_j \\sigma_{ij} -2 \\sigma_{i0} + 2 \\sum_k \\mu_k f_i^k = 0,\\color{gray}{~i = 1,...,N,}\\\\ \\frac{\\partial Q}{\\partial \\mu} = 2\\bigg[\\sum_i \\lambda_i f_i^k - f_0^k \\bigg] = 0\\color{gray}{,~k = 0, 1,..., K.} \\end{cases}\\] Имеем систему из \\(N + K + 1\\) уравнений с \\(N + K + 1\\) неизвестными: \\[\\begin{cases}\\sum_j \\lambda_j \\sigma_{ij} + \\sum_k \\mu_k f_i^k = \\sigma_{i0},~i = 1,...,N,\\\\ \\sum_i \\lambda_i f_i^k = f_0^k,~k = 0, 1,..., K. \\end{cases}\\] Заменяя ковариацию на вариограмму, получаем систему уравнений универсального кригинга: \\[\\color{red}{\\boxed{\\color{blue}{\\begin{cases}\\sum_j \\lambda_j \\gamma_{ij} - \\sum_k \\mu_k f_i^k = \\gamma_{i0},\\color{gray}{~i = 1,...,N,}\\\\ \\sum_i \\lambda_i f_i^k = f_0^k\\color{gray}{,~k = 0, 1,..., K.} \\end{cases}}}}\\] 14.4.11 Дисперсия универсального кригинга Вывод формулы для оценки дисперсии универсального кригинга выполняется аналогично случаю обычного кригинга. Умножим \\(N\\) первых уравнений на \\(\\lambda_i\\), просуммируем их по \\(i\\): \\[\\sum_j \\lambda_j \\gamma_{ij} - \\sum_k \\mu_k f_i^k = \\gamma_{i0} ~ \\Bigg|\\times \\lambda_i\\] Учтя дополнительное условие \\(\\sum_i \\lambda_i f_i^k = f_0^k\\), получаем выражение для оценки дисперсии (ошибки) универсального кригинга: \\[\\color{red}{\\boxed{\\color{blue}{\\sigma_{UK} = E[Z^* - Z_0]^2 = \\sum_{i}\\lambda_i\\gamma_{i0} - \\sum_k \\mu_k f_0^k}}}\\] 14.4.12 Кросс-валидация Значение переменной \\(Z(x)\\) оценивается в каждой точке \\(x_i\\) по данным в соседних точках \\(Z(x_j), ~ j \\neq i\\) как если бы \\(Z(x_i)\\) было неизвестно. В каждой точке вычисляется оценка кригинга \\(Z_{-i}^*\\) и соответствующая дисперсия кригинга \\(\\sigma_{Ki}^2\\). Поскольку значение \\(Z_i = Z(x_i)\\) известно, мы можем вычислить: Ошибку кригинга \\(E_i = Z_{-i}^* - Z_i\\) Стандартизированную ошибку \\(e_i = E_i / \\sigma_{Ki}\\) Если \\(\\gamma(h)\\) — теоретическая вариограмма, то \\(E_i = Z_{-i}^* - Z_i\\) — случайная величина с м.о. = \\(0\\) и дисперсией \\(\\sigma_{Ki}^2\\), а \\(e_i\\) имеет м.о. = \\(0\\) и дисперсию, равную \\(1\\). Стандартно анализируются следующие карты и графики: Карта стандартизированных ошибок \\(e_i\\). Стационарность ошибок, отсутствие эффекта пропорциональности. Гистограмма стандартизированных ошибок \\(e_i\\). Нормальность распределения, отсутствие аномалий. Диаграмма рассеяния \\((Z_{-i}^*, Z_i)\\). Сглаживающий эффект, соответствие оценки и реального значения. Диаграмма рассеяния \\((Z_{-i}^*, e_i)\\). Независимость (ортогональность) оценки и ошибки. 14.4.13 Вариограмма Вариограмма (полувариограмма) дисперсия разности значений в точках как функция от их взаимного положения: \\[\\gamma (\\mathbf{h}) = \\gamma(\\mathbf{x}, \\mathbf{x + h}) = E\\big[Z(x + h)-Z(x)\\big]^2\\] Для \\(N\\) точек, разделенных вектором \\(\\mathbf{h}\\): \\[\\gamma(\\mathbf{h}) = \\frac{1}{2N(h)}\\sum_{i=1}^{N(\\mathbf{h})} \\big[Z(\\mathbf{x_i}) - Z(\\mathbf{x_i + h})\\big]^2\\] Свойства вариограммы: Вариограмма симметрична: \\[\\gamma(\\mathbf{x}) = \\gamma(-\\mathbf{x})\\] Вариограмма связана с дисперсией: \\[\\gamma(\\infty) = Var\\big[ Z(\\mathbf{x}) \\big]\\] Вариограмма связана с ковариацией: \\[\\gamma(\\mathbf{h}) = Var\\big[ Z(\\mathbf{x}) \\big] - C(\\mathbf{h})\\] Вариограмма чувствительна к аномальным значениям (по причине второй степени) 14.4.14 Сферическая модель \\[\\gamma(h) = \\begin{cases} c_0 + c\\Big[\\frac{3h}{2a} - \\frac{1}{2}\\big(\\frac{h}{a}\\big)^3\\Big], &amp; h \\leq a; \\\\ c_0 + c, &amp; h &gt; a. \\end{cases}\\] \\[\\gamma(a) = Var[Z(p)] = c_0 + c\\] n = 60 a = 40 h = 0:n tab = tibble::tibble( h = 0:60, gamma = c(3 * (0:(a-1)) / (2 * a) - 0.5 * (0:(a-1) / a)^3, rep(1, n-a+1)) ) ggplot() + geom_line(tab, mapping = aes(h, gamma), size = 1, color = &#39;steelblue&#39;) + geom_vline(xintercept = a, color = &#39;orangered&#39;) + annotate(&quot;text&quot;, x = a + 3, y = 0.5625, label = paste(&quot;a =&quot;, a), color = &#39;orangered&#39;) + theme_bw() Данная модель достигает плато в точке \\(h = a\\). 14.4.15 Экспоненциальная модель \\[\\gamma(h) = \\begin{cases} 0, &amp; h = 0; \\\\ c_0 + (c-c_0)\\Big[1 - \\exp\\big(\\frac{-3h}{a}\\big)\\Big], &amp; h \\neq 0. \\end{cases}\\] \\[\\gamma(a) = Var[Z(p)] = c_0 + c\\] tab = tibble::tibble( h = h, gamma = 1 - exp(-3*h/a) ) pl = ggplot() + geom_line(tab, mapping = aes(h, gamma), size = 1, color = &#39;steelblue&#39;) + geom_vline(xintercept = a, color = &#39;orangered&#39;) + annotate(&quot;text&quot;, x = a + 3, y = 0.5625, label = paste(&quot;a =&quot;, a), color = &#39;orangered&#39;) + theme_bw() (pl) Данная модель достигает плато асимптотически. В точке \\(h = a\\) достигается \\(95\\%\\) уровня плато. 14.4.16 Гауссова модель \\[\\gamma(h) = c_0 + c\\Bigg[1 - \\exp\\bigg(\\frac{-3h^2}{a^2}\\bigg)\\Bigg]\\] tab = tibble::tibble( h = h, gamma = 1 - exp(-3*h^2/a^2) ) pl = ggplot() + geom_line(tab, mapping = aes(h, gamma), size = 1, color = &#39;steelblue&#39;) + geom_vline(xintercept = a, color = &#39;orangered&#39;) + annotate(&quot;text&quot;, x = a + 3, y = 0.5625, label = paste(&quot;a =&quot;, a), color = &#39;orangered&#39;) + theme_bw() (pl) Данная модель достигает плато асимптотически. В точке \\(h = a\\) достигается \\(95\\%\\) уровня плато. Отличительной чертой этой модели является ее гладкость: параболическое поведение вблизи нуля и асимптотическое приближение к плато. 14.4.17 Степенная модель \\[\\gamma(h) = \\begin{cases} 0, &amp; h = 0; \\\\ c h^\\alpha, &amp; h \\neq 0. \\end{cases}\\] tab = tibble::tibble( h = h, gamma = h^1.5 ) pl = ggplot() + geom_line(tab, mapping = aes(h, gamma), size = 1, color = &#39;steelblue&#39;) + theme_bw() (pl) Автокорреляция присутствует на всех расстояниях: \\(a \\rightarrow \\infty\\) Предположение о стационарности второго порядка не выполняется Как правило, это означает наличие тренда в данных 14.4.18 Эффект самородка (модель наггет) \\[\\gamma(h) = \\begin{cases} 0, &amp; h = 0; \\\\ c_0, &amp; h \\neq 0. \\end{cases}, ~ c_0 = C(0)\\] tab = tibble::tibble( gamma = rep(1, n+1), h = h ) ggplot() + geom_line(tab, mapping = aes(h, gamma), size = 1, color = &#39;steelblue&#39;) + geom_point(data = data.frame(x = 0, y = 1), mapping = aes(x, y), shape=21, colour = &#39;steelblue&#39;, fill = &#39;white&#39;, size = 3, stroke = 1.5) + annotate(&#39;point&#39;, x = 0, y = 0, color = &#39;steelblue&#39;, size = 4) + theme_bw() Наличие у данных вариограммы типа наггет означает отсутствие пространственной корреляции. Возможные причины: Абсолютно случайное распределение Мелкомасштабная вариабельность (меньше, чем расстояние между измерениями) Ошибки в измерениях Ошибки в координатах точек 14.4.19 Диаграмма рассеяния с лагом Lagged scatterplot — вариант диаграммы рассеяния, на котором показываются значения в точках, расстояние между которыми попадает в заданный интервал options(scipen = 999) cities = st_read(&quot;data/Italy_Cities.gpkg&quot;) ## Reading layer `Italy_Cities&#39; from data source `/Users/tsamsonov/GitHub/r-geo-course/data/Italy_Cities.gpkg&#39; using driver `GPKG&#39; ## Simple feature collection with 8 features and 37 fields ## geometry type: POINT ## dimension: XY ## bbox: xmin: 368910.4 ymin: 4930119 xmax: 686026 ymax: 5115936 ## epsg (SRID): 32632 ## proj4string: +proj=utm +zone=32 +datum=WGS84 +units=m +no_defs rainfall = read_table2(&quot;data/Rainfall.dat&quot;) %&gt;% st_as_sf(coords = c(&#39;x&#39;, &#39;y&#39;), crs = st_crs(cities), remove = FALSE) hscat(rain_24~1, data = rainfall, 1000 * c(0, 10, 20, 50, 100), pch = 19) 14.4.20 Вариограммное облако Квадрат разности значений как функция от расстояния между точками varcl = variogram(rain_24~1, data=rainfall, cutoff = 150000, cloud=TRUE) ggplot(varcl) + geom_point(aes(dist, gamma), alpha = 0.5, size = 2, color = &#39;steelblue&#39;) + ylab(&#39;semivariance&#39;) + theme_bw() 14.4.21 Эмпирическая вариограмма Эмпирическая вариограмма рассчитывается путем разбения вариограммного облака на интервалы расстояний — лаги — и подсчета среднего значения \\(\\gamma\\) в каждом лаге по следующей формуле: \\[\\hat{\\gamma} = \\frac{1}{2N_h} \\sum_{x_i - x_j \\approx h} \\big[z(x_i) - z(x_j)\\big]^2\\] width = 10000 intervals = width * 0:15 vargr = variogram(rain_24~1, data=rainfall, cutoff = 150000, width = width) Оставив только вариограмму, получим: ggplot() + geom_line(vargr, mapping = aes(dist, gamma)) + geom_point(vargr, mapping = aes(dist, gamma, size = np)) + scale_size(range = c(1, 5)) + theme_bw() Размер точки означает количество пар значений, которые попали в каждый лаг. Поскольку вариограмма есть дисперсия разности значений, ее рост при увеличении расстояния можно оценить также по увеличению размера «ящика» на диаграмме размаха \\(\\sqrt\\gamma\\): varcl = varcl %&gt;% mutate(sqgamma = sqrt(gamma), lag = cut(dist, breaks = intervals, labels = 0.001 * (intervals[-1] - 0.5*width))) ggplot(varcl) + geom_boxplot(aes(lag, sqrt(gamma)), outlier.alpha = 0.1) 14.4.22 Вариокарта Вариокарта (variogram map, variomap) представляет вариограмму как функцию приращений координат: \\[\\hat{\\gamma} (\\Delta x, \\Delta y) = \\frac{1}{2N_{\\substack{\\Delta x\\\\ \\Delta y}}} \\sum_{\\substack{\\Delta x_{ij} \\approx \\Delta x\\\\ \\Delta y_{ij} \\approx \\Delta y}} \\big[z(p_i) - z(p_j)\\big]^2\\] varmp = variogram(rain_24~1, data=rainfall, cutoff = 150000, width = width, map = TRUE)[[&#39;map&#39;]] Вариокарта используется для выявления пространственной анизотропии. Профиль по линии из центра к краю вариокарты даст эмпирическую вариограмму 14.4.23 Приближение теоретической модели Приближение (fitting) модели вариограммы предполагает: Выбор теоретической модели Подбор параметров модели: эффект самородка (nugget), радиус корреляции и плато. Дана вариограмма семейства \\(\\gamma (h; \\mathbf{b})\\), где \\(\\mathbf{b} = (b_1, ..., b_k)\\) — вектор из \\(k\\) параметров модели. Параметры \\(\\mathbf{b}\\) подбираются таким образом, чтобы минимизировать следующий функционал: \\[Q(\\mathbf{b}) = \\sum_{l=1}^{L} w_l \\big[\\hat{\\gamma}(h_l) - \\gamma (h; \\mathbf{b})\\big]^2,\\] где \\(\\big\\{\\hat{\\gamma} (h_l): l = 1,...,L\\big\\}\\) — значения эмпирической вариограммы для \\(L\\) лагов, вычисленные по \\(N(h_l)\\) векторам. Веса \\(w_l\\) обычно выбираются исходя из отношения \\(w_l = N(h_l) / |h_l|\\), чтобы придать большее значение коротким расстояниям и лагам с хорошей оценкой. Минимизация функционала осуществляется итеративно: Процесс начинается с некоторого предположения \\(\\mathbf{b}^{(0)}\\) На шаге \\(s\\) функция \\(Q\\) аппроксимируется в виде квадратичной формы \\(Q(\\mathbf{b}^{(s)}) \\approx \\sum_{i=1}^k \\sum_{j=1}^k \\delta_{ij} b_i b_j\\) путем разложения в ряд Тейлора вокруг точки \\(\\mathbf{b}^{(s)}\\). Новая точка минимума \\(\\mathbf{b}^{(s+1)}\\) находится как минимум квадратичной формы (этот минимум один). Шаги 2-3 повторяются до тех пор, пока значение \\(Q\\) не станет меньше заданного порога. Сравним результат ручного и автоматического приближения вариограммы: varmd = fit.variogram(vargr, model = vgm(psill = 215, model = &#39;Sph&#39;, range = 120000, nugget = 15)) h0 = lag * 0:(varmd[2, &#39;range&#39;]/lag) h1 = lag * (varmd[2, &#39;range&#39;]/lag + 1):(cutoff/lag) tab2 = tibble::tibble( h = c(h0, h1), gamma = c(varmd[1, &#39;psill&#39;] + (varmd[2, &#39;psill&#39;] * (3 * h0 / (2 * varmd[2, &#39;range&#39;]) - 0.5 * (h0 / varmd[2, &#39;range&#39;])^3)), rep(varmd[1, &#39;psill&#39;] + varmd[2, &#39;psill&#39;], length(h1))), fit = &#39;automatic&#39; ) tab = bind_rows(tab1, tab2) ggplot() + geom_line(vargr, mapping = aes(dist, gamma)) + geom_point(vargr, mapping = aes(dist, gamma), size = 2) + scale_size(range = c(1, 5)) + geom_line(tab, mapping = aes(h, gamma, color = fit), size = 1) + xlab(&#39;lag&#39;) + ylab(&#39;gamma&#39;) + ggtitle(&#39;Сферическая модель&#39;) + theme_bw() 14.4.24 Обычный кригинг Рассмотрим данные по температуре: box = st_bbox(rainfall) envelope = box[c(1,3,2,4)] px_grid = st_as_stars(box, dx = 2000, dy = 2000) ggplot() + geom_sf(data = rainfall, color = &#39;red&#39;) + geom_sf(data = st_as_sf(px_grid), size = 0.5, fill = NA) 14.4.25 Обычный кригинг Визуализируем найденную вариограмму и вариокарту: plot(vargr, model = varmd) plot(varmp) Проинтерполируем, используя приближенную модель вариограммы: (px_grid = krige(rain_24~1, rainfall, px_grid, model = varmd)) ## [using ordinary kriging] ## stars object with 2 dimensions and 2 attributes ## attribute(s): ## var1.pred var1.var ## Min. :-0.4092 Min. : 30.99 ## 1st Qu.: 7.7076 1st Qu.: 45.44 ## Median :18.8332 Median : 52.72 ## Mean :21.5098 Mean : 58.67 ## 3rd Qu.:32.0739 3rd Qu.: 65.48 ## Max. :67.2664 Max. :186.22 ## dimension(s): ## from to offset delta refsys point values ## x 1 213 332239 2000 +proj=utm +zone=32 +datum... NA NULL [x] ## y 1 99 5121556 -2000 +proj=utm +zone=32 +datum... NA NULL [y] 14.4.26 Оценка и дисперсия кригинга rain_colors = colorRampPalette(c(&quot;white&quot;, &quot;dodgerblue&quot;, &quot;dodgerblue4&quot;)) rain_levels = seq(0,80,by=10) rain_ncolors = length(rain_levels)-1 err_colors = colorRampPalette(c(&quot;white&quot;, &quot;coral&quot;, &quot;violetred&quot;)) err_levels = seq(0, 180, by = 20) err_ncolors = length(err_levels) - 1 cont = st_contour(px_grid[&#39;var1.pred&#39;], breaks = rain_levels, contour_lines = TRUE) conterr = st_contour(px_grid[&#39;var1.var&#39;], breaks = err_levels, contour_lines = TRUE) ggplot() + geom_stars(data = cut(px_grid[&#39;var1.pred&#39;], breaks = rain_levels)) + scale_fill_manual(name = &#39;мм&#39;, values = rain_colors(rain_ncolors), labels = paste(rain_levels[-rain_ncolors-1], &#39;-&#39;, rain_levels[-1]), drop = FALSE) + coord_sf(crs = st_crs(rainfall)) + geom_sf(data = cont, color = &#39;black&#39;, size = 0.2) + geom_sf(data = rainfall, color = &#39;black&#39;, size = 0.3) + theme_bw() ggplot() + geom_stars(data = cut(px_grid[&#39;var1.var&#39;], breaks = err_levels)) + scale_fill_manual(name = &#39;мм&#39;, values = err_colors(err_ncolors), labels = paste(err_levels[-err_ncolors-1], &#39;-&#39;, err_levels[-1]), drop = FALSE) + coord_sf(crs = st_crs(rainfall)) + geom_sf(data = conterr, color = &#39;black&#39;, size = 0.2) + geom_sf(data = rainfall, color = &#39;black&#39;, size = 0.3) + theme_bw() Дисперсия кригинга высока там, где мало данных. 14.4.27 Кросс-валидация Для выполнения кросс-валидации воспользуемся функцией krige.cv: cvl = krige.cv(rain_24~1, rainfall, varmd) %&gt;% st_as_sf() %&gt;% mutate(sterr = residual / sqrt(var1.var)) head(cvl %&gt;% st_set_geometry(NULL), 10) ## var1.pred var1.var observed residual zscore fold sterr ## 1 5.743730 34.84033 6.0 0.25627005 0.04341669 1 0.04341669 ## 2 11.137129 60.24070 10.0 -1.13712865 -0.14650910 2 -0.14650910 ## 3 6.929502 47.22732 7.0 0.07049833 0.01025846 3 0.01025846 ## 4 23.252858 48.06354 1.0 -22.25285758 -3.20979954 4 -3.20979954 ## 5 15.655167 56.76258 1.0 -14.65516724 -1.94517957 5 -1.94517957 ## 6 11.794241 44.03055 1.0 -10.79424095 -1.62672846 6 -1.62672846 ## 7 11.325378 62.65261 0.1 -11.22537769 -1.41818009 7 -1.41818009 ## 8 28.421330 75.24988 0.2 -28.22133030 -3.25330355 8 -3.25330355 ## 9 2.340115 58.30350 1.0 -1.34011550 -0.17550719 9 -0.17550719 ## 10 3.489972 62.96551 0.2 -3.28997242 -0.41461106 10 -0.41461106 Cтандартизированные ошибки в стационарном случае должны быть распределены нормально: ggplot(cvl, aes(x = sterr)) + geom_histogram(aes(y = stat(density)), fill = &#39;grey&#39;, color = &#39;black&#39;, size = 0.1) + geom_density(fill = &#39;olivedrab&#39;, alpha = 0.5) + theme_bw() Ошибки должны быть независимы от значений: ggplot(cvl, aes(x = var1.pred, sterr)) + geom_point(alpha = 0.8) + geom_smooth(method = &#39;lm&#39;) + theme_bw() cor.test(~ sterr + var1.pred, data = cvl) ## ## Pearson&#39;s product-moment correlation ## ## data: sterr and var1.pred ## t = -0.084465, df = 253, p-value = 0.9328 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.1280692 0.1176091 ## sample estimates: ## cor ## -0.005310204 Облако рассеяния оценки относительно истинных значений должно быть компактным: ggplot(cvl, aes(x = var1.pred, observed)) + geom_point(alpha = 0.8) + geom_smooth(method = &#39;lm&#39;) + theme_bw() # Диагностика модели линейной регрессии summary(lm(observed ~ var1.pred, cvl)) ## ## Call: ## lm(formula = observed ~ var1.pred, data = cvl) ## ## Residuals: ## Min 1Q Median 3Q Max ## -47.812 -3.914 -0.505 3.227 32.685 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.03375 0.93884 -0.036 0.971 ## var1.pred 1.00020 0.03919 25.519 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 8.405 on 253 degrees of freedom ## Multiple R-squared: 0.7202, Adjusted R-squared: 0.7191 ## F-statistic: 651.2 on 1 and 253 DF, p-value: &lt; 0.00000000000000022 Пространственная картина стандартизированных ошибок должна быть гомогенной: library(akima) coords = st_coordinates(rainfall) coords_grid = st_coordinates(px_grid) px_grid = px_grid %&gt;% mutate(sterr = interpp(x = coords[,1], y = coords[,2], z = cvl$sterr, xo = coords_grid[,1], yo = coords_grid[,2], linear = FALSE, extrap = TRUE)$z) sterr_levels = seq(-8,8,2) sterr_ncolors = length(sterr_levels)-1 sterr_colors = colorRampPalette(c(&#39;blue&#39;, &#39;white&#39;, &#39;red&#39;)) sterrcont = st_contour(px_grid[&#39;sterr&#39;], breaks = sterr_levels, contour_lines = TRUE) ggplot() + geom_stars(data = cut(px_grid[&#39;sterr&#39;], breaks = sterr_levels)) + scale_fill_manual(name = &#39;мм&#39;, values = sterr_colors(sterr_ncolors), labels = paste(sterr_levels[-sterr_ncolors-1], &#39;-&#39;, sterr_levels[-1]), drop = FALSE) + coord_sf(crs = st_crs(rainfall)) + geom_sf(data = sterrcont, color = &#39;black&#39;, size = 0.2) + geom_sf(data = rainfall, color = &#39;black&#39;, size = 0.3) + theme_bw() 14.5 Краткий обзор Для просмотра презентации щелкните на ней один раз левой кнопкой мыши и листайте, используя кнопки на клавиатуре: Презентацию можно открыть в отдельном окне или вкладке браузере. Для этого щелкните по ней правой кнопкой мыши и выберите соответствующую команду. 14.6 Контрольные вопросы и упражнения 14.6.1 Вопросы Дайте определения случайной величины, случайного процесса, сечения случайного процесса, реализации случайного процесса. Проиллюстрируйте их примерами. Сформулируйте определение основных моментов пространственного случайного процесса: математического ожидания, дисперсии и ковариации. Поясните суть этих понятий на конкретных примерах. Дайте определение стационарности в строгом смысле слова и стационарности второго порядка. При каком условии случайная функция является изотропной? Что такое эргодичность? Пояснить суть этого свойства на наглядном примере. Сформулируйте суть кригинга как метода интерполяции данных. В чем его сходства и отличия в сравнении с методом радиальных базисных функций? Что из себя представляет среднеквадратическая ошибка, минимизируемая в методе кригинга? Почему среднеквадратическую ошибку можно считать равной дисперсии в методе простого кригинга? Что характеризует дисперсия кригинга? Напишите систему уравнений простого кригинга и выражение для дисперсии простого кригинга. Дайте определение стационарности приращений. С какой целью вводится данный тип стационарных процессов? Какие условия должны быть выполнены для того чтобы ковариацию можно было заменить вариограммой в уравнениях кригинга? Напишите систему уравнений обычного кригинга и выражение для дисперсии обычного кригинга. Чем эти уравнения отличаются от уравнений простого кригинга? Изложите модель универсального кригинга в математической и словесной форме. Что такое базисные функции и ковариаты? Какую роль они выполняют в методе универсального кригинга? Сформулируйте условия универсальности, от которых ведет свое название метод универсального кригинга. Напишите систему уравнений универсального кригинга и выражение для дисперсии универсального кригинга. Перечислите стандартный набор действий, применяемых в рамках выполнения процедуры кросс-валидации результатов кригинга. Что такое вариограмма? Дайте математическое и словесное определение. Перечислите свойства вариограммы. Назовите основные модели вариограммы. Какая модель свидетельствует о наличии пространственного тренда в данных? Чем эмпирическая вариаограмма отличается от теоретической (модели)? Сформулируйте принципы построения и назначение основных диагностических графиков вариографии: диаграммы рассеяния с лагом, вариограммного облака, эмпирической вариограммы, вариокарты. Объясните, каким образом можно получить приближение (подгонку) теоретической модели вариограммы под эмпирические данные. Расскажите об основных возможностях пакета gstat. Перечислите функции этого пакета, которые используются для вариографии и интерполяции методом кригинга. 14.6.2 Упражнения Загрузите данные дрейфующих буев ARGO на акваторию Северной Атлантики за 30 января 2010 года. Постройте поля распределения солености и температуры методом обычного кригинга с размером ячейки 50 км. Подберите подходящую модель вариограммы. Выполните визуализацию оценки кригинга и дисперсии кригинга средствами ggplot2. Произведите кросс-валидацию полученных результатов. Подсказка: перед построением сетки интерполяции странсформируйте данные в проекцию Меркатора. Чтобы полученное поле распределения покрывало только акваторию, маскируйте полученный растр с использованием слоя ocean из набора данных Natural Earth. Перед выполнением маскирования преобразуйте мультиполигон в обычные полигоны (в противном случае маскирование отработает некорректно). Самсонов Т.Е. Визуализация и анализ географических данных на языке R. М.: Географический факультет МГУ, 2020. DOI: 10.5281/zenodo.901911 "],
["autocorrelation.html", "Глава 15 Пространственная регрессия 15.1 Введение 15.2 Линейная регрессия 15.3 Пространственная регрессия 15.4 Практический анализ 15.5 Пространственное соседство 15.6 Пространственные веса 15.7 Пространственная автокорреляция 15.8 Географически взвешенная регрессия (GWR) 15.9 Краткий обзор 15.10 Контрольные вопросы и упражнения", " Глава 15 Пространственная регрессия Программный код главы 15.1 Введение В данном модуле мы приступим к исследованию связей в географическом пространстве. Понятие пространственной автокорреляции является математическим отражением первого закона географии: все связано со всем, но близкорасположенные объекты связаны сильнее. Различные коэффициенты пространственной автокорреляции, такие как индекс Морана (Moran’s I) позволяют охарактеризовать силу этой связи с точки зрения математической статистики. Однако для их вычисления необходимо формализовать понятия географической близости, или географического соседства. В настоящем модуле рассматриваются различные подходы к решению данной проблемы. Пространственные случайные процессы часть характеризуются следующими свойствами: Пространственная зависимость (spatial dependence) — наличие автокорреляции наблюдений. Выражается в невыполнении условия независимости остатков линейной регрессии. Устраняется посредством пространственной регрессии (spatial regression). Пространственная гетерогенность (spatial heterogeneity) — нестационарность процессов, порождающих наблюдаемую переменную. Выражается в неэффективности постоянных коэффициентов линейной регрессии. Устраняется постредством географически взвешенной регрессии (geographically weighted regression). Общепринятого определения пространственной автокоорреляции (ПА) не существует. Одно из наиболее удачных определений гласит следующее: Для множества \\(S\\), состоящего из \\(n\\) географических единиц, пространственная автокорреляция есть соотношение между переменной, наблюдаемой в каждой из \\(n\\) единиц и мерой географической близости, определенной для всех \\(n(n − 1)\\) пар единиц из \\(S\\) (Hubert et al., 1981)9 Анализ ПА, как правило, осуществляется по жестко зафиксированной сетке (lattice) учетных единиц, в качестве которых могут выступать как площади, так и точки. Но, строго говоря, пространственная статистика в конечном счете любую единицу будет интерпретировать как точку. Конечной целью исследований ПА является построение статистической модели зависимости значения показателя в каждой единице от значений в соседних единицах и (опционально) неких факторов. Наличие статистически значимой ПА говорит о влиянии процессов, обуславливающих кластеризацию значений в соседних территориальных единицах. И пока эти механизмы не установлены, модель ПА дает инструмент их статистического моделирования. Добавление известных факторов в модель может улучшить точность моделирования. 15.2 Линейная регрессия Пусть дан вектор \\(\\mathbf{y} = \\{y_1, y_2, ... y_n\\}\\) измерений зависимой переменной, а также матрица \\(\\mathbf{X} = \\{x_{ij}\\}\\) размером \\(n \\times m\\), состоящая из значений \\(m\\) независимых переменных для \\(n\\) измерений. В этом случае модель линейной регрессии может быть записана как \\[\\mathbf{y} = \\mathbf{X} \\boldsymbol\\beta + \\boldsymbol\\epsilon,\\] где: \\(\\boldsymbol\\beta\\) — вектор коэффициентов регрессии; \\(\\boldsymbol\\epsilon\\) — вектор случайных ошибок, независимо распределенных относительно среднего значения в нуле. Многомерное нормальное распределение (МНР) \\(k\\)-мерного случайного вектора \\(\\mathbf{X} = (X_1, ..., X_k)^T\\) обозначается как: \\[\\mathbf{X}\\ \\sim \\mathcal{N}_k(\\boldsymbol\\mu,\\, \\boldsymbol\\Sigma)\\] МНР определяется двумя параметрами: математическое ожидание ( \\(k\\)-мерный вектор): \\[\\boldsymbol\\mu = \\operatorname{E}[\\mathbf{X}] = [ \\operatorname{E}[X_1], \\operatorname{E}[X_2], \\ldots, \\operatorname{E}[X_k]]^{\\rm T}\\] ковариационная матрица (размером \\(k \\times k\\)): \\[\\boldsymbol\\Sigma = \\operatorname{E} [(\\mathbf{X} - \\boldsymbol\\mu)( \\mathbf{X} - \\boldsymbol \\mu)^{\\rm T}] = [ \\operatorname{Cov}[X_i, X_j]; 1 \\le i,j \\le k ]\\] Вещественнозначный случайный вектор \\(\\mathbf{X} = (X_1, ..., X_k)^T\\) называется стандартным нормальным случайным вектором, если все его компоненты \\(X_n\\) независимы друг от друга и подчиняются стандартному случаю нормального закона распределения с нулевым математическим ожиданием и единичной дисперсией для всех \\(n\\): \\[X_n \\sim \\mathcal{N}(0, 1)\\] В модели линейной регрессии: \\[\\boldsymbol\\epsilon \\sim \\mathcal{N}_k(0, \\sigma^2 \\mathbf{I}),\\] где \\(I\\) — единичная матрица размером \\(k \\times k\\). Если данные получены измерениями по пространству, остатки регрессии могут демонстрировать пространственную ассоциацию (зависимость), как правило свидетельствующую о наличии дополнительных неучтённых факторов. Это означает, что обычная модель регрессии недостаточно хорошо объясняет зависимость. В качестве примера приведем модель, в которой процент домохозяйств, находящихся во владении, моделируется как переменная зависимая от уровня безработицы [Fotheringam, Brunsdon, Charlton, 2002]: Рис. 15.1: Процент домохозяйств, находящихся во владении Рис. 15.2: Уровень безработицы Обычная линейная регрессия показывает хорошую согласованность между этими параметрами: Рис. 15.3: Зависимость процента домохозяйств во владении от уровня безработицы Однако остатки регрессии демонстрируют явную пространственную зависимость, что говорит о том, что построенная модель неадекватно описывает исследуемую закономерность: Рис. 15.4: Остатки линейной регрессии Чтобы моделировать подобную зависимость остатков, необходим более широкий класс моделей: \\[\\boldsymbol\\epsilon \\sim \\mathcal{N}_k(0, \\mathbf{C}),\\] где \\(\\mathbf{C}\\) — любая допустимая ковариационная матрица. Данная модель решает проблему независимости остатков, однако порождает две других проблемы: Если зависимость остатков имеет пространственный характер (ассоциированы остатки в территориально близких локациях), то матрица \\(\\mathbf{C}\\) характер этой зависимости не отражает в явном виде. Вектор коэффициентов регрессии \\(\\boldsymbol\\beta\\) может быть получен путем минимизации \\(\\mathbf{y} - \\mathbf{X}\\boldsymbol\\beta\\) путем решения \\(\\beta = \\big(\\mathbf{X}^T \\mathbf{CX} \\big)^{-1} \\mathbf{X}^T \\mathbf{X y}\\). Однако это требует знания ковариационной матрицы, которая обычно неизвестна. Поэтому как \\(\\mathbf{C}\\), так и \\(\\boldsymbol\\beta\\) калибруются по выборке. 15.3 Пространственная регрессия Для того чтобы учесть пространственную автокорреляцию остатков, в модель линейной регрессии добавляется компонента пространственной авторегрессии (spatial autoregression), которая моделирует пространстенный лаг: \\[\\mathbf{y} = \\mathbf{X} \\mathbf{\\beta} + \\color{red}{\\rho\\mathbf{Wy}} + \\mathbf{\\epsilon},\\] \\(\\rho\\) — коэффициент регрессии, отражающий степень пространственной автокорреляции \\(\\mathbf{W}\\) — матрица пространственных весов Полученная модель называется моделью пространственной регрессии (spatial regression). Для получения коэффициентов \\(\\boldsymbol\\beta\\) и \\(\\rho\\) выполним ряд преобразований: \\[\\mathbf{y} = \\mathbf{X} \\mathbf{\\beta} + \\rho\\mathbf{Wy} + \\mathbf{\\epsilon}\\\\ \\mathbf{y} - \\rho\\mathbf{Wy} = \\mathbf{X} \\mathbf{\\beta} + \\mathbf{\\epsilon}\\\\ (\\mathbf{I} - \\rho\\mathbf{W})\\mathbf{y} = \\mathbf{X} \\mathbf{\\beta} + \\mathbf{\\epsilon}\\] Предполагая, что матрица \\((\\mathbf{I} - \\rho\\mathbf{W})\\) инвертируема, получаем систему уравнений пространственной регрессии: \\[\\color{red}{\\boxed{\\color{blue}{\\mathbf{y} = (\\mathbf{I} - \\rho\\mathbf{W})^{-1}\\mathbf{X}\\mathbf{\\beta} + (\\mathbf{I} - \\rho\\mathbf{W})^{-1}\\mathbf{\\epsilon}}}}\\] Данная модель идентична обычной регрессии \\(\\mathbf{y} = \\mathbf{X} \\mathbf{\\beta} + \\mathbf{\\epsilon}\\), но в ней независимые переменные и ошибки линейно трансформированы умножением на \\((\\mathbf{I} - \\rho\\mathbf{W})^{-1}\\). \\[\\mathbf{y} = (\\mathbf{I} - \\rho\\mathbf{W})^{-1}\\mathbf{X}\\mathbf{\\beta} + (\\mathbf{I} - \\rho\\mathbf{W})^{-1}\\mathbf{\\epsilon}\\] Трансформированная ошибка модели будет иметь ковариационную матрицу \\[\\mathbf{C} = \\sigma^2 \\Big[\\big(\\mathbf{I} - \\rho \\mathbf{W}\\big)^{-1}\\Big]^T (\\mathbf{I} - \\rho\\mathbf{W})^{-1}\\] Если ковариационная матрица функционально зависит от параметра \\(\\rho\\), то она отражает пространственную структуру автокорреляции ошибок. Ковариационная матрица должна быть положительно определенной. Для полученного выражения это будет выполняться в случае если \\(|\\rho| \\leq 1\\) (Griffith, 1988). \\[\\mathbf{y} = \\mathbf{X} \\mathbf{\\beta} + \\rho\\mathbf{Wy} + \\mathbf{\\epsilon}\\] Для нахождения коэффициентов \\(\\boldsymbol\\beta\\) и \\(\\rho\\) используется минимизация квадрата случайной компоненты, которую можно представить как \\(\\mathbf{\\epsilon} = \\mathbf{y} - \\mathbf{X} \\mathbf{\\beta} - \\rho\\mathbf{Wy}\\): \\[\\sum_i \\Bigg(y_i - \\sum_j \\beta_j x_{ij} - \\rho \\sum_j w_{ij} y_j \\Bigg)^2\\] Задача решается в 2 этапа: находится оптимальное значение \\(\\rho\\); находится оптимальное значение \\(\\boldsymbol\\beta\\) путем подстановки в вышеуказанное выражение. Модель пространственной регрессии может быть использована для осуществления пространственной фильтрации — убирания автокорреляционной составляющей. Для этого необходимо авторегрессионную компоненту (пространственный лаг) перенести в левую часть уравнения: \\[\\mathbf{y} = \\mathbf{X} \\mathbf{\\beta} + \\rho\\mathbf{Wy} + \\mathbf{\\epsilon}\\\\ \\mathbf{y}^* = \\mathbf{y} - \\rho\\mathbf{Wy} = \\mathbf{X} \\mathbf{\\beta} + \\mathbf{\\epsilon}\\] Данная модель представляет собой стандартную (непространственную) регрессию для независимой переменной \\(\\mathbf{y}^*\\), в которой пространственная корреляция убрана (подвергнута фильтрации). Пространственная фильтрация бывает полезна, когда наблюдается несоответствие масштаба наблюдений и масштаба процесса. Например, статистика по показателю, контролируемому на региональном уровне, собирается по муниципалитетам. В этом случае фильтрация позволяет подобрать параметры \\(\\mathbf{\\beta}\\), учитывающие наличие высокой пространственной автокорреляци. 15.4 Практический анализ Как мы уже сказали, исследование ПА начинается с анализа географического соседства. То есть, для каждой анализируемой единицы мы должны определить соседние по отношению к ней единицы. Это не так-то просто,поскольку существует множество способов определить соседство. Перед выполнением анализа подключим необходимые библиотеки и визуализируем исходные данные, в качестве которых выступают границы муниципалитетов Кировской области. library(sf) library(spdep) # оценка соседства, построение матрицы весов, индексы автокорреляции library(spatialreg) # пространственная регрессия library(lattice) library(RANN) library(RColorBrewer) library(readxl) library(tidyverse) library(tmap) library(GWmodel) options(scipen = 999) reg_sf = st_read(&#39;data/Kirov.gpkg&#39;) ## Reading layer `Kirov&#39; from data source `/Users/tsamsonov/GitHub/r-geo-course/data/Kirov.gpkg&#39; using driver `GPKG&#39; ## Simple feature collection with 40 features and 20 fields ## geometry type: POLYGON ## dimension: XY ## bbox: xmin: -216808.3 ymin: 2896149 xmax: 227259 ymax: 3455774 ## epsg (SRID): NA ## proj4string: +proj=eqdc +lat_0=30 +lon_0=50 +lat_1=57.5 +lat_2=59 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs reg = st_geometry(reg_sf) par(mar = c(1, 1, 1, 1)) plot(reg, border = &quot;gray50&quot;) 15.5 Пространственное соседство В целом, можно выделить три большие группы методов: Соседи по смежности Соседи по графу Соседи по метрике Соседство по смежности основано на топологических отношениях между объектами и применяется при анализе данных, приуроченных к площадным единицам — например, сетке административно-территориального деления. Смежными считаются объекты, границы которых имеют общие точки. При этом возможно два варианта соседства: по правилу ферзя (QUEEN) и правилу ладьи (ROOK). В первом случае соседними будут считаться все пары территориальных единиц, имеющие хотя бы одну общую точку на границе, т.е. соприкасющиеся сторонами и/или углами. Соседство по правилу ладьи является более строгим, так как разрешает только наличие общих сторон вдоль границ, а точечные касания в расчет не берутся. Отличия правил иллюстрирует рисунок ниже. Поиск географических соседей по правилу ферзя и правилу ладьи Соседство по графу основано на отношениях объектов в триангуляции Делоне. В эту же категорию попадают всевозможные фильтрации триангуляции Делоне, которые удаляют из нее ребра, не удовлетворяющие заданным критериям. Более подбробно о них будет сказано ниже. Соседство по метрике основано на вычислении расстояний между объектаи. Соседними по отношению к каждому объекту будут считаться либо \\(K\\) ближайших к нему объектов (соседи по количеству), либо все объекты, удаленные на растояние не далее \\(D_{max}\\) (соседи по расстоянию). Результатом анализа соседства является граф соседства(neighborhood graph), в котором сами объекты являются вершинами, а связи между ними — ребрами. Анализ географического соседства на языке R можно провести с помощью пакета spdep. Рассмотрим суть и принципы построения графов соседства на основе различных принципов. 15.5.1 Соседи по смежности Список соседей по смежности можно получить с помощью функции poly2nb(). Возвращаемый объект является классом типа nb. Для каждой единицы в нем содержится список номеров соседних по отношению к нему единиц. По умолчанию функция находит соседей по правилу ферзя: nb_queen = poly2nb(reg) # Соседство по правилу ферзя nb_queen # посмотрим сводную информацию ## Neighbour list object: ## Number of regions: 40 ## Number of nonzero links: 174 ## Percentage nonzero weights: 10.875 ## Average number of links: 4.35 class(nb_queen) # проверим тип объекта ## [1] &quot;nb&quot; Для объектов типа nb в пакете spdep определена своя функция plot(), которая позволяет визуализировать граф соседства. Функция требует на вход координаты точек, в случае площадных единиц для этого используют центроиды площадей, которые можно получить функцией coordinates(): coords = reg %&gt;% st_centroid() %&gt;% st_coordinates() # Теперь рисуем граф: plot(reg, border = &quot;gray50&quot;) plot(nb_queen, coords, pch = 19, cex = 0.5, add = TRUE) title(main = &quot;Соседи по смежности (правило ферзя)&quot;) Для определения соседей по правилу ладьи необходимо вызвать функцию poly2nb() с аргументом queen=FALSE. В нашем случае, правда, это даст тот же результат, поскольку в данных отсутствуют единицы, соприкасающиеся в одной лишь точке: nb_rook = poly2nb(reg, queen = FALSE) # Соседство по правилу ладьи plot(reg, border = &quot;grey70&quot;) plot(nb_rook, coords, pch = 19, cex = 0.5, add = TRUE) title(main = &quot;Соседи по смежности (правило ладьи)&quot;) Обратим внимание на то, что функция poly2nb() принимает на вход площадные объекты. Все помледующие методы определения соседства (по графу и по метрике) работают с точечными данными. 15.5.2 Соседи по графу Данная группа методов определения соседства основана на построении триангуляции Делоне для точек исходных данных. Далее эта триангуляция может быть оставлена в неизменном виде, или быть подвержена процедуре фильтрации, которая удалит из нее ребра, не удовлетворяющие заданному критерию. Соседи по триангуляции Делоне без фильтрации могут быть получены с помощью функции tri2nb(): nb_tin = tri2nb(coords) plot(reg, border = &quot;grey70&quot;) plot(nb_tin, coords, pch = 19, cex = 0.5, add = TRUE) title(main = &quot;Соседи по триангуляции Делоне&quot;) Соседи по сфере влияния получаются путем фильтрации триангуляции Делоне. Для каждой вершины находится расстояние до ближайшего соседа \\(D_{min}\\) — это расстояние называется радиусом сферы влияния вершины. Остальные ребра триангуляции, инцидентные (примыкающие к) данной вершине, сохраняются только если их длина \\(D\\) превышает радиус ее сферы влияния не более чем вдвое: \\(D \\leq 2D_{min}\\). Рассуждая геометрически, можно сказать, что сферы радиусом \\(D_{min}\\), построенные в точке и ее соседях по триангуляции, должны пересекаться. Процесс фильтрации по сфере влияния иллюстрирует рисунок ниже. Поиск географических соседей по правилу сферы влияния Поиск соседей по сфере влияния построен по аналогии с принципом сферы действия тяготения из небесной механики. Построение соседей по правилу сферы влияния осуществляется в 3 шага: определение соседей по триангуляции (функция tri2nb()) фильтрация триангуляции по правилу сферы влияния (функция soi.graph()) преобразование полученного объекта в класс nb(функция graph2nb()) nb_tin = soi.graph(nb_tin, coords) %&gt;% graph2nb() plot(reg, border = &quot;grey70&quot;) plot(nb_tin, coords, pch = 19, cex = 0.5, add = TRUE) title(main = &quot;Соседи по сфере влияния&quot;) Соседи по графу Гэбриела получаются также путем фильтрации триангуляции Делоне. В каждом треугольнике ребро сохранятся только тогда, когда построенная на нем окружность не включает третью точку треугольника (Gabriel, Sokal, 1969)10. Данный метод проиллюстрирован рисунком ниже. Поиск географических соседей по графу Гэбриела Поиск соседей по графу Гэбриела осуществляется в 2 шага: построение графа Гэбриела (функция gabrielneigh()) преобразование полученного объекта в класс nb(функция graph2nb()) nb_gab = gabrielneigh(coords) %&gt;% graph2nb() plot(reg, border = &quot;grey70&quot;) plot(nb_gab, coords, pch = 19, cex = 0.5, add = TRUE) title(main = &quot;Соседи по графу Гэбриела&quot;) Относительные соседи по графу получаются путем фильтрации триангуляции Делоне по следующему правилу: ребро \\(A\\), соединяющее две вершины \\(p\\) и \\(q\\), будет удалено, если найдется третья вершина \\(r\\), такая что расстояния от нее до \\(p\\) и \\(q\\) (\\(B\\) и \\(C\\) соответственно) окажутся короче, чем \\(A\\), то есть: \\(A &gt; B\\) and \\(A &gt; C\\). Полученный граф носит название графа относительных соседей (relative neighborhood graph). Данный метод был предложен французским информатиком Готфридом Туассеном для выявления структуры множества точек, которая бы максимально соответствовала восприятию человеком формы этого множества (Toussaint, 1980)11. Поиск соседей по графу относительных соседей осуществляется в 2 шага: построение графа относительных соседей (функция relativeneigh()) преобразование полученного объекта в класс nb(функция graph2nb()) nb_rel = relativeneigh(coords) %&gt;% graph2nb() plot(reg, border = &quot;grey70&quot;) plot(nb_rel, coords, pch = 19, cex = 0.5, add = TRUE) title(main = &quot;Относительные соседи по графу&quot;) 15.5.3 Соседи по метрике Поиск соседей по метрике — наиболее простой способ определения соседства. Для его использования необходимо задать метрику (как правило, расстояние между точками), а также критерий фильтрации связей: по количеству (\\(k\\) ближайших) или по расстоянию (не ближе чем \\(d_1\\), но и не далее чем \\(d_2\\)). Поиск соседей по количеству осуществляется в 2 шага: построение списка соседей (функция knearneigh()) преобразование полученного объекта в класс nb(функция knn2nb()) Рассмотрим поиск по количеству на примере нескольких пороговых значений: par(mfrow = c(2,2), mar = c(1,1,1,1)) for (i in 1:4){ nb_knn = knearneigh(coords, k = i) %&gt;% knn2nb() plot(reg, border = &quot;grey70&quot;) plot(nb_knn, coords, pch = 19, cex = 0.5, add = TRUE) title(main = paste(&quot;Ближайшие соседи (k = &quot;, i, &quot;)&quot;, sep = &#39;&#39;)) } Поиск соседей по расстоянию осуществляется средствами функции dnearneigh(), которая принимает 3 аргумента: координаты точек, минимальное \\(d_1\\) и максимальное \\(d_2\\) расстояние. Минимальное расстояние имеет смысл использовать чтобы избежать анализа совпадающих по положению объектов, или когда известен пространственный период явления, превышающий \\(d_1\\): par(mfrow = c(2,2), mar = c(1,1,1,1)) for (d in 5:8) { dnearnei = dnearneigh(coords, d1 = 0, d2 = 10000 * d) plot(reg, border = &quot;grey70&quot;) plot(dnearnei, coords, pch = 19, cex = 0.5, add = TRUE) title(main = paste(&quot;Ближайшие соседи (d &lt;=&quot;, 10000 * d, &quot;)&quot;, sep = &#39;&#39;)) } Итак, мы рассмотрели различные принципы выявления географического соседства. После того, как определен сам факт соседства, необходимо оценить силу пространственной связи между всеми парами соседних единиц. Эта оценка производится путем построения матрицы пространственных весов(spatial weights matrix). 15.6 Пространственные веса Пространственные веса характеризуют силу связи между единицами. Если единицы не являются соседними (по выбранному правилу), то пространственный вес их связи будет равен нулю. Во всех остальных случаях веса будут ненулевыми. Поскольку теоретически каждая единица может быть связана с любой другой единицей, распространена форма представления весов в виде матрицы \\(W\\) размером \\(N \\times N\\), где \\(N\\) – число единиц. На пересечении \\(i\\)-й строки и \\(j\\)-го столбца матрицы располагается вес связи между \\(i\\)-й и \\(j\\)-й единицей. Простейший вид матрицы \\(W\\) — бинарная. Если связь есть, то ее вес равен единице (1), если нет — нулю (0). Для построения бинарной матрицы нужно использовать функцию nb2listw() c параметром style=\"B\": Wbin = nb2listw(nb_queen, style = &quot;B&quot;) Wbin # посмотрим, что за объект получается на выходе (listw) ## Characteristics of weights list object: ## Neighbour list object: ## Number of regions: 40 ## Number of nonzero links: 174 ## Percentage nonzero weights: 10.875 ## Average number of links: 4.35 ## ## Weights style: B ## Weights constants summary: ## n nn S0 S1 S2 ## B 40 1600 174 348 3416 Оказывается, что это на самом деле не матрица. Это объект с двумя слотами. В слоте weights содержатся веса, а в слоте neighbours — идентификаторы соседей: Wbin$neighbours ## Neighbour list object: ## Number of regions: 40 ## Number of nonzero links: 174 ## Percentage nonzero weights: 10.875 ## Average number of links: 4.35 Wbin$weights ## [[1]] ## [1] 1 1 1 1 1 ## ## [[2]] ## [1] 1 1 ## ## [[3]] ## [1] 1 1 1 1 1 1 ## ## [[4]] ## [1] 1 1 1 1 1 1 ## ## [[5]] ## [1] 1 1 1 1 ## ## [[6]] ## [1] 1 1 1 1 1 1 1 ## ## [[7]] ## [1] 1 ## ## [[8]] ## [1] 1 1 1 1 1 1 ## ## [[9]] ## [1] 1 1 1 1 1 1 ## ## [[10]] ## [1] 1 1 1 ## ## [[11]] ## [1] 1 1 1 ## ## [[12]] ## [1] 1 1 1 1 1 ## ## [[13]] ## [1] 1 1 1 1 1 ## ## [[14]] ## [1] 1 1 1 1 1 1 1 ## ## [[15]] ## [1] 1 1 1 1 1 1 ## ## [[16]] ## [1] 1 1 1 ## ## [[17]] ## [1] 1 1 ## ## [[18]] ## [1] 1 1 1 ## ## [[19]] ## [1] 1 1 1 1 ## ## [[20]] ## [1] 1 1 1 ## ## [[21]] ## [1] 1 1 1 1 1 1 ## ## [[22]] ## [1] 1 1 1 1 1 1 ## ## [[23]] ## [1] 1 1 1 1 ## ## [[24]] ## [1] 1 1 1 1 ## ## [[25]] ## [1] 1 1 1 1 1 1 ## ## [[26]] ## [1] 1 1 1 1 1 1 ## ## [[27]] ## [1] 1 1 1 1 ## ## [[28]] ## [1] 1 1 ## ## [[29]] ## [1] 1 1 ## ## [[30]] ## [1] 1 1 1 ## ## [[31]] ## [1] 1 1 1 1 1 1 ## ## [[32]] ## [1] 1 1 1 1 1 ## ## [[33]] ## [1] 1 1 1 1 1 ## ## [[34]] ## [1] 1 1 1 1 1 ## ## [[35]] ## [1] 1 1 1 ## ## [[36]] ## [1] 1 1 1 1 1 ## ## [[37]] ## [1] 1 1 1 1 1 ## ## [[38]] ## [1] 1 1 ## ## [[39]] ## [1] 1 1 1 1 ## ## [[40]] ## [1] 1 1 1 1 ## ## attr(,&quot;mode&quot;) ## [1] &quot;binary&quot; ## attr(,&quot;B&quot;) ## [1] TRUE Дело в том, что матрица весов всегда получается разреженной. То есть, в основном она содержит нули. Это логично, поскольку у каждой точки как правило есть лишь ограниченное число соседей. При этом общее количество точек может быть достаточно большим: чем больше точек мы анализируем, тем больше будет нулей в матрице. Получается, что хранить матрицу как матрицу неэкономично. Более рационально для каждого объекта возвращать список весов, которые соответствуют его соседям. Что и делает функция nb2listw(). Матрицу весов как правило визуализируют, поскольку она может содержать в себе довольно интересные паттерны. Для этого полученный список весов нужно превратить в матрицу с помощью функции listw2mat(). Далее использовать функцию levelplot из пакета lattice, которая раскрашивает ячейки матрицы или растрового набора данных: M = listw2mat(Wbin) levelplot(M, main = &quot;Матрица весов (бинарная)&quot;) Более интересный результат дает нормированная матрица. В ней веса всех соседей нормируются на количество соседей. То есть, если у текущей точки 2 соседа, их веса будут равны 0.5. Если 3 соседа то 0.33, 4 — 0.25 и так далее. Взвешенная матрица позволяет отразить тот факт, что одна и та же территориальная единица может оказывать неодинаковое влияние на соседние единицы: Wstand = nb2listw(nb_queen, style = &quot;W&quot;) M = listw2mat(Wstand) ramp = colorRampPalette(c(&quot;white&quot;,&quot;red&quot;)) levels = 1 / 1:10 # шкала 1, 0.5, 0.33, 0.25 ... 0.1 levelplot(M, main=&quot;Матрица весов (нормированная)&quot;, at = levels, col.regions=ramp(10)) Обратите внимание, что на этот раз цвета в матрице распределены асимметрично. Однако есть методы определения соседства, которые приведут также и к асимметричному виду самой матрицы, а не только значений. Например, при поиске соседей по количеству соседство A и B вовсе не означает соседство B и A. Проверим это на опыте: # Ближайшие соседи (k = 1) nb_knn = knearneigh(coords, k = 1) %&gt;% knn2nb() Wstand = nb2listw(nb_knn, style = &quot;B&quot;) M = listw2mat(Wstand) levelplot(M, main = &quot;Матрица весов (нормированная)&quot;, at = levels, col.regions = ramp(10)) Полученная матрица весов дает искомую меру потенциальной пространственной связи (близости) между всеми парами территориальных единиц. Сопоставив эту меру со значениями показателя, зафиксированными в тех же единицах, можно получить статистическую оценку пространственной автокорреляции изучаемой величины. 15.7 Пространственная автокорреляция Далее мы рассмотрим вычисление меры пространственной автокорреляции — индекса Морана, который дает оценку статистической зависимости между значением показателя в каждой локации (территориальной единице) и значениями в соседних локациях. Имея предположение о наличии пространственной автокорреляции, можно построить модель пространственной авторегрессии, которая дает фоновое распределение показателя по территориальным единицам, а также случайные остатки. На этом занятии мы кратко познакомимся со статистической оценкой пространственной автокорреляции, а также построением простейших авторегрессионных моделей. Мы будем использовать месячную статистику по случаям заболеваний верхних дыхательных путей в Кировской области за 2015 год (данные Росстата по районам, модифицированы автором для большей наглядности анализа). Вам предстоит выполнить следующую последовательность действий: Загрузить исходные данные (границы районов и таблицу со статистикой) Присоединить таблицу к пространственным данным Построить серию карт по месяцам для визуального анализа данных Вычислить матрицу пространственных весов \\(W\\) Вычислить I-индекс Морана для численной оценки пространственной автокорреляции Построить диаграмму рассеяния Морана для визуальной оценки пространственной автокорреляции Подобрать параметры модели пространственной авторегрессии Построить карты реальных, модельных (fitted) значений и остатков (lag) Для начала построим серию карт чтобы оценить по ним наличие или отсутствие пространственной автокорреляции по месяцам: mun_src = reg_sf # Чтение таблицы со статистикой tab = read_xlsx(&quot;data/Kirov.xlsx&quot;, 1) # Соединение таблиц mun = mun_src %&gt;% left_join(tab, by = c(&quot;OBJECTID&quot; = &quot;N&quot;)) %&gt;% pivot_longer(cols = 22:31, names_to = &#39;month&#39;, values_to = &#39;nsick&#39;) %&gt;% mutate(month = ordered(month, levels = c(&#39;Январь&#39;, &#39;Февраль&#39;, &#39;Март&#39;, &#39;Апрель&#39;, &#39;Май&#39;, &#39;Июнь&#39;, &#39;Июль&#39;, &#39;Август&#39;, &#39;Сентябрь&#39;, &#39;Октябрь&#39;, &#39;Ноябрь&#39;, &#39;Декабрь&#39;))) %&gt;% st_set_geometry(&#39;geometry&#39;) # Построение серии карт ramp = colorRampPalette(c(&quot;white&quot;, &quot;orange&quot;, &quot;red&quot;)) levels = seq(0, 10000, 1000) nclasses = length(levels) - 1 ggplot() + geom_sf(mun, mapping = aes(geometry = geometry, fill = cut(nsick, levels))) + scale_fill_manual(values = ramp(nclasses), labels = paste(levels[-nclasses-1], &#39;-&#39;, levels[-1]), guide = guide_legend(reverse = TRUE), drop = FALSE) + facet_wrap(~month) Данная серия карт показывает, что наиболее интересный для анализа месяц — февраль, в котором наблюдается рост заболеваемости, а также очевидно наличие пространственной автокорреляции с двумя очагами в центральных и северо-зпапдных районах области. Вычислим матрицу пространственных весов: # Определение соседства (правило ферзя) nb_queen = poly2nb(mun_src) # Визиуализация графа соседства coords = st_centroid(mun_src) %&gt;% st_coordinates() plot(mun_src %&gt;% st_geometry(), border = &quot;darkgray&quot;) plot(nb_queen, coords, pch = 19, cex = 0.5, add = TRUE) title(main = &quot;Соседи по смежности (правило ферзя)&quot;) # Вычисление весов (нормированная матрица) W = nb2listw(nb_queen) # Визуализация матрицы весов M = listw2mat(W) ramp2 = colorRampPalette(c(&quot;white&quot;,&quot;red&quot;)) levels2 = 1 / 1:10 # шкала 1, 0.5, 0.33, 0.25 ... 0.1 levelplot(M, main = &quot;Матрица весов (нормированная)&quot;, at = levels2, col.regions = ramp2(10)) 15.7.1 Индекс Морана (Moran’s I) Анализ пространственной автокорреляции осуществляется, как правило, путем вычисления индекса Морана (Moran’s I), : \\[ I = \\frac{n \\sum^n_{i=1} \\sum^n_{j=i} w_{ij} (y_i - \\bar y)(y_j - \\bar y)}{ \\Big[\\sum^n_{i=1} \\sum^n_{j=i} w_{ij}\\Big] \\Big[\\sum^n_{i=1} (y_i - \\bar y)^2\\Big]} \\] где \\(n\\) — количество единиц, \\(w_{ij}\\) — вес пространственной связи между \\(i\\)-й и \\(j\\)-й единицей, \\(y_i\\) — значение в \\(i\\)-й единице, \\(\\bar y\\) — выборочное среднее по всем единицам Обратим внимание на то, что индекс Морана по сути и форме записи похож на линейный коэффициент корреляции Пирсона, в котором перебираются все пары соответствующих друг другу значений из рядов \\(X = \\{x_i\\}\\) и \\(Y = \\{y_i\\}\\): \\[ r_{xy} = \\frac{\\sum_{i=1}^{n}(x_i - \\bar x)(y_i - \\bar y)}{\\sqrt{\\sum_{i=1}^{n}(x_i - \\bar x)^2} \\sqrt{\\sum_{i=1}^{n}(y_i - \\bar y)^2}} \\] При вычислении индекса Морана происходит нечто подобное, но под соответствием понимается наличие соседства между \\(i\\)-й и \\(j\\)-й территориальной единицей. Степень выраженности соседства задается весом \\(W_{ij}\\), который можно наблюдать в числителе формулы индекса Морана. Таким образом, пары территориальных единиц, для которых \\(w_{ij} = 0\\), не участвуют в вычислении индекса Морана. Индекс Морана для нормально распределенных данных лежит в диапазоне от -1 до 1: +1 означает детерминированную прямую зависимость — группировку схожих (низких или высоких) значений. 0 означает абсолютно случайное распределение (CSR — complete spatial randomness) -1 означает детерминированную обратную зависимость — идеальное перемешивание низких и высоких значений, напоминающее шахматную доску Для вычисления индекса Морана следует использовать функцию moran.test(), которая дополнительно оценивает статистическую значимость полученного значения: # Выбираем данные за февраль feb = mun %&gt;% filter(month == &#39;Февраль&#39;) # Вычисление индекса (тест) Морана moran.test(feb$nsick, W) ## ## Moran I test under randomisation ## ## data: feb$nsick ## weights: W ## ## Moran I statistic standard deviate = 5.0335, p-value = 0.0000002408 ## alternative hypothesis: greater ## sample estimates: ## Moran I statistic Expectation Variance ## 0.52118132 -0.02564103 0.01180194 Результаты теста включают в себя следующие значения: Moran I statistic — полученный индекс Морана Expectation — математическое ожидание индекса при нулевой гипотезе \\(E[I]\\) Variance — дисперсия ожидаемого значения при нулевой гипотезе \\(D[I]\\) Moran I statistic standard deviate — \\(Z\\)-оценка вычисленного индекса Морана p-value — \\(p\\)-значение вычисленного индекса Морана Здесь мы видим, что значение индекса Морана равно ~\\(0.52\\) (Moran I statistic), то есть присутствует положительная пространственная автокорреляция. При этом вероятность того, что мы ошибаемся в наших выводах, и распределение на самом деле случайно - крайне мала и равна \\(2.408 \\times 10^{-7})\\) (p-value), то есть менее \\(0.0001\\%\\). Можно принимать гипотезу о наличии пространственной автокорреляции. Рассмотрим чуть подробнее, откуда берутся эти и остальные значения результатов теста, и как их правильно интерпретировать. Обычно для сравнения принимают предположение о том, что исследуемая величина распределена случайно. Это так называемая “нулевая” гипотеза. После того как мы вычислили индекс Морана по фактическим данным, можно вычислить его аналитически, приняв нулевую гипотезу. В этом случае математическое ожидание индекса \\(E[I] = -1/(n-1)\\), где \\(n\\) - количество территориальных единиц. Также может быть вычислена и дисперсия индекса Морана \\(D[I]\\) (в англоязычной литературе дисперсия обозначается \\(V[I]\\)). Эти два параметра определяют функцию распределения индекса Морана при всевозможных случайных расстановках исследуемой величины по территориальным единицам. Грубо говоря, такое распределение получится, если мы извлечем все фактические данные, будем их случайным образом перемешивать между территориями и каждый раз вычислять индекс Морана, повторяя процедуру бесконечное число раз. Полученные индексы будут распределены нормально. Значимость фактического индекса Морана можно оценить путем его сравнения с ожидаемым значением индекса \\(E[I]\\) и его стандартным отклонением \\(s = \\sqrt D\\) Для такой оценки используется \\(Z\\)-тест Фишера. \\(Z\\)-значение вычисляется по формуле: \\(Z = (I - E[I])/s\\) Эта величина говорит нам о том, на какое количество стандартных отклонений фактическое значение индекса Морана удалено от ожидаемого значения. Чем сильнее оно удалено — тем менее вероятно, что фактическое распределение случайно. Какова же эта вероятность? Каждому значению \\(Z\\)-score соответствует \\(p\\)-значение (p-value). P-value — это вероятность появления значений, удаленных от мат. ожидания далее чем \\(Z\\)-score. Например, при: \\(Z &lt; -1.96\\) или \\(Z &gt; +1.96\\) значение \\(p &lt; 0.05\\) \\(Z &lt; -2.58\\) или \\(Z &gt; +2.58\\) значение \\(p &lt; 0.01\\) Это означает, что вероятность того, что фактическое значение индекса Морана могло бы появиться на основе случайно распределенных данных с вероятностью \\(5\\%\\) и \\(1\\%\\) соответственно. Чем меньше \\(p\\), тем менее вероятно, что распределение случайно. Говорят, что \\(p\\) — это вероятность сделать ошибку первого рода, т.е. отвергнуть нулевую гипотезу, в то время как она на самом деле является истинной. 15.7.2 Перестановочный тест Морана Графически вышеприведенные рассуждения можно иллюстрировать с помощью перестановочного теста (permutation test). Для этого значения исследуемой нами величины перемешиваются между территориальными единицами и далее строится гистограмма распределения. Перестановочный тест выполняется с помощью функции moran.mc() с параметром nsim =, задающим число перестановок: (sim = moran.mc(feb$nsick, listw = W, nsim = 10000)) ## ## Monte-Carlo simulation of Moran I ## ## data: feb$nsick ## weights: W ## number of simulations + 1: 10001 ## ## statistic = 0.52118, observed rank = 10001, p-value = 0.00009999 ## alternative hypothesis: greater # Построим гистограмму по вычисленным индексам: hist(sim$res, freq = TRUE, breaks = 20, xlim = c(-1,1), main = &quot;Перестановочный тест Морана&quot;, xlab = &quot;Случайный индекс Морана&quot;, ylab = &quot;Частота появления&quot;, col = &quot;steelblue&quot;) # Нанесем фактическое значение abline(v = sim$statistic, col = &quot;red&quot;) 15.7.3 Диаграмма рассеяния Морана Наконец, еще одним графическим инструментом оценки пространственной автокорреляции является диаграмма рассеяния Морана. По оси \\(X\\) откладывается значение в каждой территориальной единице, в по оси \\(Y\\) — ее пространственный лаг, который представляет собой средневзвешенное значение по всем ее соседям: moran.plot(feb$nsick, W) На диаграмме рассеяния Морана линиями отмечаются средние значения по обеим осям, а наклонной линией представляется линейная регрессия этих значений, при этом тангенс угла наклона кривой равен значению индекса Морана. Поскольку в данном случае распределение явно не случайно, можно приступать к его моделированию. 15.7.4 Пространственная авторегрессия Поиск уравнения пространственной регрессии и его авторегрессионной составляющей может быть выполнен посредством функций spautolm() и lagsarlm() из пакета spatialreg. В качестве первого параметра каждой из этих функций выступает формула, которая работает по следующему принципу: Y ~ 1 позволит найти коэффициенты \\(\\rho\\) и остатки \\(\\epsilon\\) пространственной авторегрессии вида \\(\\mathbf{y} = \\mu + \\rho\\mathbf{Wy} + \\mathbf{\\epsilon}\\), где \\(\\mu\\) — константа. Y ~ X позволит найти коэффициенты \\(\\beta\\), \\(\\rho\\) и остатки \\(\\epsilon\\) пространственной регрессии вида \\[\\mathbf{y} = \\mu + \\mathbf{X} \\mathbf{\\beta} + \\rho\\mathbf{Wy} + \\mathbf{\\epsilon}.\\] Y ~ X - 1 позволит найти коэффициенты \\(\\beta\\), \\(\\rho\\) и остатки \\(\\epsilon\\) пространственной регрессии вида \\[\\mathbf{y} = \\mathbf{X} \\mathbf{\\beta} + \\rho\\mathbf{Wy} + \\mathbf{\\epsilon}\\] без свободного члена \\(\\mu\\) model = lagsarlm(nsick ~ 1, data = feb, listw = W) model ## ## Call: ## lagsarlm(formula = nsick ~ 1, data = feb, listw = W) ## Type: lag ## ## Coefficients: ## rho (Intercept) ## 0.704957 1223.330336 ## ## Log likelihood: -346.2344 Расшифровываются параметры модели следующим образом: Intercept = \\(\\mu\\), rho = \\(\\rho\\) Извлекаем модельные значения \\(Z\\) и записываем в таблицу # Извлекаем результаты пространственной авторегрессии feb_spreg = feb %&gt;% mutate(fitted = fitted(model), residual = residuals(model)) %&gt;% pivot_longer(cols = c(nsick, fitted, residual), names_to = &#39;type&#39;, values_to = &#39;value&#39;) %&gt;% st_set_geometry(&#39;geometry&#39;) # Построение серии карт ramp = colorRampPalette(c(&#39;steelblue3&#39;, &#39;white&#39;, &#39;orange&#39;, &#39;violetred&#39;)) levels = seq(-3000, 10000, 1000) nclasses = length(levels) - 1 # Сравниваем исходные данные, модельные и остатки ggplot() + geom_sf(feb_spreg, mapping = aes(geometry = geometry, fill = cut(value, levels))) + scale_fill_manual(values = ramp(nclasses), labels = paste(levels[-nclasses-1], &#39;-&#39;, levels[-1]), guide = guide_legend(reverse = TRUE), drop = FALSE) + facet_wrap(~type) 15.8 Географически взвешенная регрессия (GWR) В стандартной модели линейной регрессии параметры модели предполагаются постоянными: \\[\\mathbf{y} = \\mathbf{X} \\boldsymbol\\beta + \\boldsymbol\\epsilon,\\] Для \\(i\\)-й локации решению выглядит следующим образом: \\[y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + ... + \\beta_m x_{mi} + \\epsilon_i\\] Коэффициенты находятся методом наименьших квадратов: \\[\\mathbf{\\beta}&#39; = (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{Y}\\] Такой подход, однако не учитывает того, что характер зависимости между переменными может меняться по пространству. В географически взвешенной регрессионной модели веса определяются для каждой локации: \\[y_i = \\beta_{0i} + \\beta_{1i} x_{1i} + \\beta_{2i} x_{2i} + ... + \\beta_{mi} x_{mi} + \\epsilon_i\\] В этом случае область оценки параметров \\(\\mathbf{\\beta}\\) ограничивается некой окрестностью точки \\(i\\). Математически это достигается применением весовых коэффициентов для данных независимых переменных: \\[\\mathbf{\\beta}&#39;(i) = (\\mathbf{X}^T \\color{blue}{\\mathbf{W}(i)}\\mathbf{X})^{-1} \\mathbf{X}^T \\color{blue}{\\mathbf{W}(i)} \\mathbf{Y},\\] где \\(\\mathbf{W}(i)\\) есть матрица весов для точки \\(i\\). Коэффициенты матрицы подбираются таким образом, что близкие локации получают более высокий вес. Матрица \\(\\mathbf{W}(i)\\) имеет размер \\(n \\times n\\), где \\(n\\) — число точек наблюдений: \\[\\mathbf{W}(i) = \\begin{bmatrix} w_{i1} &amp; 0 &amp; 0 &amp; \\dots &amp; 0 \\\\ 0 &amp; w_{i2} &amp; 0 &amp; \\dots &amp; 0 \\\\ 0 &amp; 0 &amp; w_{i3} &amp; \\dots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; 0 &amp; \\dots &amp; w_{in} \\end{bmatrix},\\] где \\(w_{ik}\\) есть вес, который имеет точка \\(k\\) при локальной оценке параметров в точке \\(i\\). 15.8.1 Весовые функции Весовая функция должна быть убывающей. Существует множество вариантов таких функций, но наиболее часто используются гауссоподобные варианты: Рис. 15.5: Весовая функция В случае фиксированной весовой функции окрестность всегда имеет фиксированный размер: \\[w_{ij} = \\operatorname{exp}\\{-\\frac{1}{2} (d_{ij}/h)^2\\},\\] где \\(d_{ij}\\) есть расстояние, \\(h\\) — полоса пропускания. Рис. 15.6: Фиксированная весовая функция В случае адаптивной весовой функции окрестность ограничивается \\(N\\) ближайшими точками. За пределами этой окрестности веса принимаются равными нулю: Рис. 15.7: Адаптивная весовая функция Полоса пропускания \\(h\\) обладает следующими особенностями: малая полоса пропускания приводит к большой дисперсии локальных оценок; большая полоса пропускания приводит к смещенности оценки; при \\(h \\rightarrow \\infty\\) локальная модель приближается к глобальной регрессии; при \\(h \\rightarrow 0\\) локальная модель «сворачивается» вокруг данных. 15.8.2 Практический анализ В качестве примера проанализируем каким образом цена жилья зависит от количества комнат на примере данных по стоимости недвижимости в Бостоне, доступных на данном сайте, и выгруженных с североамериканского информационного портала недвижимости padmapper.com: realest = read_delim(url(&#39;https://www.jefftk.com/apartment_prices/apts-1542637382.txt&#39;), delim = &#39; &#39;, col_names = c(&#39;price&#39;, &#39;rooms&#39;, &#39;id&#39;, &#39;lon&#39;, &#39;lat&#39;)) %&gt;% st_as_sf(coords = c(&#39;lon&#39;, &#39;lat&#39;), crs = 4326) %&gt;% st_transform(3395) # tmap_mode(&#39;view&#39;) tm_shape(realest) + tm_bubbles(col = &#39;price&#39;, size = &#39;rooms&#39;, style = &#39;fixed&#39;, breaks = c(0, 1000, 2000, 3000, 4000, 5000, 10000, max(realest$price)), scale = 0.25, palette = colorRampPalette(c(&#39;steelblue4&#39;, &#39;orange&#39;, &#39;darkred&#39;))(7), alpha = 0.8) + tm_view(symbol.size.fixed = TRUE) Для того чтобы оценить пространственую неравномерность реакции стоимости жилья на увеличение количества комнат, построим модель географически взвешенной регрессии: samples = realest %&gt;% dplyr::sample_n(1000) %&gt;% as(&#39;Spatial&#39;) (gwr_res = gwr.basic(price ~ rooms, data = samples, bw = 1000, kernel = &#39;gaussian&#39;)) ## *********************************************************************** ## * Package GWmodel * ## *********************************************************************** ## Program starts at: 2020-02-10 22:08:55 ## Call: ## gwr.basic(formula = price ~ rooms, data = samples, bw = 1000, ## kernel = &quot;gaussian&quot;) ## ## Dependent (y) variable: price ## Independent variables: rooms ## Number of data points: 1000 ## *********************************************************************** ## * Results of Global Regression * ## *********************************************************************** ## ## Call: ## lm(formula = formula, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3321 -851 -393 344 34635 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2442.28 102.59 23.81 &lt;0.0000000000000002 *** ## rooms 407.06 40.46 10.06 &lt;0.0000000000000002 *** ## ## ---Significance stars ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## Residual standard error: 1718 on 998 degrees of freedom ## Multiple R-squared: 0.09209 ## Adjusted R-squared: 0.09118 ## F-statistic: 101.2 on 1 and 998 DF, p-value: &lt; 0.00000000000000022 ## ***Extra Diagnostic information ## Residual sum of squares: 2944217900 ## Sigma(hat): 1717.591 ## AIC: 17739.23 ## AICc: 17739.25 ## *********************************************************************** ## * Results of Geographically Weighted Regression * ## *********************************************************************** ## ## *********************Model calibration information********************* ## Kernel function: gaussian ## Fixed bandwidth: 1000 ## Regression points: the same locations as observations are used. ## Distance metric: Euclidean distance metric is used. ## ## ****************Summary of GWR coefficient estimates:****************** ## Min. 1st Qu. Median 3rd Qu. Max. ## Intercept 138.75 1846.07 2051.88 2432.79 5592.7 ## rooms -1459.45 454.05 517.44 627.41 1554.1 ## ************************Diagnostic information************************* ## Number of data points: 1000 ## Effective number of parameters (2trace(S) - trace(S&#39;S)): 122.7829 ## Effective degrees of freedom (n-2trace(S) + trace(S&#39;S)): 877.2171 ## AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 17661.1 ## AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 17545.06 ## Residual sum of squares: 2220569746 ## R-square value: 0.31524 ## Adjusted R-square value: 0.2192857 ## ## *********************************************************************** ## Program stops at: 2020-02-10 22:08:55 tm_shape(gwr_res$SDF) + tm_bubbles(col = &#39;rooms&#39;, # это не количество комнат, а коэффициент регрессии style = &#39;quantile&#39;, scale = 0.3, palette = &#39;Reds&#39;, alpha = 0.5) + tm_view(symbol.size.fixed = TRUE) Как видно, модель GWR наглядно показывает наличие пространственной гетерогенности (неоднороности) в распределении показателя. Четко видны районы (в основном цеентральные, но также и часть окраинных), где стоимость жилья резко возрастает при увеличении количества комнат. 15.9 Краткий обзор Для просмотра презентации щелкните на ней один раз левой кнопкой мыши и листайте, используя кнопки на клавиатуре: Презентацию можно открыть в отдельном окне или вкладке браузере. Для этого щелкните по ней правой кнопкой мыши и выберите соответствующую команду. 15.10 Контрольные вопросы и упражнения 15.10.1 Вопросы Дайте определение пространственной автокорреляции. В чем выражается пространственная зависимость и пространственная гетерогенность? Сформулируйте задачу и напишите уравнение пространственной авторегрессии. Чем обусловлена необходимость в использовании такой модели? Что такое пространственный лаг? В чем заключается процедура пространственной фильтрации? Перечислете основные методы определения географического соседства. Чем отличается соседство по методу ферзя и соседство по методу ладьи? Какие методы установления соседства напрямую неприменимы к точечным данным? Что понимается под сферой влияния в соответствующем методе установления географического соседства? По аналогии с каким принципом небесной механики построен поиск соседей на основе этого принципа? Что объединяет все методы поиска соседей по графу? На основе какой структуры данных они работают? Сформулируйте принцип фильтрации ребер графа, с помощью которого получается граф Гэбриела. Что понимается под относительным соседством по графу? Назовите два основных метода определения соседства по метрике. Перечислите основные функции пакетов R, которые можно использовать для установления географического соседства. С помощью каких структур данных осуществляется моделирование соседства в R? Дайте определение пространственного веса. Что харктеризует эта величина? Назовите основные методы вычисления пространственных весов. Какая структура данных используется для хранения информации о пространственных весах? Какими свойствами она обладает? Перечислите индексы, которые могут использоваться для оценки пространственной автокорреляции. Напишите формулу для вычисления индекса Морана. Какие значения он может принимать и как их следует интерпретировать? Аналогом какого статистического коэффициента является данный индекс? Изложите алгоритм выполнения и назначение перестановочного теста Морана. Что из себя представляет диаграмма рассеяния Морана и в каких задачах они может быть востребована? Для каких целей используется локальный анализ пространственной автокорреляции (LISA)? Какой коэффициент можно использовать для квантификации локальных оценок автокорреляции? Как он связан с индексом Морана? Сформулируйте задачу и напишите уравнение географически взвешенной регрессии. Чем обусловлена необходимость в использовании такой модели? Определите назначение весовой функции в методе географически взвешенной регрессии. Каков ее основной параметр? 15.10.2 Упражнения Выполните анализ пространственной зависимости (автокорреляции) для данных Росстата по урожайности зерновых культур по муниципалитетам Ростовской, Волгоградской и Саратовской областей. Для этого загрузите границы муниципалитетов и статистику за 2012 и 2013 гг. В процессе выполнения анализа необходимо: Визуализировать исходные данные. Отфильтровать из данных Волгоград, Ростов-на-Дону и Саратов, поскольку для них статистика отсутствует. Построить граф соседства методом ферзя и визуализировать его. Вычислить матрицу пространственных весов и визуализировать ее. Выполнить тест Морана для данных 2013 г. (далее тоже везде 2013 год). Подобрать параметры модели пространственной авторегрессии. Визуализировать результаты моделирования (исходные данные, модельные данные, остатки) Самсонов Т.Е. Визуализация и анализ географических данных на языке R. М.: Географический факультет МГУ, 2020. DOI: 10.5281/zenodo.901911 Hubert, L. J., R. G. Golledge, and C. M. Costanza (1981). Generalized Procedures for Evaluating Spatial Autocorrelation. Geographical Analysis 13, 224–32. DOI: 10.1111/j.1538-4632.1981.tb00731.x↩︎ Gabriel K. R., Sokal R. R. (1969), A new statistical approach to geographic variation analysis, Systematic Zoology, Society of Systematic Biologists, 18 (3): 259–270, DOI: 10.2307/2412323↩︎ Toussaint G. T. (1980), The relative neighborhood graph of a finite planar set, Pattern Recognition, 12 (4): 261–268, DOI: 10.1016/0031-3203(80)90066-7↩︎ "],
["point-patterns.html", "Глава 16 Точечные процессы 16.1 Точечный паттерн 16.2 Точечные процессы 16.3 Диагностика 16.4 Моделирование 16.5 Краткий обзор 16.6 Контрольные вопросы и упражнения", " Глава 16 Точечные процессы Программный код главы 16.1 Точечный паттерн Точечный паттерн (point pattern) представляет собой множество точек в \\(\\mathbb{R}^2\\), обозначаемое малой жирной буквой: \\[\\mathbf{x} = \\{x_1, x_2,...x_n\\}\\] - Количество точек \\(n = n(\\mathbf{x})\\) может быть любым неотрицательным числом Множество является неупорядоченным (индексы чисто условны) Допускаются дубликаты (совпадающие точки), однако большинство методов рассчитаны на то, что дубликатов в множестве нет. Если \\(\\mathbf{x}\\) представляет точечный паттерн и \\(B\\) — это некий регион, то \\(\\mathbf{x} \\cap B\\) есть подмножество \\(\\mathbf{x}\\), состоящее из точек, попадающих в \\(B\\): Baddeley et. al., 2016 В данном случае количество точек, попадающих в \\(B\\), равняется \\(n = n(\\mathbf{x} \\cap B)\\) 16.2 Точечные процессы __ Точечным процессом__ называется случайный процесс, реализациями которого являются точечные паттерны Конечный точечный процесс (finite point process) — это точечный процесс, каждая реализация которого представляет собой точечный паттерн с конечным числом точек. При этом для любой области \\(B\\) количество точек \\(\\mathbf{x} \\cap B\\) представляет собой случайную величину с определимыми параметрами. Локально конечный точечный процесс имеет конечное число точек в любой ограниченной области \\(B\\) (более мягкое утверждение). Реализацией такого процесса является локально конечный точечный паттерн. 16.2.1 Равномерно случайные точки Простейшим точечныйм процессом является процесс \\(U = (U_1, U_2)\\), каждая реализация которого включает одну точку \\(u = (u_1, u_2)\\). Случайная точка будет равномерно распределена в пространственной облсти \\(W\\), если ее координаты \\((U_1, U_2)\\) имеют совместную плотность распределения, которая постоянна в пределах \\(W\\) и равна нулю за ее пределами. Поскольку интеграл плотности распределения равен 1, величина постоянной будет равна \\(1/|W|\\): \\[f(u_1, u_2) = \\begin{cases} 1/|W|,~\\text{если}~(u_1, u_2) \\in W\\\\ 0, ~\\text{в противном случае} \\end{cases}\\] Если \\(B\\) представляет собой тестовую область в \\(W\\), то вероятность того, что точка \\(U\\) попадет в \\(B\\), будет равна: \\[\\mathbb{P}\\{U \\in B \\} = \\int_B f(u_1, u_2) du_1 du_2 = \\\\ = \\frac{1}{|W|} \\int_B 1 du_1 du_2 = \\frac{|B|}{|W|}\\] - эта вероятность равна доле площади \\(B\\) в \\(W\\) вероятность зависит только от площади, и не зависит от положения и формы области \\(B\\) 16.2.2 Биномиальный точечный процесс Биномиальным называется точечный процесс \\(\\mathbf{X} = \\{X_1,..., X_n\\}\\), реализации которого содержат \\(n\\) точек. Baddeley et. al., 2016 Чтобы точки были распределены равномерно по пространству, необходимо выполнение двух условий: \\(X_1,...,X_n\\) представляют собой независимые случайные величины Каждая из этих величин равномерно распределена в пределах \\(W\\). Если \\(B\\) представляет собой тестовую область, то количество \\(n(\\mathbf{X} \\cap B)\\) случайных точек, попавших в \\(B\\), будет равняться количеству индексов \\(i\\) таких, что \\(X_i \\in B\\). Чтобы определить вероятностное распределение \\(n(\\mathbf{X} \\cap B)\\), рассмотрим эту величину как количество успешных исходов в \\(n\\) независимых испытаниях. Будем считать «успехом» исход, при котором случайная точка \\(X_i\\) попадает в \\(B\\). Если испытания независимы и равномерно распределены, то вероятность успеха равна \\(p = |B| / |W|\\) и величина \\(n(\\mathbf{X} \\cap B)\\) имеет биномиальный закон распределения: \\[\\mathbb{P}\\{n(\\mathbf{X} \\cap B) = k\\} = \\left( \\begin{array}{c} n \\\\ k \\end{array} \\right) p^k (1-p)^{n-k}\\color{grey}{, k = 0, 1, ..., n}\\] Биномиальный коэффициент равен числу сочетаний из \\(n\\) по \\(k\\) (без учета порядка): \\[\\left( \\begin{array}{c} n \\\\ k \\end{array} \\right) = \\frac{n!}{(n-k)!~k!}\\] 16.2.3 Пуассоновский процесс Однородный пуассоновский точечный процесс (homogeneous Poisson point process), или абсолютная пространственная случайность (complete spatial randomness — CSR) характеризуется следующими свойствами: гомогенность: размещение точек не имеет пространственных закономерностей независимость: результат реализации процесса в одной области не оказывает влияние на результат реализации в других областях Baddeley et. al., 2016 Однородность (гомогенность) означает, что ожидаемое количество точек, попадающих в регион \\(B\\) должно быть пропорционально его площади: \\[\\operatorname E[n(\\mathbf{X} \\cap B)] = \\lambda |B|\\] Параметр \\(\\lambda\\) представляет собой среднее количество точек на единицу площади — интенсивность точечного процесса. В отличие от биномиального процесса, полностью случайный (Пуассоновский) процесс характеризуется случайным количеством точек. Пространственная независимость означает, что количества точек в двух неперекрывающихся областях \\(A\\) и \\(B\\) являются независимыми случайными переменными: \\[n(\\mathbf{X} \\cap A) \\not\\sim n(\\mathbf{X} \\cap B),~A \\cap B = \\emptyset\\] &gt; Для биномиального процесса условие независимости не выполняется, поскольку известно общее количество точек. Если в область \\(A\\) попало \\(k\\) точек, то в область \\(B\\) не может попасть более чем \\(n-k\\) точек, что нарушает условие независимости распределений. Предположение о независимости выполняется для любых непересекающихся регионов \\(A\\) и \\(B\\) и для любого числа этих регионов Одним из следствий независимости является тот факт, что количество точек, подсчитанное по регулярной сетке квадратов, также даст совокупность независимых величин (для любого размера сетки): Baddeley et. al., 2016 Упорядоченность (orderliness): при стремлении площади области к нулю, вероятность нахождения в этой области более одной точки, деленная на площадь, также стремится к нулю Baddeley et. al., 2016 Если реализации отвечают условию независимости и вероятность нахождения более одной точки в бесконечно малом квадрате пренебрежимо мала, то случайную величину \\(n(\\mathbf{X} \\cap B)\\) можно рассматривать как количество «успехов» в большом числе независимых испытаний, каждое из которых имеет малую вероятность успеха. Это означает, что \\(n(\\mathbf{X} \\cap B)\\) подчиняется распределению Пуассона, которое характеризует частоту редких событий. В соответствии с этим законом, вероятность получить \\(k\\) редких событий равна \\[\\mathbb{P}\\{N = k\\} = e^{-\\mu} \\frac{\\mu^k}{k!}\\color{grey}{,~k = 0, 1, 2, ...}\\] Величина \\(\\mu\\) представляет собой математическое ожидание распределения Пуассона. Дисперсия распределения Пуассона равна его математическому ожиданию Поскольку, как мы показали ранее, ожидаемое количество точек в регионе \\(B\\) равняется \\(\\operatorname E[n(\\mathbf{X} \\cap B)] = \\lambda |B|\\), можно сделать вывод, что случайная величина \\(n(\\mathbf{X} \\cap B)\\) имеет распределение Пуассона с математическим ожиданием: \\[\\mu = \\lambda |B|\\] Пуассоновский процесс определяется следующими параметрами: однородность: количество \\(n(\\mathbf{B} \\cap B)\\) случайных точек, попадающих в выборочную область \\(B\\) характеризуется мат. ожиданием \\(\\mathbb{E}n(\\mathbf{X} \\cap B) = \\lambda |B|\\); независимость: для неперекрывающихся выборочных областей \\(B_1, B_2, ..., B_k\\), количества \\(n(\\mathbf{X} \\cap B_1), ..., n(\\mathbf{X} \\cap B_k)\\) предствляют собой независимые случайные величины; распределение Пуассона: число \\(n(\\mathbf{B} \\cap B)\\) случайных точек, попадающих в выборочную область \\(B\\) распределено по закону Пуассона. Свойства пуассоновского процесса: условность (conditional): в любой области \\(B\\) точки процесса независимо и равномерно распределены; прореживаемость (thinning): при случайном прореживании (отборе точек) пуассоновского точечного паттерна с интенсивностью \\(\\lambda\\) результирующий паттерн будет соответствовать Пуассоновскому процессу с интенсивностью \\(p\\lambda\\), где \\(p\\) — вероятность сохранения точки (процент отбора); Baddeley et. al., 2016 суперпозиция (superposition): сумма двух независимых гомогенных случайных точечных процессов \\(Z = X \\cup Y\\) с интенсивностями \\(\\lambda_X\\) и \\(\\lambda_Y\\) является гомогенным Пуассоновским процессом с интенсивностью \\(\\lambda_Z = \\lambda_X + \\lambda_Y\\) Baddeley et. al., 2016 16.2.3.1 Симуляция Пуассоновского процесса Пусть дана область \\(B = [x_{min}, x_{max}] \\times [y_{min}, y_{max}]\\) и интенсивность точечного процесса \\(\\lambda\\). Сгенерировать случайное число \\(N\\), имеющее распределение Пуассона с параметром \\(\\mu = \\lambda |B|\\). Сгенерировать \\(N\\) координат \\(X\\), имеющих равномерное распределение на промежутке \\([x_{min}, x_{max}]\\). Сгенерировать \\(N\\) координат \\(Y\\), имеющих равномерное распределение на промежутке \\([y_{min}, y_{max}]\\). Вероятность получить 0 точек также существует и равна \\(\\mathbb{P}\\{N = 0\\} = e^{-\\mu} \\frac{\\mu^0}{0!} = e^{-\\lambda |B|}\\) 16.2.4 Неоднородный пуассоновский процесс Определяется следующими параметрами: функция интенсивности: количество \\(n(\\mathbf{X} \\cap B)\\) случайных точек, попадающих в выборочную область \\(B\\) характеризуется мат. ожиданием \\(\\mathbb{E}n(\\mathbf{X} \\cap B) = \\int_B \\lambda(u) du = \\mu\\), где \\(\\lambda(u)\\) есть пространственная функция интенсивности; независимость: для неперекрывающихся выборочных областей \\(B_1, B_2, ..., B_k\\), количества \\(n(\\mathbf{X} \\cap B_1), ..., n(\\mathbf{X} \\cap B_k)\\) предствляют собой независимые случайные величины; распределение Пуассона: число \\(n(\\mathbf{B} \\cap B)\\) случайных точек, попадающих в выборочную область \\(B\\) распределено по закону Пуассона. Данные параметры отличаются следующими свойствами: функция плотности \\(\\lambda(u)\\) определяет общее количество точек и их пространственное распределение; никаких ограничений на функцию \\(\\lambda(u)\\) не накладывается, вследствие этого модель неоднородного Пуассоновского процесса является достаточно общей; свойства условности, прореживаемости и суперпозиции справедливы также и для неоднородного пуассоновского процесса; 16.2.4.1 Симуляция неоднородного пуассоновского процесса Метод Льюиса-Шедлера (Lewis-Shedler thinning): Генерируется однородный Пуассоновской процесс с интенсивностью \\(M = \\max_L\\big[\\lambda(u)\\big]\\). Осуществляется случайное прореживание (исключение) точек с вероятностью сохранения точки \\(p(u) = \\lambda(u) / M\\), пропорциональной функции интенсивности. Чтобы понять, будет ли точка исключена, генерируется случайное число 0 или 1, имющее распределени Бернулли с вероятностью положительного исхода \\(p = p(u)\\). Это можно сделать с помощью функции rbinom(1, 1, p) \\[\\lambda(x,y) = x + y^2\\] 16.2.5 Процесс Кокса (Cox process) Процесс Кокса определяется как Пуассоновский процесс со случайной функцией интенсивности \\(\\Lambda(u)\\), которая называется порождающей интенсивностью Baddeley et. al., 2016 Слева — реализация случайной функции \\(\\Lambda(u)\\). По центру — реализация Пуассоновского точечного процесса с интенсивностью \\(\\Lambda(u)\\). Cмешанный Пуассоновский процесс: однородный Пуассоновский процесс, порождаемый постоянной случайной величиной \\(\\Lambda\\). Интенсивность процесса равна \\(\\lambda = \\mathbb E\\Lambda\\). Логнормальный процесс Кокса: процесс Кокса с порождающей интенсивностью, равной \\(\\Lambda(u) = \\exp\\big[G(u)\\big]\\), где \\(G(u)\\) — Гауссовское случайное поле. Для гауссовского случайного поля в каждой точке \\(u_i\\) случайная величина \\(G(u_i)\\) имеет нормальное распределение, для пары точек \\(u\\) и \\(v\\) пара величин \\(\\big(G(u), G(v)\\big)\\) имеет двумерное нормальное распределение. Аналогично и для произвольного числа точек. Независимые реализации логнормального процесса Кокса: Baddeley et. al., 2016 16.2.6 Кластерные процессы Генерируется «родительский» точечный процесс \\(\\mathbf{Y}\\). Каждая точка родительского процесса \\(y_i\\) порождает случайный точечный паттерн «потомков» \\(x_{ij}\\) Baddeley et. al., 2016 — Наблюдаются только точки потомков (каждая родительская точка замещается ее потомками). — Множество точек \\(x_{ij}\\) формирует реализацию кластерного точечного процесса \\(\\mathbf{X}\\). Baddeley et. al., 2016 Возможные свойства кластерных процессов: (CLP1) пуассоновские родители: родительские точки являются реализацией Пуассоновского процесса. (CLP2) независимые кластеры: кластеры независимы друг от друга. (CLP3) идентично распределенные кластеры: если совместить разные кластеры, то они будут иметь одно распределение. (CLP4) независимые потомки: потомки внутри каждого кластера независимы и одинаково распределены. Процессы, отвечающие требованиям (CLP1)—(CLP4) носят название процессов Неймана-Скотта (Neyman-Scott). (CLP5) пуассоновское количество потомков: для каждой родительской точки количество потомков есть пуассоновская случайная величина. (CLP6) изотропные кластеры: плотность распределения потомков зависит только от расстояния до родительской точки. Распространенные частные случаи: Процесс Матерна \\((\\kappa, \\mu, r)\\): процесс \\(Y\\) имеет интенсивность \\(κ\\), каждый родитель имеет \\(Π(μ)\\) потомков, случайно распределенных в радиусе \\(r\\) Реализации процесса Матерна в квадрате \\([0, 1] \\times [0, 1]\\) с интенсивностью родителей \\(\\kappa = 8\\), средним количеством потомков \\(\\mu = 5\\) и радиусом кластера \\(R = 0.1\\): Baddeley et. al., 2016 Процесс Томаса \\((\\kappa, \\mu, \\sigma)\\): процесс \\(Y\\) имеет интенсивность κ, каждый родитель имеет \\(Π(μ)\\) потомков, смещенных на расстояние, подчиняющееся распределению \\(N(0,\\sigma^2)\\) 16.2.7 Регулярные процессы Точки не могут располагаться на расстоянии ближе чем \\(r\\) — расстояния ингибиции (отталкивания). Последовательные модели: точки генерируются последовательно согласно Пуассоновскому распредедению (координаты равномерно распределены). Каждая последующая точка сохраняется, только если она находится на расстоянии не ближе, чем \\(r\\). Зависимое прореживание: генерируется Пуассоновский процесс. После этого удаляются точки, расположенные на расстоянии меньшем \\(r\\). Пары близко расположенных точек аннигилируют (процесс Матерна I). Либо точки маркируются случайным «временем прибытия» и удаляется точка, имеющая более позднее время прибытия (процесс Матерна II). Последовательная модель: Baddeley et. al., 2016 Процесс Матерна I: Baddeley et. al., 2016 Процесс Матерна II: 16.3 Диагностика В предыдущем разделе мы рассмотрели основные типы точечных процессов на плоскости, а также методы их симуляции в виде случайных распределений. В настоящем параграфе показаны различные методы, с помощью которых можно установить, к какому типу процессов относятся наблюдаемые в реальности точки. 16.3.1 Анализ интенсивности 16.3.2 Анализ зависимости 16.4 Моделирование Настоящий раздел посвящен подбору параметров модели точечного процесса для фактических данных о размещении объектов. 16.5 Краткий обзор Для просмотра презентации щелкните на ней один раз левой кнопкой мыши и листайте, используя кнопки на клавиатуре: Презентацию можно открыть в отдельном окне или вкладке браузере. Для этого щелкните по ней правой кнопкой мыши и выберите соответствующую команду. 16.6 Контрольные вопросы и упражнения 16.6.1 Вопросы Дайте определение точечного паттерна и точечного процесса. Перечислите три основных типа точечных процессов. Какими особенностями обладают конечный и локально конечный точечный процесс? Каким уравнением опрпеделяется плотность распределения для равномерно случайного точечного процесса в области \\(W\\)? Чему будет равна вероятность попадания точки в подобласть \\(B\\) этой области? Сформулируйте определение биномиального точечного процесса. Какие условия должны выполняться для процесса данного типа? Какими свойствами характеризуется однородный пуассоновский точечный процесс? Как эти свойства можно выразить математически? Перечислите основные параметры пуассоновского точечного процесса. Изложите алгоритм симуляции однородного пуассоновского точечного процесса. Назовите программные средства R, которые можно использовать для этого. Чем неоднородный пуассоновский процесс отличается от однородного? Сформулируйте отличия словесно и математически. Изложите алгоритм симуляции неоднородного пуассоновского точечного процесса по методу Льюиса-Шедлера. Назовите программные средства R, которые можно использовать для этого. Дайте определение процессу Кокса. Приведите два примера частных случаев процесса Кокса. Перечислите концептуальные принципы, лежащие в основе теории кластерных точечных процессов. Назовите шесть основных свойств, с помощью которых определяется характер кластерного точечного процесса. Какими свойствами обладают процессы Неймана-Скотта? Дайте определение кластерных процессов Матерна и Томаса. Какие программные средства имеются в среде R для анализа и симуляции кластерных точечных процессов? Сформулируйте определение регулярного точечного процесса. Каков его основной параметр? Приведите примеры регулярных процессов в географической среде. Назовите два типа моделей, используемых для представления регулярных точечных процессов. Изложите кратко используемые в них алгоритмы симуляции. Перечислите основные статистические функции, используемые для анализа точечных паттернов. Что из себя представляет индекс Моришита? Приведите формулу для его вычисления и раскройте суть каждой компоненты этой формулы. В чем заключается преимущество K-функции Рипли в сравенении с другими методами оценки характера точечных паттернов? 16.6.2 Упражнения Самсонов Т.Е. Визуализация и анализ географических данных на языке R. М.: Географический факультет МГУ, 2020. DOI: 10.5281/zenodo.901911 "],
["package-troubles.html", "A Установка пакетов A.1 Недоступен стандартный каталог A.2 Устанавливается, но не копируется", " A Установка пакетов A.1 Недоступен стандартный каталог Иногда по тем или иным причинам невозможно установить пакет в стандартный каталог. Наиболее часто эта проблема дает о себе знать в случае когда: у вас Windows и ваш пользователь назван кириллическими буквами (Маша, Петя и т.д.) у вашего пользователя нет прав административного доступа к каталогу, в который устанавливаются пакеты Чтобы проверить, где находится ваши текущие каталоги для установки пакетов, можно набрать в консоли команду .libPaths(). На Windows для этих целей резервируется сразу 2 каталога — пользовательский и системный: &gt; .libPaths() [1] &quot;C:/Users/Timofey Samsonov/Documents/R/win-library/3.5&quot; &quot;C:/Program Files/R/R-3.5.1/library&quot; На UNIX-подобных системах (macOS, Linux) используется только системный каталог: &gt; .libPaths() [1] &quot;/Library/Frameworks/R.framework/Versions/3.5/Resources/library&quot; По умолчанию на Windows пакеты устанавливаются в пользовательскую директорию (\"C:/Users/Timofey Samsonov/Documents/R/win-library/3.5\"). Если Rstudio не сможет установить пакет в эту директорию, он будет пытаться установить его в системную директорию (\"C:/Program Files/R/R-3.5.1/library\"). Если же и туда поставить не удается, будет выведено сообщение об ошибке. В этом случае вам необходимо создать новый каталог для размещения пакетов, который не будет вызывать проблем с кодировкой и доступом. Требования к каталогу следующие: наличие полных (административных) прав доступа у текущего пользователя отсутствие кириллических символов в пути Подходящие примеры каталогов: C:/Rlib, D:/Rlibraries. Создав каталог, вы можете решить проблему с пакетами временно или постоянно. Временное решение: при установке пакета укажите адрес каталога в параметре lib функции install.packages(). Например: install.packages(\"xlsx\", lib = \"C:/Rlib\") для загрузки пакета укажите местоположение пакета в дополнительном параметре lib.loc: library(xlsx, lib.loc = \"C:/Rlib\") Постоянное решение: добавьте путь к новому каталогу через функцию .libPaths(): .libPaths(c(\"С:/Rlib\", .libPaths())) используйте для установки и загрузки команды install.packages и library как обычно. Новые пакеты будут устанавливаться и загружаться из нового каталога, а системные пакеты будут по прежнему доступны из каталогов по умолчанию Внимание: при добвлении пути в .libPaths() не пишите закрывающий слэш после имени каталога: \"С:/Rlib\" сработает, а \"С:/Rlib/\" нет! Если добавление через .libPaths() по каким-то причинам не сработало, вы можете решить ту же задачу, используя системные переменные: Откройте список системных переменных (команда My Computer -&gt; System Properties -&gt; Advanced system properties -&gt; Environment Variables -&gt; User Variables). Создайте новую системную переменную (команда New User Variable), дайте ей имя R_LIBS и значение, равное пути к вашему каталогу (C:/Rlib). Сохраните результат. Выглядеть это должно примерно так: Системная переменная для библиотек A.2 Устанавливается, но не копируется Проблема касается следующего сообщения: Warning in install.packages: unable to move temporary installation в результате которого пакет не появляется в вашей библиотеке, хотя проблем с доступом к ней у вас нет. Как правило, это свидетельствует о том, что копирование файлов пакета в библиотеку блокируется антивирусом. Пакеты загружаются из CRAN во временную директорию, там разархивируются и только после этого копируются в библиотеку. Это может восприниматься антивирусом как вредоносная манипуляция. Попробуйте выключите антивирус на время установки пакет. Если по каким-то причинам это не помогло, попробуйте метод, описанный здесь "]
]
